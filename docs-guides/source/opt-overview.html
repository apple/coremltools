
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Overview &#8212; Guide to Core ML Tools</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/imgstyle.css?v=27a1495e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=c1ce5b23"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/opt-overview';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="What’s New" href="opt-whats-new.html" />
    <link rel="prev" title="Model Intermediate Language" href="model-intermediate-language.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Guide to Core ML Tools</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">coremltools API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="new-features.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-to-contribute.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-learning-models.html">Converting Deep Learning Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="target-conversion-formats.html">Source and Conversion Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="load-and-convert-model.html">Load and Convert Model Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-ml-program.html">Convert Models to ML Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-neural-network.html">Convert Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="comparing-ml-programs-and-neural-networks.html">Comparing ML Programs and Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution.html">Typed Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution-example.html">Typed Execution Workflow Example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-image-classifier.html">Converting a TensorFlow 1 Image Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-pytorch.html">Converting from PyTorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="convert-pytorch-workflow.html">PyTorch Conversion Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-tracing.html">Model Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-exporting.html">Model Exporting</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-torchvision-model-from-pytorch.html">Converting a torchvision Model from PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-pytorch-segmentation-model.html">Converting a PyTorch Segmentation Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-openelm.html">Converting an Open Efficient Language Model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="conversion-options.html">Conversion Options</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="new-conversion-options.html">New Conversion Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-input-and-output-types.html">Model Input and Output Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-inputs.html">Image Input and Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-models.html">Stateful Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="flexible-inputs.html">Flexible Input Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="composite-operators.html">Composite Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-operators.html">Custom Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph-passes-intro.html">Graph Passes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-whats-new.html">What’s New</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-overview-examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-resnet.html">Optimizing ResNet50 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-opt1_3.html">Optimizing OPT Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-stable-diffusion.html">Optimizing StableDiffusion Model</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="opt-workflow.html">Optimization Workflow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-palettization.html">Palettization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-overview.html">Palettization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-algos.html">Palettization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-api.html">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-quantization.html">Linear Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-overview.html">Quantization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-algos.html">Quantization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-api.html">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-pruning.html">Pruning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-algos.html">Pruning Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-api.html">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="opt-joint-compression.html">Combining Compression Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-conversion.html">Conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost-conversion.html">XGBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multifunction-models.html">Multifunction Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-prediction.html">Model Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="updatable-model-examples.html">Updatable Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="updatable-neural-network-classifier-on-mnist-dataset.html">Neural Network Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-tiny-drawing-classifier-pipeline-model.html">Pipeline Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-nearest-neighbor-classifier.html">Nearest Neighbor Classifier</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apple/coremltools" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/source/opt-overview.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Overview</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-compress">How to Compress</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-compression">Types of Compression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-runtime-performance-on-apple-silicon">Effect on Runtime performance on Apple Silicon</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#availability-of-features">Availability of features</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h1>
<p>This section covers optimization techniques that help you get a smaller model by compressing
its weights and activations.
In particular, it will go over APIs for taking a model from
<code class="docutils literal notranslate"><span class="pre">float</span></code> precision (16 or 32 bits per value) to &lt;= 8 bits,
while maintaining good accuracy.</p>
<p>Model compression can help reduce the
memory footprint of your model, reduce inference latency, reduce<br />
power consumption, or reduce them all at once. For instance, you may be working with a large model (e.g. &gt;1B parameters) and need
to reduce its memory footprint to make it reasonably run on an iPhone,
or you may want to enable a real-time experience for your user that
requires you to shave off a few milliseconds of the inference time,
or you may be shipping several models in your single app whose disk size you
want to keep in check. In this section, you will learn about several
techniques to help achieve these goals.
You will learn how you can try them quickly on your model
to see the effect on latency and size, and then
choose the right approach to trade off accuracy and the time/data needed to optimize, based on your model.</p>
<p>You will learn about compression schemes that are possible with the
Core ML runtime and Apple Silicon, which kind of hardware is best suited for
different kinds of schemes, and how various algorithms implemented in <code class="docutils literal notranslate"><span class="pre">coremltools</span></code>
can help you achieve memory and latency savings on your model.</p>
<p>Visit <a class="reference internal" href="opt-whats-new.html"><span class="doc std std-doc">What’s New</span></a> to see what is available on different
OS versions. Go over the <a class="reference internal" href="opt-overview-examples.html"><span class="doc std std-doc">example overview section</span></a>
to get a quick idea of typical workflows and to get a tour of compression APIs applied
on a standard convnet and a generative model.</p>
<section id="how-to-compress">
<h2>How to Compress<a class="headerlink" href="#how-to-compress" title="Link to this heading">#</a></h2>
<p>Given a pre-trained model, compression can be performed
with different ingredients in varying quantities:</p>
<ul class="simple">
<li><p><strong>Just the model</strong>:
This is referred to as data-free compression.
It is very quick to apply and can work really well for
reducing the model size by half (8 bits) or, depending on the model,
even up to 6 or 4 bits of representation, with only a slight decrease in accuracy.</p></li>
<li><p><strong>Model and a small amount of training data</strong>: This is referred to as post-training
compression with data calibration. It can lead to better accuracy for higher compression ratios.</p></li>
<li><p><strong>Model, training pipeline, and data</strong>: Having access to the full training pipeline and data
lets you fine-tune the model while compressing it. This allows for the best accuracy and compression ratio trade offs.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">coremltools.optimize</span></code> offers APIs for performing all these workflows.
You can execute some workflows directly on a Core ML model (<code class="docutils literal notranslate"><span class="pre">mlpackage</span></code>). For other workflows
requiring gradient computation, you can perform optimizations
on your PyTorch model prior to conversion.
To find out more, see
<a class="reference internal" href="opt-workflow.html"><span class="doc std std-doc">Optimization Workflow</span></a>.</p>
</section>
<section id="types-of-compression">
<h2>Types of Compression<a class="headerlink" href="#types-of-compression" title="Link to this heading">#</a></h2>
<p>There are three primary ways to reduce the precision of weights and activations
of a model:</p>
<ul class="simple">
<li><p><strong>Palettization</strong>: Refers to discretizing weights using lookup tables.
Core ML supports representing weights with palettization to get them
down to <code class="docutils literal notranslate"><span class="pre">nbits</span></code> precision, where <code class="docutils literal notranslate"><span class="pre">nbits</span></code> can be <code class="docutils literal notranslate"><span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">6,</span> <span class="pre">8}</span></code>.
Read more in the <a class="reference internal" href="opt-palettization.html"><span class="doc std std-doc">palettization section</span></a>.</p></li>
<li><p><strong>Linear quantization</strong>: Refers to approximating weights with a quantization function.
Core ML supports INT4 and INT8 quantization options for weights and INT8 for activations.
Read more in the <a class="reference internal" href="opt-quantization.html"><span class="doc std std-doc">quantization section</span></a>.</p></li>
<li><p><strong>Pruning</strong>: refers to zeroing out values that are close to zero. Core ML supports sparse representations for weights.
Read more in the <a class="reference internal" href="opt-pruning.html"><span class="doc std std-doc">pruning section</span></a>.</p></li>
</ul>
<p>These techniques can be combined as well. For example, a joint sparse and palettized model or a joint sparse and quantized weights model can result in further compression and runtime performance gains. See <a class="reference internal" href="opt-joint-compression.html"><span class="doc std std-doc">Combining Compression Types</span></a>
to learn how to do that.</p>
</section>
<section id="effect-on-runtime-performance-on-apple-silicon">
<h2>Effect on Runtime performance on Apple Silicon<a class="headerlink" href="#effect-on-runtime-performance-on-apple-silicon" title="Link to this heading">#</a></h2>
<p>Typically gains from model compression could be observed in the form of
runtime memory, latency, power consumption, or some combination of them.
However, these gains depend not only on the specific model
(for example, whether it’s compute-bound or memory-bound) and compression type,
but also on the hardware and compute unit that the model is running on.
This is because implementations for compressed kernels in the NE/GPU/CPU compilers vary.</p>
<p>For instance, some compiler backends may choose to decompress the weights fully
before runtime, leading to a latency identical to that of the <code class="docutils literal notranslate"><span class="pre">float16</span></code> model.
In other cases, decompression may happen “on the fly”,
utilizing hardware capabilities and fused kernels, needing
less data movement of weights between DRAM and processor cache,
leading to lower inference times.</p>
<p>Because the decompression strategy varies per hardware and compute unit, is highly recommended to test
on your specific model and Apple Silicon combination.
As of <code class="docutils literal notranslate"><span class="pre">iOS18</span></code>/<code class="docutils literal notranslate"><span class="pre">macOS15</span></code>, here are a few high level recommendations
that you may use to guide your experiments. For more detailed observations based on
specific modes of optimization used, refer to the performance page in the
quantization, palettization, and pruning sections.</p>
<ul class="simple">
<li><p>Weight palettization (all bits from 1 to 8) typically works the best on the Neural Engine for
runtime memory and latency gains. On the GPU you may see runtime memory benefits.</p></li>
<li><p>8-bit activation plus weight quantization, also referred to as the W8A8 mode,
can lead to considerable latency benefits on the Neural Engine by leveraging the faster int8-int8
compute path supported in newer hardware (A17 pro, M4).</p></li>
<li><p>INT4 <code class="docutils literal notranslate"><span class="pre">per-block</span></code> quantization of weights can work really well for models using the GPU on a Mac.</p></li>
<li><p>Pruning the models can lead to latency gains on the Neural Engine and the CPU
compute units.</p></li>
</ul>
<p>In most cases, you do not lose much accuracy with 6 or 8 bits of palettization
or 8 bits of weight-only quantization, which can be applied to your model in
a matter of minutes. That is one minimum amount
of compression that you should consider for
all your models that are currently shipping in <code class="docutils literal notranslate"><span class="pre">float16</span></code> precision.</p>
</section>
<section id="availability-of-features">
<h2>Availability of features<a class="headerlink" href="#availability-of-features" title="Link to this heading">#</a></h2>
<p>To find which optimization options are available in which OS versions see <a class="reference internal" href="opt-whats-new.html"><span class="std std-doc">What’s New</span></a>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You may also find it useful to view the presentation in
<a class="reference external" href="https://developer.apple.com/videos/play/wwdc2023/10047/">WWDC 2023</a>
for an introduction to the optimizations, and the presentation
in <a class="reference external" href="https://developer.apple.com/videos/play/wwdc2024/10159/">WWDC 2024</a> for an overview
of new features available from <code class="docutils literal notranslate"><span class="pre">iOS18</span></code>/<code class="docutils literal notranslate"><span class="pre">macOS15</span></code> and optimizations for
large transformer models.</p>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="model-intermediate-language.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Model Intermediate Language</p>
      </div>
    </a>
    <a class="right-next"
       href="opt-whats-new.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">What’s New</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-compress">How to Compress</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-compression">Types of Compression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-runtime-performance-on-apple-silicon">Effect on Runtime performance on Apple Silicon</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#availability-of-features">Availability of features</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apple
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, Apple Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>