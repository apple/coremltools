<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.optimize.torch.palettization.palettization_config &mdash; coremltools API Reference 8.0b1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/norightmargin.css?v=eea1f72d" />

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../../../_static/documentation_options.js?v=d50bc636"></script>
        <script src="../../../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            coremltools API Reference
          </a>
              <div class="version">
                8.0b1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.models.html">Model APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.converters.mil.mil.passes.defs.html">MIL Graph Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/coremltools.optimize.html">Optimizers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/docs-guides/index.html">Guide and Examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../source/api-versions.html">Previous Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">coremltools.optimize.torch.palettization.palettization_config</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.optimize.torch.palettization.palettization_config</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Copyright (c) 2024, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1">#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span> <span class="k">as</span> <span class="n">_OrderedDict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span> <span class="k">as</span> <span class="n">_Any</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span> <span class="k">as</span> <span class="n">_Callable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span> <span class="k">as</span> <span class="n">_Dict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span> <span class="k">as</span> <span class="n">_List</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NewType</span> <span class="k">as</span> <span class="n">_NewType</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span> <span class="k">as</span> <span class="n">_Optional</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span> <span class="k">as</span> <span class="n">_Union</span>

<span class="kn">import</span> <span class="nn">cattrs</span> <span class="k">as</span> <span class="nn">_cattrs</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">_torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">_nn</span>
<span class="kn">from</span> <span class="nn">attr</span> <span class="kn">import</span> <span class="n">define</span> <span class="k">as</span> <span class="n">_define</span>
<span class="kn">from</span> <span class="nn">attr</span> <span class="kn">import</span> <span class="n">field</span> <span class="k">as</span> <span class="n">_field</span>
<span class="kn">from</span> <span class="nn">attrs</span> <span class="kn">import</span> <span class="n">validators</span> <span class="k">as</span> <span class="n">_validators</span>

<span class="kn">from</span> <span class="nn">coremltools.optimize.torch._utils.torch_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">maybe_convert_str_to_dtype</span> <span class="k">as</span> <span class="n">_maybe_convert_str_to_dtype</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.optimize.torch.optimization_config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModuleOptimizationConfig</span> <span class="k">as</span> <span class="n">_ModuleOptimizationConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.optimize.torch.optimization_config</span> <span class="kn">import</span> <span class="n">OptimizationConfig</span> <span class="k">as</span> <span class="n">_OptimizationConfig</span>
<span class="kn">from</span> <span class="nn">coremltools.optimize.torch.optimization_config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">PalettizationGranularity</span><span class="p">,</span>
    <span class="n">_deprecated_field</span><span class="p">,</span>
    <span class="n">_validate_module_type_keys_factory</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Default advanced options for palettization</span>
<span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;cluster_permute&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">&quot;palett_max_mem&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_max_iter&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s2">&quot;prune_threshold&quot;</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_init&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_opt1d_threshold&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="s2">&quot;enforce_zero&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;palett_mode&quot;</span><span class="p">:</span> <span class="s2">&quot;dkm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;palett_tau&quot;</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span>
    <span class="s2">&quot;palett_epsilon&quot;</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span>
    <span class="s2">&quot;palett_lambda&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;add_extra_centroid&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;palett_cluster_tol&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;palett_min_tsize&quot;</span><span class="p">:</span> <span class="mi">64</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="s2">&quot;palett_unique&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;palett_shard&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;palett_batch_mode&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;palett_dist&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;per_channel_scaling_factor_scheme&quot;</span><span class="p">:</span> <span class="s2">&quot;min_max&quot;</span><span class="p">,</span>
    <span class="s2">&quot;percentage_palett_enable&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_batch_threshold&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_n_init&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;zero_threshold&quot;</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="s2">&quot;kmeans_error_bnd&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s2">&quot;channel_axis&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">DEFAULT_PALETTIZATION_OPTIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;quant_min&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">128</span><span class="p">,</span>
    <span class="s2">&quot;quant_max&quot;</span><span class="p">:</span> <span class="mi">127</span><span class="p">,</span>
    <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">_torch</span><span class="o">.</span><span class="n">qint8</span><span class="p">,</span>
    <span class="s2">&quot;lut_dtype&quot;</span><span class="p">:</span> <span class="s2">&quot;f32&quot;</span><span class="p">,</span>
    <span class="s2">&quot;weight_threshold&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;milestone&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;quantize_activations&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;enable_per_channel_scale&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;granularity&quot;</span><span class="p">:</span> <span class="s2">&quot;per_tensor&quot;</span><span class="p">,</span>
    <span class="s2">&quot;group_size&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">_default_palettization_scheme</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">**</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">,</span>
    <span class="o">**</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">,</span>
<span class="p">}</span>


<span class="c1"># Default scheme for palettization</span>
<span class="n">DEFAULT_PALETTIZATION_SCHEME</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
    <span class="n">_nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_bits&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cluster_dim&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">_default_palettization_scheme</span><span class="p">},</span>
<span class="p">}</span>


<span class="c1"># Pytorch modules from torch.ao.quantization.quantization_mappings.DEFAULT_QAT_MODULE_MAPPINGS that are supported</span>
<span class="c1"># for palettization</span>
<span class="n">SUPPORTED_PYTORCH_QAT_MODULES</span> <span class="o">=</span> <span class="p">(</span><span class="n">_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">_nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">)</span>


<div class="viewcode-block" id="ModuleDKMPalettizerConfig">
<a class="viewcode-back" href="../../../../../source/coremltools.optimize.torch.palettization.html#coremltools.optimize.torch.palettization.ModuleDKMPalettizerConfig">[docs]</a>
<span class="nd">@_define</span>
<span class="k">class</span> <span class="nc">ModuleDKMPalettizerConfig</span><span class="p">(</span><span class="n">_ModuleOptimizationConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for specifying global and module-level options for palettization</span>
<span class="sd">    algorithm implemented in :py:class:`DKMPalettizer`.</span>

<span class="sd">    The parameters specified in this config control the DKM algorithm, described in</span>
<span class="sd">    `DKM: Differentiable K-Means Clustering Layer for Neural Network Compression</span>
<span class="sd">    &lt;https://arxiv.org/abs/2108.12659&gt;`_.</span>

<span class="sd">    For most use cases, the only parameters you need to specify are ``n_bits``,  ``weight_threshold``,</span>
<span class="sd">    and ``milestone``.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Most of the parameters in this class are meant for advanced use cases and for further fine-tuning the</span>
<span class="sd">        DKM algorithm. The default values usually work for a majority of tasks.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Change the following parameters only when you use activation quantization in conjunction with</span>
<span class="sd">        DKM weight palettization: ``quant_min``, ``quant_max``, ``dtype``, and ``quantize_activations``.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_bits (:obj:`int`): Number of clusters. The number of clusters used is :math:`2^{n\_bits}`.</span>
<span class="sd">            Defaults to ``4`` for linear layers and ``2`` for all other layers.</span>
<span class="sd">        weight_threshold (:obj:`int`): A module is only palettized if the number of elements in</span>
<span class="sd">            its weight matrix exceeds ``weight_threshold``. If there are multiple weights in a</span>
<span class="sd">            module (like :py:class:`torch.nn.MultiheadAttention`), all of them must have</span>
<span class="sd">            more elements than the ``weight_threshold`` for the module to be palettized.</span>
<span class="sd">            Defaults to ``2048``.</span>
<span class="sd">        granularity (:py:class:`PalettizationGranularity`) – Granularity for palettization.</span>
<span class="sd">            One of ``per_tensor`` or ``per_grouped_channel``. Defaults to ``per_tensor``.</span>
<span class="sd">        group_size (:obj:`int`): Specify the number of channels in a group.</span>
<span class="sd">            Only effective when granularity is ``per_grouped_channel``.</span>
<span class="sd">        channel_axis (:obj:`int`): Specify the channel axis to form a group of channels.</span>
<span class="sd">            Only effective when granularity is ``per_grouped_channel``. Defaults to output channel axis. For now, only</span>
<span class="sd">            output channel axis is supported by DKM.</span>
<span class="sd">        enable_per_channel_scale (:obj:`bool`): When set to ``True``, per channel scaling is used along the channel</span>
<span class="sd">            dimension.</span>
<span class="sd">        milestone (:obj:`int`): Step or epoch at which palettization begins. Defaults to ``0``.</span>
<span class="sd">        cluster_dim (:obj:`int`, ``optional``): The dimension of each cluster.</span>
<span class="sd">        quant_min: (:obj:`int`, ``optional``): The minimum value for each element in the weight clusters if they are</span>
<span class="sd">            quantized. Defaults to ``-128``.</span>
<span class="sd">        quant_max: (:obj:`int`, ``optional``): The maximum value for each element in the weight clusters if they are</span>
<span class="sd">            quantized. Defaults to ``127``</span>
<span class="sd">        dtype (:py:class:`torch.dtype`, ``optional``): The ``dtype`` to use for quantizing the activations. Only applies</span>
<span class="sd">            when ``quantize_activations`` is ``True``. Defaults to :py:class:`torch.qint8`.</span>
<span class="sd">        lut_dtype (:obj:`str`, ``optional``): ``dtype`` to use for quantizing the clusters. Allowed options are</span>
<span class="sd">            ``&#39;i8&#39;``, ``&#39;u8&#39;``, ``&#39;f16&#39;``, ``&#39;bf16&#39;``, ``&#39;f32&#39;``.  Defaults to ``&#39;f32&#39;``, i.e.,</span>
<span class="sd">            by default, the clusters aren&#39;t quantized.</span>
<span class="sd">        quantize_activations (:obj:`bool`, ``optional``): When ``True``, the activation are quantized.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        cluster_permute (:obj:`tuple`, ``optional``): Permutation order to apply to weight partitions.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        palett_max_mem (:obj:`float`, ``optional``): Proportion of available GPU memory that should be used for</span>
<span class="sd">            palettization. Defaults to ``1.0``.</span>
<span class="sd">        kmeans_max_iter (:obj:`int`, ``optional``): Maximum number of differentiable ``k-means`` iterations.</span>
<span class="sd">            Defaults to ``3``.</span>
<span class="sd">        prune_threshold (:obj:`float`, ``optional``): Hard-shrinks weights between [``-prune_threshold``,</span>
<span class="sd">            ``prune_threshold``] to zero. Useful for joint pruning and palettization. Defaults to ``1e-7``.</span>
<span class="sd">        kmeans_init (:obj:`str`, ``optional``): ``k-means`` algorithm to use. Allowed options are</span>
<span class="sd">            ``opt1d``, ``cpu.kmeans++`` and ``kmeans++``. Defaults to ``auto``.</span>
<span class="sd">        kmeans_opt1d_threshold (:obj:`int`, ``optional``): Channel threshold to decide if ``opt1d kmeans``</span>
<span class="sd">            should be used. Defaults to ``1024``.</span>
<span class="sd">        enforce_zero (:obj:`bool`, ``optional``): If ``True``, enforces the LUT centroid which is closest to</span>
<span class="sd">            the origin to be fixed to zero. Defaults to ``False``.</span>
<span class="sd">        palett_mode (:obj:`str`, ``optional``): Criteria to calculate attention during ``k-means``. Allowed options are</span>
<span class="sd">            ``gsm``, ``dkm`` and ``hard``. Defaults to ``dkm``.</span>
<span class="sd">        palett_tau (:obj:`float`, ``optional``): Temperature factor for softmax used in DKM algorithm.</span>
<span class="sd">            Defaults to ``0.0001``.</span>
<span class="sd">        palett_epsilon (:obj:`float`, ``optional``): Distance threshold for clusters between ``k-means`` iterations.</span>
<span class="sd">            Defaults to ``0.0001``.</span>
<span class="sd">        palett_lambda (:obj:`float`, ``optional``): Reduces effects of outliers during centroid calculation.</span>
<span class="sd">            Defaults to ``0.0``.</span>
<span class="sd">        add_extra_centroid (:obj:`bool`, ``optional``): If ``True``, adds an extra centroid to the LUT.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        palett_cluster_tol (:obj:`float`, ``optional``): Tolerance for non-unique centroids in the LUT.</span>
<span class="sd">            The higher the number, the more tolerance for non-unique centroids. Defaults to ``0.0``.</span>
<span class="sd">        palett_min_tsize (:obj:`int`, ``optional``): Weight threshold beyond which to use custom packing and unpacking</span>
<span class="sd">            hook for autograd. Defaults to ``64*1024``.</span>
<span class="sd">        palett_unique (:obj:`bool`, ``optional``): If ``True``, reduces the attention map by leveraging the fact that</span>
<span class="sd">            FP16 only has ``2^16`` unique values. Useful for Large Models like LLMs where attention maps can be huge.</span>
<span class="sd">            Defaults to ``False``. More details can be found `eDKM: An Efficient and Accurate Train-time Weight</span>
<span class="sd">            Clustering for Large Language Models &lt;https://arxiv.org/pdf/2309.00964.pdf&gt;`_ .</span>
<span class="sd">        palett_shard (:obj:`bool`, ``optional``): If ``True``, the index list is sharded across GPUs.</span>
<span class="sd">            Defaults to ``False``. More details can be found `eDKM: An Efficient and Accurate Train-time Weight</span>
<span class="sd">            Clustering for Large Language Models &lt;https://arxiv.org/pdf/2309.00964.pdf&gt;`_ .</span>
<span class="sd">        palett_batch_mode (:obj:`bool`, ``optional``): If ``True``, performs batch DKM across different partitions</span>
<span class="sd">            created for different blocks. Defaults to ``False``. More details can be found `eDKM: An Efficient and Accurate Train-time Weight</span>
<span class="sd">            Clustering for Large Language Models &lt;https://arxiv.org/pdf/2309.00964.pdf&gt;`_ .</span>
<span class="sd">        palett_dist (:obj:`bool`, ``optional``): If ``True``, performs distributed distance calculation in batch_mode if</span>
<span class="sd">            distributed torch is available. Defaults to ``False``.</span>
<span class="sd">        per_channel_scaling_factor_scheme (:obj:`str`, ``optional``): Criteria to calculate the</span>
<span class="sd">            ``per_channel_scaling_factor``. Allowed options are ``min_max`` and ``abs``. Defaults to ``min_max``.</span>
<span class="sd">        percentage_palett_enable (:obj:`float`, ``optional``): Percentage partitions to enable for DKM.</span>
<span class="sd">                    Defaults to ``1.0``.</span>
<span class="sd">        kmeans_batch_threshold (:obj:`int`, ``optional``): Threshold to decide at what num_partitions to go through with</span>
<span class="sd">            sharded centroids list. num_partitions is calculated by dividing the channel size with the group_size</span>
<span class="sd">            provided. If the kmeans_batch_threshold, the algorithm resorts to performing distirbuted kmeans for lower</span>
<span class="sd">            partition numbers, given that num_partition number of GPUs are available. Defaults to ``4``.</span>
<span class="sd">        kmeans_n_init (:obj:`int`, ``optional``): Number of time the k-means algorithm will be run with different</span>
<span class="sd">            centroid seeds. The final results will be the best output of kmeans_n_init consecutive runs in terms of inertia.</span>
<span class="sd">        zero_threshold (:obj:`int`, ``optional``): Zero threshold to be used to decide min value of clamp for softmax</span>
<span class="sd">            . Defaults to ``1e-7``.</span>
<span class="sd">        kmeans_error_bnd (:obj:`float`, ``optional``): Distance threshold to decide at what distance between parameters</span>
<span class="sd">            and clusters to stop the kmeans operation. Defaults to ``0.0``.</span>

<span class="sd">    This class supports few different configurations to structure the palettization:</span>

<span class="sd">    1. **Per-tensor palettization**:  This is the default configuration where the whole tensor shares a single look-up</span>
<span class="sd">    table. The ``granularity`` is set to ``per_tensor`` and ``group_size`` is ``None``.</span>

<span class="sd">    2. **Per-grouped-channel palettization**: In this configuration, ``group_size`` number of channels along</span>
<span class="sd">    ``channel_axis`` share the same look-up table. For example, for a weight matrix of shape ``(16, 25)``, if we provide</span>
<span class="sd">     ``group_size = 8``, the shape of the look-up table would be ``(2, 2^n_bits)``.</span>

<span class="sd">    NOTE: Currently grouping is only supported along output channel axis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_bits</span><span class="p">:</span> <span class="n">_Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">weight_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;weight_threshold&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">granularity</span><span class="p">:</span> <span class="n">PalettizationGranularity</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;granularity&quot;</span><span class="p">],</span>
        <span class="n">converter</span><span class="o">=</span><span class="n">PalettizationGranularity</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">in_</span><span class="p">(</span><span class="n">PalettizationGranularity</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">group_size</span><span class="p">:</span> <span class="n">_Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;group_size&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">)),</span>
    <span class="p">)</span>
    <span class="n">channel_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">([</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">_validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="mi">0</span><span class="p">])]),</span>
    <span class="p">)</span>
    <span class="n">enable_per_channel_scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;enable_per_channel_scale&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">milestone</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;milestone&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">cluster_dim</span><span class="p">:</span> <span class="n">_Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">quant_min</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;quant_min&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">quant_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;quant_max&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">_torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">],</span>
        <span class="n">converter</span><span class="o">=</span><span class="n">_maybe_convert_str_to_dtype</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="p">[</span>
            <span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="n">_torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">_validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="n">_torch</span><span class="o">.</span><span class="n">qint8</span><span class="p">,</span> <span class="n">_torch</span><span class="o">.</span><span class="n">quint8</span><span class="p">,</span> <span class="n">_torch</span><span class="o">.</span><span class="n">float32</span><span class="p">]),</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="n">lut_dtype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;lut_dtype&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">quantize_activations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_OPTIONS</span><span class="p">[</span><span class="s2">&quot;quantize_activations&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">cluster_permute</span><span class="p">:</span> <span class="n">_Optional</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;cluster_permute&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">tuple</span><span class="p">)),</span>
    <span class="p">)</span>
    <span class="n">palett_max_mem</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_max_mem&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_max_iter&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">prune_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;prune_threshold&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_init</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_init&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_opt1d_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_opt1d_threshold&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">enforce_zero</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;enforce_zero&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_mode&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_tau&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_epsilon&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_lambda</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_lambda&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">add_extra_centroid</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;add_extra_centroid&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_cluster_tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_cluster_tol&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_min_tsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_min_tsize&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_unique</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_unique&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_shard</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_shard&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_batch_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_batch_mode&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">palett_dist</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;palett_dist&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">per_channel_scaling_factor_scheme</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;per_channel_scaling_factor_scheme&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">and_</span><span class="p">(</span>
            <span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">_validators</span><span class="o">.</span><span class="n">in_</span><span class="p">([</span><span class="s2">&quot;min_max&quot;</span><span class="p">,</span> <span class="s2">&quot;abs&quot;</span><span class="p">])</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">percentage_palett_enable</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;percentage_palett_enable&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_batch_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_batch_threshold&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_n_init</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_n_init&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">zero_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;zero_threshold&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">kmeans_error_bnd</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_PALETTIZATION_ADVANCED_OPTIONS</span><span class="p">[</span><span class="s2">&quot;kmeans_error_bnd&quot;</span><span class="p">],</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">partition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">_deprecated_field</span><span class="p">(</span>
        <span class="n">message</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;partition_size is being deprecated and will be removed in &quot;</span>
            <span class="s2">&quot;future versions. Please use group_size parameter instead.&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">cluster_dtype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_deprecated_field</span><span class="p">(</span>
        <span class="n">message</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;cluster_dtype is being deprecated and will be removed in &quot;</span>
            <span class="s2">&quot;future versions. Please use lut_dtype parameter instead.&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="nd">@group_size</span><span class="o">.</span><span class="n">validator</span>
    <span class="k">def</span> <span class="nf">per_grouped_channel_granularity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">granularity</span> <span class="o">==</span> <span class="n">PalettizationGranularity</span><span class="o">.</span><span class="n">per_grouped_channel</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">),</span> <span class="s2">&quot;group_size has to be specified along with per_grouped_channel granularity.&quot;</span>
            <span class="k">assert</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;group_size should be greater than zero&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;group_size can&#39;t be specified along with per_tensor granularity.&quot;</span></div>



<span class="n">_default_module_type_configs</span> <span class="o">=</span> <span class="n">_OrderedDict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">ModuleDKMPalettizerConfig</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">DEFAULT_PALETTIZATION_SCHEME</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>
<span class="p">)</span>


<span class="n">_GlobalConfigType</span> <span class="o">=</span> <span class="n">_NewType</span><span class="p">(</span>
    <span class="s2">&quot;GlobalConfigType&quot;</span><span class="p">,</span>
    <span class="n">_Union</span><span class="p">[</span>
        <span class="n">_Optional</span><span class="p">[</span><span class="n">ModuleDKMPalettizerConfig</span><span class="p">],</span>
        <span class="n">_List</span><span class="p">[</span><span class="n">_Optional</span><span class="p">[</span><span class="n">ModuleDKMPalettizerConfig</span><span class="p">]],</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="n">_ModuleTypeConfigType</span> <span class="o">=</span> <span class="n">_NewType</span><span class="p">(</span>
    <span class="s2">&quot;ModuleTypeConfigType&quot;</span><span class="p">,</span> <span class="n">_Dict</span><span class="p">[</span><span class="n">_Union</span><span class="p">[</span><span class="n">_Callable</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">_GlobalConfigType</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">_ModuleNameConfigType</span> <span class="o">=</span> <span class="n">_NewType</span><span class="p">(</span>
    <span class="s2">&quot;ModuleNameConfigType&quot;</span><span class="p">,</span> <span class="n">_Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_Optional</span><span class="p">[</span><span class="n">ModuleDKMPalettizerConfig</span><span class="p">]]</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_dkm_config_type</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">attribute</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_validators</span><span class="o">.</span><span class="n">deep_iterable</span><span class="p">(</span>
                <span class="n">member_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span>
                    <span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="n">ModuleDKMPalettizerConfig</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">iterable_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">list</span><span class="p">),</span>
            <span class="p">)(</span><span class="n">instance</span><span class="p">,</span> <span class="n">attribute</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_validators</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="n">ModuleDKMPalettizerConfig</span><span class="p">))(</span>
                <span class="n">instance</span><span class="p">,</span> <span class="n">attribute</span><span class="p">,</span> <span class="n">value</span>
            <span class="p">)</span>


<div class="viewcode-block" id="DKMPalettizerConfig">
<a class="viewcode-back" href="../../../../../source/coremltools.optimize.torch.palettization.html#coremltools.optimize.torch.palettization.DKMPalettizerConfig">[docs]</a>
<span class="nd">@_define</span>
<span class="k">class</span> <span class="nc">DKMPalettizerConfig</span><span class="p">(</span><span class="n">_OptimizationConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration for specifying how different submodules of a model are palettized by</span>
<span class="sd">    :py:class:`DKMPalettizer`.</span>

<span class="sd">    The ``module_type_configs`` parameter can accept a list of :py:class:`ModuleDKMPalettizerConfig`</span>
<span class="sd">    as values for a given module type. The list can specify</span>
<span class="sd">    different parameters for different ``weight_threshold`` values. This is useful if</span>
<span class="sd">    you want to apply different configs to layers of the same type with weights of different sizes.</span>

<span class="sd">    For example, to use ``4`` -bit palettization for weights with more than ``1000`` elements and</span>
<span class="sd">    ``2`` -bit palettization for weights with more than ``300`` but less than ``1000`` elements,</span>
<span class="sd">    create a config as follows:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        custom_config = {</span>
<span class="sd">            nn.Conv2d: [</span>
<span class="sd">                {&quot;n_bits&quot;: 4, &quot;cluster_dim&quot;: 4, &quot;weight_threshold&quot;: 1000},</span>
<span class="sd">                {&quot;n_bits&quot;: 2, &quot;cluster_dim&quot;: 2, &quot;weight_threshold&quot;: 300},</span>
<span class="sd">            ]</span>
<span class="sd">        }</span>
<span class="sd">        config = DKMPalettizerConfig.from_dict({&quot;module_type_configs&quot;: custom_config})</span>

<span class="sd">    Args:</span>
<span class="sd">        global_config (:py:class:`ModuleDKMPalettizerConfig`): Config to be applied globally</span>
<span class="sd">            to all supported modules. Missing values are chosen from the default config.</span>
<span class="sd">        module_type_configs (:obj:`dict` of :obj:`str` to :py:class:`ModuleDKMPalettizerConfig`):</span>
<span class="sd">            Module type level configs applied to a specific module class, such as :py:class:`torch.nn.Linear`.</span>
<span class="sd">            The keys can be either strings or module classes. When ``module_type_config`` is set to ``None``</span>
<span class="sd">            for a module type, it is not palettized.</span>
<span class="sd">        module_name_configs (:obj:`dict` of :obj:`str` to :py:class:`ModuleDKMPalettizerConfig`):</span>
<span class="sd">            Module level configs applied to specific modules.</span>
<span class="sd">            The name of the module must be a fully qualified name that can be used to fetch it</span>
<span class="sd">            from the top level module using the ``module.get_submodule(target)`` method. When</span>
<span class="sd">            ``module_name_config`` is set to ``None`` for a module, it is not palettized.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">global_config</span><span class="p">:</span> <span class="n">_GlobalConfigType</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validator</span><span class="o">=</span><span class="n">_validate_dkm_config_type</span><span class="p">)</span>
    <span class="n">module_type_configs</span><span class="p">:</span> <span class="n">_ModuleTypeConfigType</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">factory</span><span class="o">=</span><span class="n">_OrderedDict</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">deep_mapping</span><span class="p">(</span>
            <span class="n">key_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">and_</span><span class="p">(</span>
                <span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">((</span><span class="nb">str</span><span class="p">,</span> <span class="n">_Callable</span><span class="p">)),</span>
                <span class="n">_validate_module_type_keys_factory</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">DEFAULT_PALETTIZATION_SCHEME</span><span class="o">.</span><span class="n">keys</span><span class="p">())),</span>
            <span class="p">),</span>
            <span class="n">value_validator</span><span class="o">=</span><span class="n">_validate_dkm_config_type</span><span class="p">,</span>
            <span class="n">mapping_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">dict</span><span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">module_name_configs</span><span class="p">:</span> <span class="n">_ModuleNameConfigType</span> <span class="o">=</span> <span class="n">_field</span><span class="p">(</span>
        <span class="n">factory</span><span class="o">=</span><span class="n">_OrderedDict</span><span class="p">,</span>
        <span class="n">validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">deep_mapping</span><span class="p">(</span>
            <span class="n">key_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
            <span class="n">value_validator</span><span class="o">=</span><span class="n">_validate_dkm_config_type</span><span class="p">,</span>
            <span class="n">mapping_validator</span><span class="o">=</span><span class="n">_validators</span><span class="o">.</span><span class="n">instance_of</span><span class="p">(</span><span class="nb">dict</span><span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__attrs_post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_config</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module_type_configs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module_name_configs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module_type_configs</span> <span class="o">=</span> <span class="n">_default_module_type_configs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sort_configs_by_weight_threshold</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_config</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ctype</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_type_configs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_module_type</span><span class="p">(</span><span class="n">ctype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sort_configs_by_weight_threshold</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_name_configs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_module_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sort_configs_by_weight_threshold</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>

<div class="viewcode-block" id="DKMPalettizerConfig.from_dict">
<a class="viewcode-back" href="../../../../../source/coremltools.optimize.torch.palettization.html#coremltools.optimize.torch.palettization.DKMPalettizerConfig.from_dict">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config_dict</span><span class="p">:</span> <span class="n">_Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;DKMPalettizerConfig&quot;</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">)</span>
        <span class="n">converter</span> <span class="o">=</span> <span class="n">_cattrs</span><span class="o">.</span><span class="n">Converter</span><span class="p">(</span><span class="n">forbid_extra_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">converter</span><span class="o">.</span><span class="n">register_structure_hook</span><span class="p">(</span><span class="n">_ModuleTypeConfigType</span><span class="p">,</span> <span class="n">_structure_from_dict_hook</span><span class="p">)</span>
        <span class="n">converter</span><span class="o">.</span><span class="n">register_structure_hook</span><span class="p">(</span><span class="n">_ModuleNameConfigType</span><span class="p">,</span> <span class="n">_structure_from_dict_hook</span><span class="p">)</span>
        <span class="n">converter</span><span class="o">.</span><span class="n">register_structure_hook</span><span class="p">(</span><span class="n">_GlobalConfigType</span><span class="p">,</span> <span class="n">_structure_dkm_config_hook</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">converter</span><span class="o">.</span><span class="n">structure_attrs_fromdict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span></div>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_sort_configs_by_weight_threshold</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">_GlobalConfigType</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">weight_threshold</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span></div>



<span class="k">def</span> <span class="nf">_structure_dkm_config_hook</span><span class="p">(</span>
    <span class="n">config_dict</span><span class="p">:</span> <span class="n">_Union</span><span class="p">[</span><span class="n">_List</span><span class="p">[</span><span class="n">_Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_Any</span><span class="p">]],</span> <span class="n">_Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_Any</span><span class="p">]],</span> <span class="nb">type</span><span class="p">:</span> <span class="n">_Any</span>
<span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">ModuleDKMPalettizerConfig</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">cd</span><span class="p">)</span> <span class="k">for</span> <span class="n">cd</span> <span class="ow">in</span> <span class="n">config_dict</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ModuleDKMPalettizerConfig</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_structure_from_dict_hook</span><span class="p">(</span><span class="n">module_type_dict</span><span class="p">:</span> <span class="n">_Dict</span><span class="p">[</span><span class="n">_Union</span><span class="p">[</span><span class="n">_Callable</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">_Any</span><span class="p">],</span> <span class="nb">type</span><span class="p">:</span> <span class="n">_Any</span><span class="p">):</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">_OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">module_type_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">return_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_structure_dkm_config_hook</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">return_dict</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>