<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.converters.mil.mil.passes.defs.optimize_conv &mdash; coremltools API Reference  documentation</title>
      <link rel="stylesheet" href="../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/css/norightmargin.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../../../" id="documentation_options" src="../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../../../../_static/doctools.js"></script>
        <script src="../../../../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../index.html" class="icon icon-home">
            coremltools API Reference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.models.html">Model APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html">MIL Graph Passes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://coremltools.readme.io/docs">Guides and examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">coremltools.converters.mil.mil.passes.defs.optimize_conv</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.converters.mil.mil.passes.defs.optimize_conv</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Copyright (c) 2023, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1">#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">coremltools</span> <span class="kn">import</span> <span class="n">_logger</span> <span class="k">as</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Block</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Builder</span> <span class="k">as</span> <span class="n">mb</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">types</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.graph_pass</span> <span class="kn">import</span> <span class="n">AbstractGraphPass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_child_op_type</span><span class="p">,</span>
    <span class="n">_check_no_output_connection</span><span class="p">,</span>
    <span class="n">block_context_manager</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.pass_registry</span> <span class="kn">import</span> <span class="n">register_pass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.types.symbolic</span> <span class="kn">import</span> <span class="n">any_symbolic</span>


<div class="viewcode-block" id="add_conv_transpose_output_shape"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.add_conv_transpose_output_shape">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">add_conv_transpose_output_shape</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The ``conv_transpose`` input ``output_shape`` is an optional input.</span>
<span class="sd">    Since we can infer the output shape from ``type_inference``, we add</span>
<span class="sd">    ``output_shape`` input whenever it is known to be constant at</span>
<span class="sd">    compile time. For example:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Given:</span>
<span class="sd">          %1: (1, 5, 39, fp32) = conv_transpose(...) # no output_shape input.</span>

<span class="sd">        Result:</span>
<span class="sd">          %2: (3, i32) = const(val=[1,5,39])</span>
<span class="sd">          %3: (1, 5, 39, fp32) = conv_transpose(..., output_shape=%2)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span>
            <span class="ow">and</span> <span class="n">op</span><span class="o">.</span><span class="n">output_shape</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">any_symbolic</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_handle_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_handle_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># matched pattern</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv_transpose</span><span class="p">(</span>
                <span class="o">**</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">output_shape</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_has_output_shape&quot;</span><span class="p">,</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">x</span>
            <span class="p">)</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">op</span><span class="p">])</span></div>


<div class="viewcode-block" id="compose_conv1d"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.compose_conv1d">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">compose_conv1d</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In `TensorFlow &lt;https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/ops/nn_ops.py#L1657&gt;`_,</span>
<span class="sd">    ``tf.keras.layers.Conv1D`` is a composite op:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        expand a dummy dim -&gt; Conv2D -&gt; squeeze the dummy dim</span>

<span class="sd">    In `PyTorch &lt;https://github.com/pytorch/pytorch/blob/release/1.13/aten/src/ATen/native/Convolution.cpp#L1087&gt;`_,</span>
<span class="sd">    this is also true for some backends (``mkldnn`` and ``xpu``).</span>

<span class="sd">    This decomposition wrecks the coremltools ``conv1d`` graph passes,</span>
<span class="sd">    so we should recompose the fragments back to MIL ``conv``, which natively supports ``conv1d``:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Pattern 1:</span>
<span class="sd">            Given:</span>
<span class="sd">                %2 = expand_dims(%1, axes=-2) or expand_dims(%1, axes=2), %1.rank = 3</span>
<span class="sd">                %3 = conv(%2)</span>
<span class="sd">                %4 = squeeze(%3, axes=-2) or squeeze(%3, axes=2)</span>
<span class="sd">                ...</span>

<span class="sd">            Result:</span>
<span class="sd">                %4 = conv(%1)</span>
<span class="sd">                ...</span>

<span class="sd">        Pattern 2 (TensorFlow channel_last):</span>
<span class="sd">            Given:</span>
<span class="sd">                %2 = expand_dims(%1, axes=-3) or expand_dims(%1, axes=1), %1.rank = 3</span>
<span class="sd">                %3 = transpose(%2, perm=(0, 3, 1, 2))</span>
<span class="sd">                %4 = conv(%3)</span>
<span class="sd">                %5 = transpose(%4, perm=(0, 2, 3, 1))</span>
<span class="sd">                %6 = squeeze(%5, axes=-3) or squeeze(%5, axes=1)</span>
<span class="sd">                ...</span>

<span class="sd">            Result:</span>
<span class="sd">                %3 = transpose(%1, perm=(0, 2, 1))</span>
<span class="sd">                %4 = conv(%3)</span>
<span class="sd">                %6 = transpose(%4, perm=(0, 2, 1))</span>
<span class="sd">                ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compose_conv1d_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_compose_conv1d_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">help_compose_conv1d_block</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                        <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_compose_conv1d_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

                <span class="c1"># must start with expanding a 3-D tensor,</span>
                <span class="c1"># who has batch, channel, length dimensions</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;expand_dims&quot;</span> <span class="ow">or</span> <span class="n">op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="c1"># try pattern `expand_dim` -&gt; `conv2d` -&gt; `squeeze`</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_match_and_transform_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
                    <span class="c1"># has to break as the downstream iterator is affected</span>
                    <span class="k">return</span> <span class="kc">True</span>

                <span class="c1"># try pattern `expand_dim` -&gt; `transpose` -&gt; `conv2d` -&gt; `transpose` -&gt; `squeeze`</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_match_and_transform_pattern_channel_last</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
                    <span class="c1"># has to break as the downstream iterator is affected</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_compose_conv1d_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_try_match_and_transform_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expand_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        identify the pattern: `expand_dim` -&gt; `conv2d` -&gt; `squeeze`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># abort composition if dummy dimension is not added as height</span>
        <span class="k">if</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># `expand_dims` -&gt; `conv`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">expand_op</span><span class="p">,</span> <span class="s2">&quot;conv&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">conv_op</span> <span class="o">=</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># `conv` -&gt; `squeeze`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="s2">&quot;squeeze&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">squeeze_op</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># abort composition if not squeezing the dummy height</span>
        <span class="k">if</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># everything looks good</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_apply_transform</span><span class="p">(</span><span class="n">expand_op</span><span class="p">,</span> <span class="n">conv_op</span><span class="p">,</span> <span class="n">squeeze_op</span><span class="p">,</span> <span class="n">block</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_try_match_and_transform_pattern_channel_last</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">expand_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="n">Block</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        identify the pattern: `expand_dim` -&gt; `transpose` -&gt; `conv2d` -&gt; `transpose` -&gt; `squeeze`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># abort composition if dummy dimension is not added as height</span>
        <span class="k">if</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># `expand_dims` -&gt; `transpose`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">expand_op</span><span class="p">,</span> <span class="s2">&quot;transpose&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">transpose1_op</span> <span class="o">=</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># abort composition if permutation is not (0, 3, 1, 2)</span>
        <span class="n">perm1</span> <span class="o">=</span> <span class="n">transpose1_op</span><span class="o">.</span><span class="n">perm</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">perm1</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">perm1</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">4</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">perm1</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># `transpose` -&gt; `conv`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">transpose1_op</span><span class="p">,</span> <span class="s2">&quot;conv&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">conv_op</span> <span class="o">=</span> <span class="n">transpose1_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># `conv` -&gt; `transpose`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="s2">&quot;transpose&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">transpose2_op</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># abort composition if permutation is not (0, 2, 3, 1)</span>
        <span class="n">perm2</span> <span class="o">=</span> <span class="n">transpose2_op</span><span class="o">.</span><span class="n">perm</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">perm2</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">perm2</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">4</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">perm2</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># `transpose` -&gt; `squeeze`</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">transpose2_op</span><span class="p">,</span> <span class="s2">&quot;squeeze&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">squeeze_op</span> <span class="o">=</span> <span class="n">transpose2_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># abort composition if not squeezing the dummy height</span>
        <span class="k">if</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># everything looks good</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_apply_transform_channel_last</span><span class="p">(</span>
            <span class="n">expand_op</span><span class="p">,</span> <span class="n">transpose1_op</span><span class="p">,</span> <span class="n">conv_op</span><span class="p">,</span> <span class="n">transpose2_op</span><span class="p">,</span> <span class="n">squeeze_op</span><span class="p">,</span> <span class="n">block</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_apply_transform</span><span class="p">(</span>
        <span class="n">expand_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">conv_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">squeeze_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="n">Block</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">ops_to_remove</span> <span class="o">=</span> <span class="p">[</span><span class="n">expand_op</span><span class="p">,</span> <span class="n">conv_op</span><span class="p">,</span> <span class="n">squeeze_op</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_no_output_connection</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">ops_to_remove</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># prepare `conv1d`</span>
        <span class="n">conv_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">}</span>

        <span class="c1"># inherit `x` from `expand_dim`</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">expand_op</span><span class="o">.</span><span class="n">x</span>

        <span class="c1"># inherit `pad_type`, `groups`, `bias` from `conv2d`</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bias</span>

        <span class="c1"># squeeze `weight`, `strides`, `pad`, `dilations` from `conv2d`</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,),</span> <span class="n">before_op</span><span class="o">=</span><span class="n">conv_op</span>
        <span class="p">)</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;strides&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;strides&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;dilations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;dilations&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

        <span class="c1"># compose `conv1d`</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kwargs</span><span class="p">)</span>

        <span class="c1"># try replacing `expand_dim` -&gt; `conv2d` -&gt; `squeeze` output</span>
        <span class="c1"># with the new `conv1d` output</span>
        <span class="k">if</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">squeeze_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">squeeze_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">out</span>
        <span class="p">):</span>
            <span class="c1"># remove `expand_dim` -&gt; `conv2d` -&gt; `squeeze`</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">ops_to_remove</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_apply_transform_channel_last</span><span class="p">(</span>
        <span class="n">expand_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span>
        <span class="n">transpose1_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span>
        <span class="n">conv_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span>
        <span class="n">transpose2_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span>
        <span class="n">squeeze_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span>
        <span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">ops_to_remove</span> <span class="o">=</span> <span class="p">[</span><span class="n">expand_op</span><span class="p">,</span> <span class="n">transpose1_op</span><span class="p">,</span> <span class="n">conv_op</span><span class="p">,</span> <span class="n">transpose2_op</span><span class="p">,</span> <span class="n">squeeze_op</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_no_output_connection</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">ops_to_remove</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># create `transpose1`</span>
        <span class="n">transpose1_out</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">expand_op</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">transpose1_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">expand_op</span>
        <span class="p">)</span>

        <span class="c1"># prepare `conv1d`</span>
        <span class="n">conv_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">transpose1_out</span><span class="p">,</span> <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">}</span>

        <span class="c1"># inherit `pad_type`, `groups`, `bias` from `conv2d`</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bias</span>

        <span class="c1"># squeeze `weight`, `strides`, `pad`, `dilations` from `conv2d`</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,),</span> <span class="n">before_op</span><span class="o">=</span><span class="n">conv_op</span>
        <span class="p">)</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;strides&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;strides&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">conv_kwargs</span><span class="p">[</span><span class="s2">&quot;dilations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;dilations&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

        <span class="c1"># compose `conv1d`</span>
        <span class="n">conv_out</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kwargs</span><span class="p">)</span>

        <span class="c1"># create `transpose2`</span>
        <span class="n">transpose2_out</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">conv_out</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">squeeze_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">transpose2_op</span>
        <span class="p">)</span>

        <span class="c1"># try replacing `expand_dim` -&gt; `transpose` -&gt; `conv2d` -&gt; `transpose` -&gt; `squeeze` output</span>
        <span class="c1"># with the new `transpose` -&gt; `conv1d` -&gt; `transpose` output</span>
        <span class="k">if</span> <span class="n">squeeze_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">squeeze_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">squeeze_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">transpose2_out</span>
        <span class="p">):</span>
            <span class="c1"># remove `expand_dim` -&gt; `transpose` -&gt; `conv2d` -&gt; `transpose` -&gt; `squeeze`</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">ops_to_remove</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span></div>


<div class="viewcode-block" id="fuse_conv_batchnorm"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.fuse_conv_batchnorm">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">fuse_conv_batchnorm</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fuse the following ``batch_norm`` layer into ``conv`` and ``conv_transpose``. </span>
<span class="sd">    That is, convert ``conv + batch_norm`` to ``conv``, by modifying the weight and bias in the ``conv`` layer.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Given:</span>
<span class="sd">            %2 = conv(%1)</span>
<span class="sd">            ...</span>
<span class="sd">            %3 = batch_norm(%2)</span>
<span class="sd">            ...</span>

<span class="sd">        Result:</span>
<span class="sd">            %3 = conv(%1)</span>
<span class="sd">            ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_batchnorm_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_to_transform</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">bn_op</span><span class="p">):</span>
        <span class="c1"># get parameters from batch_norm layer</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">val</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">val</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">val</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">val</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">epsilon</span><span class="o">.</span><span class="n">val</span>

        <span class="c1"># get weight, bias and groups from conv layer</span>
        <span class="k">if</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">bias</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">val</span>

        <span class="c1"># get type of the conv layer</span>
        <span class="n">is_deconv</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span>
        <span class="c1"># The deconv weight transpose axes is determined by the dimension of convolution.</span>
        <span class="c1"># Conv1d should be [1, 0, 2], Conv2d should be [1, 0, 2, 3], Conv3d should be [1, 0, 2, 3, 4]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mi">3</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only supports Conv1/2/3d, which means weight&#39;s dimension should&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;between 3 and 5, but got weight with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;dimensions. &quot;</span>
            <span class="p">)</span>
        <span class="n">deconv_weight_transpose_axes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">))]</span>

        <span class="c1"># D_in denotes the spatial dimensions for conv kernel weight</span>
        <span class="c1"># for conv_transpose, conv_weight has shape [Cin, Cout / groups, *D_in]</span>
        <span class="c1"># for conv, conv_weight has shape [Cout, Cin / groups, *D_in]</span>
        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span>
            <span class="n">Cin</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">Cin</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span>

        <span class="c1"># get the type of the conv weight</span>
        <span class="n">conv_weight_type</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">dtype</span>

        <span class="c1"># create bias for conv if not exist</span>
        <span class="k">if</span> <span class="n">conv_bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Cout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>

        <span class="c1"># get the original shape of weight and bias</span>
        <span class="n">origin_weight_shape</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">origin_bias_shape</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># update the weight for conv layer</span>
        <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_conv_bias</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">conv_weight</span><span class="p">,</span> <span class="n">deconv_weight_transpose_axes</span><span class="p">)</span>
            <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="n">Cout</span><span class="p">,</span> <span class="n">Cin</span> <span class="o">//</span> <span class="n">groups</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Cout</span><span class="p">):</span>
            <span class="c1"># get batch norm parameters for each channel</span>
            <span class="n">_gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_mean</span> <span class="o">=</span> <span class="n">mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_variance</span> <span class="o">=</span> <span class="n">variance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_scale</span> <span class="o">=</span> <span class="n">_gamma</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">_variance</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>

            <span class="c1"># get conv weight and bias for each channel</span>
            <span class="n">_conv_weight</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_conv_bias</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># update the conv weight and bias</span>
            <span class="n">_conv_weight</span> <span class="o">=</span> <span class="n">_conv_weight</span> <span class="o">*</span> <span class="n">_scale</span>
            <span class="n">_conv_bias</span> <span class="o">=</span> <span class="n">_scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">_conv_bias</span> <span class="o">-</span> <span class="n">_mean</span><span class="p">)</span> <span class="o">+</span> <span class="n">_beta</span>
            <span class="n">new_conv_weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_conv_weight</span><span class="p">)</span>
            <span class="n">new_conv_bias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_conv_bias</span><span class="p">)</span>

        <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_conv_weight</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>
        <span class="n">new_conv_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_conv_bias</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">new_conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="n">Cout</span> <span class="o">//</span> <span class="n">groups</span><span class="p">,</span> <span class="n">Cin</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
            <span class="p">)</span>
            <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_conv_weight</span><span class="p">,</span> <span class="n">deconv_weight_transpose_axes</span><span class="p">)</span>

        <span class="c1"># make sure the updated weight and bias have the same shape as the original ones</span>
        <span class="k">if</span> <span class="n">new_conv_weight</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">origin_weight_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s2">&quot;conv weight should have the same shape before and after the fuse_&quot;</span>
                <span class="s2">&quot;conv_batchnorm pass. &quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">new_conv_bias</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">origin_bias_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s2">&quot;conv bias should have the same shape before and after the fuse_&quot;</span>
                <span class="s2">&quot;conv_batchnorm pass. &quot;</span>
            <span class="p">)</span>

        <span class="c1"># create a new conv op with the new bias value, copying rest of the attributes</span>
        <span class="n">out_name</span> <span class="o">=</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">conv_kargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">new_conv_weight</span><span class="p">,</span>
            <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">new_conv_bias</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">out_name</span><span class="p">,</span>
            <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">conv_kargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv_transpose</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">bn_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">bn_op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">bn_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">bn_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">bn_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_fuse_conv_batchnorm_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">or</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span><span class="p">:</span>
                <span class="c1"># abort fusion if op output is also a block output</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">None</span>
                <span class="c1"># find batch_norm op</span>
                <span class="n">child_ops</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">bn_op_candidate</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">bn_op_candidate</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;batch_norm&quot;</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">bn_op_candidate</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">fusion_occurred</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_batchnorm_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># This op can&#39;t be conv or conv_transpose</span>
                <span class="k">continue</span>

            <span class="n">bn_op</span> <span class="o">=</span> <span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">bn_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fusion_occurred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">bn_op</span><span class="p">)</span>
                <span class="c1"># has to break as the downstream iterator is affected.</span>
                <span class="k">if</span> <span class="n">fusion_occurred</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">fusion_occurred</span>
        <span class="k">return</span> <span class="n">fusion_occurred</span></div>


<div class="viewcode-block" id="fuse_conv_bias"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.fuse_conv_bias">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">fuse_conv_bias</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fold ``add``/``sub`` into ``bias`` of ``conv`` and ``conv_transpose``.</span>
<span class="sd">    That is, convert ``conv + add/sub`` to ``conv``, when ``add``/``sub`` is adding a constant.</span>

<span class="sd">    Two patterns are supported:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Pattern 1:</span>
<span class="sd">        Given:</span>
<span class="sd">            %2 = conv(%1)</span>
<span class="sd">            ...</span>
<span class="sd">            %3 = add(%2, constant) # where constant has shape (1,C,1)/(C,1) for 1d conv, (1,C,1,1)/(C,1,1) for 2d conv etc</span>
<span class="sd">            ...</span>

<span class="sd">        Result:</span>
<span class="sd">            %3 = conv(%1)</span>
<span class="sd">            ...</span>


<span class="sd">        Pattern 2:</span>
<span class="sd">        Given:</span>
<span class="sd">            %2 = conv(%1)</span>
<span class="sd">            %3 = transpose(%2)</span>
<span class="sd">            ...</span>
<span class="sd">            %4 = add(%3, constant) # where constant has a broacasable shape</span>
<span class="sd">            ...</span>

<span class="sd">        Result:</span>
<span class="sd">            %2 = conv(%1)</span>
<span class="sd">            %4 = transpose(%2)</span>
<span class="sd">            ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">child_op_types</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;sub&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_bias_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">or</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span><span class="p">:</span>
            <span class="c1"># abort fusion if op output is also a block output</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="c1"># find add</span>
            <span class="n">child_ops</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">add_op_candidate</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">add_op_candidate</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">child_op_types</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">add_op_candidate</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_to_transform_transpose_pattern</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>

        <span class="n">ops_to_remove</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># conv layer</span>
        <span class="k">if</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">and</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;conv_transpose&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">is_deconv</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span>
        <span class="n">ops_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_op</span><span class="p">)</span>

        <span class="c1"># transpose layer</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="s2">&quot;transpose&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">transpose_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ops_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">)</span>

        <span class="c1"># add/sub layer</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">,</span> <span class="s2">&quot;add&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span>
            <span class="n">transpose_op</span><span class="p">,</span> <span class="s2">&quot;sub&quot;</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">add_or_sub_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">ops_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">add_or_sub_op</span><span class="p">)</span>

        <span class="c1"># get the bias</span>
        <span class="k">if</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="k">if</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">val</span>
        <span class="n">is_first_input</span> <span class="o">=</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">is_sub</span> <span class="o">=</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;sub&quot;</span>

        <span class="c1"># get the conv bias/weight</span>
        <span class="n">conv_shape</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_weight_type</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">conv_bias</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Cout</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span> <span class="k">if</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">val</span>
        <span class="p">)</span>

        <span class="c1"># check if the bias is compatible for fusion</span>
        <span class="n">is_bias_scalar</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">bias</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">is_bias_scalar</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_bias_scalar</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="n">Cout</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span>
            <span class="n">cout_dim</span> <span class="o">=</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">perm</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span>
            <span class="k">if</span> <span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">cout_dim</span><span class="p">]</span> <span class="o">!=</span> <span class="n">Cout</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="p">(</span><span class="n">Cout</span><span class="p">))</span>

        <span class="c1"># compute the new bias</span>
        <span class="k">if</span> <span class="n">is_sub</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_first_input</span><span class="p">:</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="o">-</span><span class="n">bias</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">conv_bias</span> <span class="o">=</span> <span class="o">-</span><span class="n">conv_bias</span>

        <span class="n">new_bias</span> <span class="o">=</span> <span class="n">conv_bias</span> <span class="o">+</span> <span class="n">bias</span>

        <span class="c1"># compute the new weight</span>
        <span class="k">if</span> <span class="n">is_sub</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_first_input</span><span class="p">:</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="o">-</span><span class="n">conv_weight</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">conv_weight</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_no_output_connection</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">ops_to_remove</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># create a new conv op with the new weight, bias value, copying rest of the attributes</span>
        <span class="n">conv_kargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">new_weight</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">new_bias</span><span class="p">,</span> <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">conv_kargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv_transpose</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>

        <span class="c1"># create a new transpose op</span>
        <span class="n">out_name</span> <span class="o">=</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">tranpose_kargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">out_name</span><span class="p">,</span> <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">transpose_op</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;x&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">tranpose_kargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">**</span><span class="n">tranpose_kargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">add_or_sub_op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">add_or_sub_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">ops_to_remove</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_to_transform</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">add_op</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">add_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;sub&quot;</span><span class="p">:</span>
            <span class="n">bias_var</span> <span class="o">=</span> <span class="n">add_op</span><span class="o">.</span><span class="n">y</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bias_var</span> <span class="o">=</span> <span class="n">add_op</span><span class="o">.</span><span class="n">x</span> <span class="k">if</span> <span class="n">add_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">add_op</span><span class="o">.</span><span class="n">y</span>
        <span class="n">bias_value</span> <span class="o">=</span> <span class="n">bias_var</span><span class="o">.</span><span class="n">val</span>

        <span class="n">is_conv_op</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span>

        <span class="c1"># check that the bias value is a constant array or a scalar constant</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bias_value</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">is_bias_scalar</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bias_value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">is_bias_scalar</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># find rank of the conv input</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">rank</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">5</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># check compatibility of bias value with the rank of the conv op</span>
        <span class="c1"># either bias value should be a scalar or:</span>
        <span class="c1"># rank=3 ==&gt; (B,C,D), which means bias must be (1,C,1) or (C,1)</span>
        <span class="c1"># rank=4 ==&gt; (B,C,D1,D2), which means bias must be (1,C,1,1) or (C,1,1)</span>
        <span class="c1"># rank=5 ==&gt; (B,C,D1,D2,D3), which means bias must be (1,C,1,1,1) or (C,1,1,1)</span>

        <span class="k">if</span> <span class="n">is_bias_scalar</span><span class="p">:</span>
            <span class="n">bias_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">bias_value</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># check that there is at most one dimension in the shape that is not 1</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">bias_value</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="c1"># check that addition is not happening on the batch dimension</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bias_value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">bias_value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">False</span>
            <span class="c1"># check that last rank-2 entries in the shape vector are all 1s</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">bias_value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="p">:])</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">bias_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">bias_value</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">add_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;sub&quot;</span><span class="p">:</span>
            <span class="n">bias_value</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1"># everything looks good, now find the new updated bias</span>
        <span class="n">old_bias</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">old_bias_value</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">old_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">old_bias</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">old_bias_value</span> <span class="o">=</span> <span class="n">old_bias</span><span class="o">.</span><span class="n">val</span>
        <span class="k">if</span> <span class="n">old_bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># need to create a fresh numpy array for bias</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">bias_value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># its a scalar bias</span>
                <span class="c1"># need to find the value of Cout to form a new bias</span>
                <span class="k">if</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">False</span>
                <span class="c1"># conv_transpose has weight format [K, C_out, spatial dims]</span>
                <span class="c1"># conv has weight format [C_out, K, spatial dims]</span>
                <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">is_conv_op</span> <span class="k">else</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">new_bias_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">bias_value</span><span class="p">,</span> <span class="p">(</span><span class="n">Cout</span><span class="p">,))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_bias_value</span> <span class="o">=</span> <span class="n">bias_value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># just need to update the existing bias array</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">new_bias_value</span> <span class="o">=</span> <span class="n">old_bias_value</span> <span class="o">+</span> <span class="n">bias_value</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># create a new conv op with the new bias value, copying rest of the attributes</span>
        <span class="n">out_name</span> <span class="o">=</span> <span class="n">add_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="k">if</span> <span class="n">new_bias_value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span> <span class="ow">and</span> <span class="n">new_bias_value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="c1"># cast the bias to match the weight type</span>
            <span class="n">weight_np_type</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">nptype_from_builtin</span><span class="p">(</span>
                <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sym_type</span><span class="o">.</span><span class="n">get_primitive</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;conv_bias_fusion pass: casting bias &quot;</span>
                <span class="s2">&quot;from </span><span class="si">{}</span><span class="s2"> to </span><span class="si">{}</span><span class="s2"> to match the dtype of the weight of the conv layer&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">new_bias_value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">weight_np_type</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">new_bias_value</span> <span class="o">=</span> <span class="n">new_bias_value</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">weight_np_type</span><span class="p">)</span>
        <span class="n">new_bias_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">new_bias_value</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">conv_op</span><span class="p">)</span>

        <span class="n">conv_kargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">new_bias_var</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">out_name</span><span class="p">,</span> <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">conv_kargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">if</span> <span class="n">is_conv_op</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv_transpose</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">add_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">add_op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">add_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">add_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">add_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_fuse_conv_bias_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="n">fusion_status</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_bias_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># This op can&#39;t be conv or conv_transpose</span>
                <span class="k">continue</span>

            <span class="c1"># pattern 1 : conv + add/sub</span>
            <span class="n">add_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">add_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fusion_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">add_op</span><span class="p">)</span>
                <span class="c1"># has to break as the downstream iterator is affected.</span>
                <span class="k">if</span> <span class="n">fusion_status</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">fusion_status</span>

            <span class="c1"># pattern 2 : conv + transpose + add/sub</span>
            <span class="n">fusion_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform_transpose_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">block</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fusion_status</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">fusion_status</span>

        <span class="k">return</span> <span class="n">fusion_status</span></div>


<div class="viewcode-block" id="fuse_conv_scale"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.fuse_conv_scale">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">fuse_conv_scale</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fold ``mul``/``div`` into ``conv``/``conv_transpose`` by updating the weight/bias of the convolution layers.</span>

<span class="sd">    The scale ``const`` can be a single number (scalar) or a vector with a broadcastable shape.</span>
<span class="sd">    For example, if the output of the ``conv``/``deconv`` layer is ``(B, Cout, H, W)``,</span>
<span class="sd">    ``const`` of shape ``(Cout, 1, 1)`` and ``(1, Cout, 1, 1)`` are allowed.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Given:</span>
<span class="sd">            %2 = conv(%1)</span>
<span class="sd">            ...</span>
<span class="sd">            %3 = mul(%2, constant) # where constant is the scale constant</span>
<span class="sd">            ...</span>

<span class="sd">        Result:</span>
<span class="sd">            %3 = conv(%1)</span>
<span class="sd">            ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_scale_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_to_transform</span><span class="p">(</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">scale_op</span><span class="p">):</span>
        <span class="c1"># get the scale</span>
        <span class="k">if</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">scale_var</span> <span class="o">=</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">x</span> <span class="k">if</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">y</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">scale_var</span><span class="o">.</span><span class="n">val</span>

        <span class="c1"># for the scalar case, the scalar can be either</span>
        <span class="c1"># 1. a python int/float</span>
        <span class="c1"># 2. a 0d numpy array</span>
        <span class="c1"># 3. a 1d numpy array with shape (1,)</span>

        <span class="n">is_scalar</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">scale</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">scale</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">scale</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,):</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">is_scalar</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># get weight and bias and groups from conv layer</span>
        <span class="k">if</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">bias</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">val</span>

        <span class="c1"># get type of the conv layer</span>
        <span class="n">is_deconv</span> <span class="o">=</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span>
        <span class="n">is_conv_1d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>

        <span class="c1"># D_in denotes the spatial dimensions for conv kernel weight</span>
        <span class="c1"># for conv_transpose, conv_weight has shape [Cin, Cout / groups, *D_in]</span>
        <span class="c1"># for conv, conv_weight has shape [Cout, Cin / groups, *D_in]</span>
        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span>
            <span class="n">Cin</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Cout</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">Cin</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span>

        <span class="c1"># for the vector scale case, check if the shape is broacastable</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_scalar</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="n">Cout</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">Cout</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Cout</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># transform the scale to 1./scale for the real_div case</span>
        <span class="k">if</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;real_div&quot;</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">scale</span>

        <span class="c1"># get the type of the conv weight</span>
        <span class="n">conv_weight_type</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">dtype</span>

        <span class="c1"># create bias for conv if not exist</span>
        <span class="k">if</span> <span class="n">conv_bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Cout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">val</span>
        <span class="n">conv_bias</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>

        <span class="c1"># get the original shape of weight and bias</span>
        <span class="n">origin_weight_shape</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">origin_bias_shape</span> <span class="o">=</span> <span class="n">conv_bias</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># update the weight/bias for conv layer</span>
        <span class="k">if</span> <span class="n">is_scalar</span><span class="p">:</span>
            <span class="n">new_conv_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">conv_bias</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>
            <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">conv_weight</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="p">(</span><span class="n">Cout</span><span class="p">))</span>
            <span class="n">new_conv_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">conv_bias</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>
            <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
                <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_conv_1d</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
                <span class="n">conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="n">Cout</span><span class="p">,</span> <span class="n">Cin</span> <span class="o">//</span> <span class="n">groups</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
                <span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Cout</span><span class="p">):</span>
                <span class="n">_conv_weight</span> <span class="o">=</span> <span class="n">conv_weight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">new_conv_weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_conv_weight</span><span class="p">)</span>
            <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_conv_weight</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">conv_weight_type</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
                <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">new_conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="n">Cout</span> <span class="o">//</span> <span class="n">groups</span><span class="p">,</span> <span class="n">Cin</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_conv_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
                <span class="p">)</span>
                <span class="n">new_conv_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                    <span class="n">new_conv_weight</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_conv_1d</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
                <span class="p">)</span>

        <span class="c1"># make sure the updated weight and bias have the same shape as the original ones</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">new_conv_weight</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">origin_weight_shape</span>
        <span class="p">),</span> <span class="s2">&quot;conv weight should have the same shape before and after the fuse_conv_scale pass.&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">new_conv_bias</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">origin_bias_shape</span>
        <span class="p">),</span> <span class="s2">&quot;conv bias should have the same shape before and after the fuse_conv_scale pass.&quot;</span>

        <span class="c1"># create a new conv op with the new weight, bias value, copying rest of the attributes</span>
        <span class="n">out_name</span> <span class="o">=</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">conv_kargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">new_conv_weight</span><span class="p">,</span>
            <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">new_conv_bias</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">out_name</span><span class="p">,</span>
            <span class="s2">&quot;before_op&quot;</span><span class="p">:</span> <span class="n">conv_op</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">conv_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">conv_kargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv_transpose</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="o">**</span><span class="n">conv_kargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">scale_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">scale_op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">scale_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">scale_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">conv_op</span><span class="p">,</span> <span class="n">scale_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_fuse_conv_scale_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">or</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span><span class="p">:</span>
                <span class="c1"># abort fusion if op output is also a block output</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">None</span>
                <span class="c1"># find batch_norm op</span>
                <span class="n">child_ops</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">scale_op_candidate</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">scale_op_candidate</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mul&quot;</span><span class="p">,</span> <span class="s2">&quot;real_div&quot;</span><span class="p">]:</span>
                        <span class="k">return</span> <span class="n">scale_op_candidate</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">fusion_occurred</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_conv_scale_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># This op can&#39;t be conv or conv_transpose</span>
                <span class="k">continue</span>

            <span class="n">scale_op</span> <span class="o">=</span> <span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">scale_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fusion_occurred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">scale_op</span><span class="p">)</span>
                <span class="c1"># has to break as the downstream iterator is affected.</span>
                <span class="k">if</span> <span class="n">fusion_occurred</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">fusion_occurred</span>
        <span class="k">return</span> <span class="n">fusion_occurred</span></div>


<div class="viewcode-block" id="fuse_pad_conv"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_conv.fuse_pad_conv">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">fuse_pad_conv</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    When we observe ``pad -&gt; transpose -&gt; conv``, we move the ``pad`` to be next to ``conv``.</span>
<span class="sd">    This allows us to meld ``pad + conv`` if possible.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Given:</span>
<span class="sd">            %1 = pad(%0, ...)</span>
<span class="sd">            %2 = transpose(%1, ...)</span>
<span class="sd">            %3 = conv(%2, ...)</span>
<span class="sd">            ...</span>

<span class="sd">        Result:</span>
<span class="sd">            %1.a = transpose(%0, ...)</span>
<span class="sd">            $2.a = pad(%1.a, ...)</span>
<span class="sd">            %3 = conv(%2.a)</span>
<span class="sd">            ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pad_conv_connect_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([])</span>
        <span class="n">child_ops</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span>

        <span class="k">for</span> <span class="n">child_op</span> <span class="ow">in</span> <span class="n">child_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">child_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;transpose&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">skip_ops</span> <span class="o">=</span> <span class="n">child_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span>
            <span class="k">for</span> <span class="n">skip_op</span> <span class="ow">in</span> <span class="n">skip_ops</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">skip_op</span><span class="o">.</span><span class="n">op_type</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">ret</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="n">child_op</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">ret</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_try_to_transform</span><span class="p">(</span><span class="n">pad_op</span><span class="p">,</span> <span class="n">transpose_ops</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_compute_new_pad_values</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pad_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="n">pad_amounts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pad_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
            <span class="n">transpose_axes</span> <span class="o">=</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
            <span class="n">rank_diff</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">transpose_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">pad_amounts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pad_amounts</span><span class="p">)</span>
            <span class="c1"># append &quot;rank_diff&quot; rows of zeros to the top</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank_diff</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">pad_amounts_new</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">pad_amounts_new</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">pad_amounts</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">pad_amounts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank_diff</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">pad_amounts</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">transpose_axes</span><span class="p">):</span>
                <span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_amounts</span><span class="p">[</span><span class="n">axis</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_amounts</span><span class="p">[</span><span class="n">axis</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># get the top &quot;rank_diff&quot; rows</span>
            <span class="n">top_rows</span> <span class="o">=</span> <span class="n">pad_amounts_new</span><span class="p">[:</span><span class="n">rank_diff</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">top_rows</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="c1"># cut &quot;rank_diff&quot; from the top</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">rank_diff</span><span class="p">:,</span> <span class="p">:]</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">pad_amounts_new</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">pad_amounts_new</span>

        <span class="k">if</span> <span class="n">pad_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">pad_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">pad_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">transpose_ops</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">transpose_op</span> <span class="ow">in</span> <span class="n">transpose_ops</span><span class="p">:</span>
            <span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">_compute_new_pad_values</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pad_amounts_new</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">with</span> <span class="n">pad_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
                <span class="n">new_transpose_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">pad_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
                    <span class="n">perm</span><span class="o">=</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                    <span class="n">before_op</span><span class="o">=</span><span class="n">transpose_op</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">new_pad_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">new_transpose_var</span><span class="p">,</span> <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="n">pad_amounts_new</span><span class="p">}</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pad_op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">new_pad_inputs</span><span class="p">:</span>
                        <span class="n">new_pad_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="n">new_pad_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">before_op</span><span class="o">=</span><span class="n">transpose_op</span><span class="p">,</span> <span class="o">**</span><span class="n">new_pad_inputs</span><span class="p">)</span>
            <span class="n">pad_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">transpose_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">new_pad_var</span>
            <span class="p">)</span>

        <span class="n">pad_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">transpose_ops</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_op</span><span class="p">])</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_pad_conv_connect_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="n">fusion_status</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pad_conv_connect_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;pad&quot;</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">transpose_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">transpose_ops</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fusion_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">transpose_ops</span><span class="p">,</span> <span class="n">block</span><span class="p">)</span>
                <span class="c1"># has to break as the downstream iterator is affected.</span>
                <span class="k">if</span> <span class="n">fusion_status</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">fusion_status</span>
        <span class="k">return</span> <span class="n">fusion_status</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>