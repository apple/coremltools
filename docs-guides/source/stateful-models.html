

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Stateful Models &#8212; Guide to Core ML Tools</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/imgstyle.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/stateful-models';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classifiers" href="classifiers.html" />
    <link rel="prev" title="Image Input and Output" href="image-inputs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Guide to Core ML Tools</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">coremltools API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="new-features.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-to-contribute.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-learning-models.html">Converting Deep Learning Models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="target-conversion-formats.html">Source and Conversion Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="load-and-convert-model.html">Load and Convert Model Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-ml-program.html">Convert Models to ML Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-neural-network.html">Convert Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="comparing-ml-programs-and-neural-networks.html">Comparing ML Programs and Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution.html">Typed Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution-example.html">Typed Execution Workflow Example</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-image-classifier.html">Converting a TensorFlow 1 Image Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-pytorch.html">Converting from PyTorch</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="convert-pytorch-workflow.html">PyTorch Conversion Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-tracing.html">Model Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-scripting.html">Model Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-nlp-model.html">Converting a Natural Language Processing Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-torchvision-model-from-pytorch.html">Converting a torchvision Model from PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch-conversion-examples.html">Converting a PyTorch Segmentation Model</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="conversion-options.html">Conversion Options</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="new-conversion-options.html">New Conversion Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-input-and-output-types.html">Model Input and Output Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-inputs.html">Image Input and Output</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Stateful Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="flexible-inputs.html">Flexible Input Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="composite-operators.html">Composite Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-operators.html">Custom Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph-passes-intro.html">Graph Passes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="opt-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-whats-new.html">Whats new</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-overview-examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-resnet.html">Optimizing ResNet50 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-opt1_3.html">Optimizing OPT Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-workflow.html">Optimization Workflow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-palettization.html">Palettization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-overview.html">Palettization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-quantization.html">Linear Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-algos.html">Quantization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-pruning.html">Pruning</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-joint-compression.html">Combining compression types</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-conversion.html">Conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost-conversion.html">XGBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multifunction-models.html">Multifunction Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-prediction.html">Model Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="updatable-model-examples.html">Updatable Models</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="updatable-neural-network-classifier-on-mnist-dataset.html">Neural Network Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-tiny-drawing-classifier-pipeline-model.html">Pipeline Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-nearest-neighbor-classifier.html">Nearest Neighbor Classifier</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apple/coremltools" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/source/stateful-models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Stateful Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-a-simple-accumulator">Example: A Simple Accumulator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-states-for-a-pytorch-model">Registering States for a PyTorch Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-to-a-stateful-core-ml-model">Converting to a Stateful Core ML Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-states-with-predictions">Using States with Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-stateful-model-in-mil">Creating a Stateful Model in MIL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-toy-attention-model-with-stateful-kv-cache">Example: Toy Attention Model with Stateful KV-Cache</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="stateful-models">
<span id="index-0"></span><h1>Stateful Models<a class="headerlink" href="#stateful-models" title="Permalink to this heading">#</a></h1>
<p>This section introduces how Core ML models support stateful prediction.
Starting from <code class="docutils literal notranslate"><span class="pre">iOS18</span></code> / <code class="docutils literal notranslate"><span class="pre">macOS15</span></code>, Core ML models can have a <em>state</em> input type.
With a <em>stateful model</em>, you can keep track of specific  intermediate values
(referred to as <em>states</em>), by persisting and updating them across
inference runs. The model can implicitly read data from a state, and write back to a state.</p>
<section id="example-a-simple-accumulator">
<h2>Example: A Simple Accumulator<a class="headerlink" href="#example-a-simple-accumulator" title="Permalink to this heading">#</a></h2>
<p>To illustrate how stateful models work, we can
use a toy example of an accumulator that keeps track of the sum
of its inputs, and the output is a square of the input + accumulator.
One way to create this model is to explicitly have accumulator inputs and outputs,
as shown in the following figure. To run prediction with this model, we explicitly
provide the accumulator as an input, get it back as the output and copy over
its value to the input for the next prediction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># prediction code with stateless model</span>

<span class="n">acc_in</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">y_1</span><span class="p">,</span> <span class="n">acc_out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">acc_in</span><span class="p">)</span>
<span class="n">acc_in</span> <span class="o">=</span> <span class="n">acc_out</span>
<span class="n">y_2</span><span class="p">,</span> <span class="n">acc_out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_2</span><span class="p">,</span> <span class="n">acc_in</span><span class="p">)</span>
<span class="n">acc_in</span> <span class="o">=</span> <span class="n">acc_out</span>
<span class="o">...</span>
</pre></div>
</div>
<p><img alt="Stateless with I/O" src="../_images/stateless-acc-example.png" /></p>
<p>With stateful models you can read and write the accumulator state directly. You don’t need to define them as inputs or outputs and copy them explicitly from output of the previous prediction to the input of the next prediction call. The model takes care of updating the value implicitly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># prediction code with stateful model</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">initialize</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_2</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p><img alt="Stateful model" src="../_images/stateful-model-accum.png" /></p>
<p>Using stateful models in Core ML is convenient because it simplifies your code,
and it leaves the decision on how to update the state to the
model runtime, which maybe more efficient.</p>
<p>State inputs show up alongside the usual model inputs in the Xcode UI as shown in
the snapshot below.</p>
<p><img alt="States in Xcode UI" src="../_images/Xcode_stateful_model_io.png" /></p>
</section>
<section id="registering-states-for-a-pytorch-model">
<h2>Registering States for a PyTorch Model<a class="headerlink" href="#registering-states-for-a-pytorch-model" title="Permalink to this heading">#</a></h2>
<p>To set up a PyTorch model to be converted to a Core ML stateful model, the first step is to use the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer"><code class="docutils literal notranslate"><span class="pre">register_buffer</span></code></a> API in PyTorch to register buffers in the model to use as state tensors.</p>
<p>For example, the following code defines a model to demonstrate an accumulator, and registers the <code class="docutils literal notranslate"><span class="pre">accumulator</span></code> buffer as the state:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;accumulator&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accumulator</span> <span class="o">+=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulator</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulator</span>

</pre></div>
</div>
</section>
<section id="converting-to-a-stateful-core-ml-model">
<h2>Converting to a Stateful Core ML Model<a class="headerlink" href="#converting-to-a-stateful-core-ml-model" title="Permalink to this heading">#</a></h2>
<p>To convert the model to a stateful Core ML model,
use the <code class="docutils literal notranslate"><span class="pre">states</span></code> parameter
with <code class="docutils literal notranslate"><span class="pre">convert()</span></code>
to define a <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.input_types.html#coremltools.converters.mil.input_types.StateType"><code class="docutils literal notranslate"><span class="pre">StateType</span></code></a>
tensor using the same state name
(<code class="docutils literal notranslate"><span class="pre">accumulator</span></code>) that was used with <code class="docutils literal notranslate"><span class="pre">register_buffer</span></code> :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
    <span class="n">traced_model</span><span class="p">,</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span> <span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span> <span class="p">],</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span> <span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span> <span class="p">],</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ct</span><span class="o">.</span><span class="n">StateType</span><span class="p">(</span>
            <span class="n">wrapped_type</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
            <span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;accumulator&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">],</span>
    <span class="n">minimum_deployment_target</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">iOS18</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The stateful models feature is available starting with <code class="docutils literal notranslate"><span class="pre">iOS18</span></code>/<code class="docutils literal notranslate"><span class="pre">macOS15</span></code> for the <code class="docutils literal notranslate"><span class="pre">mlprogram</span></code> model type.
Hence, during conversion, the minimum deployment target must be provided accordingly.</p>
</div>
</section>
<section id="using-states-with-predictions">
<h2>Using States with Predictions<a class="headerlink" href="#using-states-with-predictions" title="Permalink to this heading">#</a></h2>
<p>Use the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel.make_state"><code class="docutils literal notranslate"><span class="pre">make_state()</span></code></a>
method of MLModel to initialize the state, which you can then pass to the
<a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel.predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a>
method as the <code class="docutils literal notranslate"><span class="pre">state</span></code> parameter. This parameter is passed by reference;
the state isn’t saved to the model. You can use one state,
then use another state, and then go back to the first state, as shown in the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">state1</span> <span class="o">=</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">make_state</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using first state&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state1</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># (2)^2 </span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state1</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># (5+2)^2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state1</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># (-1+5+2)^2</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">state2</span> <span class="o">=</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">make_state</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using second state&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">9.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state2</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># (9)^2 </span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state2</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1"># (2+9)^2</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Back to first state&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state1</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1">#(3-1+5+2)^2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">7.</span><span class="p">])},</span> <span class="n">state</span><span class="o">=</span><span class="n">state1</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span> <span class="c1">#(7+3-1+5+2)^2</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Using first state
[4.]
[49.]
[36.]

Using second state
[81.]
[121.]

Back to first state
[81.]
[256.]
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Comparing torch model’s numerical outputs with the converted Core ML stateful
model outputs to verify numerical match has to be done carefully, as
running it more than once changes the value of the state and hence the outputs accordingly.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the Core ML Tools Python API, state values are opaque.
You can get a new state and pass a state to <code class="docutils literal notranslate"><span class="pre">predict</span></code>,
but you cannot inspect the state or change values of tensors in the state.
However <a class="reference external" href="https://developer.apple.com/documentation/coreml/mlstate">APIs</a>
in the Core ML Framework allow to inspect and modify the state.</p>
</div>
</section>
<section id="creating-a-stateful-model-in-mil">
<h2>Creating a Stateful Model in MIL<a class="headerlink" href="#creating-a-stateful-model-in-mil" title="Permalink to this heading">#</a></h2>
<p>You can use the <a class="reference external" href="https://apple.github.io/coremltools/docs-guides/source/model-intermediate-language.html">Model Intermediate Language</a> (MIL) to create a stateful model directly from MIL ops. Construct a MIL program using the Python <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.html#module-coremltools.converters.mil.mil"><code class="docutils literal notranslate"><span class="pre">Builder</span></code></a> class for MIL as shown in the following example, which creates a simple accumulator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Builder</span> <span class="k">as</span> <span class="n">mb</span><span class="p">,</span> <span class="n">types</span>

<span class="nd">@mb</span><span class="o">.</span><span class="n">program</span><span class="p">(</span><span class="n">input_specs</span><span class="o">=</span><span class="p">[</span><span class="n">mb</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">fp16</span><span class="p">),</span> 
                         <span class="n">mb</span><span class="o">.</span><span class="n">StateTensorSpec</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">fp16</span><span class="p">),],)</span>
<span class="k">def</span> <span class="nf">prog</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">accumulator_state</span><span class="p">):</span>
    <span class="c1"># Read state</span>
    <span class="n">accumulator_value</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">read_state</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">accumulator_state</span><span class="p">)</span>
    <span class="c1"># Update value</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">accumulator_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="c1"># Write state</span>
    <span class="n">mb</span><span class="o">.</span><span class="n">coreml_update_state</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">accumulator_state</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y</span>

<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span><span class="n">minimum_deployment_target</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">iOS18</span><span class="p">)</span>
</pre></div>
</div>
<p>The result is a stateful Core ML model (<code class="docutils literal notranslate"><span class="pre">mlmodel</span></code>), converted from the MIL representation.</p>
</section>
<section id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this heading">#</a></h2>
<p>Using state input types can be convenient for working with models that
require storing some intermediate values, updating them and then reusing them
in subsequent predictions to avoid extra computations.
One such example of a model is a language model (LM) that uses the <a class="reference external" href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)">transformer
architecture</a>
and attention blocks. An LM typically works by digesting sequences of
input data and producing output tokens in an
auto-regressive manner: that is, producing one output token at a time,
updating some internal state in the process,
using that token and updated state to do the next prediction to produce the next output
token, and so on.</p>
<p>In the case of a transformer,
which involves three large tensors
that the model processes : “Query”, “Key”, and “Value”, a common
optimization strategy is to avoid extra computations at token generation time
by caching the “Key” and “Value” tensors and updating them incrementally to be reused in
each iteration of processing new tokens.
This optimization can be applied to Core ML models by making the Key-Values,
as explicit inputs/outputs of the model.
Here is where State model types can also be utilized for more convenience and
potential runtime performance improvements.
For instance, please check out the <a class="reference external" href="https://developer.apple.com/videos/play/wwdc2024/10159/">2024 WWDC session</a> for an
example that uses the <a class="reference external" href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Mistral 7B model</a>
and utilizes the stateful prediction feature for improved performance on a GPU on a macbook pro.<br />
The code for converting and deploying Mistral 7B model is released in <a class="reference external" href="https://github.com/huggingface/swift-transformers/blob/preview/Examples/Mistral7B/export.py">Hugging Face Mistral7B Example</a> along with the
<a class="reference external" href="https://huggingface.co/blog/mistral-coreml">blog article</a>.</p>
</section>
<section id="example-toy-attention-model-with-stateful-kv-cache">
<h2>Example: Toy Attention Model with Stateful KV-Cache<a class="headerlink" href="#example-toy-attention-model-with-stateful-kv-cache" title="Permalink to this heading">#</a></h2>
<p>To help you better understand how to make an attention model stateful with key cache and value cache, here is a
toy example.</p>
<p>We start with a toy model with simple attention, where the <code class="docutils literal notranslate"><span class="pre">query</span></code>, <code class="docutils literal notranslate"><span class="pre">key</span></code>, and <code class="docutils literal notranslate"><span class="pre">value</span></code> are calculated by a linear layer
and then fed into the <code class="docutils literal notranslate"><span class="pre">scaled_dot_product_attention</span></code>.
This toy example only focuses on stateful kv-cache, so it omits other details such as multi-head, multi-layer,
positional encoding, final logits, etc.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">SimpleAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">):</span>
         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, embed_size)</span>
         <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, embed_size)</span>
         <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, embed_size)</span>
         <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ToyModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">):</span>
         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">SimpleAttention</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">attention_output</span><span class="p">)</span>
</pre></div>
</div>
<p>To use key cache and value cache for attention, we can write a new class <code class="docutils literal notranslate"><span class="pre">SimpleAttentionWithKeyValueCache</span></code> which
inherits the <code class="docutils literal notranslate"><span class="pre">SimpleAttention</span></code>, and the in the <code class="docutils literal notranslate"><span class="pre">forward</span></code> function we re-use previously computed <code class="docutils literal notranslate"><span class="pre">k</span></code> and <code class="docutils literal notranslate"><span class="pre">v</span></code>,
and fill the newly computed <code class="docutils literal notranslate"><span class="pre">k</span></code> and <code class="docutils literal notranslate"><span class="pre">v</span></code> back to the cache.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleAttentionWithKeyValueCache</span><span class="p">(</span><span class="n">SimpleAttention</span><span class="p">):</span>
<span class="w">     </span><span class="sd">&quot;&quot;&quot;Add kv-cache into SimpleAttention.&quot;&quot;&quot;</span>

     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">k_cache</span><span class="p">,</span> <span class="n">v_cache</span><span class="p">):</span>
         <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="n">newly_computed_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="n">newly_computed_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

         <span class="c1"># Update kv-cache in-place.</span>
         <span class="n">q_len</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
         <span class="n">end_step</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
         <span class="n">past_kv_len</span> <span class="o">=</span> <span class="n">end_step</span> <span class="o">-</span> <span class="n">q_len</span>
         <span class="n">k_cache</span><span class="p">[:,</span> <span class="n">past_kv_len</span><span class="p">:</span><span class="n">end_step</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">newly_computed_k</span>
         <span class="n">v_cache</span><span class="p">[:,</span> <span class="n">past_kv_len</span><span class="p">:</span><span class="n">end_step</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">newly_computed_v</span>

         <span class="c1"># The K and V we need is (batch_size, q_len + past_kv_len, embed_size).</span>
         <span class="n">K</span> <span class="o">=</span> <span class="n">k_cache</span><span class="p">[:,</span> <span class="p">:</span><span class="n">end_step</span><span class="p">,</span> <span class="p">:]</span>
         <span class="n">V</span> <span class="o">=</span> <span class="n">v_cache</span><span class="p">[:,</span> <span class="p">:</span><span class="n">end_step</span><span class="p">,</span> <span class="p">:]</span>

         <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span>
             <span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">attention_mask</span>
         <span class="p">)</span>
</pre></div>
</div>
<p>Then the toy model with kv-cache will look like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ToyModelWithKeyValueCache</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="p">):</span>
         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">SimpleAttentionWithKeyValueCache</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

         <span class="bp">self</span><span class="o">.</span><span class="n">kvcache_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;k_cache&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kvcache_shape</span><span class="p">))</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;v_cache&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kvcache_shape</span><span class="p">))</span>

     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
         <span class="bp">self</span><span class="p">,</span>
         <span class="n">input_ids</span><span class="p">,</span>  <span class="c1"># [batch_size, seq_len]</span>
         <span class="n">causal_mask</span><span class="p">,</span>  <span class="c1"># [batch_size, seq_len, seq_len + past_kv_len]</span>
     <span class="p">):</span>
         <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
         <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">causal_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_cache</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_cache</span><span class="p">)</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">attention_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Now let’s compare the speed between the original model and the stateful kv-cache model.</p>
<p>First we set up some hyper-parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">max_seq_len</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>The original model could be initialized and converted by the following code snippet.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">torch_model</span> <span class="o">=</span> <span class="n">ToyModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
<span class="n">torch_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">))</span>
<span class="n">torch_output</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_model</span><span class="p">,</span> <span class="p">[</span><span class="n">input_ids</span><span class="p">])</span>
<span class="n">query_length</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">RangeDim</span><span class="p">(</span><span class="n">lower_bound</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_ids&quot;</span><span class="p">)]</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)]</span>

<span class="n">converted_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
     <span class="n">traced_model</span><span class="p">,</span>
     <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
     <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
     <span class="n">minimum_deployment_target</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">iOS18</span><span class="p">,</span>
     <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_AND_GPU</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Notice that the <code class="docutils literal notranslate"><span class="pre">minimum_deployment_target=ct.target.iOS18</span></code> is not necessary if you only
want to use the stateless model, as stateless models are supported before iOS18.
Here we set it just for fair comparison with the stateful kvcache model later.</p>
<p>We can time the prediction of the stateless model</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>

<span class="n">t_start</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
     <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">token_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)}</span>
     <span class="n">converted_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Time without kv-cache: </span><span class="si">{</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.0e3</span><span class="si">}</span><span class="s2"> ms&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now let’s initialize and convert the stateful kv-cache model in a similar way</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">past_kv_len</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">torch_model_kvcache</span> <span class="o">=</span> <span class="n">ToyModelWithKeyValueCache</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_seq_len</span>
<span class="p">)</span>
<span class="n">torch_model_kvcache</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">torch_model_kvcache</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">causal_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">+</span> <span class="n">past_kv_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Make sure the output matches the non-kv-cache version.</span>
<span class="n">torch_kvcache_output</span> <span class="o">=</span> <span class="n">torch_model_kvcache</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">causal_mask</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">torch_output</span><span class="p">,</span> <span class="n">torch_kvcache_output</span><span class="p">)</span>

<span class="n">traced_model_kvcache</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_model_kvcache</span><span class="p">,</span> <span class="p">[</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">causal_mask</span><span class="p">])</span>
<span class="n">query_length</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">RangeDim</span><span class="p">(</span><span class="n">lower_bound</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">end_step_dim</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">RangeDim</span><span class="p">(</span><span class="n">lower_bound</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_ids&quot;</span><span class="p">),</span>
    <span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_length</span><span class="p">,</span> <span class="n">end_step_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;causal_mask&quot;</span>
    <span class="p">),</span>
<span class="p">]</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)]</span>

<span class="c1"># In addition to `inputs` and `outputs`, we need `states` which uses the same name as the</span>
<span class="c1"># registered buffers in `ToyModelWithKeyValueCache`.</span>
<span class="n">states</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ct</span><span class="o">.</span><span class="n">StateType</span><span class="p">(</span>
        <span class="n">wrapped_type</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">torch_model_kvcache</span><span class="o">.</span><span class="n">kvcache_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span>
        <span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;k_cache&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">ct</span><span class="o">.</span><span class="n">StateType</span><span class="p">(</span>
        <span class="n">wrapped_type</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">torch_model_kvcache</span><span class="o">.</span><span class="n">kvcache_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span>
        <span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;v_cache&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">]</span>
<span class="n">converted_model_kvcache</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
    <span class="n">traced_model_kvcache</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
    <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
    <span class="n">minimum_deployment_target</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">iOS18</span><span class="p">,</span>
    <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_AND_GPU</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We can also time the prediction of this stateful kv-cache model</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">past_kv_len</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">kv_cache_state</span> <span class="o">=</span> <span class="n">converted_model_kvcache</span><span class="o">.</span><span class="n">make_state</span><span class="p">()</span>
<span class="n">t_start</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">token_id</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="s2">&quot;causal_mask&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">past_kv_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">converted_model_kvcache</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">kv_cache_state</span><span class="p">)</span>
    <span class="n">past_kv_len</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Time with kv-cache: </span><span class="si">{</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.0e3</span><span class="si">}</span><span class="s2"> ms&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>After running the prediction, we can get the following output (on a MacBook Pro with M3 Max chip)</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Time (ms) without kv-cache: 4245.6
Time (ms) with kv-cache: 238.0
</pre></div>
</div>
<p>It demonstrates how to modify the attention module to get a stateful model with kv-cache, which runs much faster than
the original stateless model.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="image-inputs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Image Input and Output</p>
      </div>
    </a>
    <a class="right-next"
       href="classifiers.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classifiers</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-a-simple-accumulator">Example: A Simple Accumulator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-states-for-a-pytorch-model">Registering States for a PyTorch Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-to-a-stateful-core-ml-model">Converting to a Stateful Core ML Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-states-with-predictions">Using States with Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-stateful-model-in-mil">Creating a Stateful Model in MIL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-toy-attention-model-with-stateful-kv-cache">Example: Toy Attention Model with Stateful KV-Cache</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apple
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Apple Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>