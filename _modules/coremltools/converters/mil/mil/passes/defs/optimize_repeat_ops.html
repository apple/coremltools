<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops &mdash; coremltools API Reference 7.1 documentation</title>
      <link rel="stylesheet" href="../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/css/norightmargin.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../../../" id="documentation_options" src="../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../../../../_static/doctools.js"></script>
        <script src="../../../../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../index.html" class="icon icon-home">
            coremltools API Reference
          </a>
              <div class="version">
                7.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.models.html">Model APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html">MIL Graph Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/coremltools.optimize.html">Optimizers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/docs-guides/index.html">Guide and Examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../source/api-versions.html">Previous Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Copyright (c) 2023, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1">#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">coremltools</span> <span class="kn">import</span> <span class="n">_logger</span> <span class="k">as</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Block</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Builder</span> <span class="k">as</span> <span class="n">mb</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Function</span><span class="p">,</span> <span class="n">Operation</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.graph_pass</span> <span class="kn">import</span> <span class="n">AbstractGraphPass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.helper</span> <span class="kn">import</span> <span class="n">_check_child_op_type</span><span class="p">,</span> <span class="n">block_context_manager</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.pass_registry</span> <span class="kn">import</span> <span class="n">register_pass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.types.symbolic</span> <span class="kn">import</span> <span class="n">any_symbolic</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.types.type_mapping</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RangeTuple</span><span class="p">,</span>
    <span class="n">builtin_to_range</span><span class="p">,</span>
    <span class="n">builtin_to_resolution</span><span class="p">,</span>
    <span class="n">string_to_builtin</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.var</span> <span class="kn">import</span> <span class="n">Var</span>


<div class="viewcode-block" id="merge_consecutive_paddings"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.merge_consecutive_paddings">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">merge_consecutive_paddings</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Identify two consecutive ``pad`` layers which could be merged into a single ``pad`` layer.</span>

<span class="sd">    This is possible only if one of the following conditions is satisfied:</span>

<span class="sd">    - The paddings are &quot;constant&quot; and have the same ``constant_val``.</span>
<span class="sd">    - The paddings act along different axes.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Input graph:</span>
<span class="sd">        input(1, 2, 6, 8) ------&gt; pad([1, 1], mode=&#39;reflect) -----&gt; pad([1, 1, 0, 0], mode=&#39;reflect&#39;) ---&gt; out(1, 2, 8, 10)</span>

<span class="sd">        Output graph:</span>
<span class="sd">        input(1, 2, 6, 8) ------&gt; pad([1, 1, 1, 1], mode=&#39;reflect) ---&gt; out(1, 2, 8, 10)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                <span class="n">block_changed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_padding_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">padding_op</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;pad&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">padding_op</span><span class="p">,</span> <span class="s2">&quot;pad&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">child_padding_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">padding_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span> <span class="o">!=</span> <span class="n">child_padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Ensure the paddings have the same length by prepending zeros to the shorter one</span>
        <span class="n">first_pad</span> <span class="o">=</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">child_pad</span> <span class="o">=</span> <span class="n">child_padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_pad</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_pad</span><span class="p">):</span>
            <span class="n">child_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">child_pad</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">first_pad</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_pad</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">child_pad</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_pad</span><span class="p">):</span>
            <span class="n">first_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">first_pad</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">child_pad</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_pad</span><span class="p">)))</span>
        <span class="n">final_pad</span> <span class="o">=</span> <span class="n">child_pad</span> <span class="o">+</span> <span class="n">first_pad</span>

        <span class="k">if</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
            <span class="c1"># if the padding is constant, then the values need to be equal</span>
            <span class="k">if</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;constant_val&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span> <span class="o">!=</span> <span class="n">child_padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;constant_val&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if the padding is not constant, then we can&#39;t merge if both pads affected the same</span>
            <span class="c1"># side of the image</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">first_pad</span><span class="p">,</span> <span class="n">child_pad</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">padding_op</span><span class="p">,</span> <span class="n">child_padding_op</span><span class="p">,</span> <span class="n">final_pad</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">padding_op</span><span class="p">,</span> <span class="n">child_padding_op</span><span class="p">,</span> <span class="n">final_pad</span><span class="p">):</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;mode&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
            <span class="n">pad</span><span class="o">=</span><span class="n">final_pad</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">constant_val</span><span class="o">=</span><span class="n">padding_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;constant_val&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
            <span class="n">before_op</span><span class="o">=</span><span class="n">padding_op</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">padding_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">padding_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">child_padding_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">x</span>
        <span class="p">)</span>
        <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">padding_op</span><span class="p">,</span> <span class="n">child_padding_op</span><span class="p">])</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_merge_padding_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_pattern</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">op</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="merge_consecutive_transposes"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.merge_consecutive_transposes">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">merge_consecutive_transposes</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Identify consecutive &#39;transpose&#39; layers which could be merged into a single &#39;transpose&#39; layer.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Input graph:</span>
<span class="sd">        input ------&gt; transpose -----&gt; 1 or more transpose layers ---&gt; out</span>

<span class="sd">        Output graph:</span>
<span class="sd">        input ------&gt; transpose ---&gt; out</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_merge_transposes_in_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_match_and_replace_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">transpose_op</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;transpose&quot;</span> <span class="ow">and</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">,</span> <span class="s2">&quot;transpose&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">child_transpose_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">transpose_op</span><span class="p">,</span> <span class="n">child_transpose_op</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">transpose_op</span><span class="p">,</span> <span class="n">child_transpose_op</span><span class="p">):</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">perm</span><span class="o">.</span><span class="n">val</span>
        <span class="n">new_perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">perm</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">child_transpose_op</span><span class="o">.</span><span class="n">perm</span><span class="o">.</span><span class="n">val</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">transpose_op</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">new_perm</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">transpose_op</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transpose_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">transpose_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">child_transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">transpose_op</span><span class="p">,</span> <span class="n">child_transpose_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_merge_transposes_in_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">help_merge_transpose_ops</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_and_replace_pattern</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_merge_transpose_ops</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>


<div class="viewcode-block" id="merge_consecutive_relus"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.merge_consecutive_relus">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">merge_consecutive_relus</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Identify consecutive ``relu`` layers which could be merged into a single ``relu`` layer.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Input graph:</span>
<span class="sd">        input ------&gt; relu -----&gt; 1 or more relu layers ---&gt; out</span>

<span class="sd">        Output graph:</span>
<span class="sd">        input ------&gt; relu ---&gt; out</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_merge_relus_in_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_match_and_replace_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">relu_op</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">relu_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span> <span class="ow">and</span> <span class="n">_check_child_op_type</span><span class="p">(</span><span class="n">relu_op</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">child_relu_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">relu_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">relu_op</span><span class="p">,</span> <span class="n">child_relu_op</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_ops</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">relu_op</span><span class="p">,</span> <span class="n">child_relu_op</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">relu_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">try_replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">relu_op</span><span class="p">,</span> <span class="n">old_var</span><span class="o">=</span><span class="n">child_relu_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_var</span><span class="o">=</span><span class="n">relu_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">child_relu_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_merge_relus_in_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">help_merge_relu_ops</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_and_replace_pattern</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_merge_relu_ops</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>


<div class="viewcode-block" id="merge_consecutive_reshapes"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.merge_consecutive_reshapes">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">merge_consecutive_reshapes</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Identify consecutive ``reshape`` ops which could be merged into a single ``reshape``.</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        Input graph:</span>
<span class="sd">        input -&gt; reshape -&gt; 1 or more reshapes -&gt; output</span>

<span class="sd">        Output graph:</span>
<span class="sd">        input -&gt; reshape -&gt; output</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># TODO (rdar://105227587): merge a tree of consecutive reshapes</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_merge_consecutive_reshapes_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_match_pattern</span><span class="p">(</span><span class="n">reshape_op</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a ``reshape`` op,</span>
<span class="sd">        consider it as the head of a sequence of ``reshape`` ops, and</span>
<span class="sd">        then end the sequence at a non-removable ``reshape`` op.</span>
<span class="sd">        Return this sequence as a list.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">reshape_op</span>

        <span class="k">while</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;reshape&quot;</span><span class="p">:</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="c1"># current reshape has 0 or 2+ child ops:</span>
            <span class="c1"># * no child: this is the end of graph</span>
            <span class="c1"># * 2+ children: only pattern of sequential reshape ops (1 child)</span>
            <span class="c1">#   is supported for now. For more general cases, please see TODO below</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="c1"># current reshape output is a block output, so it is non-removable</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">op</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_merge_consecutive_reshapes_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">help_merge_consecutive_reshapes_block</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                    <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
                        <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_merge_consecutive_reshapes_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
                <span class="c1"># move on to the next op if this op is not reshape</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;reshape&quot;</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="n">reshape_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_match_pattern</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="c1"># merge the list of consecutive reshape ops</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reshape_ops</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># create a new reshape op</span>
                    <span class="n">reshape_out</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                        <span class="n">before_op</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="p">)</span>
                    <span class="c1"># replace the consecutive reshape ops with the new reshape op</span>
                    <span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                        <span class="n">anchor_op</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                        <span class="n">old_var</span><span class="o">=</span><span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">new_var</span><span class="o">=</span><span class="n">reshape_out</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">reshape_ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">reshape_ops</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="n">help_merge_consecutive_reshapes_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>

<span class="k">class</span> <span class="nc">CastOptimizationNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_type</span><span class="p">,</span> <span class="n">match_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        param op_type : Type of an operation.</span>
<span class="sd">        param match_criterion : A callable function that matches a MIL op and returns a boolean.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        .. sourcecode:: python</span>

<span class="sd">            CastOptimizationNode(&quot;mul&quot;),</span>
<span class="sd">            CastOptimizationNode(&quot;round&quot;),</span>
<span class="sd">            CastOptimizationNode(&quot;add&quot;, lambda op: op.y.val == 0),</span>
<span class="sd">            CastOptimizationNode(&quot;clip&quot;, lambda op: op.alpha.val == -128 and op.beta.val == 127),</span>
<span class="sd">            CastOptimizationNode(&quot;cast&quot;, lambda op: op.dtype.val == &quot;int8&quot;),</span>
<span class="sd">            CastOptimizationNode(&quot;cast&quot;, lambda op: op.dtype.val == &quot;fp32&quot;),</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">op_type</span> <span class="o">=</span> <span class="n">op_type</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">match_criterion</span><span class="p">:</span>
            <span class="n">match_criterion</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">op</span><span class="p">:</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">match_criterion</span> <span class="o">=</span> <span class="n">match_criterion</span>

<div class="viewcode-block" id="cast_optimization"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.cast_optimization">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">cast_optimization</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This optimization pass performs the following:</span>

<span class="sd">    - Removes redundant ``cast`` op; that is, ``cast`` where source and destination tensors have same dtypes.</span>
<span class="sd">    - Fuses two consecutive `cast` ops if applicable, repeatedly.</span>

<span class="sd">    This is a non-algebraic translation which assumes that the upcasting doesn&#39;t change the user&#39;s intent.</span>

<span class="sd">    (1) Example for redundant ``cast`` op removal:</span>
<span class="sd">        .. code-block::</span>

<span class="sd">            Input graph:</span>
<span class="sd">            input(fp16) -&gt; cast(dtype=&quot;fp16&quot;) -&gt; relu -&gt; out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            input -&gt; relu -&gt; out</span>

<span class="sd">        The input and output tensors for the ``cast`` op are both with type of ``fp16``. Hence, it can be removed.</span>

<span class="sd">    (2) Example for two ``cast`` ops fusion:</span>
<span class="sd">        .. code-block::</span>

<span class="sd">            Input graph:</span>
<span class="sd">            input(int8) -&gt; cast(dtype=&quot;fp16&quot;) -&gt; cast(dtype=&quot;fp32&quot;) -&gt; out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            input(int8) -&gt; cast(dtype=&quot;fp32&quot;) -&gt; out</span>

<span class="sd">        The data range and resolution of the above graph are limited by the int8 input, so the fusion is allowed.</span>

<span class="sd">    (3) Negative example for two ``cast`` ops fusion:</span>
<span class="sd">        .. code-block::</span>
<span class="sd">            Input graph:</span>
<span class="sd">            input(fp32) -&gt; cast(dtype=&quot;bool&quot;) -&gt; cast(dtype=&quot;fp16&quot;) -&gt; out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            Same as input graph.</span>

<span class="sd">        The above two ``cast`` ops cannot be merged, since after the first cast, the resolution of the numerical output</span>
<span class="sd">        is downcasted to binary (``0, 1``). If we fuse them, the output would be in the range and resolution of ``fp16`` instead.</span>

<span class="sd">    (3) Another Negative example for two ``cast`` ops fusion:</span>
<span class="sd">        .. code-block::</span>
<span class="sd">            Input graph:</span>
<span class="sd">            input(int32) -&gt; cast(dtype=&quot;int8&quot;) -&gt; cast(dtype=&quot;uint8&quot;) -&gt; out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            Same as input graph.</span>

<span class="sd">        The above two ``cast`` ops cannot be merged, since in the original graph, by going through two casts,</span>
<span class="sd">        the output numerical range is capped to ``[0, 127]``.</span>

<span class="sd">        However, if two ``cast`` ops are reduced to 1 ``cast(dtype=&quot;uint8&quot;)``, the output numerical would in the range of ``[0, 255]``.</span>
<span class="sd">        The fusion would cause numerical issue for the numbers between ``[128, 255]``, which is prohibited.</span>

<span class="sd">    In general, two ``cast`` ops can be merged if the output data range and resolution is not affected.</span>

<span class="sd">    For more examples, please see the unittests start with prefix &quot;TestCastOptimization&quot; in test_passes.py</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_or_cancel_consecutive_casts_block_wrapper</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_propagate_range_resolution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dtype</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span> <span class="n">dtype_chain</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">type</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given an input type ``in_dtype``, and a chain of casting, return the resulting output data range and resolution.</span>

<span class="sd">        For example, ``in_dtype = fp32`` and ``dtype_chain = [int8, int32]``. This means an input data with type ``fp32``,</span>
<span class="sd">        is propagated through ``cast(dtype=&quot;int8&quot;)`` and ``cast(dtype=&quot;int32&quot;)`` in order.</span>

<span class="sd">        1. The input fp32 data range is ``[-3.4e+38, 3.4e+38]`` with resolution ``1e-06``.</span>
<span class="sd">        2. After the first ``cast(dtype=&quot;int8&quot;)`` downcast, the range becomes ``[-128, 127]`` with resolution ``1``.</span>
<span class="sd">        3. Even the ``int32`` has a larger range, the resulting range is still capped to ``[-128, 127]``.</span>

<span class="sd">        For the above example, this function returns range of ``[-128, 127]`` and resolution ``1``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype_chain</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
        <span class="n">cur_range</span><span class="p">,</span> <span class="n">cur_resolution</span> <span class="o">=</span> <span class="n">builtin_to_range</span><span class="p">(</span><span class="n">in_dtype</span><span class="p">),</span> <span class="n">builtin_to_resolution</span><span class="p">(</span><span class="n">in_dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dtype_chain</span><span class="p">:</span>
            <span class="n">tmp_range</span><span class="p">,</span> <span class="n">tmp_resolution</span> <span class="o">=</span> <span class="n">builtin_to_range</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">builtin_to_resolution</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="n">cur_range</span> <span class="o">=</span> <span class="n">RangeTuple</span><span class="p">(</span>
                <span class="nb">max</span><span class="p">(</span><span class="n">cur_range</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">tmp_range</span><span class="o">.</span><span class="n">low</span><span class="p">),</span> <span class="nb">min</span><span class="p">(</span><span class="n">cur_range</span><span class="o">.</span><span class="n">high</span><span class="p">,</span> <span class="n">tmp_range</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">cur_resolution</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">cur_resolution</span><span class="p">,</span> <span class="n">tmp_resolution</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cur_range</span><span class="p">,</span> <span class="n">cur_resolution</span>

    <span class="k">def</span> <span class="nf">_is_cast_ops_fusable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cast_1</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">cast_2</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if two cast ops can be fused by verifying the consistency between the range and resolution before and after fusion.</span>

<span class="sd">        Take the same example shown in ``_propagate_range_resolution``:</span>

<span class="sd">            input(fp32) -&gt; cast(dtype=&quot;int8&quot;) -&gt; cast(dtype=&quot;int32&quot;)</span>

<span class="sd">        The original pattern has output range and resolution ``[-128, 127]``, ``1``.</span>

<span class="sd">        However, if the two ``cast`` ops are fused:</span>

<span class="sd">            input(fp32) -&gt; cast(dtype=&quot;int32&quot;)</span>

<span class="sd">        The output range becomes the range of int32, which is not ``[-128, 127]``.</span>
<span class="sd">        As the result, the fusion is prohibited.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_dtype</span><span class="p">,</span> <span class="n">cast_1_dtype</span><span class="p">,</span> <span class="n">cast_2_dtype</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cast_1</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">string_to_builtin</span><span class="p">(</span><span class="n">cast_1</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">val</span><span class="p">),</span>
            <span class="n">string_to_builtin</span><span class="p">(</span><span class="n">cast_2</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">val</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">ref_range</span><span class="p">,</span> <span class="n">ref_resolution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_propagate_range_resolution</span><span class="p">(</span>
            <span class="n">x_dtype</span><span class="p">,</span> <span class="p">(</span><span class="n">cast_1_dtype</span><span class="p">,</span> <span class="n">cast_2_dtype</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">out_range</span><span class="p">,</span> <span class="n">out_resolution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_propagate_range_resolution</span><span class="p">(</span><span class="n">x_dtype</span><span class="p">,</span> <span class="p">(</span><span class="n">cast_2_dtype</span><span class="p">,))</span>

        <span class="k">return</span> <span class="n">out_range</span> <span class="o">==</span> <span class="n">ref_range</span> <span class="ow">and</span> <span class="n">out_resolution</span> <span class="o">==</span> <span class="n">ref_resolution</span>

    <span class="k">def</span> <span class="nf">_dup_if_affect_io</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_var</span><span class="p">:</span> <span class="n">Var</span><span class="p">,</span> <span class="n">old_var</span><span class="p">:</span> <span class="n">Var</span><span class="p">,</span> <span class="n">before_op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We cannot replace old_var with new_var, if:</span>
<span class="sd">        1. old_var is a function output</span>
<span class="sd">        2. new_var is a function input</span>
<span class="sd">        Since the name of the function is going to be changed and become invalid.</span>

<span class="sd">        For this special corner case, we use an identity op to duplicate the new_var.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">block_1</span> <span class="o">=</span> <span class="n">before_op</span><span class="o">.</span><span class="n">enclosing_block</span>
        <span class="n">is_new_var_function_input</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">block_1</span><span class="p">,</span> <span class="n">Function</span><span class="p">)</span> <span class="ow">and</span> <span class="n">new_var</span> <span class="ow">in</span> <span class="n">block_1</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">block_2</span> <span class="o">=</span> <span class="n">old_var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span>
        <span class="n">is_old_var_function_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block_2</span><span class="p">,</span> <span class="n">Function</span><span class="p">)</span> <span class="ow">and</span> <span class="n">old_var</span> <span class="ow">in</span> <span class="n">block_2</span><span class="o">.</span><span class="n">outputs</span>

        <span class="k">if</span> <span class="n">is_new_var_function_input</span> <span class="ow">and</span> <span class="n">is_old_var_function_output</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mb</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">before_op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_var</span>

    <span class="k">def</span> <span class="nf">_fuse_cast_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cast_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Operation</span><span class="p">],</span> <span class="n">reuse_input_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fuse the pattern of:</span>
<span class="sd">            input -&gt; cast_1(dtype=dtype_1) -&gt; cast_2(dtype=dtype_2) -&gt; out</span>

<span class="sd">        If ``reuse_input_var = True``, the pattern is reduced to:</span>
<span class="sd">            input -&gt; out</span>

<span class="sd">        otherwise, a new ``cast`` op with the same ``dtype`` as ``cast_2`` is created:</span>
<span class="sd">            input -&gt; cast_3(dtype=dtype_2) -&gt; out</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cast_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">cast_ops</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="n">cast_ops</span><span class="p">,))</span>

        <span class="n">ops_to_remove</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">cast_1</span><span class="p">,</span> <span class="n">cast_2</span> <span class="ow">in</span> <span class="n">cast_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">reuse_input_var</span><span class="p">:</span>
                <span class="n">new_output_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dup_if_affect_io</span><span class="p">(</span><span class="n">cast_1</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">cast_2</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cast_1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fused_output_var_name</span> <span class="o">=</span> <span class="n">cast_1</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_to_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cast_2</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
                <span class="n">new_output_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">cast_1</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">cast_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">fused_output_var_name</span><span class="p">,</span>
                    <span class="n">before_op</span><span class="o">=</span><span class="n">cast_2</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="c1"># It&#39;s important to use `cast_2.enclosing_block` since `cast_2` might be present in a block nested under `cast_1.enclosing_block`</span>
            <span class="n">cast_2</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">cast_2</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="n">cast_2</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">new_output_var</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Remove just the last cast op and let dce eliminate the rest of the ops if needed,</span>
            <span class="c1"># The reason is that first cast op could be feeding into other non-cast ops.</span>
            <span class="n">ops_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cast_2</span><span class="p">)</span>

        <span class="n">ops_to_remove</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">ops_to_remove</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_try_to_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root_op</span><span class="p">,</span> <span class="n">cast_ops_across_blocks</span><span class="p">):</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">root_op</span><span class="o">.</span><span class="n">enclosing_block</span>

        <span class="c1"># Scenario: Redundant cast when source and destination dtype are same.</span>
        <span class="k">if</span> <span class="n">root_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;cast&quot;</span> <span class="ow">and</span> <span class="n">root_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">is_tensor_or_scalar_of</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">root_op</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">val</span><span class="p">):</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">root_op</span><span class="o">.</span><span class="n">x</span>
            <span class="n">old_var</span> <span class="o">=</span> <span class="n">root_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dup_if_affect_io</span><span class="p">(</span><span class="n">root_op</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">old_var</span><span class="p">,</span> <span class="n">root_op</span><span class="p">)</span>
            <span class="n">block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">root_op</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="n">old_var</span><span class="p">,</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">root_op</span><span class="p">])</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># Scenario: Consecutive casts</span>
        <span class="n">candidate_child_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">root_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;cast&quot;</span><span class="p">:</span>
                <span class="n">candidate_child_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="n">fusion_happens</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">child_op</span> <span class="ow">in</span> <span class="n">candidate_child_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_cast_ops_fusable</span><span class="p">(</span><span class="n">root_op</span><span class="p">,</span> <span class="n">child_op</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">root_op</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">is_tensor_or_scalar_of</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">child_op</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">val</span><span class="p">):</span>
                <span class="c1"># when consecutive casts cancel each other</span>
                <span class="c1"># Please check out: test_linear_consecutive_cast_ops_cancellation in TestCastOptimization</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_cast_ops</span><span class="p">((</span><span class="n">root_op</span><span class="p">,</span> <span class="n">child_op</span><span class="p">),</span> <span class="n">reuse_input_var</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">fusion_happens</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">child_op</span><span class="o">.</span><span class="n">enclosing_block</span> <span class="o">!=</span> <span class="n">block</span><span class="p">:</span>
                    <span class="c1"># If cast_2 is in an inner block, we handle it at once in a seperated function `_fuse_casts_ops_across_blocks`</span>
                    <span class="n">cast_ops_across_blocks</span><span class="p">[</span><span class="n">child_op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">root_op</span><span class="p">,</span> <span class="n">child_op</span><span class="p">))</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_cast_ops</span><span class="p">((</span><span class="n">root_op</span><span class="p">,</span> <span class="n">child_op</span><span class="p">))</span>
                <span class="n">fusion_happens</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">fusion_happens</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_fuse_casts_ops_across_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span> <span class="n">ops_to_fused</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Operation</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_cast_ops</span><span class="p">(</span><span class="n">ops_to_fused</span><span class="p">)</span>

    <span class="nd">@block_context_manager</span>
    <span class="k">def</span> <span class="nf">_fuse_or_cancel_consecutive_casts_block_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_fuse_or_cancel_consecutive_casts_block</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">cast_ops_across_blocks</span><span class="p">):</span>
            <span class="c1"># We first make sure all the inner blocks are optimized</span>
            <span class="c1"># It is important to do it seperately in the very beginning, to ensure the last step of optimization cast ops across the block boundary is correct.</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_or_cancel_consecutive_casts_block_wrapper</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">)):</span>
                <span class="c1"># start pattern match if cast op is encountered</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;cast&quot;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_to_transform</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">cast_ops_across_blocks</span><span class="p">):</span>
                        <span class="c1"># has to break as the downstream iterator is affected.</span>
                        <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">block_changed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">cast_ops_across_blocks</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">set</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">block_changed</span><span class="p">:</span>
            <span class="n">block_changed</span> <span class="o">=</span> <span class="n">_fuse_or_cancel_consecutive_casts_block</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">cast_ops_across_blocks</span><span class="p">)</span>

        <span class="c1"># fuse the cast ops across the inner / outer block boundary</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cast_ops_across_blocks</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_casts_ops_across_blocks</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">v</span><span class="p">))</span></div>

<span class="k">class</span> <span class="nc">TransformAxisUpdateOps</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parent class for every axis update op&#39;s class</span>

<span class="sd">    An axis update op is an op that can be updated, such that it can allow a transpose layer to &quot;pass&quot; through it.</span>
<span class="sd">    That is,</span>

<span class="sd">    op(transpose(x)) == transpose(op_updated(x))</span>

<span class="sd">    where</span>
<span class="sd">    &quot;op&quot; : original op,</span>
<span class="sd">    &quot;op_updated&quot;: op after being updated.</span>

<span class="sd">    Example:</span>

<span class="sd">    if x is a tensor of rank 2, and transpose has perm=[1,0],</span>
<span class="sd">    then</span>

<span class="sd">    reduce_mean[axis=1](transpose(x)) == transpose(reduce_mean[axis=0](x))</span>

<span class="sd">    here reduce_mean op with axis=1 can be updated to a reduce_mean op with axis=0,</span>
<span class="sd">    to allow the transpose to &quot;pass&quot; through it, i.e. get applied after it.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">transpose_axes</span><span class="p">,</span> <span class="n">var_to_hypothetical_value_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span> <span class="o">=</span> <span class="n">transpose_axes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value_dict</span> <span class="o">=</span> <span class="n">var_to_hypothetical_value_dict</span>

    <span class="k">def</span> <span class="nf">can_transpose_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Each &quot;axis&quot; op must determine whether it can act like a unary op</span>
<span class="sd">        and allow the transpose to pass through.</span>
<span class="sd">        Return True if it can allow the transpose to pass through, otherwise return False.</span>

<span class="sd">        :return: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This function must be implemented by each op&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that updates some attribute of the axis op,</span>
<span class="sd">        based on the transpose axes value.</span>
<span class="sd">        This method only gets called if &quot;can_transpose_pass&quot; returns True.</span>

<span class="sd">        Update the op such that the output %i2 should be equal to %o2</span>

<span class="sd">        Before:</span>
<span class="sd">        %i_1 = transpose_op(%i_0, perm=transpose_axes)</span>
<span class="sd">        %i2 = op(%i1)</span>

<span class="sd">        After:</span>
<span class="sd">        %o1 = op_updated(%i0)</span>
<span class="sd">        %o2 = transpose_op(%o1, perm=transpose_axes)</span>

<span class="sd">        :return: None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This function must be implemented by each op&quot;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_find_transpose_compliment</span><span class="p">(</span><span class="n">perm</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return the permutation value that when applied will reverse the</span>
<span class="sd">        effect of the given permutation.</span>

<span class="sd">        e.g.: if perm == (1, 2, 3, 0), then return (3, 0, 1, 2), which will undo the</span>
<span class="sd">        first permutation&#39;s effect</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span>
        <span class="n">all_positive_perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="o">+</span> <span class="n">rank</span> <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">perm</span><span class="p">]</span>
        <span class="n">perm_inverse</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="n">perm_inverse</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_positive_perm</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">perm_inverse</span>


<span class="k">class</span> <span class="nc">_HypotheticalValue</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A hypothetical value that simply wraps a Var. Actual Var it wraps doesn&#39;t really matter, as</span>
<span class="sd">    its mainly for debugging.</span>
<span class="sd">    This class really exists to differentiate a &quot;_LazyTransposeHypotheticalValue&quot; type with a</span>
<span class="sd">    non-&quot;_LazyTransposeHypotheticalValue&quot; type.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">var</span>  <span class="c1"># type : Var</span>


<span class="k">class</span> <span class="nc">_LazyTransposeHypotheticalValue</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A hypothetical value that represents a transpose op on top of a hypothetical value, or a</span>
<span class="sd">    collection of transpose_ops, which have the same &quot;perm&quot; parameter.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypothetical_value</span><span class="p">,</span> <span class="n">transpose_ops</span><span class="p">,</span> <span class="n">perm</span><span class="p">):</span>
        <span class="c1"># Input hypothetical value to the transpose op.</span>
        <span class="c1"># When there are multiple transpose ops, this is the incoming hypothetical value to any one of those</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrapped_hypothetical_value</span> <span class="o">=</span> <span class="n">hypothetical_value</span>  <span class="c1"># type : _HypotheticalValue</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypothetical_value</span><span class="p">,</span> <span class="n">_HypotheticalValue</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;transpose optimization pass: incorrect type passed for hypothetical_value&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">transpose_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;transpose&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;transpose optimization pass: _LazyTransposeHypotheticalValue can only be made with transpose ops&quot;</span>
                <span class="p">)</span>
            <span class="n">perm_op</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">perm_op</span> <span class="o">!=</span> <span class="n">perm</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;transpose optimization pass: _LazyTransposeHypotheticalValue can only be made with transpose ops with the same &#39;perm&#39; values&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">perm</span> <span class="o">=</span> <span class="n">perm</span>  <span class="c1"># type : list[int], perm parameter of all the transpose ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_ops</span> <span class="o">=</span> <span class="n">transpose_ops</span>  <span class="c1"># type : Set(op)</span>


<span class="k">class</span> <span class="nc">_TransposeOptimization</span><span class="p">:</span>
    <span class="n">_DEBUG</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Set to true to plot the block before and after the transformation.</span>

    <span class="c1"># Dictionary from axis update op to its class</span>
    <span class="c1"># This is filled in by child classes of the class &quot;TransformAxisUpdateOps&quot;.</span>
    <span class="n">_AXIS_UPDATE_OPS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="c1"># TODO: instead of a hard-coded set, use op-traits</span>
    <span class="c1"># These are the ops that satisfy the following property:</span>
    <span class="c1"># - single non constant input</span>
    <span class="c1"># - single output</span>
    <span class="c1"># - non rank changing</span>
    <span class="c1"># - doesn&#39;t need to be updated of a transpose passes through it. i.e.</span>
    <span class="c1">#  Transpose(op(x)) == op(Transpose(x))</span>
    <span class="n">_UNARY_LIKE_OP_TYPES</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;log&quot;</span><span class="p">,</span>
        <span class="s2">&quot;relu6&quot;</span><span class="p">,</span>
        <span class="s2">&quot;abs&quot;</span><span class="p">,</span>
        <span class="s2">&quot;acos&quot;</span><span class="p">,</span>
        <span class="s2">&quot;asin&quot;</span><span class="p">,</span>
        <span class="s2">&quot;atan&quot;</span><span class="p">,</span>
        <span class="s2">&quot;atanh&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ceil&quot;</span><span class="p">,</span>
        <span class="s2">&quot;clip&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cos&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cosh&quot;</span><span class="p">,</span>
        <span class="s2">&quot;erf&quot;</span><span class="p">,</span>
        <span class="s2">&quot;exp&quot;</span><span class="p">,</span>
        <span class="s2">&quot;exp2&quot;</span><span class="p">,</span>
        <span class="s2">&quot;floor&quot;</span><span class="p">,</span>
        <span class="s2">&quot;identity&quot;</span><span class="p">,</span>
        <span class="s2">&quot;logical_not&quot;</span><span class="p">,</span>
        <span class="s2">&quot;round&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rsqrt&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sin&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sinh&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
        <span class="s2">&quot;square&quot;</span><span class="p">,</span>
        <span class="s2">&quot;pow&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tan&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
        <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
        <span class="s2">&quot;clamped_relu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;elu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;linear_activation&quot;</span><span class="p">,</span>
        <span class="s2">&quot;scaled_tanh&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sigmoid_hard&quot;</span><span class="p">,</span>
        <span class="s2">&quot;softplus&quot;</span><span class="p">,</span>
        <span class="s2">&quot;softplus_parametric&quot;</span><span class="p">,</span>
        <span class="s2">&quot;softsign&quot;</span><span class="p">,</span>
        <span class="s2">&quot;thresholded_relu&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">block</span>

        <span class="c1"># for each var in the block, this dictionary stores the hypothetical value that is assigned to it during</span>
        <span class="c1"># graph traversal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{}</span>
        <span class="p">)</span>  <span class="c1"># type : var : _HypotheticalValue or _LazyTransposeHypotheticalValue</span>
        <span class="c1"># start out by filling this dictionary with all the inputs of the block</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">input_var</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">input_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">_HypotheticalValue</span><span class="p">(</span><span class="n">input_var</span><span class="p">)</span>

        <span class="c1"># Dictionaries below are used to store transpose cancellation/fusion information.</span>
        <span class="c1"># These are filled during the traversal of the graph,</span>
        <span class="c1"># after which they are used by the `_apply_transform` method</span>

        <span class="c1"># transpose op to the list of transpose ops that are its compliments and can be cancelled away with it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[])</span>  <span class="c1"># type : op : List[op]</span>

        <span class="c1"># transpose op to the list of ops before which it has to materialize, i.e. the root transpose op</span>
        <span class="c1">#  can be moved downstream in the graph, as far as these materialize ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="p">[]</span>
        <span class="p">)</span>  <span class="c1"># type : op : List[Tuple(op, Var)]</span>

        <span class="c1"># list of the ops that need to be updated (either their axis parameter or one of their constant inputs)</span>
        <span class="c1"># if the transpose op is fused away or moved downstream in the graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_axis_update_ops</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[])</span>  <span class="c1"># type : op : List[op]</span>

        <span class="c1"># for book keeping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ops_updated</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">materialized_ops_handled</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transpose_ops_removed</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="c1"># save the output sinks&#39; information</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_output_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># We modify the graph temporarily for outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_output_sinks</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_add_output_sinks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># We add an identity sink for all outputs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_output_vars</span> <span class="o">=</span> <span class="p">{</span><span class="n">var</span><span class="p">:</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">outputs</span><span class="p">}</span>
        <span class="n">new_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_sinks_var</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">out_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out_var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_sinks_var</span><span class="p">:</span>
                <span class="n">out_sink</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">out_var</span><span class="p">)</span>
                <span class="n">output_sinks_var</span><span class="p">[</span><span class="n">out_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_sink</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out_sink</span> <span class="o">=</span> <span class="n">output_sinks_var</span><span class="p">[</span><span class="n">out_var</span><span class="p">]</span>
            <span class="n">new_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_sink</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_sink</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">set_outputs</span><span class="p">(</span><span class="n">new_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_visit_unary_like_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">input_var</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># pass the input var&#39;s hypothetical_value to the output var&#39;s, since shape invariant ops do</span>
        <span class="c1"># not modify the incoming hypothetical_value</span>

        <span class="k">if</span> <span class="n">input_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_var</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;transpose optimization pass: op &#39;</span><span class="si">{}</span><span class="s2">&#39;, of type = &#39;</span><span class="si">{}</span><span class="s2">&#39;, has multiple outputs, hence it&quot;</span>
                <span class="s2">&quot;cannot be handled like a unary op&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">input_var</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_visit_materialize_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
        <span class="c1"># this is the catch all category of ops</span>
        <span class="c1"># these are the &quot;not-lazy-transpose-pass-through&quot; kind of ops</span>
        <span class="c1"># output hypothetical_value is same as the vars</span>
        <span class="k">for</span> <span class="n">out_var</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">out_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">_HypotheticalValue</span><span class="p">(</span><span class="n">out_var</span><span class="p">)</span>

        <span class="c1"># check for the inputs</span>
        <span class="c1"># if there is a lazy transpose hypothetical value as an input,</span>
        <span class="c1"># all the transpose ops it hold,</span>
        <span class="c1"># need to be materialized here now, i.e., we should update &quot;transpose_op_to_materialize_ops&quot;</span>
        <span class="k">for</span> <span class="n">input_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_vars</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
            <span class="n">input_hypothetical_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">input_var</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_hypothetical_value</span><span class="p">,</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">):</span>
                <span class="n">all_lazy_transpose_ops</span> <span class="o">=</span> <span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">transpose_ops</span>
                <span class="k">for</span> <span class="n">transpose_op</span> <span class="ow">in</span> <span class="n">all_lazy_transpose_ops</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="p">[</span><span class="n">transpose_op</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">op</span><span class="p">,</span> <span class="n">input_var</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_visit_axis_update_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check:</span>
<span class="sd">        - at least one of the non-constant inputs to this op is of type _LazyTransposeHypotheticalValue</span>
<span class="sd">        - for all non-constant inputs, that are of type _LazyTransposeHypotheticalValue, they</span>
<span class="sd">        have the same perm value.</span>
<span class="sd">        These checks are common for all &quot;axis update&quot; ops.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_vars</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">only_nonconst_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">num_lazy_input_vars</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">input_vars</span><span class="p">:</span>
            <span class="n">hypothetical_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypothetical_value</span><span class="p">,</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">):</span>
                <span class="n">num_lazy_input_vars</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">perm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">perm</span> <span class="o">=</span> <span class="n">hypothetical_value</span><span class="o">.</span><span class="n">perm</span>
                <span class="k">elif</span> <span class="n">perm</span> <span class="o">!=</span> <span class="n">hypothetical_value</span><span class="o">.</span><span class="n">perm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                    <span class="k">return</span>

        <span class="k">if</span> <span class="n">num_lazy_input_vars</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># checks specific to the op type</span>
        <span class="n">op_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_AXIS_UPDATE_OPS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">op_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Transform class for op of type &#39;</span><span class="si">{}</span><span class="s2">&#39; not found&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">op_cls</span><span class="p">(</span>
            <span class="o">**</span><span class="p">{</span>
                <span class="s2">&quot;op&quot;</span><span class="p">:</span> <span class="n">op</span><span class="p">,</span>
                <span class="s2">&quot;transpose_axes&quot;</span><span class="p">:</span> <span class="n">perm</span><span class="p">,</span>
                <span class="s2">&quot;var_to_hypothetical_value_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span><span class="o">.</span><span class="n">can_transpose_pass</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># add this op to the dictionary &quot;transpose_op_to_axis_update_ops&quot;</span>
        <span class="c1"># and update self.var_to_hypothetical_value[op.outputs[0]]</span>
        <span class="n">all_lazy_transpose_ops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">wrapped_hypothetical_value</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">input_vars</span><span class="p">:</span>
            <span class="n">input_hypothetical_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_hypothetical_value</span><span class="p">,</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">):</span>
                <span class="n">all_lazy_transpose_ops</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">transpose_ops</span><span class="p">)</span>
                <span class="n">wrapped_hypothetical_value</span> <span class="o">=</span> <span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">wrapped_hypothetical_value</span>

        <span class="k">for</span> <span class="n">transpose_op</span> <span class="ow">in</span> <span class="n">all_lazy_transpose_ops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_axis_update_ops</span><span class="p">[</span><span class="n">transpose_op</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">output</span><span class="p">]</span> <span class="o">=</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">(</span>
                <span class="n">wrapped_hypothetical_value</span><span class="p">,</span>
                <span class="n">all_lazy_transpose_ops</span><span class="p">,</span>
                <span class="n">perm</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_do_transposes_cancel</span><span class="p">(</span><span class="n">perm1</span><span class="p">,</span> <span class="n">perm2</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">perm1</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">perm2</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">perm1</span><span class="p">)))</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">perm1</span><span class="p">]</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="p">[</span><span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">perm2</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">x2</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_visit_transpose_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
        <span class="n">input_var</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
        <span class="n">input_hypothetical_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">input_var</span><span class="p">]</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        There are 3 cases to handle:</span>

<span class="sd">        1. input type == _HypotheticalValue</span>
<span class="sd">        2. input type == _LazyTransposeHypotheticalValue and this op is the transpose compliment of it</span>
<span class="sd">        3. input type == _LazyTransposeHypotheticalValue and this op is NOT the transpose compliment of it</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_hypothetical_value</span><span class="p">,</span> <span class="n">_HypotheticalValue</span><span class="p">):</span>
            <span class="c1"># case 1</span>
            <span class="c1"># the input is not a lazy transpose.</span>
            <span class="c1"># Since the current node is a transpose, there are two sub-cases.</span>
            <span class="c1">#  a) It&#39;s a output node. We materialize it directly.</span>
            <span class="c1">#  b) It might get cancelled downstream, so make the output var&#39;s</span>
            <span class="c1">#     hypothetical_value a lazy transpose</span>
            <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_output_vars</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">(</span>
                    <span class="n">input_hypothetical_value</span><span class="p">,</span> <span class="nb">set</span><span class="p">([</span><span class="n">op</span><span class="p">]),</span> <span class="n">perm</span>
                <span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># input is a Lazy transpose hypothetical value. Lets first check whether the current</span>
        <span class="c1"># transpose cancels it or not</span>
        <span class="n">do_cancel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_transposes_cancel</span><span class="p">(</span><span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">perm</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">do_cancel</span><span class="p">:</span>
            <span class="c1"># case 2</span>
            <span class="c1"># transposes cancel, so now the hypothetical_value of the output will</span>
            <span class="c1"># be same as the hypothetical value wrapped inside the upstream lazy transpose</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span>
                <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">wrapped_hypothetical_value</span>
            <span class="c1"># also update the dictionary &quot;transpose_op_to_cancel_ops&quot;</span>
            <span class="n">all_lazy_transpose_ops</span> <span class="o">=</span> <span class="n">input_hypothetical_value</span><span class="o">.</span><span class="n">transpose_ops</span>
            <span class="k">for</span> <span class="n">transpose_op</span> <span class="ow">in</span> <span class="n">all_lazy_transpose_ops</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">[</span><span class="n">transpose_op</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># case 3</span>
            <span class="c1"># transposes don&#39;t cancel</span>
            <span class="c1"># this is same as a materialize op then</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_visit_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>

        <span class="n">input_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_vars</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">input_vars</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span>
            <span class="p">),</span> <span class="s2">&quot;transpose optimization pass: hypothetical value for var &#39;</span><span class="si">{}</span><span class="s2">&#39;, not found&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">var</span><span class="o">.</span><span class="n">name</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_UNARY_LIKE_OP_TYPES</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_unary_like_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_AXIS_UPDATE_OPS</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_axis_update_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;transpose&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_transpose_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">_HypotheticalValue</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_materialize_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">block_traversal</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Since the ops are already organized in a topological manner,</span>
        <span class="c1"># simply iterate through all the ops</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_visit_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_verify_cancellable_transposes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># invert &quot;transpose_op_to_cancel_ops&quot;</span>
        <span class="n">transpose_cancel_ops_to_starting_transpose_set</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="nb">set</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">op</span><span class="p">,</span> <span class="n">cancel_ops_list</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">cancel_op</span> <span class="ow">in</span> <span class="n">cancel_ops_list</span><span class="p">:</span>
                <span class="n">transpose_cancel_ops_to_starting_transpose_set</span><span class="p">[</span><span class="n">cancel_op</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">op</span><span class="p">]))</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">transpose_cancel_ops_to_starting_transpose_set</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span>
            <span class="p">),</span> <span class="s2">&quot;transpose reduction optimization: transpose op &#39;</span><span class="si">{}</span><span class="s2">&#39; cannot be both a starting and cancel op&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">op</span><span class="o">.</span><span class="n">name</span>
            <span class="p">)</span>

        <span class="c1"># invert &quot;transpose_op_to_materialize_ops&quot;</span>
        <span class="n">materizalize_ops_to_starting_transpose_set</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="nb">set</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">op</span><span class="p">,</span> <span class="n">materialize_ops</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">materialize_op</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">materialize_ops</span><span class="p">:</span>
                <span class="n">materizalize_ops_to_starting_transpose_set</span><span class="p">[</span><span class="n">materialize_op</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">op</span><span class="p">]))</span>

                <span class="c1"># the starting transpose op may not be in &quot;transpose_op_to_cancel_ops&quot;</span>
                <span class="c1"># but it needs to be removed if it materializes later, hence we need to add it</span>
                <span class="c1"># to the &quot;transpose_op_to_cancel_ops&quot;, with an empty value, i.e. no other ops to cancel because of it</span>
                <span class="k">if</span> <span class="n">op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">[</span><span class="n">op</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># (starting transpose ops) and (transpose cancel ops + materialize ops) form a bipartite graph.</span>
        <span class="c1"># Find the connected components of this graph, by doing a BFS traversal</span>
        <span class="n">connected_components</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List[(Set(op), Set(op)), Set(op)]</span>
        <span class="n">visited</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">visited</span><span class="p">[</span><span class="n">op</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">set_a</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">op</span><span class="p">])</span>  <span class="c1"># set of starting transpose ops</span>
            <span class="n">set_b1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># set of transpose cancel ops connected to set_a</span>
            <span class="n">set_b2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># set of materialize ops connected to set_a</span>
            <span class="n">queue</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">[</span><span class="n">op</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="p">:</span>
                <span class="n">materialize_ops_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="p">[</span><span class="n">op</span><span class="p">]))[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">materialize_ops_list</span><span class="p">)</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">queue</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">o</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">visited</span><span class="p">[</span><span class="n">o</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="c1"># enque nodes connected to o</span>
                <span class="k">if</span> <span class="n">o</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">:</span>
                    <span class="n">set_a</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">o</span><span class="p">]))</span>
                    <span class="k">for</span> <span class="n">neighbor_op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">[</span><span class="n">o</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">neighbor_op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                            <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neighbor_op</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">o</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="p">:</span>
                        <span class="n">materialize_ops_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                            <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="p">[</span><span class="n">o</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">neighbor_op</span> <span class="ow">in</span> <span class="n">materialize_ops_list</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">neighbor_op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                                <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neighbor_op</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">transpose_cancel_ops_to_starting_transpose_set</span><span class="p">:</span>
                    <span class="n">set_b1</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">o</span><span class="p">]))</span>
                    <span class="k">for</span> <span class="n">neighbor_op</span> <span class="ow">in</span> <span class="n">transpose_cancel_ops_to_starting_transpose_set</span><span class="p">[</span><span class="n">o</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">neighbor_op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                            <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neighbor_op</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">set_b2</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">o</span><span class="p">]))</span>
                    <span class="k">for</span> <span class="n">neighbor_op</span> <span class="ow">in</span> <span class="n">materizalize_ops_to_starting_transpose_set</span><span class="p">[</span><span class="n">o</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">neighbor_op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                            <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neighbor_op</span><span class="p">)</span>
            <span class="n">connected_components</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">set_a</span><span class="p">,</span> <span class="n">set_b1</span><span class="p">,</span> <span class="n">set_b2</span><span class="p">))</span>

        <span class="n">starting_ops_to_remove</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># starting ops to remove from the optimization list</span>

        <span class="c1"># now for each connected component, make a decision whether to cancel it or not</span>
        <span class="c1"># (either all transpose ops in a set get cancelled or they don&#39;t)</span>
        <span class="k">for</span> <span class="n">op_set</span><span class="p">,</span> <span class="n">op_cancel_set</span><span class="p">,</span> <span class="n">materialize_op_set</span> <span class="ow">in</span> <span class="n">connected_components</span><span class="p">:</span>

            <span class="n">block_output</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># check that output is not directly connected to a starting transpose op</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">op_set</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                    <span class="n">starting_ops_to_remove</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">op_set</span><span class="p">)</span>
                    <span class="n">block_output</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">block_output</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">materizalize_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">materialize_op_set</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">materizalize_set</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">op_set</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">op_cancel_set</span><span class="p">):</span>
                <span class="n">starting_ops_to_remove</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">op_set</span><span class="p">)</span>

        <span class="c1"># remove ops</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">starting_ops_to_remove</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_remove_transpose_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starting_transpose_op</span><span class="p">):</span>

        <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">starting_transpose_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
        <span class="n">starting_transpose_op_out_var</span> <span class="o">=</span> <span class="n">starting_transpose_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">starting_transpose_op_input_var</span> <span class="o">=</span> <span class="n">starting_transpose_op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>

        <span class="c1"># update all the &quot;axis_update&quot; ops</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_axis_update_ops</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">starting_transpose_op</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">if</span> <span class="n">op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ops_updated</span><span class="p">:</span>
                <span class="n">op_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_AXIS_UPDATE_OPS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">op_cls</span><span class="p">(</span>
                    <span class="o">**</span><span class="p">{</span>
                        <span class="s2">&quot;op&quot;</span><span class="p">:</span> <span class="n">op</span><span class="p">,</span>
                        <span class="s2">&quot;transpose_axes&quot;</span><span class="p">:</span> <span class="n">perm</span><span class="p">,</span>
                        <span class="s2">&quot;var_to_hypothetical_value_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ops_updated</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="c1"># short circuit starting_transpose_op and its cancel ops</span>

        <span class="n">to_be_removed_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">name_changed_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="p">[</span><span class="n">starting_transpose_op</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">[</span><span class="n">starting_transpose_op</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_ops_removed</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">to_be_removed_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transpose_ops_removed</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="n">input_var</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>  <span class="c1"># input to the transpose op</span>
            <span class="n">output_var</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># output of the transpose op</span>
            <span class="n">parent_op</span> <span class="o">=</span> <span class="n">input_var</span><span class="o">.</span><span class="n">op</span>  <span class="c1"># parent op of the transpose op</span>

            <span class="k">if</span> <span class="n">output_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_output_vars</span><span class="p">:</span>
                <span class="c1"># output is a block output, so this must be one of the &quot;edge&quot; transpose compliment ops</span>
                <span class="c1"># We need to set `input_var` as the block output var</span>
                <span class="c1"># Change the name of the input_var to match the block output if input_var is not changed.</span>
                <span class="c1"># If the same input_var is in output twice, we can&#39;t rename it twice, therefore we initiate an</span>
                <span class="c1"># Identity op to match the name</span>
                <span class="k">if</span> <span class="n">input_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">input_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">output_var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">parent_op</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># set anchor op as None.</span>
                <span class="k">elif</span> <span class="n">input_var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name_changed_vars</span><span class="p">:</span>
                    <span class="n">input_var</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">output_var</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">input_var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">output_var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">name_changed_vars</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="n">input_var</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">input_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">output_var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">parent_op</span> <span class="o">=</span> <span class="n">input_var</span><span class="o">.</span><span class="n">op</span>

            <span class="c1"># connect all the child ops of the output_var to the parent of the transpose op.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">parent_op</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="n">output_var</span><span class="p">,</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span>
                <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Insert a transpose op JUST before each one of the materialize ops</span>
<span class="sd">        i.e.</span>
<span class="sd">        Given:  %i1 = op(...)</span>
<span class="sd">                ...</span>
<span class="sd">                ... = materialize_op(..., %i1 ,...)</span>
<span class="sd">                ...</span>

<span class="sd">        Result: %i1 = op(...)</span>
<span class="sd">                ...</span>
<span class="sd">                %i2 = transpose_op(%i1, %perm)</span>
<span class="sd">                ... = materialize_op(..., %i2 ,...)</span>
<span class="sd">                ...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">op</span><span class="p">,</span> <span class="n">input_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_materialize_ops</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">starting_transpose_op</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">input_var</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">materialized_ops_handled</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">materialized_ops_handled</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">op</span><span class="p">,</span> <span class="n">input_var</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">input_var</span> <span class="o">==</span> <span class="n">starting_transpose_op_out_var</span><span class="p">:</span>
                <span class="c1"># materialize op is connected to the starting transpose op</span>
                <span class="c1"># in this case, connect to its parent</span>
                <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">i1</span> <span class="o">=</span> <span class="n">starting_transpose_op_input_var</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">i1</span> <span class="o">=</span> <span class="n">input_var</span>

            <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="p">:</span>
                <span class="c1"># The input_var of output sink is itself a output. We can safely</span>
                <span class="c1"># modify the name of the input_var since it should only be consumed</span>
                <span class="c1"># by block output here.</span>
                <span class="k">if</span> <span class="n">i1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name_changed_vars</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">i1</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">i1</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">i1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;_before_transpose_op_&quot;</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">i1</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;_before_transpose_op_&quot;</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">i1</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">old_output_vars</span><span class="p">[</span><span class="n">i1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">i1</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                <span class="n">end_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="n">i1</span><span class="p">,</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="n">to_be_removed_ops</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Take in the data collected during graph traversal</span>
<span class="sd">        and transform the graph by cancelling out transpose ops that can be removed.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Block before optimize transpose transform:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_DEBUG</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">graphviz</span>

            <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">get_dot_string</span><span class="p">(</span>
                    <span class="n">highlight_debug_op_names</span><span class="o">=</span><span class="p">[],</span> <span class="n">highlight_debug_op_types</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;transpose&quot;</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;/tmp/block_before_reduce_transpose&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        First check which transposes can be cancelled.</span>
<span class="sd">        After this function call we get an updated dictionary &quot;transpose_op_to_cancel_ops&quot;</span>
<span class="sd">        with only the transpose ops that can really be cancelled in the graph</span>
<span class="sd">        Reasons to not cancel:</span>
<span class="sd">        - materialize_ops are greater than cancel_ops, so removing transpose will instead end up increasing the count of transposes</span>
<span class="sd">        - removing a transpose op can only be successful, if all of its cancel ops are removed, removing all the cancel ops</span>
<span class="sd">          is only successful if all of their starting transpose ops are removed and so on. This check is also done in</span>
<span class="sd">           &quot;_verify_cancellable_transposes()&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_verify_cancellable_transposes</span><span class="p">()</span>

        <span class="c1"># apply transform</span>
        <span class="k">for</span> <span class="n">transpose_op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_op_to_cancel_ops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remove_transpose_ops</span><span class="p">(</span><span class="n">transpose_op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">set_outputs</span><span class="p">([</span><span class="n">sink_op</span><span class="o">.</span><span class="n">x</span> <span class="k">for</span> <span class="n">sink_op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_sink_ops</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_DEBUG</span><span class="p">:</span>
            <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">get_dot_string</span><span class="p">(</span>
                    <span class="n">highlight_debug_op_names</span><span class="o">=</span><span class="p">[],</span> <span class="n">highlight_debug_op_types</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;transpose&quot;</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;/tmp/block_after_reduce_transpose&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Block after optimize transpose transform:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
            <span class="n">op</span><span class="o">.</span><span class="n">type_value_inference</span><span class="p">(</span><span class="n">overwrite_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">register_axis_update_op</span><span class="p">(</span><span class="n">ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param ops: Ops that will be registered. For example: the class &quot;_TransformReduceMean&quot; can</span>
<span class="sd">        be used to register ops including &quot;reduce_prod&quot;, &quot;reduce_sum&quot; etc.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">class_wrapper</span><span class="p">(</span><span class="n">op_update_cls</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">op_type</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">op_type</span> <span class="ow">in</span> <span class="n">_TransposeOptimization</span><span class="o">.</span><span class="n">_AXIS_UPDATE_OPS</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Update class for op of type &#39;</span><span class="si">{}</span><span class="s2">&#39; already defined&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op_type</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">_TransposeOptimization</span><span class="o">.</span><span class="n">_AXIS_UPDATE_OPS</span><span class="p">[</span><span class="n">op_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">op_update_cls</span>
            <span class="k">return</span> <span class="n">op_update_cls</span>

        <span class="k">return</span> <span class="n">class_wrapper</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_input_vars</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">only_nonconst_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Var</span><span class="p">]:</span>
        <span class="n">input_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">Var</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">only_nonconst_vars</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">val</span><span class="o">.</span><span class="n">op</span> <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="n">input_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">val</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">Var</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;transpose optimization pass: unrecognized input type of &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;op=&#39;</span><span class="si">{</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;, input=&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">only_nonconst_vars</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">op</span> <span class="ow">and</span> <span class="n">var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span><span class="p">:</span>
                            <span class="k">continue</span>
                    <span class="n">input_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;transpose optimization pass: unrecognized input type of &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;op=&#39;</span><span class="si">{</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;, input=&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">input_vars</span>


<span class="nd">@_TransposeOptimization</span><span class="o">.</span><span class="n">register_axis_update_op</span><span class="p">(</span><span class="n">ops</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;concat&quot;</span><span class="p">])</span>
<span class="k">class</span> <span class="nc">_TransformConcat</span><span class="p">(</span><span class="n">TransformAxisUpdateOps</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_TransformConcat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;axis&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">can_transpose_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Check that all non const inputs are of type _LazyTransposeHypotheticalValue.</span>
        <span class="c1"># That they have the same perm value has already been checked before.</span>
        <span class="n">input_vars</span> <span class="o">=</span> <span class="n">_TransposeOptimization</span><span class="o">.</span><span class="n">_get_input_vars</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="n">only_nonconst_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">input_vars</span><span class="p">:</span>
            <span class="n">hypothetical_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value_dict</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypothetical_value</span><span class="p">,</span> <span class="n">_LazyTransposeHypotheticalValue</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis_var</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">new_axis_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">axis_var</span><span class="o">.</span><span class="n">val</span><span class="p">]</span>

        <span class="c1"># to be used, if there is a consant inputs to the concat op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_const_inputs</span><span class="p">()</span>

        <span class="c1"># insert a new constant for the new axis, JUST before the op</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
            <span class="n">new_axis_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">new_axis_val</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_axis_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis_var</span><span class="p">,</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_axis_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_const_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">transpose_perm_for_const</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">):</span>
            <span class="n">transpose_perm_for_const</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

        <span class="c1"># if there is a constant input, transpose it</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">input_var</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span><span class="p">:</span>
                <span class="n">const_val</span> <span class="o">=</span> <span class="n">input_var</span><span class="o">.</span><span class="n">val</span>
                <span class="n">new_const_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">const_val</span><span class="p">,</span> <span class="n">transpose_perm_for_const</span><span class="p">)</span>
                <span class="c1"># insert a new constant JUST before the op</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
                    <span class="n">new_const_input_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">new_const_val</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                    <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_const_input_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                    <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                    <span class="n">old_var</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span>
                    <span class="n">new_var</span><span class="o">=</span><span class="n">new_const_input_var</span><span class="p">,</span>
                    <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>


<span class="nd">@_TransposeOptimization</span><span class="o">.</span><span class="n">register_axis_update_op</span><span class="p">(</span><span class="n">ops</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;split&quot;</span><span class="p">])</span>
<span class="k">class</span> <span class="nc">_TransformSplit</span><span class="p">(</span><span class="n">_TransformConcat</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_TransformSplit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># The split op is handled the same as the concat op, except it does not need</span>
    <span class="c1"># to transform const inputs</span>
    <span class="k">def</span> <span class="nf">_update_const_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>


<span class="nd">@_TransposeOptimization</span><span class="o">.</span><span class="n">register_axis_update_op</span><span class="p">(</span><span class="n">ops</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">])</span>
<span class="k">class</span> <span class="nc">_TransformPad</span><span class="p">(</span><span class="n">TransformAxisUpdateOps</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_TransformPad</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_var</span><span class="o">.</span><span class="n">op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_compute_new_pad_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pad_amounts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_var</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">rank_diff</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">pad_amounts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pad_amounts</span><span class="p">)</span>
        <span class="c1"># append &quot;rank_diff&quot; rows of zeros to the top</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank_diff</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">pad_amounts</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">pad_amounts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank_diff</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">pad_amounts</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">axis</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_amounts</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">axis</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_amounts</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># get the top &quot;rank_diff&quot; rows</span>
        <span class="n">top_rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">[:</span><span class="n">rank_diff</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">top_rows</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># cut &quot;rank_diff&quot; from the top</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">[</span><span class="n">rank_diff</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">can_transpose_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">_TransposeOptimization</span><span class="o">.</span><span class="n">_get_input_vars</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="n">only_nonconst_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">1</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">!=</span> <span class="s2">&quot;const&quot;</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_new_pad_values</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># check that if mode is not constant, the updated padding</span>
        <span class="c1"># would stay limited to last 2 axes</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">!=</span> <span class="s2">&quot;constant&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_new_pad_values</span><span class="p">()</span>
        <span class="c1"># insert a new constant for pad val, JUST before the op</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
            <span class="n">new_pad_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_amounts_new</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_pad_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_var</span><span class="p">,</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_pad_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="nd">@_TransposeOptimization</span><span class="o">.</span><span class="n">register_axis_update_op</span><span class="p">(</span>
    <span class="n">ops</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;reduce_l1_norm&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_l2_norm&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_max&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_log_sum&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_log_sum_exp&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_mean&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_min&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_prod&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_sum&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reduce_sum_square&quot;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="k">class</span> <span class="nc">_TransformReduceMean</span><span class="p">(</span><span class="n">TransformAxisUpdateOps</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_TransformReduceMean</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axes_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;axes&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axes_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes_var</span><span class="o">.</span><span class="n">op</span>

    <span class="k">def</span> <span class="nf">can_transpose_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># allow transpose to push through it only if keep_dims are True since that doesn&#39;t change the rank</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes_op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># update axis of the op</span>
        <span class="n">old_axes_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes_var</span><span class="o">.</span><span class="n">val</span>
        <span class="n">new_axes_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_axes_val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_axes_val</span><span class="p">):</span>
            <span class="n">new_axes_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

        <span class="c1"># insert a new constant for the axis, JUST before the op</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
            <span class="n">new_axis_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">new_axes_val</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_axis_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_var</span><span class="p">,</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_axis_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="nd">@_TransposeOptimization</span><span class="o">.</span><span class="n">register_axis_update_op</span><span class="p">(</span>
    <span class="n">ops</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;mul&quot;</span><span class="p">,</span> <span class="s2">&quot;sub&quot;</span><span class="p">,</span> <span class="s2">&quot;real_div&quot;</span><span class="p">,</span> <span class="s2">&quot;maximum&quot;</span><span class="p">,</span> <span class="s2">&quot;minimum&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="k">class</span> <span class="nc">_TransformAdd</span><span class="p">(</span><span class="n">TransformAxisUpdateOps</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_TransformAdd</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># self.tranpose_input: this is the input coming from an upstream transpose op. If both inputs are</span>
        <span class="c1">#                      connected to an upstream transpose, this will be set to one of those</span>
        <span class="c1"># self.other_input: the other input, that is not coming from a transpose</span>
        <span class="n">is_x_input_lazy_transpose</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">x</span><span class="p">],</span> <span class="n">_LazyTransposeHypotheticalValue</span>
        <span class="p">)</span>
        <span class="n">is_y_input_lazy_transpose</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_to_hypothetical_value_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">y</span><span class="p">],</span> <span class="n">_LazyTransposeHypotheticalValue</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">is_x_input_lazy_transpose</span> <span class="ow">and</span> <span class="n">is_y_input_lazy_transpose</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">x</span>
        <span class="k">elif</span> <span class="n">is_y_input_lazy_transpose</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_x_input_lazy_transpose</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">x</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">y</span>
        <span class="k">elif</span> <span class="n">is_x_input_lazy_transpose</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_y_input_lazy_transpose</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">y</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># we should not be here since this class is only invoked,</span>
            <span class="c1"># when there is at least one input var of type _LazyTransposeHypotheticalValue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">can_transpose_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">         Return True if the one of the following is true:</span>
<span class="sd">         - (scenario 1) both inputs are of type _LazyTransposeHypotheticalValue, with the same perm value</span>
<span class="sd">         - one input is of type _LazyTransposeHypotheticalValue and the other satisfies one of the following:</span>
<span class="sd">             - (scenario 2) it is constant. In this case, the constant can be updated accordingly to allow the transpose to pass through</span>
<span class="sd">             - (scenario 3) if its non constant, then all of the following must be true</span>
<span class="sd">                 - its shape is fully defined</span>
<span class="sd">                 - the transpose compliment operation on the other input can be expressed via a reshape. This can</span>
<span class="sd">                   be done if there is only 1 non unit dimension in its shape, or if there are more than 1 non unit dims,</span>
<span class="sd">                   the transpose compliment operation only permutes the unit dimensions.</span>

<span class="sd">        In scenario 3, the transpose will be removed, by adding an extra static reshape.</span>
<span class="sd">        This is based on the assumption that a static reshape op will be less expensive than transpose.</span>
<span class="sd">        An example of scenario 3 is displayed below:</span>

<span class="sd">         Input pattern:</span>

<span class="sd">         (shape=(10, 20, 30))</span>
<span class="sd">              |</span>
<span class="sd">              |</span>
<span class="sd">              V</span>
<span class="sd">          Transpose op</span>
<span class="sd">          (shape = (20, 30, 10))</span>
<span class="sd">              |</span>
<span class="sd">              |</span>
<span class="sd">              V</span>
<span class="sd">          this op  &lt;--------- (shape = (10,)) (other non const input)</span>
<span class="sd">              |</span>
<span class="sd">              V</span>


<span class="sd">         After transpose passes through:</span>

<span class="sd">         (shape=(10, 20, 30))</span>
<span class="sd">              |</span>
<span class="sd">              |</span>
<span class="sd">              V</span>
<span class="sd">          this op  &lt;--------- (shape = (10, 1, 1)) Reshape op &lt;---------- (shape = (10,)) (other non const input)</span>
<span class="sd">              |</span>
<span class="sd">              V</span>
<span class="sd">          Transpose op</span>
<span class="sd">          (shape = (20, 30, 10))</span>
<span class="sd">              |</span>
<span class="sd">              V</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># ---------------------</span>
        <span class="c1"># check for scenario 1</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># are both inputs _LazyTransposeHypotheticalValue?</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># ---------------------</span>
        <span class="c1"># check for scenario 2</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># is the second input a constant?</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">rank</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">other_input_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">any_symbolic</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">rank</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># ---------------------</span>
        <span class="c1"># check for scenario 3</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># can other input be &quot;reshaped&quot; to allow the transpose to pass through?</span>
        <span class="k">if</span> <span class="n">any_symbolic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">transpose_compliment_perm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_transpose_compliment</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span>
        <span class="c1"># make the rank of the other input, same as that of the transpose input,</span>
        <span class="c1"># by broadcasting</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rank</span><span class="p">:</span>
            <span class="n">other_input_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">)</span>

        <span class="c1"># how many non unit dimensions in the other input&#39;s shape?</span>
        <span class="k">if</span> <span class="n">other_input_shape</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="n">rank</span><span class="p">,</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="c1"># 0 or 1 non unit dimension</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># more than 1 non unit dimensions in other input</span>
            <span class="c1"># check if transpose is moving only dimensions that have values 1</span>
            <span class="c1"># if true, then the transpose compliment can be expressed via a reshape</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">transpose_compliment_perm</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">axis</span> <span class="ow">and</span> <span class="n">other_input_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">False</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># ----------------------</span>
        <span class="c1"># update for scenario 1</span>
        <span class="c1"># ----------------------</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># nothing to update</span>
            <span class="k">return</span>

        <span class="c1"># --------------------------</span>
        <span class="c1"># update for scenario 2 &amp; 3</span>
        <span class="c1"># --------------------------</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># other input is a scalar, no need to modify it</span>
            <span class="k">return</span>

        <span class="c1"># broadcast the shape of other input to match the rank</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tranpose_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">other_input_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rank</span><span class="p">:</span>
            <span class="n">other_input_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">)</span>

        <span class="c1"># find new shape after transpose compliment</span>
        <span class="n">transpose_compliment_perm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_transpose_compliment</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transpose_axes</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">transpose_compliment_perm</span><span class="p">):</span>
            <span class="n">new_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">other_input_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># update the const (scenario 2)</span>
            <span class="n">const_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="o">.</span><span class="n">val</span>
            <span class="n">new_const_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                <span class="n">const_value</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">other_input_shape</span><span class="p">),</span> <span class="n">transpose_compliment_perm</span>
            <span class="p">)</span>
            <span class="c1"># insert a new constant JUST before the op</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
                <span class="n">new_const_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">new_const_val</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_const_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="p">,</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">new_const_var</span><span class="p">,</span>
                <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># insert a reshape (scenario 3)</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="p">:</span>
                <span class="n">new_other_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">before_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
                <span class="n">anchor_op</span><span class="o">=</span><span class="n">new_other_var</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                <span class="n">end_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">,</span>
                <span class="n">old_var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">other_input</span><span class="p">,</span>
                <span class="n">new_var</span><span class="o">=</span><span class="n">new_other_var</span><span class="p">,</span>
                <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>


<div class="viewcode-block" id="reduce_transposes"><a class="viewcode-back" href="../../../../../../../source/coremltools.converters.mil.mil.passes.defs.html#coremltools.converters.mil.mil.passes.defs.optimize_repeat_ops.reduce_transposes">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;common&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">reduce_transposes</span><span class="p">(</span><span class="n">AbstractGraphPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reduce transposes when it is applicable. For example:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        # Example 1</span>
<span class="sd">            Input graph:</span>
<span class="sd">            input -----&gt; transpose(axis=[1,0]) -----&gt; transpose(axis=[1,0]) ---&gt; out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            input -----&gt; identity -----&gt; out</span>

<span class="sd">        # Example 2</span>
<span class="sd">            Input graph:</span>
<span class="sd">            input----&gt;transpose(axis=[0,3,1,2])----&gt;relu----&gt;transpose(axis=[0,2,3,1])---&gt;out</span>

<span class="sd">            Output graph:</span>
<span class="sd">            input-----&gt;relu-----&gt;out</span>

<span class="sd">        # Example 3</span>
<span class="sd">            Input graph:</span>
<span class="sd">            input(shape=10,2,3,5)---&gt;transpose(axis=[0,2,3,1])-----&gt;relu----&gt;pool-----&gt;out1</span>
<span class="sd">                                                               |</span>
<span class="sd">                                                               |</span>
<span class="sd">                                                               ---&gt;relu-----&gt;log----&gt;transpose(axis=[0,3,1,2])----&gt;out2</span>

<span class="sd">            Output graph:</span>
<span class="sd">            input(shape=10,2,3,5)-----&gt;relu----&gt;transpose(axis=[0,2,3,1])----&gt;pool-----&gt;out1</span>
<span class="sd">                                   |</span>
<span class="sd">                                   |</span>
<span class="sd">                                   ---&gt;relu-----&gt;log----&gt;out2</span>

<span class="sd">    Please see ``TransposeOptimizationPass`` for more details.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    This pass is divided into 3 phases:</span>

<span class="sd">    `1st phase:` Information gathering.</span>

<span class="sd">    - Plug in Identity ops for all output nodes. This allows us to treat all ops uniformly during traversal.</span>
<span class="sd">    - Block is traversed in the topological order, starting from the ops connected to the inputs.</span>
<span class="sd">    - During the traversal, a value is associated with every var in the block.</span>
<span class="sd">      This value can be either of type ``_HypotheticalValue`` or ``_LazyTransposeHypotheticalValue``.</span>
<span class="sd">      The main purpose of type ``_HypotheticalValue`` is to indicate that it is `not` of type ``_LazyTransposeHypotheticalValue``.</span>
<span class="sd">    - ``_LazyTransposeHypotheticalValue`` represents either one or multiple transpose ops with the same perm value. This information</span>
<span class="sd">      is stored in this class. It also wraps a ``_HypotheticalValue`` that was the last hypothetical value which was generated</span>
<span class="sd">      prior to the origin of ``_LazyTransposeHypotheticalValue``.</span>
<span class="sd">    - Each op decides which type of hypothetical value to associate with its output vars, based on its op type,</span>
<span class="sd">      attributes, and the types of the hypothetical values of its input vars.</span>
<span class="sd">    - Ops are classified into 4 categories: `unary like`, `axis update`, `transpose`, and `materialize` (for all the rest).</span>
<span class="sd">    - Transpose ops are the ops from which a ``_LazyTransposeHypotheticalValue`` originate.</span>
<span class="sd">        - If the input to it is a ``_HypotheticalValue``, its output will be a ``_LazyTransposeHypotheticalValue``,</span>
<span class="sd">          indicating that this ``transpose`` op is available to get cancelled downstream.</span>
<span class="sd">        - If the input to it is a ``_LazyTransposeHypotheticalValue``, then it is checked whether this op cancels it or not.</span>
<span class="sd">            - If the op cancels it, a ``_HypotheticalValue`` value is generated at the output and the information about this ``transpose`` cancellation</span>
<span class="sd">              is recorded in the dictionary ``transpose_op_to_cancel_ops``.</span>
<span class="sd">            - If the op does not cancel, the current ``transpose`` op is categrorized as a `materialize` op. Therefore, the information in</span>
<span class="sd">              dictionary ``transpose_op_to_materialize_ops`` is updated accordingly. The output of the op is now mapped to a</span>
<span class="sd">              ``_HypotheticalValue``.</span>
<span class="sd">    - Unary like ops: These simply transfer their input hypothetical value type to the output.</span>
<span class="sd">    - Axis update ops: If a ``transpose`` can pass through them, they are treated like a unary op and the dictionary</span>
<span class="sd">      ``transpose_op_to_axis_update_ops`` is updated. If the op cannot be updated in any manner to</span>
<span class="sd">      allow a ``transpose`` to pass through, this op is then categorized as a `materialize` op and handled accordingly.</span>
<span class="sd">    - Materialize ops: All ``_LazyTransposeHypotheticalValue`` input vars, if present, materialize here. Output of this op</span>
<span class="sd">      is always of type ``_HypotheticalValue``. If the input is a ``_LazyTransposeHypotheticalValue``, update the dictionary</span>
<span class="sd">      ``transpose_op_to_materialize_ops``.</span>
<span class="sd">    - To treat an op like a unary op, add its type to ``_UNARY_LIKE_OP_TYPES``. In future changes we want to make this process</span>
<span class="sd">      automatic by detecting an op as a `unary like` by its &quot;traits&quot;.</span>
<span class="sd">    - To treat an op like `axis update` op, add a class specific to the op implementing the class ``TransformAxisUpdateOps``.</span>
<span class="sd">      For examples, see classes ``_TransformConcat``, ``_TransformPad``, and so on. The dictionary ``AXIS_UPDATE_OPS`` is automatically filled</span>
<span class="sd">      in by the decorator ``_TransposeOptimization.register_axis_update_op``.</span>

<span class="sd">    `2nd phase:` Determining which ``transpose`` ops to remove from the graph.</span>

<span class="sd">    All ``transpose`` ops that have a corresponding compliment op in dict ``transpose_op_to_cancel_ops`` is a candidate.</span>
<span class="sd">    However, you need to ensure the following:</span>

<span class="sd">    - If a ``transpose`` op is removed, then all of its ``cancel`` ops in ``transpose_op_to_cancel_ops`` must also be removed,</span>
<span class="sd">      to ensure correctness of the graph. The same is true in the reverse direction as well;</span>
<span class="sd">      that is, for every ``cancel`` op that is removed, all its parent ``transpose`` ops upstream must also be removed.</span>
<span class="sd">    - ``transpose`` ops should be removed only if the number of ``cancel`` ops is greater than the number of ``transpose`` ops</span>
<span class="sd">      that would get freshly introduced to the block as a result of materialization ops. Currently in the algorithm,</span>
<span class="sd">      each materialization op/output var (dicts ``transpose_op_to_materialize_ops``/``old_output_vars``)</span>
<span class="sd">      results in one more ``transpose`` op, although this can be further optimized in the future.</span>

<span class="sd">    To resolve this, we recognize that nodes consisting of sets ``(a)`` and ``(b)`` form a bipartitle graph, where,</span>
<span class="sd">    ``(a) ==`` starting ``transpose`` ops (originators of ``_LazyTransposeHypotheticalValue``)</span>
<span class="sd">    and ``(b) ==`` set of ``transpose`` ``cancel`` ops and ``materialize`` ops.</span>

<span class="sd">    - In this bipartite graph, we find all the connected components for each connected component.</span>
<span class="sd">      Either the entire set of ``transpose`` ops in it are removed/materialized, or none</span>
<span class="sd">      of them are touched.</span>
<span class="sd">    - Thus for each set, a determination is made based on counting the number of ``cancel`` ops and ``materialize`` ops.</span>
<span class="sd">    - Based on this determination, the final set of ``transpose`` ops to be removed is updated.</span>

<span class="sd">    `3rd phase:` Transforming the graph.</span>

<span class="sd">    - ``transpose`` starting ops and the ``cancel`` ops are removed.</span>
<span class="sd">    - Axis update ops, affected by these ``transpose`` ops, are updated.</span>
<span class="sd">    - Transposes are materialized; that is, added just before the ``materialize`` ops, which are linked to the starting ``transpose`` ops.</span>
<span class="sd">      The starting ``transpose`` op can be materialized (inserted) multiple times, before each of the ``materialize`` ops downstream.</span>
<span class="sd">    - Block outputs are handled in a similar fashion as the `materialize` ops.</span>
<span class="sd">    - Type inference on all ops is invoked after all the transformations.</span>
<span class="sd">    - All Identity ops that are plugged into the graph to treat outputs as materialized are removed.</span>

<span class="sd">    `Debugging`</span>

<span class="sd">    If the ``debug`` flag is set to ``True``, the block before and after the transformation is plotted,</span>
<span class="sd">    with transpose nodes highlighted.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce_transposes_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_reduce_transposes_block</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Only apply the optimization if the block is flat,</span>
<span class="sd">        i.e, it does not contain any op which contains a sub-block.</span>
<span class="sd">        TODO:</span>
<span class="sd">        Removing transposes and transpose compliments requires re-running</span>
<span class="sd">        type inference for the set of ops in between the fused transpose ops,</span>
<span class="sd">        which is simpler to do when all the ops in the block are free of sub blocks.</span>
<span class="sd">        The case of transpose fusion with sub-block containing ops needs to be handled with more care and test cases.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span>

        <span class="k">with</span> <span class="n">block</span><span class="p">:</span>
            <span class="n">opt_transposes</span> <span class="o">=</span> <span class="n">_TransposeOptimization</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
            <span class="n">opt_transposes</span><span class="o">.</span><span class="n">block_traversal</span><span class="p">()</span>
            <span class="n">opt_transposes</span><span class="o">.</span><span class="n">apply_transform</span><span class="p">()</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>