Search.setIndex({"docnames": ["index", "source/classifiers", "source/comparing-ml-programs-and-neural-networks", "source/composite-operators", "source/conversion-options", "source/convert-a-tensorflow-1-deepspeech-model", "source/convert-a-tensorflow-1-image-classifier", "source/convert-a-torchvision-model-from-pytorch", "source/convert-learning-models", "source/convert-nlp-model", "source/convert-pytorch", "source/convert-pytorch-workflow", "source/convert-tensorflow", "source/convert-tensorflow-2-bert-transformer-models", "source/convert-to-ml-program", "source/convert-to-neural-network", "source/coremltools-examples", "source/custom-operators", "source/faqs", "source/flexible-inputs", "source/graph-passes-intro", "source/how-to-contribute", "source/image-inputs", "source/installing-coremltools", "source/introductory-quickstart", "source/libsvm-conversion", "source/load-and-convert-model", "source/mlmodel", "source/mlmodel-utilities", "source/model-input-and-output-types", "source/model-intermediate-language", "source/model-prediction", "source/model-scripting", "source/model-tracing", "source/multifunction-models", "source/new-conversion-options", "source/new-features", "source/opt-conversion", "source/opt-opt1_3", "source/opt-overview", "source/opt-overview-examples", "source/opt-palettization", "source/opt-palettization-algos", "source/opt-palettization-api", "source/opt-palettization-overview", "source/opt-palettization-perf", "source/opt-pruning", "source/opt-pruning-algos", "source/opt-pruning-api", "source/opt-pruning-overview", "source/opt-pruning-perf", "source/opt-quantization", "source/opt-quantization-algos", "source/opt-quantization-api", "source/opt-quantization-overview", "source/opt-quantization-perf", "source/opt-resnet", "source/opt-whats-new", "source/opt-workflow", "source/overview-coremltools", "source/pytorch-conversion-examples", "source/quantization-neural-network", "source/sci-kit-learn-conversion", "source/stateful-models", "source/target-conversion-formats", "source/tensorflow-1-workflow", "source/tensorflow-2", "source/typed-execution", "source/typed-execution-example", "source/unified-conversion-api", "source/updatable-model-examples", "source/updatable-nearest-neighbor-classifier", "source/updatable-neural-network-classifier-on-mnist-dataset", "source/updatable-tiny-drawing-classifier-pipeline-model", "source/xcode-model-preview-types", "source/xgboost-conversion"], "filenames": ["index.rst", "source/classifiers.md", "source/comparing-ml-programs-and-neural-networks.md", "source/composite-operators.md", "source/conversion-options.rst", "source/convert-a-tensorflow-1-deepspeech-model.md", "source/convert-a-tensorflow-1-image-classifier.md", "source/convert-a-torchvision-model-from-pytorch.md", "source/convert-learning-models.rst", "source/convert-nlp-model.md", "source/convert-pytorch.rst", "source/convert-pytorch-workflow.md", "source/convert-tensorflow.rst", "source/convert-tensorflow-2-bert-transformer-models.md", "source/convert-to-ml-program.md", "source/convert-to-neural-network.md", "source/coremltools-examples.md", "source/custom-operators.md", "source/faqs.md", "source/flexible-inputs.md", "source/graph-passes-intro.md", "source/how-to-contribute.md", "source/image-inputs.md", "source/installing-coremltools.md", "source/introductory-quickstart.md", "source/libsvm-conversion.md", "source/load-and-convert-model.md", "source/mlmodel.md", "source/mlmodel-utilities.md", "source/model-input-and-output-types.md", "source/model-intermediate-language.md", "source/model-prediction.md", "source/model-scripting.md", "source/model-tracing.md", "source/multifunction-models.md", "source/new-conversion-options.md", "source/new-features.md", "source/opt-conversion.md", "source/opt-opt1_3.md", "source/opt-overview.md", "source/opt-overview-examples.rst", "source/opt-palettization.rst", "source/opt-palettization-algos.md", "source/opt-palettization-api.md", "source/opt-palettization-overview.md", "source/opt-palettization-perf.md", "source/opt-pruning.rst", "source/opt-pruning-algos.md", "source/opt-pruning-api.md", "source/opt-pruning-overview.md", "source/opt-pruning-perf.md", "source/opt-quantization.rst", "source/opt-quantization-algos.md", "source/opt-quantization-api.md", "source/opt-quantization-overview.md", "source/opt-quantization-perf.md", "source/opt-resnet.md", "source/opt-whats-new.md", "source/opt-workflow.md", "source/overview-coremltools.md", "source/pytorch-conversion-examples.md", "source/quantization-neural-network.md", "source/sci-kit-learn-conversion.md", "source/stateful-models.md", "source/target-conversion-formats.md", "source/tensorflow-1-workflow.md", "source/tensorflow-2.md", "source/typed-execution.md", "source/typed-execution-example.md", "source/unified-conversion-api.md", "source/updatable-model-examples.rst", "source/updatable-nearest-neighbor-classifier.md", "source/updatable-neural-network-classifier-on-mnist-dataset.md", "source/updatable-tiny-drawing-classifier-pipeline-model.md", "source/xcode-model-preview-types.md", "source/xgboost-conversion.md"], "titles": ["Core ML Tools", "Classifiers", "Comparing ML Programs and Neural Networks", "Composite Operators", "Conversion Options", "Converting a TensorFlow 1 DeepSpeech Model", "Converting a TensorFlow 1 Image Classifier", "Converting a torchvision Model from PyTorch", "Converting Deep Learning Models", "Converting a Natural Language Processing Model", "Converting from PyTorch", "PyTorch Conversion Workflow", "Converting from TensorFlow", "Converting TensorFlow 2 BERT Transformer Models", "Convert Models to ML Programs", "Convert Models to Neural Networks", "Examples", "Custom Operators", "Core ML Tools FAQs", "Flexible Input Shapes", "Graph Passes", "Contributing", "Image Input and Output", "Installing Core ML Tools", "Getting Started", "LibSVM", "Load and Convert Model Workflow", "MLModel Overview", "MLModel Utilities", "Model Input and Output Types", "Model Intermediate Language", "Model Prediction", "Model Scripting", "Model Tracing", "Multifunction Models", "New Conversion Options", "New Features", "Conversion", "Optimizing OPT Model", "Overview", "Examples", "Palettization", "Algorithms", "API Overview", "Palettization Overview", "Performance", "Pruning", "Algorithms", "API Overview", "Overview", "Performance", "Linear Quantization", "Quantization Algorithms", "API Overview", "Overview", "Performance", "Optimizing ResNet50 Model", "Whats new", "Optimization Workflow", "What Is Core ML Tools?", "Converting a PyTorch Segmentation Model", "Compressing Neural Network Weights", "Scikit-learn", "Stateful Models", "Source and Conversion Formats", "TensorFlow 1 Workflow", "TensorFlow 2 Workflow", "Typed Execution", "Typed Execution Workflow Example", "Core ML Tools API Overview", "Updatable Models", "Nearest Neighbor Classifier", "Neural Network Classifier", "Pipeline Classifier", "Xcode Model Preview Types", "XGBoost"], "terms": {"model": [0, 4, 10, 12, 20, 21, 25, 27, 35, 36, 39, 40, 42, 44, 47, 49, 50, 52, 54, 57, 59, 61, 62, 64, 67, 69, 71, 75], "from": [0, 1, 2, 3, 5, 6, 9, 11, 13, 14, 16, 17, 18, 21, 22, 24, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74], "tensorflow": [0, 2, 3, 7, 14, 18, 19, 21, 23, 24, 29, 30, 31, 35, 59, 69, 74], "pytorch": [0, 2, 14, 17, 21, 23, 28, 30, 31, 32, 33, 35, 38, 39, 45, 48, 56, 57, 58, 59, 69, 74], "librari": [0, 2, 3, 6, 11, 23, 68], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74], "guid": [0, 18, 20, 23, 39, 47, 48, 53, 59, 66], "includ": [0, 2, 6, 7, 9, 18, 21, 22, 23, 24, 26, 28, 31, 32, 34, 35, 36, 49, 60, 61, 64, 69], "instruct": [0, 17, 18, 23, 30, 31, 36, 53, 69], "exampl": [0, 5, 6, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 29, 30, 32, 33, 37, 38, 39, 44, 48, 49, 58, 61, 66, 67, 69, 70, 71, 72, 73], "For": [0, 1, 2, 3, 6, 7, 9, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75], "detail": [0, 6, 7, 9, 11, 14, 17, 18, 19, 21, 22, 24, 26, 27, 29, 30, 35, 37, 39, 43, 48, 50, 53, 55, 58, 59, 65, 66], "about": [0, 1, 6, 7, 9, 11, 18, 21, 22, 23, 24, 27, 28, 34, 35, 36, 37, 38, 39, 42, 43, 47, 48, 50, 53, 56, 59, 60, 64, 66, 69, 73, 74], "us": [0, 1, 2, 4, 6, 7, 9, 11, 12, 13, 14, 15, 16, 20, 21, 23, 25, 26, 30, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "class": [0, 1, 3, 6, 9, 16, 19, 22, 24, 26, 27, 28, 29, 30, 32, 33, 34, 36, 53, 57, 58, 59, 60, 61, 63, 66], "method": [0, 6, 7, 9, 11, 14, 18, 22, 23, 24, 26, 27, 28, 29, 31, 37, 38, 40, 43, 45, 48, 52, 53, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72], "see": [0, 1, 2, 3, 6, 7, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 45, 47, 48, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75], "coremltool": [0, 1, 2, 3, 5, 6, 7, 9, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 45, 47, 48, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], "index": [0, 34, 44], "search": 0, "page": [0, 9, 18, 21, 23, 36, 39, 42, 43, 47, 48, 58, 59, 61, 66, 67, 69, 74], "format": [0, 2, 6, 7, 8, 9, 10, 14, 16, 17, 18, 19, 21, 24, 25, 26, 31, 35, 36, 37, 43, 44, 49, 50, 53, 57, 58, 59, 62, 65, 67, 71, 74, 75], "what": [0, 1, 13, 18, 21, 24, 30, 32, 34, 36, 39, 40, 44, 49, 58, 65, 71, 72], "i": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74], "instal": [0, 5, 6, 7, 9, 24, 36, 73], "get": [0, 1, 2, 5, 6, 11, 14, 16, 17, 18, 22, 23, 26, 27, 30, 31, 38, 39, 43, 47, 53, 56, 57, 58, 60, 63, 65, 67, 72, 74], "start": [0, 1, 5, 7, 12, 22, 29, 30, 31, 34, 35, 37, 38, 42, 43, 44, 45, 47, 48, 49, 53, 56, 58, 59, 63, 73, 74], "new": [0, 2, 3, 4, 5, 6, 9, 17, 18, 21, 31, 34, 37, 39, 43, 58, 59, 60, 63, 64, 65, 68], "featur": [0, 1, 2, 5, 10, 16, 18, 19, 21, 22, 24, 27, 29, 31, 34, 37, 43, 63, 68, 73, 74], "faq": 0, "contribut": [0, 16, 20, 54], "deep": [0, 2, 64, 69], "learn": [0, 2, 3, 7, 11, 16, 22, 24, 27, 28, 34, 35, 36, 37, 39, 42, 47, 53, 56, 59, 60, 64, 66, 67, 69, 74], "option": [0, 14, 17, 18, 19, 20, 24, 29, 30, 33, 37, 38, 39, 43, 48, 53, 55, 57, 60, 69, 72], "intermedi": [0, 2, 3, 11, 14, 17, 18, 54, 58, 61, 63, 67], "languag": [0, 2, 3, 5, 10, 11, 14, 17, 18, 19, 26, 27, 47, 48, 63], "workflow": [0, 8, 10, 12, 16, 21, 30, 31, 37, 39, 43, 48, 52, 55, 56, 57], "palett": [0, 16, 18, 28, 36, 39, 42, 45, 47, 49, 50, 54, 57, 58, 60], "linear": [0, 2, 34, 37, 38, 39, 43, 48, 49, 50, 53, 54, 58, 59, 61, 71, 73], "quantiz": [0, 16, 21, 28, 36, 39, 42, 43, 47, 48, 49, 50, 55, 57, 58], "prune": [0, 16, 18, 36, 37, 39, 49, 50, 54, 57, 58], "compress": [0, 16, 18, 36, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 57], "neural": [0, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 22, 26, 30, 31, 32, 36, 38, 39, 45, 50, 52, 53, 54, 55, 56, 59, 64, 65, 66, 68, 69, 70, 73, 74], "network": [0, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 22, 26, 30, 31, 32, 33, 34, 36, 43, 50, 52, 54, 55, 56, 59, 64, 65, 66, 68, 69, 70, 73, 74], "weight": [0, 2, 5, 14, 16, 18, 24, 26, 34, 36, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 54, 55, 56, 57, 58, 65, 66, 72], "libsvm": [0, 16, 59, 69], "scikit": [0, 16, 27, 59, 69], "xgboost": [0, 16, 59, 69], "multifunct": [0, 36], "xcode": [0, 2, 7, 13, 18, 19, 26, 27, 31, 34, 45, 50, 55, 63, 67], "preview": [0, 13, 22, 24, 27, 60], "type": [0, 1, 2, 4, 5, 6, 7, 8, 11, 13, 15, 17, 18, 21, 24, 26, 27, 28, 34, 36, 37, 38, 40, 42, 43, 48, 49, 53, 54, 57, 60, 61, 63, 65, 66, 69, 70, 72, 73], "util": [0, 1, 5, 17, 18, 19, 21, 26, 27, 31, 34, 36, 39, 43, 48, 61, 63, 72, 73], "predict": [0, 1, 5, 9, 13, 18, 19, 22, 26, 28, 30, 34, 45, 55, 58, 59, 60, 65, 66, 67, 71, 72, 73, 74], "updat": [0, 2, 5, 18, 23, 28, 34, 36, 37, 42, 43, 53, 57, 63, 71], "A": [1, 2, 9, 17, 21, 23, 27, 28, 30, 31, 33, 34, 38, 43, 48, 49, 53, 58, 60, 66, 67, 72], "special": [1, 2, 9, 31, 34, 37, 67], "kind": [1, 2, 39, 47], "core": [1, 3, 5, 10, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 44, 45, 47, 49, 52, 54, 56, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75], "ml": [1, 3, 4, 5, 8, 10, 12, 13, 15, 17, 20, 21, 25, 26, 28, 29, 31, 32, 33, 34, 37, 38, 39, 44, 45, 47, 49, 52, 54, 56, 60, 61, 62, 65, 66, 70, 71, 73, 74, 75], "provid": [1, 2, 5, 7, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 31, 38, 40, 42, 43, 45, 47, 48, 49, 54, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 72, 73, 74], "label": [1, 6, 24, 48, 53, 56, 60, 71, 72, 73, 74], "name": [1, 2, 3, 5, 6, 7, 9, 13, 17, 19, 22, 23, 24, 25, 26, 27, 28, 30, 34, 37, 42, 43, 45, 47, 48, 50, 52, 53, 55, 60, 61, 63, 65, 68, 72, 73, 75], "probabl": [1, 5, 6, 28, 32, 71, 72, 73], "dictionari": [1, 17, 28, 43, 48, 60], "output": [1, 2, 4, 5, 6, 9, 11, 13, 16, 19, 20, 24, 25, 28, 30, 32, 34, 36, 38, 43, 44, 47, 52, 53, 54, 58, 60, 63, 65, 66, 67, 69, 71, 72, 73, 74, 75], "topic": [1, 30, 71], "describ": [1, 2, 4, 7, 11, 13, 14, 18, 19, 21, 23, 24, 26, 30, 33, 36, 37, 38, 43, 48, 52, 53, 60, 61, 67], "step": [1, 3, 5, 6, 7, 10, 13, 19, 21, 23, 24, 26, 27, 31, 33, 36, 42, 43, 48, 53, 56, 58, 59, 60, 63, 65, 66, 68, 73, 74], "unifi": [1, 2, 5, 7, 11, 12, 14, 18, 22, 24, 26, 29, 30, 35, 36, 59, 64, 66, 69], "convers": [1, 2, 5, 6, 7, 8, 10, 14, 17, 20, 22, 23, 24, 27, 28, 30, 34, 36, 39, 43, 48, 59, 60, 63, 65, 66, 67, 68, 69], "classifierconfig": [1, 6, 7, 24], "open": [1, 6, 7, 13, 14, 19, 21, 24, 31, 36, 68], "an": [1, 2, 3, 6, 7, 10, 11, 13, 14, 16, 17, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 48, 53, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 71, 72, 74], "imag": [1, 4, 11, 12, 19, 24, 34, 35, 36, 45, 55, 66, 68, 69, 72, 73, 74], "input": [1, 2, 3, 4, 11, 13, 17, 20, 24, 25, 26, 28, 30, 32, 33, 34, 36, 38, 42, 43, 47, 48, 52, 53, 57, 58, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75], "displai": [1, 7, 19, 22, 24, 27, 60], "follow": [1, 2, 3, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 43, 44, 48, 49, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74], "its": [1, 2, 7, 9, 11, 17, 22, 23, 24, 26, 27, 28, 31, 33, 34, 39, 47, 49, 50, 55, 57, 59, 63, 65, 67, 68, 71], "In": [1, 2, 3, 5, 6, 7, 9, 11, 14, 17, 22, 24, 26, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 42, 43, 45, 47, 48, 49, 53, 54, 55, 56, 58, 63, 65, 67, 72, 73], "abov": [1, 3, 5, 7, 11, 14, 17, 22, 30, 34, 37, 38, 44, 48, 50, 53, 54, 56, 57, 65, 68], "section": [1, 4, 7, 14, 18, 19, 30, 32, 33, 36, 37, 39, 48, 52, 53, 56, 58, 61, 63, 67, 68, 69], "metadata": [1, 13, 14, 16, 26, 72, 73, 74], "tab": [1, 13, 19, 22, 23, 24, 34, 45, 50, 55, 60, 71, 74], "leftmost": 1, "precis": [1, 2, 6, 18, 29, 39, 42, 44, 50, 52, 56, 58, 61], "ar": [1, 2, 3, 4, 5, 6, 7, 9, 11, 14, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 67, 68, 71, 72, 73], "train": [1, 2, 5, 6, 7, 9, 10, 11, 16, 22, 24, 26, 27, 28, 31, 32, 33, 38, 39, 42, 45, 50, 54, 55, 56, 59, 60, 62, 67, 68, 72, 73, 74, 75], "identifi": [1, 28], "show": [1, 3, 6, 7, 17, 19, 22, 23, 24, 27, 28, 30, 31, 34, 43, 44, 48, 60, 63, 65, 68, 74], "associ": [1, 2, 71, 72, 73], "top": [1, 5, 7, 17, 24, 30, 32, 45, 55, 56], "1": [1, 2, 3, 7, 9, 11, 12, 13, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 36, 38, 39, 42, 43, 44, 45, 47, 49, 50, 52, 53, 55, 57, 59, 60, 63, 66, 71, 72, 73, 74], "addit": [1, 2, 5, 6, 7, 14, 21, 22, 24, 26, 37, 43, 47, 50, 53, 58, 67, 72], "consum": [1, 2, 67], "can": [1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "encod": [1, 13, 32], "dure": [1, 3, 6, 14, 16, 18, 19, 20, 22, 24, 31, 32, 34, 36, 37, 42, 45, 47, 53, 54, 55, 56, 59, 63, 64, 65, 67, 68], "creation": [1, 31, 59], "more": [1, 2, 5, 6, 7, 9, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 37, 38, 39, 42, 43, 45, 47, 48, 49, 50, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 67, 68, 72, 74, 75], "inform": [1, 5, 6, 7, 13, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 38, 42, 43, 48, 60, 62, 65, 72, 74, 75], "code": [1, 2, 3, 5, 6, 7, 9, 11, 16, 17, 19, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 38, 43, 48, 53, 56, 58, 63, 67, 68, 74], "repeat": [1, 9, 37], "below": [1, 9, 24, 34, 37, 38, 42, 43, 45, 47, 48, 53, 55, 56, 57, 58, 63], "how": [1, 2, 6, 7, 9, 11, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 31, 34, 37, 38, 42, 43, 47, 48, 56, 58, 60, 63, 65, 66, 67, 68, 72, 74], "add": [1, 3, 7, 13, 16, 17, 18, 20, 21, 24, 31, 48, 60, 63, 65, 67, 68, 72, 73, 74], "classif": [1, 22, 34, 45, 55, 66, 73], "your": [1, 2, 3, 5, 6, 7, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 42, 47, 53, 55, 58, 59, 61, 63, 66, 67, 68, 73], "assum": [1, 7, 22, 31, 32, 37, 43], "correspond": [1, 3, 5, 18, 22, 28, 37, 44, 68], "distribut": [1, 5, 23, 67], "conveni": [1, 11, 22, 28, 31, 58, 63, 66], "automat": [1, 5, 6, 16, 18, 22, 23, 29, 37, 38, 52, 65, 67, 68, 72], "wrap": [1, 31, 60], "form": [1, 2, 34, 42, 43, 60], "To": [1, 2, 3, 5, 6, 7, 9, 11, 13, 14, 15, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 43, 47, 48, 53, 58, 60, 63, 64, 65, 66, 68, 72, 74], "defin": [1, 2, 3, 6, 13, 16, 18, 19, 24, 26, 27, 30, 32, 33, 34, 38, 43, 53, 60, 63, 65, 67, 74], "import": [1, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 43, 48, 53, 56, 58, 60, 61, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 75], "ct": [1, 3, 5, 6, 7, 9, 11, 13, 14, 15, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 43, 48, 53, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 74, 75], "image_input": [1, 6, 7, 11, 18, 22, 24], "imagetyp": [1, 6, 7, 11, 16, 18, 24, 29, 35, 66, 68, 72, 73], "shape": [1, 2, 4, 5, 6, 7, 9, 11, 13, 17, 22, 24, 26, 30, 31, 32, 33, 34, 37, 38, 44, 53, 60, 63, 65, 66, 68, 69, 72, 73], "224": [1, 6, 7, 11, 18, 19, 22, 24, 26, 31, 33, 53, 56, 60, 65], "3": [1, 6, 7, 11, 13, 18, 19, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 37, 38, 39, 42, 44, 45, 47, 49, 50, 53, 56, 57, 58, 59, 60, 63, 65, 66, 68, 71, 72, 73, 74], "classifier_config": [1, 6, 7, 24], "class_label": [1, 7, 24, 72], "convert": [1, 2, 4, 16, 19, 20, 25, 27, 29, 31, 32, 33, 34, 44, 45, 52, 58, 59, 61, 62, 64, 67, 69, 74, 75], "keras_model": [1, 22, 24, 72], "pil": [1, 6, 7, 22, 24, 31, 60, 68], "load": [1, 3, 5, 8, 11, 13, 14, 16, 17, 18, 19, 22, 28, 30, 31, 34, 35, 38, 43, 45, 50, 55, 61, 62, 65, 66, 67, 68, 74], "resiz": [1, 6, 7, 22, 24, 31, 60, 68], "expect": [1, 3, 5, 7, 22, 24, 55, 66, 68, 72, 73], "size": [1, 5, 7, 16, 17, 19, 22, 24, 27, 28, 31, 33, 34, 37, 38, 39, 43, 45, 47, 48, 49, 50, 55, 58, 60, 61, 62, 68, 71], "example_imag": [1, 22, 24], "daisi": [1, 7, 22, 24], "jpg": [1, 6, 7, 22, 24, 31, 60, 68], "make": [1, 5, 16, 18, 19, 21, 22, 25, 26, 27, 30, 31, 32, 33, 39, 48, 59, 60, 63], "print": [1, 3, 5, 6, 9, 14, 18, 19, 24, 27, 28, 30, 31, 63, 65, 68, 73], "out": [1, 7, 11, 18, 24, 27, 28, 36, 39, 43, 47, 48, 50, 56, 57, 58, 59, 60, 63, 65, 71], "out_dict": [1, 22, 24, 31], "classlabel": [1, 6, 7, 24], "all": [1, 2, 3, 5, 7, 9, 16, 17, 18, 21, 22, 23, 26, 30, 31, 32, 33, 35, 36, 37, 38, 39, 42, 43, 45, 47, 48, 50, 53, 55, 56, 57, 58, 59, 61, 64, 65, 67, 68, 73], "framework": [1, 2, 3, 21, 22, 23, 24, 28, 30, 31, 63, 64, 67, 69], "howev": [1, 6, 7, 18, 19, 26, 29, 31, 32, 34, 35, 37, 38, 39, 42, 43, 44, 52, 53, 55, 56, 60, 61, 63, 64, 67, 68], "you": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 47, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75], "also": [1, 2, 5, 6, 7, 11, 13, 14, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 35, 37, 38, 39, 42, 43, 44, 45, 47, 50, 52, 53, 54, 56, 58, 60, 63, 64, 65, 67, 68, 72], "observ": [1, 38, 39, 53, 54, 55, 56], "which": [1, 2, 3, 5, 6, 7, 9, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 67, 68, 72, 73], "analysi": 1, "preprocess": [1, 11, 16, 24, 60, 65], "As": [2, 3, 7, 9, 11, 17, 18, 21, 22, 31, 37, 38, 39, 48, 67, 68], "evolv": [2, 3], "sophist": 2, "complex": 2, "thei": [2, 17, 21, 22, 37, 43, 44, 53, 55, 58, 67], "work": [2, 7, 11, 16, 19, 22, 31, 39, 42, 47, 52, 56, 58, 60, 61, 63, 65, 66, 67, 74], "repres": [2, 3, 5, 16, 17, 19, 22, 27, 31, 37, 38, 39, 42, 43, 44, 45, 49, 54, 61, 64, 68], "oper": [2, 4, 5, 6, 7, 11, 18, 22, 23, 30, 33, 38, 42, 43, 47, 53, 54, 61, 65, 66, 68, 69, 71, 73], "The": [2, 3, 5, 6, 7, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74], "foundat": [2, 14], "futur": [2, 14, 57], "improv": [2, 14, 18, 21, 24, 31, 36, 38, 49, 50, 54, 56, 58, 63], "few": [2, 5, 6, 30, 31, 37, 38, 39, 40, 42, 47, 49, 52, 53, 58, 67, 72], "major": [2, 9, 18, 64, 67], "between": [2, 5, 9, 18, 24, 28, 34, 35, 38, 39, 47, 58, 61, 64, 67, 68], "layer": [2, 5, 13, 18, 28, 30, 32, 33, 34, 37, 38, 47, 48, 49, 52, 53, 64, 66, 67, 72, 73], "comput": [2, 6, 7, 17, 20, 30, 32, 38, 39, 42, 43, 45, 47, 48, 50, 52, 53, 54, 55, 56, 58, 60, 61, 63, 67], "graph": [2, 4, 5, 16, 18, 24, 26, 29, 30, 32, 33, 37, 53, 64, 67, 68, 69], "programmat": [2, 24], "embed": [2, 7, 16, 38, 45, 47, 50, 55], "decoupl": [2, 14], "serial": [2, 6], "tensor": [2, 3, 5, 6, 9, 14, 17, 22, 26, 28, 29, 30, 32, 33, 37, 38, 42, 43, 44, 45, 48, 49, 53, 54, 56, 57, 60, 61, 63, 65, 68], "implicit": [2, 30], "explicit": [2, 10, 63, 67], "limit": [2, 11, 19, 26, 37, 38, 53, 60, 64], "control": [2, 9, 11, 20, 22, 28, 31, 32, 33, 43, 53, 54, 67], "over": [2, 3, 9, 22, 28, 32, 37, 38, 39, 45, 50, 56, 58, 63, 67, 68], "granular": [2, 37, 38, 42, 43, 48, 52, 53, 56, 58], "advantag": [2, 24, 31, 45, 49], "execut": [2, 6, 7, 8, 14, 18, 20, 22, 24, 26, 31, 61], "numer": [2, 6, 37, 38, 40, 63, 65, 67], "produc": [2, 5, 6, 9, 11, 14, 16, 22, 26, 28, 29, 30, 31, 32, 34, 35, 37, 38, 47, 57, 60, 61, 63, 67, 68, 72], "one": [2, 5, 7, 9, 18, 19, 22, 23, 27, 30, 31, 33, 34, 39, 43, 47, 53, 55, 56, 57, 61, 63, 66, 67, 72], "segment": [2, 5, 10, 11, 16, 28], "anoth": [2, 7, 24, 31, 34, 48, 57, 63, 66, 67], "runtim": [2, 18, 19, 20, 22, 37, 40, 45, 49, 54, 55, 56, 57, 58, 61, 63, 67], "respect": [2, 7, 45, 47, 48, 50, 53, 55, 56, 67], "specifi": [2, 6, 7, 9, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 34, 35, 38, 43, 44, 48, 53, 56, 66, 67], "minimum": [2, 14, 19, 35, 39, 43, 63, 67], "result": [2, 5, 6, 7, 11, 16, 21, 22, 28, 31, 32, 33, 34, 40, 49, 53, 56, 60, 63, 65, 67, 71, 74], "easili": [2, 5, 18, 30, 42, 58], "when": [2, 6, 7, 9, 11, 17, 18, 19, 21, 22, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 49, 50, 53, 54, 55, 58, 61, 67, 68], "By": [2, 7, 22, 26, 31, 37, 53, 61, 67, 71], "comparison": [2, 7, 14, 30, 38], "ti": [2, 67], "unit": [2, 6, 7, 18, 39, 45, 50, 55, 61, 66, 67], "gpu": [2, 18, 26, 31, 35, 38, 39, 55, 59, 63, 67, 68], "float": [2, 16, 18, 29, 35, 36, 37, 39, 44, 49, 54, 67, 68, 73, 74], "32": [2, 14, 18, 22, 29, 34, 38, 39, 58, 61, 66, 67, 72], "back": [2, 18, 63, 71], "metal": 2, "perform": [2, 5, 7, 9, 11, 17, 18, 23, 24, 26, 30, 31, 33, 37, 38, 41, 42, 43, 46, 47, 48, 49, 51, 52, 53, 54, 56, 58, 59, 63, 66, 67, 68], "shader": 2, "while": [2, 3, 5, 9, 16, 17, 19, 22, 26, 31, 34, 35, 37, 38, 39, 42, 43, 45, 48, 49, 52, 56, 58, 59, 61, 64, 67, 68, 73], "onli": [2, 3, 5, 17, 18, 21, 22, 24, 26, 28, 31, 32, 33, 34, 37, 38, 39, 42, 43, 45, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 64, 67, 68], "16": [2, 5, 18, 28, 29, 33, 35, 36, 37, 38, 39, 44, 45, 50, 53, 56, 58, 67, 68, 74], "path": [2, 6, 18, 26, 27, 31, 35, 39, 53, 64, 65, 66, 67, 72], "both": [2, 5, 6, 22, 26, 29, 32, 34, 37, 38, 52, 54, 56, 58, 72], "especi": [2, 26, 35, 38, 55], "newer": [2, 9, 11, 15, 18, 23, 24, 26, 29, 36, 39, 43, 44, 49, 50, 54, 55, 56, 60, 64, 67, 68, 74], "devic": [2, 17, 18, 19, 22, 24, 31, 34, 38, 45, 48, 50, 55, 56, 58, 59], "effici": [2, 17, 20, 22, 29, 34, 38, 49, 52, 58, 63], "compil": [2, 16, 17, 19, 27, 39, 72], "sinc": [2, 5, 6, 14, 17, 22, 26, 29, 31, 32, 34, 38, 42, 45, 47, 53, 55, 56, 58, 61, 64, 65, 66, 67, 68], "do": [2, 7, 9, 18, 19, 20, 24, 26, 30, 31, 34, 36, 37, 39, 43, 53, 56, 58, 63, 65, 67, 68], "store": [2, 13, 22, 31, 37, 38, 44, 49, 50, 54, 63, 72], "protobuf": [2, 18, 26, 27, 28, 30, 65], "file": [2, 6, 7, 11, 13, 14, 18, 21, 23, 24, 25, 26, 27, 31, 43, 45, 47, 48, 50, 53, 55, 59, 60, 65, 66, 68, 72, 74, 75], "memori": [2, 5, 11, 19, 24, 38, 39, 42, 45, 49, 50, 54, 55, 58, 59], "significantli": [2, 67], "": [2, 6, 7, 9, 11, 17, 19, 21, 24, 26, 27, 31, 32, 33, 37, 38, 42, 43, 44, 47, 48, 49, 52, 53, 56, 59, 61, 63, 65, 67, 68, 71, 72, 74], "api": [2, 5, 7, 11, 12, 14, 16, 17, 18, 20, 22, 24, 25, 26, 28, 29, 30, 31, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47, 51, 56, 59, 61, 62, 63, 64, 65, 66, 70, 75], "download": [2, 5, 23, 45, 47, 50, 55, 60, 65, 66, 74], "user": [2, 3, 16, 19, 23, 25, 36, 37, 39, 43, 53, 59, 67, 73], "mlprogram": [2, 11, 14, 19, 22, 26, 28, 29, 34, 35, 44, 49, 53, 57, 61, 63, 64, 65, 66], "wai": [2, 21, 22, 23, 24, 26, 28, 31, 33, 37, 38, 39, 42, 48, 56, 58, 59, 63, 66, 67], "than": [2, 15, 17, 22, 24, 26, 28, 30, 31, 32, 34, 38, 42, 43, 47, 48, 49, 53, 55, 56, 58, 61, 63, 64], "origin": [2, 6, 7, 9, 22, 24, 27, 28, 32, 37, 44, 47, 52, 53, 58, 60, 64, 65, 68], "neuralnetwork": [2, 15, 19, 24, 26, 27, 57, 61, 64, 67], "them": [2, 5, 6, 16, 20, 21, 22, 23, 24, 30, 31, 34, 37, 39, 42, 53, 58, 60, 63, 64, 67, 72, 74], "There": [2, 42, 43, 54, 57], "sever": [2, 22, 31, 32, 33, 36, 38, 39, 42, 43, 45, 47], "At": [2, 27, 32, 34, 38], "level": [2, 5, 7, 27, 30, 32, 37, 39, 43, 47, 48, 49, 50, 53, 58, 66, 68], "set": [2, 6, 13, 16, 17, 18, 27, 28, 30, 31, 38, 42, 43, 44, 47, 48, 49, 52, 53, 56, 61, 63, 64, 65, 67, 68, 73, 74], "mathemat": [2, 3, 54], "equat": [2, 3, 22, 54], "shown": [2, 3, 7, 11, 14, 15, 18, 19, 22, 24, 26, 28, 30, 31, 33, 34, 37, 44, 63, 67, 71], "left": [2, 24, 60, 74], "side": [2, 24, 60, 74], "figur": [2, 19, 22, 23, 34, 44, 63, 74], "often": [2, 24, 38, 58], "machin": [2, 3, 24, 27, 34, 59, 67], "cours": [2, 24, 48, 71], "beginn": 2, "three": [2, 5, 7, 22, 27, 42, 47, 54, 63, 68], "express": [2, 3, 37, 54], "descript": [2, 5, 7, 13, 16, 17, 18, 19, 20, 21, 24, 31, 58, 64, 67, 68, 71, 72, 73], "abstract": 2, "concis": 2, "scalabl": 2, "center": [2, 44], "previou": [2, 5, 6, 7, 9, 14, 19, 22, 23, 24, 26, 30, 31, 37, 48, 55, 57, 60, 63, 68, 71], "direct": 2, "connect": [2, 59, 72], "each": [2, 5, 7, 16, 18, 20, 21, 22, 30, 31, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 52, 54, 55, 56, 60, 63, 67, 68, 71, 72, 73], "other": [2, 5, 9, 11, 19, 21, 22, 23, 24, 31, 32, 33, 37, 38, 39, 40, 43, 49, 53, 55, 56, 61, 65, 67, 69, 72], "feed": [2, 28, 43, 65, 72], "sourc": [2, 3, 6, 8, 13, 18, 19, 24, 26, 29, 30, 31, 36, 37, 67, 69, 71], "undergo": [2, 57], "seri": [2, 5, 30], "transform": [2, 5, 7, 9, 12, 16, 20, 22, 38, 42, 47, 52, 57, 60, 63, 67, 74], "gener": [2, 7, 9, 22, 24, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 47, 48, 50, 52, 59, 61, 63, 64, 65, 66, 68], "through": [2, 7, 11, 21, 32, 33, 36, 48, 52, 53, 54, 56, 59, 60], "sink": 2, "node": [2, 3, 17], "mani": [2, 34, 58], "particular": [2, 3, 23, 34, 39, 56], "edg": 2, "establish": [2, 9], "match": [2, 5, 6, 17, 31, 37, 61, 63, 67, 68], "although": 2, "graphic": [2, 26, 31, 35], "understand": [2, 7, 11, 21, 24, 67], "visual": [2, 31, 36], "actual": [2, 17, 19, 26, 31, 32, 35, 38, 53, 56, 68], "just": [2, 3, 5, 18, 32, 37, 39, 43, 45, 53, 58, 68], "like": [2, 5, 7, 16, 24, 31, 32, 37, 43, 45, 47, 53, 60, 72], "ani": [2, 5, 21, 22, 23, 27, 37, 38, 43, 47, 49, 56, 59, 65, 67, 68], "directli": [2, 3, 5, 6, 10, 14, 18, 26, 27, 28, 32, 33, 34, 36, 37, 38, 39, 43, 52, 56, 58, 63, 65, 66, 68], "right": [2, 6, 7, 16, 23, 24, 39, 60, 65, 68, 73, 74], "flexibl": [2, 4, 5, 14, 60, 65, 67, 69], "incorpor": [2, 7, 24], "function": [2, 5, 17, 18, 21, 22, 30, 32, 33, 34, 38, 39, 42, 43, 58, 60, 64, 72], "block": [2, 30, 32, 37, 38, 39, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 63], "flow": [2, 7, 9, 11, 32, 33, 43, 53, 58], "strongli": [2, 67], "variabl": [2, 29, 33, 65, 67], "op": [2, 6, 17, 20, 24, 28, 30, 37, 43, 48, 50, 52, 61, 63, 64, 65, 67, 68], "v": [2, 38], "consist": [2, 5, 7, 27, 33, 68], "main": [2, 30, 32, 34], "short": [2, 5, 17, 24], "version": [2, 3, 6, 7, 9, 10, 13, 14, 15, 21, 22, 24, 26, 27, 29, 31, 32, 38, 39, 40, 42, 43, 45, 50, 55, 56, 57, 58, 60, 66, 67, 68, 73], "opset": 2, "fulli": [2, 18, 26, 33, 36, 37, 39, 48, 55, 72], "itself": [2, 38, 67], "proto": [2, 27, 64, 72, 73], "def": [2, 3, 6, 9, 17, 18, 19, 22, 30, 31, 32, 33, 34, 38, 60, 61, 63, 66, 68, 71, 72], "refer": [2, 3, 20, 22, 24, 25, 28, 29, 30, 39, 43, 44, 48, 49, 50, 53, 54, 55, 59, 61, 62, 63, 75], "messag": [2, 7, 24], "without": [2, 5, 10, 22, 26, 37, 43, 49, 53, 56, 58, 60, 61, 64, 66, 71], "paramet": [2, 6, 7, 11, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 42, 43, 44, 48, 53, 58, 60, 61, 63, 64, 65, 69, 71, 72, 74], "distinguish": 2, "compris": 2, "constant": [2, 20, 30, 48, 53], "ha": [2, 5, 6, 14, 17, 18, 21, 22, 26, 30, 31, 32, 33, 34, 37, 42, 43, 48, 53, 56, 63, 67, 72, 73], "except": [2, 5, 19, 28, 30, 43], "const": [2, 17, 28, 30, 65], "attribut": [2, 9, 17, 22], "so": [2, 5, 7, 13, 14, 17, 18, 19, 21, 22, 24, 26, 31, 32, 34, 37, 49, 50, 53, 56, 58, 61, 63, 67, 68, 72], "posit": [2, 5, 19, 30], "irrelev": 2, "some": [2, 6, 9, 18, 19, 26, 32, 37, 38, 39, 42, 43, 53, 57, 58, 61, 63, 65, 67, 74], "constrain": [2, 54], "call": [2, 3, 5, 6, 16, 18, 20, 22, 31, 34, 38, 42, 43, 44, 48, 54, 63, 64, 66, 68, 71], "var": 2, "separ": [2, 9, 14, 24, 32, 34], "outsid": [2, 71], "architectur": [2, 5, 7, 14, 24, 38, 42, 47, 63, 74], "save": [2, 6, 7, 10, 11, 13, 16, 18, 19, 20, 25, 26, 28, 31, 33, 34, 37, 39, 49, 50, 53, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75], "packag": [2, 5, 6, 7, 11, 19, 21, 22, 24, 27, 34, 36, 59, 61, 65, 66, 69, 73], "entir": [2, 5, 32, 44, 67], "singl": [2, 19, 20, 30, 32, 34, 39, 44, 54, 58, 65, 67, 68, 74], "therefor": [2, 7, 9, 17, 22, 24, 26, 31, 47, 55, 68], "either": [2, 7, 11, 14, 23, 24, 26, 29, 30, 35, 38, 39, 43, 47, 48, 49, 57, 58, 64, 67], "mlmodel": [2, 3, 5, 6, 9, 11, 13, 14, 18, 19, 21, 22, 24, 25, 26, 29, 30, 31, 32, 34, 36, 37, 43, 58, 60, 61, 62, 63, 64, 65, 66, 71, 72, 73, 74, 75], "mlpackag": [2, 6, 7, 11, 13, 14, 18, 19, 22, 24, 28, 31, 34, 39, 53, 56, 57, 58, 60, 64, 65, 66, 74], "mlmodelc": [2, 31], "archiv": 2, "find": [2, 6, 11, 21, 24, 26, 30, 35, 39, 43, 47, 48, 58, 61], "insid": [2, 5, 9, 32, 42], "content": [2, 5], "text": [2, 5, 7, 9, 13, 31, 34], "project": [2, 6, 7, 23, 24, 60], "ad": [2, 3, 6, 7, 18, 22, 24, 34, 45, 55, 57, 64, 73, 74], "command": [2, 7, 9, 21, 23, 24, 60], "line": [2, 23, 58, 72], "place": [2, 17, 28, 31, 42, 59, 73], "current": [2, 17, 21, 23, 36, 39, 64, 71, 72], "directori": [2, 6, 18, 24, 31, 64, 66], "xcrun": 2, "coremlcompil": 2, "most": [2, 3, 5, 23, 24, 26, 30, 31, 34, 36, 37, 38, 39, 42, 43, 52, 58, 66, 67, 68, 71], "compon": [2, 5, 14, 22, 27], "yet": 2, "If": [2, 6, 7, 9, 11, 14, 16, 18, 19, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 43, 47, 48, 52, 58, 60, 66, 67, 68, 71], "mai": [2, 3, 6, 7, 17, 18, 19, 21, 22, 24, 26, 28, 31, 34, 35, 38, 39, 40, 45, 47, 50, 52, 53, 54, 55, 56, 57, 58, 61, 67, 68], "want": [2, 9, 17, 18, 22, 28, 32, 34, 37, 39, 53, 58, 60, 67], "continu": [2, 3, 9, 18, 23, 30, 64], "On": [2, 14, 32, 39, 49, 54, 55, 56], "still": [2, 18, 19, 21, 24, 26, 31, 32, 37, 42, 45, 47, 48, 56, 64], "pipelin": [2, 16, 18, 23, 24, 27, 39, 43, 58, 59, 62, 70], "portion": [2, 9, 67], "custom": [2, 4, 28, 43, 48, 53, 66, 69], "own": [2, 16, 29, 54], "swift": [2, 16, 26, 31, 67], "implement": [2, 5, 16, 18, 37, 38, 39, 43, 47, 53, 57], "case": [2, 3, 5, 6, 7, 11, 13, 17, 26, 28, 30, 32, 33, 34, 38, 39, 42, 43, 52, 54, 57, 58, 63, 67, 68, 72], "composit": [2, 4, 18, 30, 69], "built": [2, 37], "builder": [2, 3, 16, 17, 18, 30, 63, 71, 72], "suffici": [2, 14, 42, 47, 48, 52, 68], "handl": [2, 3, 5, 6, 16, 37, 61, 65], "unsupport": [2, 3, 17, 30], "exist": [2, 6, 18, 19, 21, 34, 72], "better": [2, 6, 11, 31, 38, 39, 42, 47, 53, 56, 58, 61, 66, 68], "seamlessli": [2, 37], "wa": [2, 7, 9, 10, 15, 24, 37, 38, 48, 56, 63, 64, 68, 72, 73], "introduc": [2, 10, 17, 18, 37, 48, 50, 53, 63], "4": [2, 6, 10, 12, 13, 14, 19, 23, 30, 37, 38, 39, 42, 43, 44, 45, 49, 50, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 66, 68, 71, 72], "intern": [2, 18, 36, 63], "ir": [2, 18], "stack": [2, 5, 18, 52], "tree": [2, 22, 24, 59], "vector": [2, 34, 37, 49, 59, 71, 73], "svm": 2, "glm": 2, "enabl": [2, 18, 22, 29, 31, 32, 39, 43, 44, 53, 56, 61, 65], "unif": 2, "2": [2, 3, 5, 6, 7, 12, 18, 19, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 44, 45, 49, 50, 57, 59, 60, 63, 65, 68, 71, 72, 74], "begin": [2, 6, 9], "frontend": [2, 3, 17, 24], "python": [2, 5, 6, 7, 16, 17, 18, 22, 24, 27, 30, 36, 43, 59, 60, 63, 65, 68, 69], "object": [2, 3, 5, 9, 14, 16, 18, 19, 24, 26, 27, 28, 31, 33, 42, 43, 45, 56, 60, 64, 65, 66], "centric": 2, "simplifi": [2, 20, 54, 63], "specif": [2, 4, 6, 17, 19, 21, 22, 28, 31, 33, 34, 35, 38, 39, 40, 42, 43, 58, 63, 67, 68, 73], "pass": [2, 3, 4, 6, 9, 17, 18, 22, 23, 24, 26, 32, 33, 38, 43, 47, 52, 53, 54, 56, 57, 60, 63, 66, 68, 69], "translat": [2, 3, 17, 18, 30], "common": [2, 5, 7, 18, 28, 34, 43, 49, 63, 69], "sequenc": [2, 5, 9, 30, 34, 38, 63], "final": [2, 5, 20, 31, 42, 43, 47, 48, 53, 56, 58, 65, 66, 72], "backend": [2, 17, 18, 31, 39, 45, 64, 67, 72], "disk": [2, 22, 31, 39, 43, 56, 61, 65], "subsequ": [2, 19, 31, 63], "avail": [2, 3, 5, 17, 22, 23, 24, 26, 31, 34, 35, 36, 37, 38, 42, 43, 45, 52, 53, 56, 58, 60, 61, 63, 64, 65, 67, 74], "must": [2, 7, 17, 19, 21, 22, 29, 63, 72], "further": [2, 24, 38, 39, 44, 48, 49, 52, 54, 55, 67], "straightforward": 2, "becaus": [2, 23, 26, 29, 31, 38, 53, 63], "same": [2, 3, 5, 6, 7, 9, 21, 22, 24, 26, 31, 32, 34, 37, 38, 42, 43, 44, 45, 47, 53, 60, 63, 67, 68], "ident": [2, 39], "regularli": 3, "encount": [3, 17, 32, 50], "construct": [3, 5, 9, 16, 18, 28, 30, 32, 34, 37, 43, 61, 63, 73], "overview": [3, 18, 20, 26, 28, 40, 41, 46, 51, 56, 58, 61], "dispos": 3, "mb": [3, 17, 30, 56, 63], "matmul": [3, 65, 66], "It": [3, 5, 6, 7, 14, 17, 22, 24, 27, 28, 34, 39, 42, 47, 50, 53, 58, 69, 72, 73], "t5": 3, "need": [3, 5, 6, 7, 14, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 36, 37, 38, 39, 43, 48, 50, 53, 55, 56, 58, 59, 60, 63, 65, 67, 68, 72, 74], "first": [3, 6, 7, 14, 19, 21, 22, 24, 26, 27, 30, 31, 36, 37, 38, 53, 58, 59, 60, 63, 65, 66, 68, 73], "10": [3, 11, 13, 14, 19, 22, 23, 24, 28, 30, 36, 38, 43, 52, 55, 64, 65, 66, 68, 69, 72], "0": [3, 5, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 36, 38, 39, 42, 43, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 63, 64, 65, 66, 68, 71, 72, 73, 74], "statement": [3, 13, 60], "tft5model": 3, "from_pretrain": [3, 9, 13, 38], "small": [3, 32, 33, 38, 39, 42, 45, 47, 50, 58], "return": [3, 5, 7, 9, 17, 19, 22, 27, 28, 30, 31, 32, 33, 34, 38, 53, 58, 60, 61, 63, 66, 68, 71], "instanc": [3, 22, 27, 39, 58, 63], "tf": [3, 5, 6, 16, 18, 21, 22, 24, 26, 29, 64, 65, 66, 68, 73], "kera": [3, 13, 16, 21, 22, 24, 26, 36, 64, 72], "simul": [3, 42, 52, 53, 56], "scenario": [3, 28, 31, 34, 69], "lack": [3, 65], "support": [3, 9, 11, 14, 18, 27, 30, 31, 32, 37, 39, 42, 43, 44, 47, 54, 57, 58, 61, 63, 67], "disabl": [3, 7, 11, 67], "einsum": 3, "tf_op_registri": [3, 17], "_tf_ops_registri": 3, "del": 3, "run": [3, 5, 6, 7, 18, 20, 22, 23, 26, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 45, 50, 55, 59, 60, 63, 65, 66, 67, 68], "error": [3, 21, 30, 38, 44, 52, 53, 58, 60, 68, 71, 72], "occur": [3, 31, 50, 71], "indic": [3, 7, 21, 42, 44, 49, 68, 73], "document": [3, 19, 24, 59, 60], "einstein": 3, "summat": 3, "notat": 3, "varieti": [3, 27, 47, 65], "reduce_sum": 3, "transpos": [3, 7, 30, 31], "trace": [3, 10, 11, 16, 19, 26, 29, 31, 34, 37, 43, 53, 58, 63], "string": [3, 22, 24, 28, 50, 72, 74], "usual": [3, 31, 43, 50, 52, 63, 67], "complic": [3, 32], "don": [3, 5, 21, 26, 28, 30, 31, 32, 33, 63, 74], "t": [3, 5, 11, 15, 17, 19, 21, 26, 28, 29, 30, 31, 32, 33, 38, 60, 61, 63, 74], "know": [3, 19, 24, 28, 30, 39, 47, 65, 68], "possibl": [3, 5, 17, 21, 26, 32, 33, 35, 39, 50, 55, 56, 71, 72, 73], "look": [3, 14, 38, 39, 43, 56, 58, 68], "essenti": 3, "batch": [3, 22, 31, 45, 50, 53, 55, 56, 66, 72], "matrix": [3, 38, 42, 44, 47], "multipl": [3, 19, 20, 30, 34, 38, 44, 47, 50, 58, 74], "second": [3, 5, 31, 37, 38, 39, 42, 58, 63, 73], "fact": 3, "write": [3, 18, 30, 59, 61, 63], "decor": [3, 17, 30], "register_tf_op": [3, 17], "grab": 3, "context": [3, 9, 13, 17], "assert": [3, 7, 24], "attr": [3, 17], "bnqd": 3, "bnkd": 3, "bnqk": 3, "b": [3, 65, 66], "x": [3, 6, 7, 9, 17, 19, 21, 22, 25, 30, 31, 32, 33, 34, 60, 63, 65, 66, 68, 72, 73], "y": [3, 25, 32, 63, 65, 66, 68], "transpose_x": 3, "fals": [3, 13, 17, 30, 38, 65, 72], "transpose_i": 3, "true": [3, 5, 6, 7, 9, 11, 17, 31, 32, 43, 48, 53, 56, 60, 61, 65, 66, 71, 72, 73], "Be": [3, 18], "sure": [3, 18, 21, 24, 31, 48], "ensur": [3, 6, 7, 11, 19, 21, 24, 37, 53, 66], "invok": [3, 7, 22, 31, 32, 33, 34, 37, 43, 65], "whenev": [3, 17, 23], "register_torch_op": 3, "With": [3, 5, 7, 9, 11, 15, 19, 24, 31, 36, 37, 38, 56, 59, 63, 67, 68], "again": [3, 6, 31, 68, 72], "verifi": [3, 22, 24, 31, 59, 63, 65, 68, 71], "complet": [3, 9, 17, 21, 67], "impli": [3, 49], "resolv": [3, 21], "torch": [3, 9, 11, 19, 26, 31, 32, 33, 34, 38, 42, 45, 47, 50, 52, 53, 55, 56, 57, 58, 60, 63], "torch_op_registri": 3, "_torch_ops_registri": 3, "_get_input": 3, "selu": 3, "requir": [3, 10, 17, 19, 21, 22, 23, 27, 37, 38, 39, 42, 43, 47, 52, 53, 58, 63, 67, 68, 72, 74], "elu": 3, "alpha": 3, "6732632423543772": 3, "mul": 3, "0507009873554805": 3, "program": [4, 6, 7, 8, 11, 13, 15, 17, 18, 19, 26, 29, 60, 63, 64, 65, 66, 69], "state": [4, 5, 36, 38, 45, 50, 55, 56], "classifi": [4, 7, 12, 22, 24, 26, 34, 62, 65, 69, 70, 74], "explor": [5, 38, 47, 52, 56], "relat": [5, 37], "capabl": [5, 65], "tool": [5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 24, 27, 29, 30, 34, 37, 38, 47, 52, 54, 60, 61, 63, 64, 65, 66, 71, 72, 73], "speech": [5, 16, 65], "recognit": [5, 16, 65], "task": [5, 23, 34, 38, 45, 55, 58], "transcript": 5, "system": [5, 6, 9, 14, 22, 23, 24, 31, 67, 68], "stage": [5, 21, 34, 53], "post": [5, 38, 39, 42, 45, 48, 53, 55, 56, 59], "process": [5, 6, 7, 10, 11, 16, 21, 24, 26, 28, 31, 34, 35, 36, 37, 38, 40, 42, 43, 49, 54, 58, 59, 61, 63, 67, 71], "doe": [5, 23, 24, 26, 29, 31, 34, 37, 38, 52, 61, 67, 68], "heavi": 5, "lift": 5, "emploi": [5, 26, 55], "standard": [5, 7, 21, 22, 39, 42, 45, 47, 60], "techniqu": [5, 18, 30, 36, 39, 40, 49, 50, 52, 56, 58], "focu": 5, "involv": [5, 42, 58, 63], "extract": [5, 60], "mel": 5, "frequenc": 5, "cepstral": 5, "coeffici": 5, "mfcc": 5, "raw": [5, 7, 23], "fed": [5, 9, 48], "charact": 5, "time": [5, 6, 9, 16, 18, 32, 38, 39, 42, 43, 45, 47, 50, 55, 56, 58, 63, 68], "those": [5, 9, 34, 50, 53, 58], "postprocess": 5, "ctc": 5, "decod": [5, 7, 9, 24, 38], "pre": [5, 6, 7, 11, 16, 18, 22, 24, 26, 39, 42, 45, 47, 52, 55, 58, 59, 68, 74], "long": [5, 18, 31, 68], "term": [5, 49, 58, 61, 72], "lstm": 5, "dens": [5, 37, 38, 42, 48, 49, 50, 57, 66, 72], "seq2seq": 5, "asset": [5, 31, 34], "inspect": [5, 14, 28, 63, 65, 72], "demo_util": 5, "py": [5, 6, 24, 71], "sampl": [5, 13, 21, 22, 24, 28, 33, 37, 38, 42, 47, 52, 56, 58, 67, 68, 74], "audio_sample_16bit_mono_16khz": 5, "wav": 5, "alphabet": 5, "configur": [5, 21, 23, 27, 28, 31, 37, 38, 44, 48, 53, 56, 58, 67], "txt": [5, 6, 7, 24], "scorer": 5, "kenlm": 5, "7": [5, 6, 14, 15, 23, 24, 25, 26, 29, 31, 36, 37, 42, 45, 49, 50, 56, 61, 63, 64, 68, 72], "checkpoint": [5, 45], "script": [5, 7, 10, 11, 16, 21, 23, 26, 33, 43], "export": [5, 16, 18, 26, 36, 38], "pip": [5, 6, 7, 9, 21, 23, 24, 60, 68], "repositori": [5, 18, 21, 23], "export_dir": 5, "tmp": 5, "checkpoint_dir": 5, "alphabet_config_path": 5, "scorer_path": 5, "dev": [5, 13, 66], "null": [5, 43, 53], "after": [5, 6, 17, 18, 22, 23, 24, 29, 31, 32, 53, 61, 65, 74], "tf_model": [5, 13, 17, 18, 22, 26, 65, 66], "output_graph": [5, 65], "pb": [5, 6, 18, 26, 64, 65, 68], "inspect_tf_output": 5, "logit": [5, 6, 38], "new_state_c": 5, "new_state_h": 5, "mean": [5, 7, 22, 32, 37, 38, 45, 47, 53, 57, 58, 60, 61, 65, 67, 72, 73], "contain": [5, 9, 14, 22, 26, 29, 30, 34, 48, 49, 72, 74], "subgraph": 5, "strip": 5, "off": [5, 38, 39, 43, 53, 56, 58, 68, 72, 73], "remain": [5, 31, 48], "have": [5, 6, 7, 16, 18, 19, 21, 22, 24, 26, 28, 30, 31, 32, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 53, 56, 57, 61, 63, 67], "alreadi": [5, 18, 21, 23, 26, 31, 32, 43, 48], "been": [5, 6, 14, 21, 22, 32, 37, 43, 45, 48, 53, 56, 57, 72], "audiofil": 5, "636": 5, "19": 5, "26": [5, 38, 56], "view": [5, 22, 38, 39], "width": [5, 22, 31, 72, 73], "number": [5, 9, 16, 19, 27, 28, 34, 38, 43, 44, 45, 50, 54, 55, 56, 61, 72], "chang": [5, 18, 21, 26, 29, 31, 32, 36, 37, 48, 53, 57, 63, 71, 72], "length": [5, 19, 38, 44], "12": [5, 11, 13, 14, 24, 36, 38, 50, 56, 60, 64, 74], "inspect_input": 5, "input_nod": 5, "dimens": [5, 7, 9, 16, 18, 31, 43, 54, 71, 73], "creat": [5, 6, 7, 11, 13, 14, 16, 17, 18, 21, 22, 23, 24, 26, 27, 31, 34, 43, 44, 49, 53, 60, 68], "loop": [5, 9, 11, 32, 33, 43, 53], "break": [5, 7, 34, 38], "chunk": [5, 38], "max_time_step": 5, "logits_sequ": 5, "input_dict": 5, "input_length": 5, "np": [5, 6, 7, 9, 13, 19, 22, 29, 30, 31, 34, 63, 65, 66, 68], "arrai": [5, 6, 7, 13, 16, 17, 19, 22, 29, 63, 66, 68], "astyp": [5, 6, 7, 13, 30, 31, 60, 68], "float32": [5, 6, 7, 14, 18, 22, 29, 30, 31, 38, 45, 53, 65, 66, 67, 68, 73], "previous_state_c": 5, "zero": [5, 13, 31, 32, 37, 39, 43, 47, 48, 49, 50, 52, 53, 54, 57], "2048": [5, 28, 38, 43], "initi": [5, 9, 19, 22, 31, 43, 45, 53, 63, 65, 66], "cell": 5, "previous_state_h": 5, "hidden": 5, "n": [5, 6, 37, 42, 44, 45, 47, 48, 49, 50, 52, 55, 65, 68], "evalu": [5, 6, 16, 17, 22, 24, 31, 38, 42, 47], "pred": 5, "append": [5, 9, 28], "prob": 5, "concaten": 5, "end": [5, 6, 9, 31], "r": [5, 34, 56, 60], "flush": 5, "slice": 5, "along": [5, 21, 28, 38, 42, 43, 44, 45, 47, 49, 53, 58, 72], "manag": [5, 22, 23], "go": [5, 23, 34, 37, 38, 39, 47, 56, 58, 63, 71], "rerun": 5, "obtain": [5, 26, 38, 45, 47, 52, 53], "flag": [5, 6, 17, 43, 67], "n_step": 5, "default": [5, 6, 7, 9, 15, 22, 24, 25, 26, 34, 35, 37, 43, 44, 48, 52, 53, 54, 61, 65, 67, 68, 71, 73, 75], "valu": [5, 6, 7, 14, 17, 22, 24, 26, 28, 30, 31, 32, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 57, 60, 61, 63, 64, 65, 66, 67, 72], "take": [5, 7, 9, 11, 16, 18, 24, 26, 29, 30, 31, 37, 38, 39, 42, 43, 48, 49, 52, 56, 57, 58, 60, 63, 65, 67, 68, 73], "newli": [5, 6, 24, 37, 68], "differ": [5, 16, 18, 19, 22, 24, 28, 31, 32, 34, 35, 38, 39, 42, 43, 47, 48, 53, 54, 56, 57, 58, 61, 65, 68], "now": [5, 6, 7, 9, 18, 24, 31, 34, 35, 37, 38, 43, 56, 60, 64, 67, 71, 73], "none": [5, 9, 19, 23, 28, 31, 43, 48, 53, 60, 65, 68, 71], "coreml": [5, 6, 7, 11, 13, 18, 22, 24, 28, 30, 36, 38, 39, 42, 43, 45, 47, 48, 52, 53, 56, 57, 58, 60, 68, 71, 74], "arbitrari": [5, 19], "offer": [5, 14, 18, 28, 36, 39, 47], "reshap": [5, 7, 18, 31, 65], "simplic": 5, "valid": [5, 33, 42, 47, 68, 71], "accuraci": [5, 6, 7, 16, 19, 21, 24, 38, 39, 40, 42, 45, 48, 50, 53, 54, 55, 56, 58, 61, 65, 67, 68, 72], "far": 5, "two": [5, 31, 32, 34, 36, 37, 38, 43, 50, 53, 56, 58, 64, 68, 72], "variant": [5, 13, 34], "fix": [5, 6, 7, 9, 19, 21, 31, 65], "accept": [5, 19, 22, 43, 72], "transpar": 5, "tensortyp": [5, 7, 9, 11, 19, 22, 26, 29, 31, 32, 34, 53, 60, 63, 65], "under": [5, 21, 24, 57, 58, 64, 74], "hood": 5, "infer": [5, 17, 18, 26, 34, 36, 37, 38, 39, 50, 52, 53, 54, 55, 56, 59, 63, 65, 67], "propag": 5, "remov": [5, 7, 24, 59, 73], "unnecessari": 5, "ones": [5, 43, 49, 58, 65], "incept": 6, "v1": [6, 65], "demonstr": [6, 9, 13, 16, 24, 26, 27, 31, 32, 43, 53, 60, 61, 63, 65, 66, 68, 71, 72, 74], "correctli": [6, 16, 24, 32, 37, 60, 65, 66, 71], "deprec": [6, 18, 68], "difficult": [6, 68], "appropri": [6, 21, 23, 32, 58, 68], "miniconda": [6, 23, 68], "environ": [6, 68], "conda": [6, 68], "15": [6, 7, 11, 14, 22, 23, 31, 38, 45, 50, 53, 54, 55, 56, 60, 64, 68], "tensorflow1": [6, 68], "env": [6, 23, 68], "activ": [6, 23, 31, 32, 39, 43, 47, 55, 57, 58, 66, 68, 72], "altern": [6, 11, 15, 66, 68], "old": [6, 18, 68], "stackoverflow": [6, 68], "u": [6, 7, 9, 21, 23, 24, 38, 56, 60, 68, 72], "pillow": [6, 24, 60, 68], "request": [6, 7, 21, 24], "matplotlib": [6, 68], "frozen": [6, 16, 18, 26, 64], "__future__": 6, "print_funct": 6, "o": [6, 21, 39, 40, 43, 56, 57, 65], "sy": 6, "tarfil": 6, "download_file_and_unzip": 6, "url": [6, 72], "dir_path": 6, "unzip": 6, "address": [6, 21], "local": 6, "makedir": 6, "k": [6, 16, 17, 38, 45, 57, 58, 61, 71, 73], "rfind": 6, "fname": 6, "fpath": 6, "join": [6, 65], "version_info": 6, "urllib": [6, 7, 24, 60], "urlretriev": 6, "els": [6, 32, 58, 68, 71], "tar": 6, "extractal": 6, "close": [6, 7, 22, 39], "inception_v1_url": 6, "http": [6, 7, 13, 21, 24, 66, 73], "storag": [6, 7, 18, 24, 36, 37, 49, 50, 59, 61], "googleapi": [6, 7, 24], "com": [6, 7, 13, 21, 24, 60, 73, 74], "org": [6, 7, 24, 66, 74], "inception_v1_2016_08_28_frozen": 6, "gz": 6, "check": [6, 16, 18, 21, 36, 39, 43, 58, 63, 65, 66, 68, 71], "tf_model_path": 6, "rb": [6, 65, 68], "f": [6, 32, 33, 43, 65, 68], "read": [6, 7, 24, 37, 38, 59, 63, 65, 68], "reset_default_graph": [6, 68], "original_gdef": [6, 68], "graphdef": [6, 65, 68], "parsefromstr": [6, 65, 68], "let": [6, 7, 22, 31, 34, 38, 43, 56, 61, 71, 72], "as_default": [6, 65, 68], "g": [6, 39, 43, 50, 54, 55, 57, 58, 68], "import_graph_def": [6, 65, 68], "get_oper": [6, 65, 68], "len": [6, 7, 24, 65, 68], "nop": 6, "id": [6, 72], "str": 6, "get_shap": [6, 65], "noutput": 6, "point": [6, 18, 32, 34, 37, 38, 42, 44, 52, 53, 54, 61, 68, 74], "placehold": [6, 19, 65], "softmax": [6, 66, 72], "inceptionv1": 6, "order": [6, 9, 17, 20, 24, 26, 28, 29, 30, 37, 40, 42, 43, 47, 56, 64, 66], "imagenet_slim_label": 6, "coreml_model_fil": 6, "inception_v1": 6, "coreml_model": [6, 22, 25, 53, 62, 75], "progress": [6, 21], "warn": [6, 9, 19, 32, 60], "userwarn": 6, "renam": [6, 16, 22, 29], "inceptionv1_logits_predictions_softmax": 6, "click": [6, 7, 13, 19, 22, 23, 24, 45, 47, 50, 55, 60, 68, 73, 74], "golden_retriever_carlo": 6, "folder": [6, 7, 23, 31, 74], "golden": 6, "retriev": [6, 24, 65, 74], "wikipedia": 6, "numpi": [6, 7, 9, 13, 19, 22, 24, 28, 29, 30, 31, 34, 60, 63, 65, 66, 68], "img": [6, 7, 22, 31, 68], "lanczo": [6, 7], "coreml_input": [6, 9], "coreml_output": 6, "coreml_pred_dict": 6, "coreml_predicted_class_label": 6, "we": [6, 18, 21, 23, 26, 30, 33, 34, 37, 38, 42, 43, 45, 47, 48, 52, 53, 56, 58, 60, 63, 65, 71, 72], "img_np": [6, 7, 31, 68], "flatten": [6, 66, 68, 72], "max": [6, 31, 54, 68, 72], "amax": [6, 68], "img_tf": 6, "expand_dim": [6, 68], "axi": [6, 17, 37, 43, 68], "highest": 6, "tf_input_nam": 6, "tf_output_nam": 6, "255": [6, 7, 18, 22, 60, 73], "session": [6, 24, 34, 59, 63, 65, 68], "sess": [6, 65, 68], "tf_out": [6, 65, 66], "feed_dict": [6, 65, 68], "idx": [6, 7, 53, 56], "argmax": [6, 9, 60], "label_fil": 6, "readlin": 6, "correct": [6, 18, 24, 28, 31, 32, 38, 43, 52, 58], "alwai": [6, 18, 37, 58, 61, 65], "crucial": 6, "best": [6, 19, 32, 38, 39, 42, 47, 56, 58, 61, 65, 67, 68], "approach": [6, 34, 37, 39, 42, 52, 58], "author": [6, 21, 24, 27, 38, 71, 72, 73], "come": [6, 38], "slim": [6, 24], "preprocess_for_ev": 6, "inception_preprocess": 6, "pixel": [6, 7, 16, 19, 22, 60], "scale": [6, 7, 18, 22, 24, 37, 43, 52, 53, 54, 55, 57, 58, 61, 66], "lie": 6, "within": [6, 9, 17, 19, 24, 34, 38, 49, 56, 61, 67, 71], "interv": [6, 19, 22, 24, 66], "research": [6, 24], "english": 6, "setter": 6, "301507": 6, "bias": [6, 22], "channel": [6, 22, 31, 32, 37, 43, 52, 53, 54, 55, 56, 57, 58, 61], "should": [6, 7, 17, 18, 19, 21, 23, 28, 31, 32, 33, 37, 38, 39, 48, 50, 52, 61, 73], "multipli": [6, 47], "bia": [6, 7, 18, 22, 24, 34, 37, 54, 61, 66], "higher": [6, 14, 18, 38, 39, 42, 43, 47, 50, 56, 58, 67, 68], "68707207e": 6, "04": [6, 42, 47, 52, 55], "01963953e": 6, "05": [6, 42, 52, 55, 56], "33356332e": 6, "15576135e": 6, "79885838e": 6, "21910377e": 6, "lower": [6, 38, 39, 42, 44, 58, 61], "optim": [6, 7, 9, 11, 17, 19, 20, 26, 28, 29, 30, 31, 32, 35, 36, 37, 39, 40, 42, 43, 45, 47, 48, 50, 52, 53, 54, 55, 59, 61, 63, 67, 72], "faster": [6, 31, 39, 55, 57, 58], "would": [6, 19, 30, 31, 32, 34, 37, 38, 39, 43, 48, 49, 53, 56, 65, 67, 68], "restrict": [6, 7, 31, 67], "cpu": [6, 7, 18, 26, 31, 35, 38, 39, 50, 55, 59, 60, 67, 68], "usecpuonli": [6, 31, 65], "instead": [6, 22, 30, 31, 32, 36, 38, 53, 67, 71], "compute_unit": [6, 7, 18, 26, 31, 35], "mobilenet": [7, 22, 24, 26, 65, 66], "convolut": [7, 16, 32, 33, 48, 56, 61, 67, 72, 73], "design": 7, "mobil": 7, "vision": [7, 22, 24, 59, 60], "applic": [7, 21, 22, 24, 26, 57, 66, 68], "similar": [7, 17, 18, 21, 24, 37, 38, 43, 44, 67], "dataset": [7, 9, 24, 38, 42, 45, 47, 48, 52, 55, 57, 72, 73], "torchscript": [7, 9, 22, 26, 32, 33, 64], "jit": [7, 9, 11, 19, 22, 26, 31, 33, 34, 43, 53, 58, 60, 63], "onc": [7, 21, 32, 38, 39, 43, 47, 52, 53, 56, 63, 65], "torch_model": [7, 11, 22, 26, 31, 43], "mobilenet_v2": [7, 11, 26], "pretrain": [7, 11, 38, 56, 60], "eval": [7, 9, 11, 19, 26, 31, 34, 43, 53, 56, 60, 63], "dropout": [7, 11, 72], "befor": [7, 11, 17, 21, 22, 23, 24, 32, 38, 39, 43, 44, 53, 65, 66, 68, 73], "reason": [7, 11, 22, 34, 39], "random": [7, 9, 11, 19, 22, 30, 31, 34, 60, 65, 66], "data": [7, 9, 11, 16, 21, 22, 24, 27, 28, 29, 31, 32, 33, 37, 39, 40, 42, 43, 45, 47, 49, 50, 54, 55, 57, 59, 60, 61, 62, 63, 66, 68, 72], "rank": [7, 34, 37], "depend": [7, 9, 11, 23, 31, 32, 33, 38, 39, 42, 45, 47, 50, 55, 56, 58, 61, 67, 68], "example_input": [7, 11, 18, 19, 22, 26, 31, 43, 53, 56, 58], "rand": [7, 11, 19, 22, 26, 30, 31, 33, 34, 53, 65, 66], "traced_model": [7, 11, 19, 22, 26, 31, 43, 53, 63], "imagenet": [7, 24, 26, 45, 55, 66], "benchmark": [7, 9, 42], "background": [7, 24, 60, 68, 73, 74], "imagenetlabel": [7, 24], "label_url": [7, 24], "urlopen": [7, 24], "utf": 7, "8": [7, 13, 14, 22, 23, 25, 37, 38, 39, 42, 43, 44, 45, 48, 50, 52, 53, 54, 56, 58, 64, 72], "splitlin": [7, 24], "1000": [7, 24, 53, 56, 71], "base": [7, 9, 13, 19, 22, 23, 24, 26, 27, 31, 33, 34, 39, 40, 42, 43, 47, 50, 55, 56, 57, 67, 68, 71, 73], "typic": [7, 21, 22, 26, 34, 39, 42, 43, 45, 47, 49, 50, 52, 53, 58, 63, 65, 66, 67], "appli": [7, 9, 11, 17, 18, 20, 22, 28, 29, 32, 33, 37, 38, 39, 40, 42, 43, 47, 48, 50, 52, 53, 56, 57, 58, 60, 63, 66, 67, 68, 71], "226": [7, 18, 22], "485": [7, 18, 22, 60], "229": [7, 18, 22, 60], "456": [7, 18, 22, 38, 60], "406": [7, 18, 22, 60], "225": [7, 18, 22, 60], "input_1": [7, 19, 22, 24, 28], "mlmultiarrai": [7, 16, 29, 31, 35, 65, 66], "argument": [7, 14, 15, 22, 30, 31, 34, 37, 43, 61, 64, 65, 68], "next": [7, 9, 31, 34, 37, 38, 47, 52, 53, 56, 63], "computeunit": [7, 18, 26, 31, 35], "cpu_onli": [7, 18, 26, 31], "extens": [7, 14, 26, 31, 53, 56, 60], "help": [7, 21, 35, 38, 39, 48, 50, 52, 53, 54, 56, 59], "confirm": [7, 71, 72], "algorithm": [7, 39, 41, 43, 45, 46, 48, 50, 51, 53, 56, 57, 58, 61], "resampl": 7, "img_path": 7, "field": [7, 13, 37], "get_spec": [7, 14, 18, 27, 28, 31, 68, 73], "select": [7, 16, 24, 29, 32, 45, 50, 53, 55, 60, 67], "dictionarytyp": 7, "whichoneof": [7, 14, 27], "coreml_dict_nam": 7, "coreml_out_dict": [7, 65, 66], "coreml_prob_dict": 7, "values_vector": 7, "list": [7, 9, 17, 21, 27, 28, 30, 36, 37, 48, 53, 56, 57, 58, 61, 64, 65, 66, 72], "keys_vector": 7, "kei": [7, 18, 27, 28, 29, 36, 37, 42, 43, 63, 74], "top_3_indices_coreml": 7, "argsort": 7, "rang": [7, 9, 16, 18, 22, 32, 43, 48, 52, 54, 56, 60, 68, 71], "score_valu": 7, "class_id": 7, "score": [7, 38, 60, 71, 72, 73], "someth": 7, "685693740844727": 7, "vase": 7, "516246795654297": 7, "ant": 7, "185517311096191": 7, "normal": [7, 22, 24, 26, 43, 44, 53, 66], "divid": [7, 37, 49, 58], "prepar": [7, 43, 48, 53, 56, 58], "asarrai": 7, "newaxi": 7, "torch_tensor_input": 7, "from_numpi": [7, 37], "deviat": [7, 22, 42, 47, 60], "nn": [7, 9, 19, 22, 32, 33, 34, 38, 43, 53, 60, 63, 66], "sequenti": [7, 28, 52, 72], "transform_model": 7, "std": [7, 22, 60], "torch_out": [7, 9], "torch_out_np": 7, "detach": 7, "squeez": [7, 68], "top_3_indic": 7, "642789840698242": 7, "53633975982666": 7, "257798194885254": 7, "veri": [7, 22, 31, 32, 38, 39, 42, 58], "compar": [8, 14, 18, 24, 28, 30, 38, 50, 55, 58, 63, 64, 65], "combin": [9, 11, 16, 20, 37, 39, 68], "properli": [9, 21], "condit": [9, 11, 32, 33], "appear": [9, 13, 21, 23, 24, 32, 60, 74], "explain": [9, 32], "experiment": [9, 32, 52, 53, 57, 58], "mix": [9, 67], "part": [9, 17, 32, 72, 73], "free": [9, 39, 42, 47, 57], "bodi": [9, 16, 32], "outer": [9, 54], "maco": [9, 11, 14, 22, 24, 35, 36, 38, 59, 64, 69], "monterei": 9, "eight": 9, "million": 9, "web": 9, "simpl": [9, 16, 22, 33, 48, 61, 65, 72, 73], "word": 9, "given": [9, 17, 24, 37, 39, 42, 58, 60, 72, 74], "manhattan": 9, "bridg": 9, "rest": [9, 19], "arteri": 9, "citi": 9, "subwai": 9, "busiest": 9, "countri": 9, "gpt2lmheadmodel": 9, "gpt2token": 9, "integ": [9, 29, 37, 38, 52, 54], "token": [9, 13, 38, 63], "partial": 9, "until": 9, "eo": 9, "finishmysent": 9, "modul": [9, 19, 22, 32, 33, 34, 37, 43, 45, 47, 48, 60, 63, 71], "inherit": 9, "next_token_predictor": 9, "denot": [9, 57], "forward": [9, 19, 22, 32, 33, 34, 38, 43, 47, 53, 56, 60, 63], "happen": [9, 32, 39, 45], "__init__": [9, 17, 19, 32, 33, 34, 60, 61, 63, 66], "self": [9, 17, 19, 21, 22, 32, 33, 34, 60, 61, 63, 66, 71], "198": 9, "super": [9, 17, 19, 32, 33, 34, 60, 61, 63, 66], "default_token": 9, "_": [9, 31, 32], "dim": [9, 33, 37], "keepdim": 9, "cat": [9, 60, 74], "token_predictor": 9, "gpt2": 9, "tracer": [9, 11, 22, 33, 60], "random_token": 9, "randint": 9, "10000": 9, "5": [9, 14, 22, 23, 28, 36, 38, 42, 45, 48, 50, 56, 63, 66, 68, 71, 72, 73], "traced_token_predictor": 9, "manner": [9, 38, 47, 48, 49, 53, 57, 63], "elicit": 9, "might": 9, "ignor": [9, 60], "bulk": 9, "instanti": [9, 22, 31, 32, 33], "scripted_model": [9, 32], "64": [9, 32, 38, 43, 44, 47, 58, 72], "int32": [9, 13, 17, 29], "dtype": [9, 13, 17, 22, 30, 31, 38, 43, 53, 58, 63, 66], "rangedim": [9, 19], "test": [9, 13, 19, 21, 24, 28, 30, 31, 39, 60, 61, 65, 66, 68, 74], "sentence_frag": 9, "generated_text_torch": 9, "prediction_dict": 9, "generated_tensor": 9, "sentence_2": 9, "generated_text": 9, "onnx": [10, 11, 18, 21, 36], "recommend": [10, 18, 23, 36, 37, 39, 53, 55, 58, 64, 65, 68], "natur": [10, 11, 16], "torchvis": [10, 11, 16, 22, 26, 31, 45, 55, 56, 60], "io": [11, 14, 18, 22, 24, 35, 36, 38, 45, 50, 55, 64, 65], "13": [11, 22, 23, 35, 36, 45, 50, 56, 59, 64, 69], "watcho": [11, 14, 24, 36, 64], "6": [11, 19, 22, 23, 24, 28, 29, 33, 36, 38, 39, 42, 43, 44, 45, 48, 56, 57, 58, 60, 61, 66, 72], "tvo": [11, 14, 36, 64], "primari": [11, 59], "earlier": 11, "via": [11, 28, 34, 37, 48, 53, 57, 58], "represent": [11, 18, 20, 24, 30, 35, 37, 39, 44, 48, 49, 50, 59, 63], "mobilenetv2": [11, 16, 22, 24, 42, 45, 47, 50, 52, 55, 65], "won": [11, 32, 33], "experi": [11, 32, 33, 39, 42, 47, 48, 56, 58, 61, 67], "convert_to": [11, 14, 15, 19, 22, 24, 26, 35, 53, 64, 65, 66, 67], "newmodel": 11, "elimin": [11, 20, 35], "introduct": [11, 32, 39, 48], "deepspeech": [12, 16, 65], "bert": [12, 16, 74], "huggingfac": [13, 34, 38], "17": [13, 31, 38, 47, 50, 71], "distilberttoken": 13, "tfdistilbertformaskedlm": 13, "distilbert_model": 13, "build": [13, 18, 21, 30, 33, 38, 45, 50, 55, 56, 66], "max_seq_length": 13, "input_shap": [13, 19, 24, 26, 31, 66, 72], "batch_siz": 13, "maximum_sequence_length": 13, "input_lay": 13, "prediction_model": 13, "fill": [13, 21], "adher": [13, 17, 49], "input_valu": 13, "our": [13, 33, 43, 56, 72], "sentenc": 13, "hello": 13, "my": [13, 18], "dog": [13, 60, 74], "cute": 13, "tensorflow_hub": [13, 66], "tf_hub": [13, 66], "384": 13, "input_word": 13, "input_mask": 13, "segment_id": 13, "bert_lay": 13, "keraslay": [13, 66], "tfhub": [13, 66], "bert_en_uncased_l": 13, "12_h": 13, "768_a": 13, "trainabl": [13, 66], "pooled_output": 13, "sequence_output": 13, "bertqa": [13, 74], "user_defined_metadata": [13, 24, 60, 74], "appl": [13, 18, 21, 24, 31, 52, 59, 60, 74], "bert_with_preview_typ": 13, "doubl": [13, 16, 22, 24, 60, 72, 74], "mac": [13, 23, 24, 38, 39, 60, 74], "finder": [13, 24, 60, 74], "launch": [13, 24, 60, 74], "pane": [13, 24, 60, 74], "copi": [13, 21, 22, 31, 60, 63], "past": [13, 21], "qa": [13, 74], "passag": 13, "enter": [13, 21], "question": [13, 18, 21, 38], "answer": [13, 38], "candid": 13, "highlight": [13, 18, 23], "evolut": 14, "ios15": [14, 15, 22, 26, 29, 35, 64], "macos12": [14, 15, 22, 26, 29, 35, 64], "watchos8": [14, 15, 22, 35, 64], "tvos15": [14, 15, 22, 35, 64], "deploy": [14, 26, 29, 35, 44, 49, 63], "target": [14, 15, 17, 22, 24, 26, 28, 29, 34, 35, 37, 43, 44, 47, 49, 53, 56, 58, 63, 72], "older": [14, 15, 18, 24, 26, 64], "mil": [14, 18, 20, 24, 29, 37, 64], "source_model": [14, 15, 18, 22, 29, 67], "overrid": [14, 17, 26, 29, 35, 64], "behavior": [14, 17, 21, 26, 64], "minimum_deployment_target": [14, 15, 22, 26, 29, 34, 35, 37, 43, 53, 58, 63, 64], "ios14": [14, 15, 64], "compute_precis": [14, 18, 35, 67, 68], "skip": [14, 23, 28, 32, 34, 48, 50, 56, 61, 68], "float16": [14, 22, 29, 39, 42, 45, 47, 50, 52, 55, 56, 57, 58, 63, 68], "0b3": [14, 68], "beta": [14, 57], "cannot": [14, 63], "edit": [14, 28], "my_model": [14, 25, 75], "determin": [14, 19, 21, 22, 32, 40, 43, 67], "whether": [14, 26, 37, 39, 67], "linux": [14, 23, 31, 69], "properti": [14, 17, 18, 28, 29, 61, 67, 71], "spec": [14, 16, 18, 19, 28, 64, 68, 71, 73], "summar": [14, 29, 43, 56, 64], "tabl": [14, 37, 38, 39, 42, 43, 44, 45, 47, 55, 56, 57, 61, 64, 74], "11": [14, 22, 23, 24, 34, 36, 38, 42, 64], "didn": 15, "snippet": [16, 17, 19, 22, 26, 27, 28, 29, 31, 33, 38, 56, 58, 65, 68], "full": [16, 27, 28, 31, 36, 39, 43, 47, 53, 58, 60, 61, 74], "savedmodel": [16, 26, 64, 66], "predetermin": [16, 18, 29], "decompos": 16, "augment": [16, 45], "magnitud": [16, 47, 48, 49, 57], "fine": [16, 28, 34, 38, 39, 45, 47, 48, 50, 54, 57, 59, 67, 72], "tune": [16, 34, 38, 39, 45, 47, 48, 50, 57, 59, 72], "reduc": [16, 18, 29, 30, 36, 38, 39, 45, 49, 50, 53, 54, 55, 56, 59, 61, 67], "bit": [16, 22, 37, 38, 39, 42, 43, 44, 45, 49, 52, 53, 54, 55, 56, 57, 58], "multi": [16, 17], "larg": [16, 18, 19, 31, 34, 38, 39, 42, 44, 47, 54, 58, 63, 67], "pose": 16, "regressor": [16, 34, 62], "nearest": [16, 38, 52, 53, 70], "neighbor": [16, 70], "empti": [16, 71, 73], "compos": [16, 60, 73], "draw": [16, 73], "sketch": [16, 73], "d": [16, 44, 48, 72], "submit": [16, 21], "integr": [17, 23, 24, 31, 34, 36, 58, 59], "easi": 17, "down": [17, 23, 38, 39, 50, 55, 61], "variou": [17, 29, 38, 39, 52, 53, 56], "hardwar": [17, 18, 39, 40, 49, 50, 52, 53, 54, 55, 67, 68], "topk": 17, "sort": [17, 47], "avoid": [17, 63], "extra": [17, 35, 38, 53, 63], "bind": 17, "register_op": 17, "is_custom_op": 17, "member": [17, 21], "commun": [17, 21, 31], "class_nam": 17, "interfac": [17, 22, 24, 27, 34], "input_ord": 17, "pack": [17, 49], "known": [17, 47, 52, 54, 55, 64], "static": [17, 18, 29, 38], "_op_req": 17, "symbol": [17, 53], "is_symbol": 17, "input_typ": 17, "boolinputtyp": 17, "defaultinput": 17, "inputspec": 17, "tensorinputtyp": 17, "intinputtyp": 17, "floatinputtyp": 17, "listinputtyp": 17, "stringinputtyp": 17, "doc_str": 17, "custom_topk": 17, "input_spec": [17, 30, 63], "type_domain": 17, "bool": [17, 30], "fp16": [17, 37, 38, 63], "fp32": [17, 29, 30], "customtopk": 17, "kwarg": [17, 61], "type_infer": 17, "x_type": 17, "x_shape": 17, "val": [17, 28, 30], "msg": 17, "greater": [17, 28, 43, 48], "rais": [17, 19, 71], "valueerror": [17, 71], "ret_shap": 17, "mandatori": 17, "registr": 17, "custom_mil_op": 17, "tf_alia": 17, "topkv2": 17, "overridden": 17, "put": 17, "custom_tf_op": 17, "here": [17, 30, 34, 37, 38, 40, 43, 48, 50, 53, 55, 56, 63], "model_from_tf": [17, 26], "endpoint": 17, "mlcustomlay": 17, "frequent": 18, "ask": [18, 21], "rather": [18, 22, 24, 30, 31, 49], "speed": [18, 31, 38, 45, 50], "up": [18, 19, 21, 24, 29, 31, 34, 37, 38, 39, 42, 43, 45, 47, 48, 50, 56, 58, 60, 61, 63, 74], "less": [18, 31, 32, 36, 37, 38, 39, 47, 56, 59, 61], "space": [18, 36, 37, 59, 61, 73], "power": [18, 36, 39, 59], "consumpt": [18, 22, 36, 39, 59], "latenc": [18, 36, 39, 45, 47, 49, 50, 54, 55, 58, 59], "note": [18, 19, 26, 30, 37, 38, 45, 47, 50, 53, 55, 56, 57], "therebi": [18, 31, 37, 39, 44, 49, 50], "occupi": [18, 61], "grayscal": [18, 35, 72, 73], "multiarrai": [18, 29, 31, 74], "mpsgraph": 18, "upgrad": [18, 36], "latest": [18, 23], "prior": [18, 22, 37, 39], "longer": [18, 36, 50, 64, 68], "maintain": [18, 39, 47], "offici": 18, "tf2": [18, 21], "tf1": [18, 21, 30], "_save_h5_as_frozen_pb": 18, "troubleshoot": 18, "simpli": [18, 34, 37, 43, 48, 58, 72], "issu": 18, "github": [18, 21, 23, 24, 73, 74], "queri": [18, 63], "workaround": [18, 34], "try": [18, 21, 39, 56, 58, 59, 60, 61, 71], "cpuonli": [18, 67], "newest": [18, 21, 23, 24, 35, 36, 60], "pleas": [18, 21, 22, 24, 39, 43, 50, 55, 63], "repo": [18, 20, 23], "miss": [18, 22, 65], "pick": [18, 26, 29, 37, 67], "mymodel": [18, 19, 28], "input_nam": [18, 19, 22, 25, 28, 31, 71, 72, 73], "inp": [18, 28, 48], "output_nam": [18, 28, 65, 71, 72, 73], "rename_featur": [18, 22, 28, 29], "ne": [18, 26, 31, 35, 38, 39, 53, 55, 56, 57, 58, 59, 67, 68], "enumeratedshap": [18, 19, 29], "unless": [18, 45, 47, 50, 55], "dynam": [18, 19, 38, 53, 67], "finit": [18, 19], "128": [18, 19, 38, 42, 47, 52, 53, 54, 56, 58, 60, 66, 71, 72, 73], "consid": [18, 19, 24, 34, 39, 56], "symmetr": [18, 52, 53, 56, 61], "asymmetr": [18, 52], "mode": [18, 28, 37, 38, 39, 43, 44, 45, 47, 53, 54, 55, 56, 57, 58, 61, 64], "compiledmlmodel": [18, 31, 34], "consider": [18, 31, 38, 39, 42, 55], "resolut": 19, "style": [19, 34, 67, 68], "transfer": [19, 68], "bound": [19, 38, 39, 50, 54, 71], "maximum": [19, 43, 60], "opportun": 19, "harder": 19, "necessari": 19, "purpos": 19, "constraint": [19, 49, 53, 67], "testconvmodul": 19, "omit": [19, 43], "element": [19, 28, 38, 42, 43, 44, 47, 48, 50, 53, 61], "in_channel": [19, 32], "out_channel": [19, 32], "kernel_s": [19, 32, 72], "conv": [19, 32, 37, 43], "conv2d": [19, 32, 33, 48, 72], "50": [19, 24, 28, 47, 48, 50, 55, 56], "25": [19, 42, 56, 60, 72], "67": [19, 24, 42, 45, 47], "enumerated_shap": 19, "input_2": [19, 28], "output_1": 19, "output_2": 19, "fast": [19, 26, 31, 35, 38, 68], "non": [19, 24, 31, 37, 43, 44, 48, 49, 53, 57, 72], "slower": 19, "mark": [19, 24, 38, 72], "permit": 19, "lower_bound": 19, "upper_bound": 19, "100": [19, 21, 22, 24, 30, 48, 53, 56, 68], "45": [19, 30, 38, 45, 55], "range_shap": 19, "upper": 19, "undetermin": 19, "sanit": 19, "default_s": 19, "allow": [19, 37, 38, 39, 42, 44, 47, 48, 52, 53, 60, 61, 63, 67, 70, 71], "doesn": [19, 21, 38, 60], "crash": 19, "practic": [19, 24, 28, 29, 34, 42, 47, 65, 68], "neural_network": [19, 57, 61, 72], "flexible_shape_util": 19, "annot": 19, "guarante": [19, 67], "These": [19, 22, 24, 26, 31, 36, 38, 39, 42], "add_multiarray_ndshape_enumer": 19, "set_multiarray_ndshape_rang": 19, "load_spec": [19, 27, 72], "feature_nam": 19, "infin": 19, "re": [19, 28, 32, 60], "mymodel_upd": 19, "canonic": 20, "dead_code_elimin": 20, "unus": [20, 56], "whose": [20, 31, 37, 39], "const_elimin": 20, "fuse": [20, 39], "fuse_elementwise_to_batchnorm": 20, "detect": [20, 24, 37, 45], "batchnorm": [20, 61], "pass_pipelin": [20, 37], "graph_pass": 20, "md": [20, 21, 23], "publicli": 21, "bsd": [21, 27], "licens": [21, 24, 27, 71, 72, 73], "welcom": 21, "idea": [21, 39, 42, 47], "grow": 21, "product": 21, "guidelin": 21, "conduct": [21, 53], "blob": [21, 72], "master": [21, 23, 24], "tell": [21, 72], "enhanc": [21, 64], "encourag": 21, "comment": [21, 24], "templat": 21, "bug": 21, "much": [21, 26, 31, 34, 38, 39, 47, 56, 58, 72], "sai": [21, 34, 39, 56, 58], "promptli": 21, "respond": 21, "log": [21, 23, 30], "reproduc": 21, "softwar": [21, 23, 67], "pull": 21, "being": [21, 38, 43, 44, 45, 48, 56], "report": [21, 42, 45, 47, 56], "dropdown": 21, "menu": 21, "filter": 21, "thumb": 21, "problem": [21, 25, 47], "walk": [21, 59], "ideal": 21, "comfort": 21, "share": [21, 34, 38, 44, 53, 54], "develop": [21, 26, 31, 59], "review": 21, "team": 21, "proce": 21, "even": [21, 31, 33, 38, 39, 55, 56, 58, 67, 68], "typo": 21, "hesit": 21, "send": 21, "doc": [21, 50, 55], "fork": [21, 23], "approv": 21, "statu": 21, "turquois": 21, "color": [21, 22, 60, 68, 74], "triag": 21, "examin": [21, 22], "assign": [21, 42, 60], "releas": [21, 23, 57, 68], "await": 21, "respons": [21, 59, 67], "investig": 21, "discuss": 21, "duplic": 21, "previous": [21, 24], "repro": 21, "red": [21, 22], "unexpect": [21, 28], "clarif": 21, "orang": 21, "caff": [21, 36], "contributor": 21, "good": [21, 24, 29, 38, 39, 42, 45, 56, 58, 68], "multidimension": [22, 29, 66], "well": [22, 24, 34, 37, 38, 39, 42, 43, 44, 47, 48, 52, 53, 54, 55, 56, 58, 60, 67, 68, 74], "exclud": 22, "image_arrai": 22, "One": [22, 38, 43, 47, 48, 63], "benefit": [22, 37, 38, 39, 45, 50, 53, 55, 56], "ineffici": 22, "could": [22, 31, 34, 37, 38, 39, 49], "becom": [22, 38, 56], "bottleneck": [22, 45, 54, 55], "cvpixelbuff": 22, "rgb": [22, 31], "h": 22, "w": [22, 56, 65, 66], "height": [22, 31, 72, 73], "color_layout": 22, "colorlayout": 22, "macos13": [22, 29, 37, 44, 49, 57], "readi": [22, 31], "79": 22, "ipython": [22, 71], "blanch": 22, "whiten": 22, "imagefilteringmodel": 22, "256": [22, 26, 37, 63], "colorimag": 22, "coloroutput": 22, "enumer": [22, 24, 26, 43, 53, 56], "palmtre": 22, "antialia": [22, 31, 68], "palmtrees_256_by_256": 22, "photo": 22, "palm": 22, "moon": 22, "palmtrees_result": 22, "png": 22, "colortocolormodel": 22, "drag": [22, 24, 60, 74], "styliz": [22, 68], "button": [22, 23], "jpeg": [22, 31], "per": [22, 37, 39, 43, 45, 50, 52, 53, 54, 55, 56, 57, 58, 60], "int": [22, 32, 37, 74], "onecomponent16half": 22, "grayscale_float16": 22, "ios16": [22, 29, 44, 49, 57], "global": [22, 43], "accord": 22, "y_red_channel": 22, "x_red_channel": 22, "red_bia": 22, "y_green_channel": 22, "x_green_channel": 22, "green_bia": 22, "y_blue_channel": 22, "x_blue_channel": 22, "blue_bia": 22, "recip": [22, 45], "quickstart": 22, "127": [22, 24, 54, 66], "formula": 22, "green": 22, "blue": 22, "rewritten": 22, "equival": [22, 55], "averag": [22, 38, 58], "wheel": [23, 36], "9": [23, 25, 36, 38, 42, 45, 56, 63, 68, 72], "last": [23, 28, 32, 53, 71, 72, 73], "stabl": [23, 31], "familiar": 23, "termin": [23, 32], "app": [23, 24, 31, 34, 39, 59, 67], "basic": 23, "shell": 23, "venv": 23, "reliabl": [23, 38], "recent": [23, 36, 71], "whl": 23, "m": [23, 38, 45, 47, 48, 49, 50, 55], "bin": 23, "ci": 23, "link": [23, 31, 42, 45, 47, 50, 55, 68], "branch": 23, "commit": [23, 48], "merg": [23, 34], "job": 23, "access": [23, 28, 39, 57, 58], "scroll": 23, "readm": 23, "head": [23, 34], "column": 23, "build_wheel_macos_py38": 23, "brows": 23, "dist": 23, "cp38": 23, "macosx_10_12_intel": 23, "cmake": 23, "clone": 23, "sh": 23, "zsh": 23, "host": 24, "galleri": 24, "predefin": 24, "categori": [24, 58, 60], "h5py": 24, "21": [24, 38, 60], "Then": [24, 43, 66], "popular": 24, "entri": [24, 31, 37, 44], "isinst": 24, "byte": [24, 50, 60], "utf8": 24, "collect": [24, 53, 56, 60, 72, 74], "advanc": 24, "bake": 24, "ui": [24, 63], "input_descript": [24, 27], "output_descript": [24, 27], "paper": [24, 48, 52], "sandler": 24, "andrew": 24, "howard": 24, "menglong": 24, "zhu": 24, "andrei": 24, "zhmoginov": 24, "liang": 24, "chieh": 24, "chen": 24, "net": 24, "short_descript": [24, 27], "domin": 24, "present": [24, 26, 31, 39], "1001": [24, 65, 71], "anim": 24, "food": 24, "vehicl": 24, "person": [24, 60, 70, 74], "etc": [24, 27, 37, 38, 39, 40, 43, 47, 55, 58], "public": [24, 27, 74], "74": [24, 56], "imageclassifi": [24, 74], "tvm": [24, 31], "made": [24, 31, 38, 50], "choos": [24, 39, 42, 50, 53, 60, 61, 64, 74], "platform": 24, "loaded_model": 24, "00": 24, "78": [24, 38, 52, 55], "428": 24, "1097": 24, "frontend_tensorflow2": 24, "205": 24, "06": [24, 47, 50], "71": [24, 38, 42, 45, 47, 52, 55, 56, 68], "02": [24, 38], "24": [24, 38], "backend_mlprogram": 24, "305": 24, "titl": 24, "navig": [24, 60], "finish": [24, 60], "svmutil": 25, "svm_problem": 25, "libsvm_model": 25, "svm_train": 25, "svm_paramet": 25, "model_from_torch": 26, "wide": [26, 31, 59, 64], "tri": 26, "hdf5": [26, 64, 66], "xception": [26, 66], "h5": [26, 64, 66, 72], "299": [26, 66], "freez": [26, 65], "mobilenet_v1_1": 26, "0_224": [26, 65], "frozen_graph": 26, "compat": [26, 65], "mobilenet_v2_1": [26, 65], "0_224_frozen": [26, 65], "pt": [26, 33, 64], "torchvision_mobilenet_v2": 26, "engin": [26, 31, 35, 38, 39, 45, 50, 53, 54, 55, 56, 59, 67, 68], "debug": [26, 28, 35], "mlcomputeunit": [26, 67], "mlmodelconfigur": [26, 31], "cpu_and_gpu": 26, "cpu_and_n": 26, "untyp": 26, "encapsul": 27, "modifi": [27, 31, 58, 63], "minim": [27, 47, 52, 58, 59], "readabl": 27, "c": 27, "java": 27, "perl": 27, "high": [27, 39, 44, 58, 68], "pars": [27, 65], "supportvectorregressor": 27, "save_spec": [27, 73], "price": [27, 62], "hous": [27, 62], "bedroom": [27, 31, 62], "bath": [27, 31, 62], "sklearn": [27, 62], "linear_model": [27, 62], "linearregress": [27, 62], "panda": [27, 62], "pd": [27, 62], "read_csv": [27, 62], "csv": [27, 28, 62], "fit": [27, 62], "john": 27, "smith": 27, "seattl": 27, "area": 27, "manual": 27, "bathroom": 27, "squar": [27, 42, 63, 72], "feet": 27, "housepric": [27, 31, 62], "old_feature_nam": 28, "new_feature_nam": 28, "reload": 28, "weights_dir": 28, "convert_double_to_float_multiarray_typ": 28, "deal": 28, "against": 28, "evaluate_classifi": 28, "metric": [28, 45, 55, 58, 68, 72], "data_and_predict": 28, "num_error": 28, "evaluate_regressor": 28, "regress": [28, 34, 63], "rmse": 28, "max_error": 28, "evaluate_transform": 28, "input_data": 28, "expected_output": 28, "scaler_spec": 28, "get_weights_metadata": [28, 43, 48], "larger": [28, 38, 42, 50, 53], "certain": [28, 37, 47, 48, 49, 61, 74], "sparsiti": [28, 47, 48, 49, 50, 56, 58], "percentag": [28, 38], "uniqu": [28, 34, 37, 43], "weight_threshold": [28, 43, 48, 53], "total": 28, "child": 28, "map": [28, 31, 45, 54, 68], "coremlweightmetadata": 28, "preserv": [28, 38, 50, 52, 58, 67], "cto": [28, 43, 53, 57, 58], "optimizationconfig": [28, 43, 48, 53, 58], "grain": [28, 48, 54], "op_type_config": [28, 43, 48], "op_name_config": [28, 43, 48], "set_op_nam": 28, "set_op_typ": 28, "segmentationmodel_with_metadata": [28, 60, 74], "threshold": [28, 37, 47, 48], "sensit": [28, 38, 45, 50, 55, 56, 57, 58, 61, 67], "weight_metadata_dict": 28, "iter": [28, 43, 48, 63], "large_weight": 28, "25600": 28, "sparse_weight": 28, "palettized_weight": 28, "weight_nam": 28, "weight_metadata": 28, "item": [28, 32], "ratio": [28, 38, 39, 42, 45, 47, 48, 50, 52, 55, 68], "unique_valu": 28, "child_op": 28, "op_typ": 28, "params_name_map": 28, "last_weight_nam": 28, "global_config": [28, 38, 43, 48, 53, 56, 58], "oppalettizerconfig": [28, 43, 58], "nbit": [28, 39, 43, 58, 61], "kmean": [28, 43, 58, 61], "config": [28, 31, 38, 42, 43, 45, 47, 48, 50, 52, 53, 55, 56, 58, 68], "compressed_mlmodel": [28, 43, 58], "palettize_weight": [28, 38, 42, 43, 56, 57, 58], "least": 29, "overhead": [29, 38], "my_input_nam": 29, "my_output_nam": 29, "source_torch_model": 29, "unlik": [29, 54, 67], "why": 30, "scratch": [30, 33, 66], "behind": 30, "scene": 30, "third": [30, 37, 59], "parti": [30, 37, 59], "accommod": 30, "tailor": 30, "dialect": 30, "tensorspec": [30, 63, 66], "prog": [30, 63], "relu": [30, 32, 33, 34, 66, 72], "perm": 30, "reduce_mean": 30, "ax": 30, "keep_dim": 30, "block0": 30, "transpose_perm_0": 30, "i32": 30, "reduce_axes_0": 30, "reduce_keep_dims_0": 30, "scalar": [30, 44], "log_epsilon_0": 30, "1e": [30, 37, 65, 66, 68], "epsilon": 30, "exactli": [30, 32, 47, 68], "five": [30, 32], "permut": 30, "1240": 31, "interact": 31, "commonli": [31, 45], "arrayfeaturetyp": 31, "imagefeaturetyp": [31, 72], "mlfeaturevalu": 31, "underli": 31, "bundl": 31, "mlfeaturetyp": 31, "achiev": [31, 38, 39, 42, 43, 47, 50, 54, 56, 58], "insert": [31, 37, 42, 43, 48, 53, 73], "output_dict": 31, "20": [31, 53, 55, 65, 71], "60": [31, 38, 42, 47, 56], "load_imag": 31, "resize_to": 31, "uint8": [31, 43, 60], "manipul": 31, "pil_img": 31, "fromarrai": [31, 60], "assumpt": 31, "model_expected_input_shap": 31, "load_image_as_numpy_arrai": 31, "img_as_np_arrai": 31, "diffus": 31, "adopt": 31, "vibrant": 31, "artist": 31, "unpreced": 31, "prompt": [31, 38], "locat": [31, 49, 53], "mlpackg": 31, "diagram": 31, "async": 31, "2023": [31, 39], "world": [31, 59], "confer": [31, 59], "captur": [31, 32, 33, 34, 45, 50, 53, 55], "minut": [31, 38, 39, 56, 58], "cach": [31, 38, 39, 63], "expens": [31, 42], "temporari": 31, "delet": 31, "regnet_y_128fg": 31, "get_compiled_model_path": 31, "regnet_y_128gf": 31, "compiled_model_path": 31, "persist": [31, 63], "shutil": 31, "copytre": 31, "dirs_exist_ok": 31, "abl": [31, 38, 50, 56, 58, 61, 72], "quick": [31, 39, 58, 73], "macbook": [31, 63], "pro": [31, 38, 39, 45, 50, 53, 54, 55, 56, 57, 63], "m1": 31, "sonoma": 31, "vari": [31, 38, 39, 40, 45, 50, 55, 56, 58, 61, 67, 68], "factor": [31, 38, 40, 42, 47, 50, 54, 58], "rel": [31, 38], "measur": [31, 38, 53, 56], "perf_count": 31, "tick": 31, "taken": [31, 38, 56], "1f": 31, "sec": 31, "14": [31, 38, 42, 45, 47, 50, 52, 55, 59], "analyz": [32, 53], "four": 32, "thu": [32, 38, 42], "intent": 32, "fragment": 32, "plu": [32, 39], "twice": 32, "otherwis": [32, 33, 35, 45, 47, 50, 55], "_loopbodi": 32, "pad": 32, "controlflownet": 32, "num_channel": 32, "loop_bodi": 32, "avg": 32, "loop_count": 32, "structur": [32, 47, 48, 49, 50], "sens": 32, "keep": [32, 33, 38, 39, 42, 59, 63], "hand": [32, 45, 49, 55, 56, 72], "whole": [32, 34, 44, 49, 54, 67], "ve": 32, "were": [32, 36, 37, 38, 42, 43, 45, 47, 50, 55, 60], "logic": 32, "controlflownet2": 32, "randn": 32, "easiest": [33, 42], "scripter": 33, "reus": [33, 63], "ll": 33, "conv1": [33, 43], "max_pool2d": 33, "simplenet": 33, "layer1": 33, "layer2": 33, "randomli": 33, "worri": 33, "ios18": [34, 37, 38, 39, 43, 44, 45, 49, 55, 56, 57, 58, 63], "macos15": [34, 39, 43, 44, 45, 49, 55, 57, 63], "independ": [34, 38, 67], "where": [34, 37, 38, 39, 42, 43, 44, 47, 49, 50, 53, 56, 63], "illustr": [34, 58, 63], "extractor": [34, 73], "dedupl": 34, "calcul": 34, "hash": 34, "chosen": [34, 47, 49, 53, 72], "backbon": [34, 42, 45], "definit": [34, 65], "benefici": [34, 38], "sub": [34, 38], "peft": 34, "attach": [34, 58], "variat": 34, "deploi": [34, 36, 38, 64, 68], "ai": 34, "video": [34, 59], "wwdc": [34, 39, 63], "2024": [34, 39, 63], "linear1": 34, "6000": 34, "linear2": 34, "base_model": 34, "adpat": 34, "e": [34, 39, 43, 50, 54, 55, 57, 58], "low": [34, 37, 42, 66], "approxim": [34, 39, 42, 44, 66], "get_peft_model": 34, "loraconfig": 34, "adapt_model_with_lora": 34, "lora_config": 34, "target_modul": 34, "lora_alpha": 34, "adapted_model": 34, "adapted_model_1": 34, "mlmodel_1": 34, "input_adpated_model_1": 34, "out_adpated_model_1": 34, "adapted_model_2": 34, "mlmodel_2": 34, "input_adpated_model_2": 34, "out_adpated_model_2": 34, "done": [34, 39, 43, 47, 57, 58, 63], "multifunctiondescriptor": 34, "save_multifunct": 34, "desc": 34, "add_funct": 34, "src_function_nam": 34, "target_function_nam": 34, "adapter_1": 34, "adapter_2": 34, "default_function_nam": 34, "combined_adpater_model": 34, "function_nam": 34, "y_1": [34, 63], "y_2": [34, 63], "roughli": 34, "72m": 34, "6000x6000": 34, "36m": 34, "ignorn": 34, "4x6000x32": 34, "768m": 34, "fraction": [34, 49], "additon": 34, "tip": 34, "neither": 35, "nor": 35, "cast": [35, 54, 68], "tfcoreml": 36, "onnx_coreml": 36, "convert_neural_network_weights_to_fp16": 36, "convert_neural_network_spec_weights_to_fp16": 36, "quantize_spec_weight": 36, "quantize_weight": [36, 61], "neuralnetworkshap": 36, "get_allowed_shape_rang": 36, "can_allow_multiple_input_shap": 36, "visualize_spec": 36, "netron": 36, "viewer": 36, "get_custom_layer_nam": 36, "replace_custom_layer_nam": 36, "has_custom_lay": 36, "move": [36, 42, 45, 55, 56, 57, 58], "transit": 36, "realiz": 37, "explicitli": [37, 63, 67], "action": [37, 60, 67], "cover": [37, 39], "henc": [37, 38, 39, 55, 63, 66], "lot": [37, 47, 50], "model_with_sparse_weight": 37, "passpipelin": 37, "default_prun": 37, "ios17": [37, 45, 50, 53, 55, 57], "exact": [37, 53], "cluster": [37, 42, 43, 44, 61], "discret": [37, 39], "model_with_lut_weight": 37, "default_palett": 37, "overal": [37, 67], "lookup": [37, 42, 44, 61], "compact": 37, "lut": [37, 42, 43, 45, 56, 57, 58], "hard": [37, 68], "accur": [37, 42, 47, 48, 52, 68], "group": [37, 38, 43, 44, 45, 49, 56, 57, 58], "wise": [37, 38], "instabl": 37, "lead": [37, 38, 39, 42, 44, 45, 47, 55, 58], "incorrect": 37, "forgot": 37, "succe": 37, "emb": [37, 73], "anyth": 37, "nativ": [37, 67], "regist": 37, "buffer": [37, 63], "_coreml_": 37, "parameter_nam": 37, "field_nam": 37, "dense1": 37, "n_bit": [37, 38, 43, 56, 58], "quantization_scal": 37, "compression_typ": 37, "quantization_n_bit": 37, "zero_point": [37, 54], "palettization_scal": 37, "found": [37, 53], "subsect": 37, "pruned_torch_model": 37, "register_buff": [37, 63], "got": 37, "metadata_vers": 37, "conv_1": 37, "conv_2": 37, "palettized_torch_model": [37, 43], "lut1": 37, "scale_1": 37, "lut2": 37, "qint": 37, "quint": 37, "schema": 37, "inject": 37, "quantized_torch_model": 37, "linear_2": 37, "weight_scal": 37, "bias_scal": 37, "model_with_quantized_weight": 37, "joint": [37, 39], "scheme": [37, 39, 54, 61, 67], "similarli": [37, 45, 58, 68], "joint_compressed_model": 37, "zero_point_1": 37, "scale_2": 37, "zero_point_2": 37, "joint_compressed_mlmodel": 37, "lut_1_param": 37, "lut_2_param": 37, "honor": 37, "record": 37, "No": 37, "3072": 37, "block_siz": [37, 38, 48, 53], "ye": 37, "constexpr_blockwise_shift_scal": 37, "constexpr_lut_to_dens": 37, "affin": [37, 54], "unsign": 37, "symmet": 37, "cluster_dim": [37, 43, 44], "group_siz": [37, 38, 43, 44, 56, 58], "group_axi": 37, "nonzero": 37, "int8": [37, 38, 39, 43, 53, 54, 55, 56, 57, 58], "compresion_typ": 37, "tutori": [38, 59], "3b": 38, "billion": 38, "gb": 38, "optforcausallm": 38, "facebook": 38, "torch_dtyp": 38, "use_cach": 38, "perplex": 38, "c4": 38, "wikitext2": 38, "knowledg": 38, "arc_challeng": 38, "arc_easi": 38, "lambada_openai": 38, "triviaqa": 38, "posttrainingquant": [38, 52, 53, 57], "round": [38, 52, 53, 54, 58], "posttrainingquantizerconfig": [38, 53], "from_dict": [38, 43, 48, 53, 56, 58], "weight_dtyp": [38, 48, 53], "int4": [38, 39], "per_block": [38, 53, 54], "compressed_model": [38, 53], "row": 38, "per_tensor": [38, 43, 44, 54], "per_channel": [38, 48, 53, 54], "linear_quantize_weight": [38, 52, 53, 57, 58], "trade": [38, 39, 56, 58], "uncompress": [38, 42, 45, 47, 58], "63": [38, 42, 45], "07": [38, 47, 52, 55], "62": 38, "81": [38, 42, 56, 63], "61": 38, "08": [38, 42, 47], "98": [38, 42, 52, 55], "66": [38, 42, 47, 52, 55, 56], "18763": 38, "31087": 38, "31": 38, "51": [38, 56], "91": 38, "38": [38, 42, 45, 55], "1024": [38, 44, 48], "668": 38, "23": [38, 42, 56], "22": [38, 56, 59], "41": [38, 45], "39": 38, "747": 38, "28": [38, 42, 50, 66, 72, 73], "829": 38, "993": 38, "55": [38, 47, 56], "83": [38, 47], "33": 38, "bare": 38, "loss": [38, 42, 43, 47, 48, 52, 53, 56, 58, 61, 72], "2x": [38, 58, 61], "reduct": [38, 47], "give": [38, 39, 40, 45, 55, 56, 58, 67], "poor": 38, "decreas": [38, 39], "fewer": [38, 54], "increas": [38, 45, 55, 56, 58], "signific": [38, 42, 58], "smaller": [38, 39, 43, 56, 58], "bold": 38, "6x": 38, "wherea": [38, 56], "gain": [38, 39, 55, 56, 58], "posttrainingpalett": [38, 42, 43, 56, 57, 58], "posttrainingpalettizerconfig": [38, 43, 56, 58], "per_grouped_channel": [38, 42, 43, 44, 45, 56, 58], "enable_per_channel_scal": [38, 43], "num_kmeans_work": 38, "turn": [38, 53, 56, 67], "offset": [38, 54, 57, 58], "outlier": 38, "parallel": 38, "massiv": [38, 47, 48], "skmpalett": [38, 42, 43, 57, 58], "squeezellm": [38, 42], "spars": [38, 39, 42, 48, 49, 50, 56, 57], "autotoken": 38, "skmpalettizerconfig": [38, 43, 58], "calibration_nsampl": [38, 43, 48, 53], "get_c4": 38, "nsampl": 38, "seqlen": 38, "subset": [38, 42, 47], "train_data": 38, "load_dataset": 38, "allenai": 38, "tokenized_train_data": 38, "loss_fn": [38, 43, 53], "lm_logit": 38, "shift_logit": 38, "contigu": 38, "shift_label": 38, "loss_fct": 38, "crossentropyloss": 38, "dataload": [38, 43, 48, 53, 56], "gradient": [38, 39, 42, 43, 47, 53, 58, 72], "fisher": [38, 42], "matric": [38, 42, 43, 44, 49], "serv": 38, "estim": [38, 52, 53, 58, 73, 74], "819": 38, "57": 38, "821": 38, "80": [38, 42, 52, 55], "58": [38, 42, 47], "823": 38, "827": 38, "34": 38, "47": [38, 42, 45, 47], "834": 38, "676": 38, "93": [38, 42, 45], "35": 38, "18": [38, 55, 56, 59], "521": 38, "6704": 38, "dramat": 38, "degrad": [38, 42, 58, 61], "pronounc": 38, "68": [38, 42], "regim": 38, "stark": 38, "820": 38, "822": 38, "43": [38, 45, 55], "824": 38, "53": 38, "828": 38, "48": [38, 45, 50, 55, 56], "835": 38, "677": 38, "522": 38, "6703": 38, "disappear": 38, "iphon": [38, 39, 45, 50, 53, 54, 55, 56], "seed": [38, 56], "92": [38, 42, 45, 52, 55], "1x": 38, "76": [38, 42, 47, 52, 55, 56], "24x": 38, "49": [38, 55, 63], "95x": 38, "4x": 38, "30": [38, 71], "72": [38, 56], "3x": 38, "59": [38, 42], "almost": 38, "spent": 38, "Such": [38, 67], "de": [38, 53], "conclud": 38, "italic": 38, "a100": 38, "min": [38, 54, 72], "learnt": [38, 53], "tend": 38, "littl": 38, "correl": 38, "qualiti": 38, "footprint": [39, 58, 59], "1b": 39, "real": 39, "shave": 39, "milli": 39, "ship": 39, "goal": [39, 56, 58], "quickli": [39, 47], "suit": 39, "visit": 39, "tour": 39, "convnet": 39, "amount": [39, 45, 48, 50, 53, 55, 58], "ingredi": 39, "realli": 39, "half": [39, 61], "slight": 39, "calibr": [39, 42, 43, 47, 54, 56, 57], "primarili": [39, 45, 50], "ing": 39, "kernel": [39, 57], "decompress": [39, 45, 55, 57], "fly": [39, 57], "capabilit": 39, "movement": 39, "dram": 39, "processor": 39, "highli": 39, "recommed": 39, "w8a8": [39, 53, 55, 56, 57], "leverag": [39, 54, 56, 59], "a17": [39, 54, 55, 56, 57], "m4": [39, 55, 56, 57], "lose": [39, 56, 58, 61], "matter": 39, "transfom": 39, "resnet50": [40, 42, 45, 47, 50, 52, 55], "opt": 40, "impact": [42, 47, 67], "talk": 42, "mind": 42, "means_clust": 42, "deriv": 42, "centroid": [42, 43, 44], "tradeoff": 42, "recov": [42, 52], "hessian": [42, 47], "computation": 42, "perturb": 42, "closer": 42, "fischer": 42, "dkm": [42, 43, 56], "soft": 42, "submodul": 42, "across": [42, 47, 48, 54, 63], "retain": [42, 52, 56], "intens": [42, 58], "distanc": 42, "attent": [42, 43, 63], "substanti": 42, "dkmpalett": [42, 43, 56, 57], "info": [42, 47], "trial": [42, 47], "86": [42, 47, 52, 55], "70": [42, 58], "54": [42, 45], "89": [42, 52, 55], "97": [42, 45], "mobilenetv3": [42, 45, 47, 50], "82": [42, 45], "65": [42, 45], "46": [42, 50], "44": [42, 55], "75": [42, 47, 48, 49, 50, 56, 58], "01": [42, 47, 72], "99": [42, 45, 52, 55], "centernet": [42, 45], "resnet34": [42, 45], "29": [42, 56], "03": [42, 47, 48, 55], "94": [42, 45, 55], "27": [42, 55], "due": [43, 48, 54], "yaml": [43, 48, 53], "512": [43, 53, 68], "uncompressed_model_path": [43, 58], "op_config": [43, 48, 53, 58], "uniform": [43, 44], "conv3": 43, "linear_config": [43, 48], "model_util": 43, "get_torch_model": 43, "palettization_config_dict": 43, "granulat": 43, "palettization_config": 43, "lut_dtyp": 43, "channel_axi": 43, "effect": [43, 53, 58], "too": 43, "module_type_config": [43, 48, 53], "module_name_config": [43, 53], "skm": 43, "data_util": 43, "get_calibration_data": 43, "from_yaml": [43, 48, 53], "lambda": 43, "mod": 43, "dat": 43, "nll_loss": 43, "calibration_data": 43, "callabl": 43, "plug": 43, "dkmpalettizerconfig": [43, 56], "friendli": 43, "converg": 43, "demand": 43, "kick": 43, "10th": 43, "That": 43, "mileston": [43, 53, 56], "training_util": 43, "train_step": [43, 48, 56], "get_dataload": 43, "num_palettization_epoch": 43, "inplac": [43, 48, 53, 56], "epoch": [43, 48, 56, 72], "batch_idx": 43, "everi": [43, 48, 50], "quantize_activ": 43, "quant_min": 43, "quant_max": 43, "cluster_dtyp": 43, "knob": 43, "though": [43, 58], "checkout": 43, "notebook": 43, "mnist": [43, 58, 72], "accordingli": [43, 58, 63], "palettized_coreml_model": 43, "togeth": 44, "belong": 44, "watchos9": [44, 49], "tvos16": [44, 49], "macos14": [45, 57], "drop": [45, 56, 58], "seen": [45, 52, 55], "literatur": 45, "median": [45, 50, 55], "statist": [45, 50, 53, 55, 56], "a16": [45, 50, 55], "mention": [45, 48, 50, 55, 57], "mobilevitv2": [45, 52, 55], "cvnet": [45, 55], "coco": 45, "differenti": [45, 47, 53, 57], "52": [45, 47, 50, 55], "37": [45, 47, 50, 55], "85": 45, "shot": [47, 48], "lowest": [47, 48, 49], "percentil": [47, 48], "meaning": 47, "pattern": 47, "prune_weight": [47, 48, 56, 57], "coreltool": 47, "constantsparsityschedul": [47, 48], "begin_step": 47, "l2": [47, 52], "norm": [47, 48, 52, 53, 56], "reconstruct": 47, "solv": 47, "jointli": [47, 50], "layerwisecompressor": [47, 48, 52, 53], "efficaci": 47, "extend": [47, 61, 73], "unstructur": [47, 49, 50], "desir": [47, 56, 58, 68, 71], "mask": [47, 49, 60], "descent": [47, 72], "adapt": [47, 48, 58], "presenc": 47, "levl": 47, "studi": 47, "meet": [47, 56], "awar": [47, 52, 58], "73": [47, 50, 56], "69": [47, 56], "77": [47, 50, 52, 55], "40": 47, "opmagnitudeprunerconfig": 48, "opthresholdprunerconfig": 48, "usag": 48, "model_compress": 48, "target_spars": [48, 56], "fc": 48, "upto": 48, "sturcutr": 48, "n_m_ratio": 48, "magnitudeprun": [48, 50, 56, 57], "sparse_gpt_config": 48, "125": 48, "layerwisecompressorconfig": [48, 53], "compressor": 48, "cuda": 48, "qualifi": 48, "regex": 48, "quantization_granular": 48, "quantization_schem": [48, 53, 56], "magnitudeprunerconfig": [48, 56], "magniutdeprun": 48, "magniutdeprunerconfig": 48, "pruner": [48, 56], "sparsif": 48, "gradual": 48, "increment": [48, 63], "schedul": [48, 56], "update_step": [48, 56], "per_scalar": 48, "num_epoch": [48, 56], "train_dataload": 48, "per_kernel": 48, "sparisti": 48, "polynomialdecayschedul": [48, 56], "upon": [48, 52], "hook": 48, "incremenet": 48, "replac": [48, 65], "sparsifi": [49, 57], "56": 49, "01000001b": 49, "accompani": 49, "enforc": [49, 67], "smallest": 49, "impos": [49, 53], "goe": 50, "linearli": [50, 53, 54], "consecut": 50, "individu": [50, 71], "rtn": [52, 53], "fastest": [52, 58], "suggets": 52, "linearquant": [52, 53, 56, 57], "linear_quantize_activ": [52, 53, 56, 57, 58], "layerwis": 52, "paradigm": 52, "betwen": 52, "around": 52, "layerwise_compress": [52, 57, 58], "qat": [52, 58], "arithmet": 52, "lost": 52, "ptq": 52, "former": 52, "09": [52, 55, 56], "oplinearquantizerconfig": [53, 58], "linear_symmetr": [53, 58, 61], "compressed_8_bit_model": 53, "slightli": [53, 56, 68], "onward": 53, "activation_config": 53, "opactivationlinearquantizerconfig": [53, 58], "compressed_model_a8": 53, "sample_data": [53, 58], "quantized_model": [53, 56, 61], "layerwisecomressor": 53, "gptq": [53, 57], "input_cach": 53, "backward": [53, 56], "linearquantizerconfig": [53, 56], "modulelinearquantizerconfig": [53, 56], "no_grad": [53, 56, 60], "And": [53, 71], "influenc": 53, "fake": 53, "never": 53, "400": 53, "200": [53, 56], "first_lay": 53, "final_lay": 53, "fakequant": 53, "counterpart": 53, "written": [53, 72], "explan": 53, "quint8": 53, "adjust": [53, 72], "straight": 53, "fx": 53, "prepare_qat_fx": 53, "graphmodul": 53, "traceabl": 53, "interpol": 54, "dequant": [54, 61], "w_unquant": 54, "w_quantiz": 54, "clip": [54, 68], "quantizationgranular": 54, "bandwidth": 54, "eas": 55, "pressur": 55, "slowdown": 55, "sometim": 55, "slow": 55, "mostli": 55, "ipad": 55, "throughput": 55, "w16a16": 55, "great": [55, 59], "36": [55, 63], "articl": 56, "cnn": 56, "stai": 56, "budget": 56, "exercis": 56, "baselin": 56, "49mb": 56, "63m": 56, "quickest": 56, "behav": 56, "config_dict": 56, "palettized_model": [56, 58], "equal": [56, 67], "margin": 56, "big": 56, "regain": [56, 58], "pallet": 56, "25m": 56, "12m": 56, "38m": 56, "34m": 56, "71m": 56, "sweet": 56, "spot": [56, 68], "worflow": 56, "moduledkmpalettizerconfig": 56, "set_glob": 56, "train_load": 56, "15x": 56, "easier": [56, 60], "14m": 56, "hour": 56, "300": 56, "1m": 56, "modulemagnitudeprunerconfig": 56, "initial_spars": 56, "pruned_model": 56, "90": 56, "23m": 56, "05m": 56, "86m": 56, "enough": [56, 67], "pruning_schedul": 56, "setup": [56, 72], "25000": 56, "62500": 56, "quit": 56, "chip": [56, 57], "07m": 56, "speedup": 56, "quicker": 56, "ahead": 57, "acceler": [57, 67], "quantization_util": [57, 61], "later": [57, 58, 72], "subspac": 57, "0b1": [57, 58, 68], "sparsegpt": 57, "namespac": 57, "characterist": 58, "noth": 58, "instantli": 58, "decent": 58, "sole": 58, "account": 58, "hypothet": 58, "curv": 58, "brief": 58, "comprehens": 58, "pseudocod": 58, "model_config": 58, "uncompressed_torch_model": 58, "traced_palettized_model": 58, "mainli": 58, "compressed_torch_model": 58, "data_load": 58, "loss_funct": 58, "a8w16": 58, "act_quant_op_config": 58, "act_quant_model_config": 58, "mlmodel_compressed_activ": 58, "a8w8": 58, "weight_quant_op_config": 58, "weight_quant_model_config": 58, "mlmodel_compress": 58, "invoc": 58, "strictli": 59, "privat": 59, "educ": 59, "materi": 59, "technologi": 59, "browser": 59, "binder": 59, "famili": 59, "ensembl": 59, "simplefilt": 60, "futurewarn": 60, "json": [60, 74], "deeplabv3": 60, "hub": [60, 66], "v0": 60, "deeplabv3_resnet101": 60, "input_imag": 60, "cat_dog": 60, "pascal": 60, "voc": 60, "totensor": 60, "input_tensor": [60, 65], "input_batch": 60, "unsqueez": 60, "torch_predict": 60, "plot": [60, 68], "overlaid": 60, "display_segment": 60, "output_predict": 60, "as_tensor": 60, "semant": 60, "putpalett": 60, "overlai": 60, "alpha_imag": 60, "putalpha": 60, "rgba": 60, "seg_imag": 60, "alpha_composit": 60, "tupl": 60, "sidestep": 60, "wrappeddeeplabv3resnet101": 60, "traceable_model": 60, "segmentationmodel_no_metadata": [60, 74], "labels_json": [60, 74], "imagesegment": [60, 74], "aeroplan": [60, 74], "bicycl": [60, 74], "bird": [60, 74], "board": [60, 74], "bottl": [60, 74], "bu": [60, 74], "car": [60, 74], "chair": [60, 74], "cow": [60, 74], "diningt": [60, 74], "hors": [60, 74], "motorbik": [60, 74], "pottedpl": [60, 74], "sheep": [60, 74], "sofa": [60, 74], "tvormonitor": [60, 74], "param": [60, 74], "dump": [60, 74], "pallett": 60, "alter": 61, "chanc": 61, "kept": 61, "affect": [61, 67], "safest": 61, "model_fp32": [61, 68], "model_fp16": 61, "fourth": 61, "model_8bit": 61, "quantization_mod": 61, "linearsymmetr": 61, "kmeans_lut": 61, "custom_lut": 61, "shouldn": 61, "advancedquantizedlayerselector": 61, "count": 61, "depthwis": 61, "4096": 61, "selector": 61, "skip_layer_typ": 61, "depthwiseconv": 61, "minimum_conv_kernel_channel": 61, "minimum_conv_weight_count": 61, "neuralnetworklay": 61, "finer": 61, "rule": 61, "quantizedlayerselector": 61, "dense_2": [61, 72], "mylayerselector": 61, "do_quant": 61, "ret": 61, "track": 63, "implicitli": 63, "toi": 63, "sum": [63, 68], "stateless": 63, "acc_in": 63, "acc_out": 63, "x_1": 63, "x_2": 63, "care": 63, "acc": 63, "leav": 63, "decis": 63, "mayb": 63, "alongsid": [63, 72], "snapshot": 63, "statetyp": 63, "wrapped_typ": 63, "make_st": 63, "isn": 63, "state1": 63, "state2": 63, "121": 63, "carefulli": 63, "opaqu": 63, "statetensorspec": 63, "accumulator_st": 63, "accumulator_valu": 63, "read_stat": 63, "coreml_update_st": 63, "lm": 63, "digest": 63, "auto": 63, "strategi": [63, 72], "potenti": 63, "mistral": 63, "7b": 63, "concret": 64, "mainten": 64, "receiv": 64, "ios11": 64, "macos10": 64, "milspec": 64, "freeze_graph": 65, "truncated_norm": 65, "stddev": 65, "tempfil": 65, "model_dir": 65, "mkdtemp": 65, "graph_def_fil": 65, "tf_graph": 65, "checkpoint_fil": 65, "ckpt": 65, "frozen_graph_fil": 65, "tf_frozen": 65, "global_variables_initi": 65, "somewher": 65, "write_graph": 65, "as_text": 65, "saver": 65, "input_graph": 65, "input_sav": 65, "input_binari": 65, "input_checkpoint": 65, "output_node_nam": 65, "restore_op_nam": 65, "restore_al": 65, "filename_tensor_nam": 65, "clear_devic": 65, "initializer_nod": 65, "float_v2_1": 65, "v2": 65, "graph_def": 65, "gfile": 65, "prospect": 65, "nprospect": 65, "sink_op": 65, "parent": 65, "unknown": [65, 73], "reshape_1": 65, "coreml_out": [65, 66, 68], "assert_allclos": [65, 66], "rtol": [65, 66], "atol": [65, 66], "www": 66, "inputlay": 66, "192": 66, "googl": 66, "mobilenet_v2_050_192": 66, "tf_keras_model": 66, "load_model": [66, 72], "customdens": 66, "add_weight": 66, "random_norm": 66, "gelu": 66, "input_signatur": 66, "gelu_tanh_activ": 66, "sqrt": 66, "pi": 66, "044715": 66, "pow": 66, "tanh": 66, "conc_func": 66, "get_concrete_funct": 66, "abil": 67, "mismatch": 67, "irrespect": 67, "partit": 67, "maxim": 67, "chart": 67, "contrast": 67, "ever": 67, "expand": 67, "bar": 67, "float16computeprecis": 67, "elig": 68, "suitabl": 68, "wave": 68, "spatial": 68, "fast_neural_style_wav": 68, "fp16computeprecis": 68, "seat": 68, "model_input_nam": 68, "model_output_nam": 68, "coreml_output_tensor": 68, "session_config": 68, "tf_out_tensor": 68, "signal": 68, "nois": 68, "snr": 68, "_compute_snr": 68, "noise_var": 68, "signal_energi": 68, "max_signal_energi": 68, "log10": 68, "38136549121856": 68, "20db": 68, "coreml_out_fp32": 68, "coreml_output_tensor_fp32": 68, "95": 68, "75957654819682": 68, "inde": 68, "pyplot": 68, "plt": 68, "_normal": 68, "amin": 68, "fig": 68, "ax_arrai": 68, "subplot": 68, "imshow": 68, "set_titl": 68, "fontsiz": 68, "70db": 68, "faithfulli": 68, "classic": 69, "mlupdatetask": 70, "number_of_dimens": [71, 73], "nearest_neighbor": [71, 73], "knearestneighborsclassifierbuild": [71, 73], "default_class_label": [71, 73], "defaultlabel": 71, "number_of_neighbor": 71, "weighting_schem": [71, 73], "inverse_dist": [71, 73], "index_typ": [71, 73], "mit": [71, 72, 73], "shortdescript": [71, 72, 73], "traininginput": [71, 72, 73], "knn": 71, "is_updat": 71, "numberofneighbor": 71, "number_of_neighbors_allowed_rang": 71, "traceback": 71, "e8bea591e72c": 71, "eng": 71, "312": 71, "knearestneighborsclassifi": 71, "defaultvalu": 71, "313": 71, "314": 71, "315": 71, "316": 71, "spec_valu": 71, "set_number_of_neighbors_with_bound": 71, "allowed_set": [71, 72], "number_of_neighbors_allowed_set": 71, "attempt": 71, "invalid": 71, "98c77c72c722": 71, "320": 71, "321": 71, "322": 71, "323": 71, "324": 71, "allowed_rang": 71, "revert": 71, "leaf": 71, "kd_tree": 71, "set_index_typ": 71, "mlmodel_updatable_path": [71, 72], "updatableknn": 71, "mlmodel_updat": [71, 72], "categor": 72, "cross": 72, "entropi": 72, "stochast": 72, "adam": 72, "sgd": 72, "create_keras_base_model": 72, "maxpooling2d": 72, "clear_sess": 72, "pool_siz": 72, "categorical_crossentropi": 72, "lr": 72, "keras_model_path": 72, "kerasmnist": 72, "convert_keras_to_mlmodel": 72, "keras_url": 72, "mlmodel_url": 72, "keras_convert": 72, "digitprob": 72, "predicted_feature_nam": 72, "digit": 72, "coreml_model_path": 72, "mnistdigitclassifi": 72, "neuralnetworkbuild": 72, "inspect_lay": 72, "dense_2__activation__": 72, "dense_2_output": 72, "innerproduct": 72, "dense_1__activation___output": 72, "dense_1__activation__": 72, "dense_1_output": 72, "inspect_input_featur": 72, "neuralnetwork_spec": 72, "multiarraytyp": [72, 73], "datatyp": [72, 73], "28x28": 72, "featuretypes_pb2": 72, "_featuretypes_pb2": 72, "colorspac": [72, 73], "handwriten": 72, "model_spec": 72, "dense_1": 72, "cce": 72, "set_categorical_cross_entropy_loss": 72, "losslay": 72, "learningr": 72, "minibatchs": 72, "momentum": 72, "sgdparam": 72, "set_sgd_optim": 72, "set_epoch": 72, "handwritten": 72, "coreml_updatable_model_path": 72, "updatablemnistdigitclassifi": 72, "digitprobabilities_tru": 72, "inspect_loss_lay": 72, "categoricalcrossentropylosslay": 72, "inspect_optim": 72, "sgdoptim": 72, "32l": 72, "inspect_updatable_lay": 72, "flatten_1_output": 72, "black": 73, "stroke": 73, "render": 73, "white": 73, "star": 73, "heart": 73, "embedding_path": 73, "tinydrawingembed": 73, "embedding_model": 73, "embedding_spec": 73, "dimension": 73, "googlecreativelab": 73, "quickdraw": 73, "knn_builder": 73, "knn_spec": 73, "pipeline_spec": 73, "model_pb2": 73, "specificationvers": 73, "_minimum_updatable_spec_vers": 73, "isupdat": 73, "predictedfeaturenam": 73, "predictedprobabilitiesnam": 73, "tini": 73, "pipelineclassifi": 73, "copyfrom": 73, "output_path": 73, "tinydrawingclassifi": 73, "hexcod": 74, "poseestim": 74, "width_multipli": 74, "output_strid": 74, "dict": 74, "depth": 74, "depthestim": 74, "posenet": 74, "detectinghumanbodyposesinanimag": 74, "posefind": 74, "posenetmobilenet075s16fp16": 74, "params_json": 74, "posenet_with_preview_typ": 74, "posenet_model": 74, "j": 74, "cr\u00e8che": 74, "stand": 74, "man": 74, "domain": 74, "creativecommon": 74}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"core": [0, 2, 6, 7, 9, 11, 18, 19, 23, 27, 30, 36, 43, 48, 53, 57, 59, 63, 64, 69], "ml": [0, 2, 6, 7, 9, 11, 14, 16, 18, 19, 22, 23, 24, 27, 30, 35, 36, 43, 48, 53, 57, 59, 63, 64, 67, 68, 69, 72], "tool": [0, 18, 23, 36, 57, 59, 69], "api": [0, 1, 19, 43, 48, 52, 53, 57, 58, 69], "refer": [0, 19], "overview": [0, 16, 27, 30, 39, 43, 44, 48, 49, 53, 54, 69, 74], "unifi": 0, "convers": [0, 3, 4, 11, 16, 18, 26, 29, 35, 37, 64], "optim": [0, 16, 18, 38, 56, 57, 58], "other": 0, "convert": [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 22, 24, 26, 28, 30, 35, 36, 37, 43, 48, 53, 60, 63, 65, 66, 68, 72], "mlmodel": [0, 16, 27, 28], "classifi": [1, 6, 16, 28, 71, 72, 73], "preview": [1, 16, 74], "model": [1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 22, 24, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 43, 45, 48, 53, 55, 56, 58, 60, 63, 65, 66, 68, 70, 72, 73, 74], "xcode": [1, 14, 16, 22, 24, 60, 74], "info": [1, 37, 45, 55], "produc": [1, 24, 64], "The": [1, 9], "vision": 1, "compar": [2, 7, 68], "program": [2, 14, 16, 22, 24, 30, 35, 67, 68], "neural": [2, 15, 18, 19, 24, 35, 61, 67, 72], "network": [2, 15, 18, 19, 24, 35, 61, 67, 72], "benefit": 2, "represent": 2, "differ": [2, 52, 64], "detail": 2, "mil": [2, 3, 16, 17, 30, 63], "support": [2, 17, 22, 23, 36, 59, 64, 72], "composit": [3, 16, 17], "oper": [3, 16, 17, 64], "instal": [3, 21, 23, 60, 68], "transform": [3, 13, 28, 66], "import": [3, 9, 22], "pre": [3, 65, 66], "train": [3, 43, 47, 48, 52, 53, 58, 65, 66], "decompos": 3, "exist": 3, "regist": [3, 17, 63], "function": [3, 61, 66], "us": [3, 5, 17, 18, 19, 22, 24, 27, 28, 29, 31, 32, 37, 56, 63, 65], "op": [3, 18], "pytorch": [3, 7, 9, 10, 11, 16, 18, 22, 26, 29, 36, 37, 43, 52, 53, 60, 63, 64], "more": [3, 11, 30, 31, 65], "exampl": [3, 16, 22, 24, 26, 27, 28, 31, 34, 40, 43, 60, 63, 65, 68, 74], "option": [4, 16, 22, 26, 35, 61], "tensorflow": [5, 6, 12, 13, 16, 17, 22, 26, 36, 64, 65, 66, 68], "1": [5, 6, 16, 17, 26, 37, 56, 61, 64, 65, 68], "deepspeech": 5, "how": [5, 39, 54, 64], "asr": 5, "work": [5, 27, 53, 54], "set": [5, 7, 9, 11, 14, 19, 22, 23, 24, 26, 29, 35, 60, 71, 72], "up": [5, 9, 23], "preprocess": [5, 6, 7, 18, 22], "an": [5, 18, 22, 35, 47, 68, 73], "audio": 5, "file": [5, 64], "feed": 5, "input": [5, 6, 7, 9, 16, 18, 19, 22, 27, 29, 31, 35, 60, 65], "Into": 5, "dynam": 5, "static": 5, "One": 5, "imag": [6, 7, 16, 18, 22, 29, 31, 60, 65], "requir": [6, 7, 9, 13, 14, 24, 31, 60], "download": [6, 7, 24, 26, 68], "load": [6, 7, 24, 26, 27, 60, 72], "graph": [6, 20, 65], "definit": 6, "test": [6, 7, 22], "make": [6, 7, 24, 68, 72], "predict": [6, 7, 16, 24, 27, 31, 63, 68], "befor": 6, "can": 6, "vari": 6, "slightli": 6, "torchvis": [7, 18], "from": [7, 10, 12, 19, 23, 26, 31, 36], "mobilenetv2": 7, "evalu": [7, 11, 28], "mode": [7, 11, 52], "trace": [7, 9, 22, 32, 33, 60], "class": [7, 17], "label": [7, 21], "output": [7, 18, 22, 27, 29, 31, 35, 68], "get": [7, 24, 28, 73], "protobuf": 7, "spec": [7, 27, 72], "tensor": [7, 67], "torch": [7, 18, 22, 37, 43, 48], "print": 7, "deep": [8, 18], "learn": [8, 18, 30, 31, 62], "natur": 9, "languag": [9, 16, 30], "process": 9, "gpt": 9, "2": [9, 13, 16, 17, 26, 56, 64, 66], "nlp": 9, "librari": [9, 59], "script": [9, 32], "encod": 9, "sentenc": 9, "fragment": 9, "run": [9, 24], "workflow": [11, 17, 26, 36, 58, 65, 66, 68], "minimum": [11, 64], "deploy": [11, 36, 64], "target": [11, 36, 64], "gener": 11, "torchscript": 11, "version": [11, 18, 23, 36, 37, 64], "For": [11, 16, 23, 36, 61], "inform": 11, "bert": [13, 66], "distilbert": 13, "tf": 13, "hub": 13, "precis": [14, 35, 54, 67, 68], "float": [14, 22, 28, 61], "16": [14, 22, 61], "default": [14, 18, 19, 29, 64], "save": [14, 22, 24, 27], "packag": [14, 23], "13": 14, "newer": 14, "find": 14, "type": [14, 16, 22, 29, 31, 35, 39, 67, 68, 71, 74], "avail": [14, 19, 39, 44, 49, 57], "quick": 16, "start": [16, 18, 24], "execut": [16, 35, 67, 68], "intermedi": [16, 30], "flexibl": [16, 18, 19], "shape": [16, 18, 19, 29], "custom": [16, 17, 18, 61], "tree": 16, "linear": [16, 51], "util": [16, 28], "updat": [16, 19, 27, 70, 72, 73], "last": 17, "resort": 17, "develop": [17, 64], "step": 17, "defin": [17, 66, 72], "3": [17, 36], "4": [17, 18, 36], "implement": 17, "swift": 17, "layer": [17, 61], "faq": 18, "coremltool": 18, "7": [18, 57], "previou": [18, 36], "releas": [18, 36], "6": 18, "5": 18, "kera": [18, 66], "fix": 18, "high": 18, "numer": 18, "error": 18, "declar": 18, "comput": [18, 26, 31, 35, 68], "nn": 18, "handl": 18, "unsupport": 18, "choos": [18, 47, 67], "name": [18, 29], "engin": 18, "With": [18, 22, 27, 58, 66], "why": [18, 31, 32, 34], "i": [18, 59], "better": 18, "than": 18, "": [18, 60], "quantiz": [18, 37, 38, 44, 51, 52, 53, 54, 56, 61], "compil": [18, 31], "faster": 18, "initi": 18, "select": 19, "predetermin": 19, "enumer": 19, "provid": [19, 29], "perform": [19, 39, 45, 50, 55, 64], "advantag": 19, "prealloc": 19, "multi": [19, 28, 31], "rang": 19, "each": [19, 58], "dimens": 19, "enabl": 19, "unbound": 19, "onli": [19, 61], "pass": [20, 37], "contribut": 21, "sourc": [21, 23, 64, 68], "code": [21, 60], "issu": 21, "queri": 21, "upgrad": [21, 23], "instruct": 21, "secur": 21, "document": 21, "imagetyp": 22, "now": 22, "mlmultiarrai": 22, "statement": 22, "filter": 22, "open": [22, 60, 74], "scalar": 22, "grayscal": 22, "multiarrai": 22, "add": 22, "python": [23, 31], "maco": [23, 31], "prerequisit": 23, "beginn": 23, "build": 23, "conda": 23, "new": [23, 35, 36, 57], "virtual": 23, "environ": 23, "third": 23, "parti": 23, "metadata": [24, 27, 28, 60], "v": 24, "libsvm": 25, "follow": 26, "unit": [26, 31, 35], "specif": [27, 64], "descript": [27, 28], "renam": 28, "featur": [28, 36, 39, 44, 49, 64], "all": 28, "doubl": 28, "arrai": [28, 31], "regressor": 28, "weight": [28, 37, 52, 53, 61], "behavior": 29, "dtype": 29, "creat": [30, 63, 71, 72, 73], "about": [30, 31], "specifi": [31, 37], "deprec": [31, 36], "flag": 31, "time": [31, 48], "mai": 32, "Not": 32, "accur": 32, "jit": 32, "mix": 32, "limit": 33, "multifunct": 34, "combin": 34, "toi": 34, "lora": 34, "adapt": 34, "pick": 35, "8": [36, 57, 61], "note": 36, "migrat": 36, "older": 36, "method": 36, "pipelin": [37, 73], "spars": 37, "palett": [37, 38, 41, 43, 44, 56], "compress": [37, 38, 39, 56, 58, 61], "embed": [37, 73], "activ": [37, 52, 53, 54, 56], "jointli": 37, "protocol": 37, "opt": 38, "data": [38, 48, 52, 53, 56, 58], "free": [38, 48, 52, 53, 56, 58], "result": [38, 42, 45, 47, 50, 55], "algorithm": [38, 42, 47, 52], "runtim": [38, 39], "calibr": [38, 48, 52, 53, 58], "base": [38, 48, 52, 53, 58, 72], "effect": [38, 39], "per": [38, 44], "channel": [38, 44], "scale": [38, 44], "impact": [38, 52], "latenc": [38, 56], "conclus": 38, "appl": 39, "silicon": 39, "k": [42, 43], "mean": [42, 43], "sensit": [42, 43], "differenti": [42, 43], "methodologi": [42, 45, 47, 50, 55], "post": [43, 47, 52, 58], "granular": [44, 54], "vector": 44, "lut": [44, 61], "benchmark": [45, 47, 50, 55], "prune": [46, 47, 48, 56], "sparsegpt": [47, 48], "magnitudeprun": 47, "accuraci": [47, 52], "gptq": 52, "fine": [52, 56, 58], "tune": [52, 56, 58], "awar": 53, "qat": 53, "symmetr": 54, "resnet50": 56, "scenario": 56, "minim": 56, "size": 56, "summari": 56, "reduct": 56, "what": [57, 59], "softwar": [57, 60], "ios15": 57, "macos12": 57, "lower": 57, "dataset": 58, "addit": 59, "resourc": 59, "framework": 59, "segment": [60, 74], "normal": 60, "sampl": 60, "format": [61, 64, 66, 72], "bit": 61, "control": 61, "which": 61, "ar": 61, "scikit": 62, "state": 63, "A": 63, "simpl": 63, "accumul": 63, "applic": 63, "x": 64, "improv": 64, "export": 65, "frozen": 65, "recommend": 66, "user": 66, "sequenti": 66, "subclass": 66, "concret": 66, "appropri": 67, "untyp": 67, "paramet": 68, "comparison": 68, "foat": 68, "32": 68, "visual": 68, "nearest": [71, 73], "neighbor": [71, 73], "number": 71, "valu": 71, "index": 71, "appli": 72, "its": 72, "make_updat": 72, "bodi": 74, "pose": 74, "xgboost": 75}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Core ML Tools": [[0, "core-ml-tools"]], "API Reference": [[0, null], [19, "api-reference"]], "Overview": [[0, null], [30, "overview"], [39, "overview"], [49, "overview"], [54, "overview"], [74, "overview"]], "Unified Conversion": [[0, null]], "Optimization": [[0, null], [16, "optimization"]], "Other Converters": [[0, null]], "MLModel": [[0, null], [16, "mlmodel"]], "Classifiers": [[1, "classifiers"], [16, "classifiers"]], "Preview a Classifier Model": [[1, "preview-a-classifier-model"]], "Xcode Info": [[1, null]], "Produce a Classifier Model": [[1, "produce-a-classifier-model"]], "The Vision Classifier API": [[1, null]], "Comparing ML Programs and Neural Networks": [[2, "comparing-ml-programs-and-neural-networks"]], "ML Program Benefits": [[2, "ml-program-benefits"]], "Model Representations": [[2, "model-representations"]], "Differences in Detail": [[2, "differences-in-detail"]], "ML Programs and MIL": [[2, "ml-programs-and-mil"]], "Core ML model support": [[2, null]], "Composite Operators": [[3, "composite-operators"]], "Install Transformers": [[3, null]], "Import and Convert the Pre-trained Model": [[3, "import-and-convert-the-pre-trained-model"]], "Decompose into Existing MIL Operators": [[3, "decompose-into-existing-mil-operators"]], "Register the Function": [[3, null]], "Using Composite Ops with PyTorch Conversion": [[3, "using-composite-ops-with-pytorch-conversion"]], "More Examples": [[3, "more-examples"], [65, "more-examples"]], "Conversion Options": [[4, "conversion-options"], [16, "conversion-options"], [26, null]], "Converting a TensorFlow 1 DeepSpeech Model": [[5, "converting-a-tensorflow-1-deepspeech-model"]], "How ASR Works": [[5, null]], "Set Up the Model": [[5, "set-up-the-model"]], "Convert the Model and Preprocess an Audio File": [[5, "convert-the-model-and-preprocess-an-audio-file"]], "Feed the Input Into the Model": [[5, "feed-the-input-into-the-model"]], "Use a Dynamic TensorFlow Model": [[5, "use-a-dynamic-tensorflow-model"]], "Convert a Dynamic Model to a Static One": [[5, "convert-a-dynamic-model-to-a-static-one"]], "Converting a TensorFlow 1 Image Classifier": [[6, "converting-a-tensorflow-1-image-classifier"]], "Requirements": [[6, "requirements"], [7, "requirements"], [9, "requirements"], [13, null], [13, null], [24, "requirements"]], "Download the Model": [[6, "download-the-model"], [24, "download-the-model"]], "Load the Graph Definition": [[6, "load-the-graph-definition"]], "Convert to Core ML": [[6, "convert-to-core-ml"], [7, "convert-to-core-ml"], [11, "convert-to-core-ml"]], "Load a Test Image": [[6, "load-a-test-image"]], "Input the Image and Make a Prediction": [[6, "input-the-image-and-make-a-prediction"]], "Preprocess the Image Before Converting": [[6, "preprocess-the-image-before-converting"]], "Predictions Can Vary Slightly": [[6, null]], "Converting a torchvision Model from PyTorch": [[7, "converting-a-torchvision-model-from-pytorch"]], "Load the MobileNetV2 Model": [[7, "load-the-mobilenetv2-model"]], "Set the Model to Evaluation Mode": [[7, null], [11, null]], "Trace the Model": [[7, "trace-the-model"]], "Download the Class Labels": [[7, "download-the-class-labels"]], "Preprocess the Image Input for torchvision Models": [[7, "preprocess-the-image-input-for-torchvision-models"]], "Images for Input and Output": [[7, null]], "Load the Test Image": [[7, "load-the-test-image"]], "Get the protobuf spec": [[7, "get-the-protobuf-spec"]], "Make a Core ML Prediction": [[7, "make-a-core-ml-prediction"]], "Make a PyTorch Prediction and Compare": [[7, "make-a-pytorch-prediction-and-compare"]], "Convert the Image to a Tensor": [[7, "convert-the-image-to-a-tensor"]], "Make a Prediction with Torch and Print Outputs": [[7, "make-a-prediction-with-torch-and-print-outputs"]], "Converting Deep Learning Models": [[8, "converting-deep-learning-models"]], "Converting a Natural Language Processing Model": [[9, "converting-a-natural-language-processing-model"]], "The GPT-2 NLP Model": [[9, "the-gpt-2-nlp-model"]], "Import Libraries and Set Up the Model": [[9, "import-libraries-and-set-up-the-model"]], "Trace and Script the Model": [[9, "trace-and-script-the-model"]], "Convert the Model to Core ML": [[9, "convert-the-model-to-core-ml"]], "Encode the Sentence Fragment as Input": [[9, "encode-the-sentence-fragment-as-input"]], "Run the PyTorch Model": [[9, "run-the-pytorch-model"]], "Run the Converted Core ML Model": [[9, "run-the-converted-core-ml-model"]], "Converting from PyTorch": [[10, "converting-from-pytorch"]], "PyTorch Conversion Workflow": [[11, "pytorch-conversion-workflow"]], "Minimum Deployment Target": [[11, null], [64, "minimum-deployment-target"]], "Generate a TorchScript Version": [[11, "generate-a-torchscript-version"]], "For More Information": [[11, null]], "Converting from TensorFlow": [[12, "converting-from-tensorflow"]], "Converting TensorFlow 2 BERT Transformer Models": [[13, "converting-tensorflow-2-bert-transformer-models"]], "Convert the DistilBERT Transformer Model": [[13, "convert-the-distilbert-transformer-model"]], "Convert the TF Hub BERT Transformer Model": [[13, "convert-the-tf-hub-bert-transformer-model"]], "Convert Models to ML Programs": [[14, "convert-models-to-ml-programs"]], "Set the ML Program Precision": [[14, "set-the-ml-program-precision"]], "Float 16 Default": [[14, null]], "Save ML Programs as Model Packages": [[14, "save-ml-programs-as-model-packages"]], "Requires Xcode 13 or Newer": [[14, null]], "Find the Model Type in a Model Package": [[14, "find-the-model-type-in-a-model-package"]], "Availability of ML Programs": [[14, "availability-of-ml-programs"]], "Convert Models to Neural Networks": [[15, "convert-models-to-neural-networks"]], "Examples": [[16, "examples"], [27, "examples"], [40, "examples"]], "For a Quick Start": [[16, "for-a-quick-start"]], "ML Program with Typed Execution": [[16, "ml-program-with-typed-execution"]], "TensorFlow 2": [[16, "tensorflow-2"]], "TensorFlow 1": [[16, "tensorflow-1"]], "PyTorch": [[16, "pytorch"]], "Model Intermediate Language (MIL)": [[16, "model-intermediate-language-mil"]], "Image Inputs": [[16, "image-inputs"]], "Flexible Input Shapes": [[16, "flexible-input-shapes"], [19, "flexible-input-shapes"]], "Composite and Custom Operators": [[16, "composite-and-custom-operators"]], "Trees and Linear Models": [[16, "trees-and-linear-models"]], "MLModel Overview": [[16, "mlmodel-overview"], [27, "mlmodel-overview"]], "Model Prediction": [[16, "model-prediction"], [31, "model-prediction"]], "Xcode Model Preview Types": [[16, "xcode-model-preview-types"], [74, "xcode-model-preview-types"]], "MLModel Utilities": [[16, "mlmodel-utilities"], [28, "mlmodel-utilities"]], "Updatable Models": [[16, "updatable-models"], [70, "updatable-models"]], "Custom Operators": [[17, "custom-operators"]], "Use Custom Operators as a Last Resort": [[17, null]], "Developer Workflow": [[17, "developer-workflow"]], "Step 1: Register the MIL Operator": [[17, "step-1-register-the-mil-operator"]], "Step 2: Define a TensorFlow Composite Operator": [[17, "step-2-define-a-tensorflow-composite-operator"]], "Step 3: Convert the Model": [[17, "step-3-convert-the-model"]], "Step 4: Implement Classes in Swift": [[17, "step-4-implement-classes-in-swift"]], "Custom Layer Support": [[17, null]], "Core ML Tools FAQs": [[18, "core-ml-tools-faqs"]], "Core ML Tools Versions": [[18, "core-ml-tools-versions"]], "coremltools 7": [[18, "coremltools-7"]], "Previous releases": [[18, "previous-releases"]], "coremltools 6": [[18, "coremltools-6"]], "coremltools 5": [[18, "coremltools-5"]], "coremltools 4": [[18, "coremltools-4"]], "PyTorch Conversion": [[18, "pytorch-conversion"]], "Keras Conversion": [[18, "keras-conversion"]], "Fixing High Numerical Error": [[18, "fixing-high-numerical-error"]], "Image Preprocessing for Converting torchvision": [[18, "image-preprocessing-for-converting-torchvision"]], "Error in Declaring Network or Computing NN Outputs": [[18, "error-in-declaring-network-or-computing-nn-outputs"]], "Starting a Deep Learning Core ML Model": [[18, "starting-a-deep-learning-core-ml-model"]], "Handling an Unsupported Op": [[18, "handling-an-unsupported-op"]], "Choosing Custom Names for Input and Outputs": [[18, "choosing-custom-names-for-input-and-outputs"]], "Neural Engine With Flexible Input Shapes": [[18, "neural-engine-with-flexible-input-shapes"]], "Why optimize.torch is better than PyTorch\u2019s default quantization": [[18, "why-optimize-torch-is-better-than-pytorchs-default-quantization"]], "Use a compiled model for faster initialization": [[18, "use-a-compiled-model-for-faster-initialization"]], "Select From Predetermined Shapes": [[19, "select-from-predetermined-shapes"]], "Enumerated Shapes Provide a Performance Advantage": [[19, null]], "Core ML Preallocates the Default Shape": [[19, null]], "Enumerated Shapes with Multi-input Models": [[19, null]], "Set the Range for Each Dimension": [[19, "set-the-range-for-each-dimension"]], "Enable Unbounded Ranges": [[19, "enable-unbounded-ranges"]], "Update a Core ML Model to Use Flexible Input Shapes": [[19, "update-a-core-ml-model-to-use-flexible-input-shapes"]], "Available Only for Neural Networks": [[19, null]], "Graph Passes": [[20, "graph-passes"]], "Contributing": [[21, "contributing"]], "Source code": [[21, null]], "Issues and queries": [[21, "issues-and-queries"]], "Install/upgrade instructions": [[21, null]], "Security issue": [[21, null]], "Documentation": [[21, "documentation"]], "Contributions": [[21, "contributions"]], "Labels": [[21, "labels"]], "Image Input and Output": [[22, "image-input-and-output"]], "ImageType Now Supported for Output": [[22, null]], "Use an MLMultiArray": [[22, "use-an-mlmultiarray"]], "Use an ImageType": [[22, "use-an-imagetype"]], "ImageType for Input": [[22, "imagetype-for-input"]], "ImageType for Output": [[22, "imagetype-for-output"]], "ImageType Input and Output Example": [[22, "imagetype-input-and-output-example"]], "Import Statements": [[22, "import-statements"]], "Image Filter Model": [[22, "image-filter-model"]], "Trace the PyTorch Model": [[22, "trace-the-pytorch-model"]], "Convert the Model to an ML Program": [[22, "convert-the-model-to-an-ml-program"], [68, "convert-the-model-to-an-ml-program"]], "Test With an Image": [[22, "test-with-an-image"]], "Save and Open in Xcode": [[22, "save-and-open-in-xcode"]], "Set the Scalar Type": [[22, "set-the-scalar-type"]], "Grayscale Images and Float 16 Multiarrays": [[22, null]], "Add Image Preprocessing Options": [[22, "add-image-preprocessing-options"]], "Preprocessing for TensorFlow": [[22, "preprocessing-for-tensorflow"]], "Preprocessing for Torch": [[22, "preprocessing-for-torch"]], "Installing Core ML Tools": [[23, "installing-core-ml-tools"]], "Supported Python and MacOS Versions": [[23, null]], "Prerequisites": [[23, "prerequisites"]], "For Beginners": [[23, null]], "Install or Build Core ML Tools": [[23, "install-or-build-core-ml-tools"]], "Set Up Conda": [[23, "set-up-conda"]], "Set Up a New Virtual Environment": [[23, "set-up-a-new-virtual-environment"]], "Install Core ML Tools": [[23, "install-core-ml-tools"]], "Install Third-party Packages": [[23, "install-third-party-packages"]], "Install From Source": [[23, "install-from-source"]], "Build From Source": [[23, "build-from-source"]], "Upgrade Core ML Tools": [[23, "upgrade-core-ml-tools"]], "Getting Started": [[24, "getting-started"]], "Convert the Model": [[24, "convert-the-model"], [60, "convert-the-model"]], "Set the Model Metadata": [[24, "set-the-model-metadata"]], "Make Predictions": [[24, "make-predictions"]], "Save and Load the Model": [[24, "save-and-load-the-model"]], "Run the Example": [[24, "run-the-example"]], "Use the Model with Xcode": [[24, "use-the-model-with-xcode"]], "Produce a Neural Network": [[24, "produce-a-neural-network"]], "ML Programs vs. Neural Networks": [[24, null]], "LibSVM": [[25, "libsvm"]], "Load and Convert Model Workflow": [[26, "load-and-convert-model-workflow"]], "Convert From TensorFlow 2": [[26, "convert-from-tensorflow-2"]], "Convert From TensorFlow 1": [[26, "convert-from-tensorflow-1"]], "Download for the Following Example": [[26, null], [26, null]], "Convert from PyTorch": [[26, "convert-from-pytorch"], [36, "convert-from-pytorch"]], "Set the Compute Units": [[26, "set-the-compute-units"]], "Core ML Specification": [[27, "core-ml-specification"]], "Load and Save the MLModel": [[27, "load-and-save-the-mlmodel"]], "Use the MLModel for Prediction": [[27, "use-the-mlmodel-for-prediction"]], "Work With the Spec": [[27, "work-with-the-spec"]], "Update the Metadata and Input/Output Descriptions": [[27, "update-the-metadata-and-input-output-descriptions"]], "Rename a Feature": [[28, "rename-a-feature"]], "Convert All Double Multi-array Feature Descriptions to Float": [[28, "convert-all-double-multi-array-feature-descriptions-to-float"]], "Evaluate Classifier, Regressor, and Transformer Models": [[28, "evaluate-classifier-regressor-and-transformer-models"]], "Get Weights Metadata": [[28, "get-weights-metadata"]], "Using the Metadata": [[28, "using-the-metadata"]], "Example": [[28, "example"]], "Model Input and Output Types": [[29, "model-input-and-output-types"]], "Use the Default Behavior": [[29, "use-the-default-behavior"]], "Use Images": [[29, "use-images"]], "Provide the Shape of the Input": [[29, "provide-the-shape-of-the-input"]], "Set the dtype": [[29, "set-the-dtype"]], "Set Names for PyTorch Conversion": [[29, "set-names-for-pytorch-conversion"]], "Model Intermediate Language": [[30, "model-intermediate-language"]], "Create a MIL Program": [[30, "create-a-mil-program"]], "Convert MIL to Core ML": [[30, "convert-mil-to-core-ml"]], "Learn More about MIL": [[30, null]], "macOS Required for Model Prediction": [[31, null]], "Types of Inputs and Outputs": [[31, "types-of-inputs-and-outputs"]], "Learn More About Image Input and Output": [[31, null]], "Specifying Compute Units": [[31, "specifying-compute-units"]], "Deprecated Flag": [[31, null]], "Multi-array Prediction": [[31, "multi-array-prediction"]], "Image Prediction": [[31, "image-prediction"]], "Image Prediction for a Multi-array Model": [[31, "image-prediction-for-a-multi-array-model"]], "Using Compiled Python Models for Prediction": [[31, "using-compiled-python-models-for-prediction"]], "Why Use a Compiled Model?": [[31, "why-use-a-compiled-model"]], "Predict From the Compiled Model": [[31, "predict-from-the-compiled-model"]], "Timing Example": [[31, "timing-example"]], "Model Scripting": [[32, "model-scripting"]], "Why Tracing May Not be Accurate": [[32, "why-tracing-may-not-be-accurate"]], "Use JIT Script": [[32, "use-jit-script"]], "Mix Tracing and Scripting": [[32, "mix-tracing-and-scripting"]], "Model Tracing": [[33, "model-tracing"]], "Tracing Limitations": [[33, null]], "Multifunction Models": [[34, "multifunction-models"]], "Why Combine Models?": [[34, "why-combine-models"]], "Combining models: toy example with LoRA adapters": [[34, "combining-models-toy-example-with-lora-adapters"]], "New Conversion Options": [[35, "new-conversion-options"]], "Convert to ML Program or Neural Network": [[35, "convert-to-ml-program-or-neural-network"]], "Set the Compute Precision for an ML Program": [[35, "set-the-compute-precision-for-an-ml-program"]], "Pick the Compute Units for Execution": [[35, "pick-the-compute-units-for-execution"]], "Input and Output Type Options": [[35, "input-and-output-type-options"]], "New Features": [[36, "new-features"]], "New in Core ML Tools 8": [[36, "new-in-core-ml-tools-8"]], "Previous Versions": [[36, "previous-versions"]], "Release Notes": [[36, "release-notes"]], "Migration Workflow (Core ML Tools 3 \u2192 4)": [[36, "migration-workflow-core-ml-tools-3-4"]], "Convert from TensorFlow": [[36, "convert-from-tensorflow"]], "For older deployment targets": [[36, null], [36, null]], "Deprecated Methods and Support": [[36, "deprecated-methods-and-support"]], "Conversion": [[37, "conversion"]], "Specify pass pipeline": [[37, "specify-pass-pipeline"]], "Convert models with sparse weights": [[37, "convert-models-with-sparse-weights"], [37, "id1"]], "Convert models with palettized weights": [[37, "convert-models-with-palettized-weights"], [37, "id2"]], "Use compression info embedded in torch models": [[37, "use-compression-info-embedded-in-torch-models"]], "Convert PyTorch models with quantized weights and activations": [[37, "convert-pytorch-models-with-quantized-weights-and-activations"]], "Convert models with jointly compressed weights": [[37, "convert-models-with-jointly-compressed-weights"]], "Compression info protocol": [[37, "compression-info-protocol"]], "Version 1": [[37, "version-1"]], "Optimizing OPT Model": [[38, "optimizing-opt-model"]], "Quantization": [[38, "quantization"]], "Data-free compression": [[38, "data-free-compression"], [38, "id1"]], "Results": [[38, "results"], [38, "id2"], [42, "results"], [45, "results"], [47, "results"], [50, "results"], [55, "results"]], "Algorithm Runtime": [[38, "algorithm-runtime"], [38, "id3"]], "Palettization": [[38, "palettization"], [41, "palettization"]], "Calibration data based compression": [[38, "calibration-data-based-compression"]], "Effect of per channel scales": [[38, "effect-of-per-channel-scales"]], "Impact on Latency": [[38, "impact-on-latency"]], "Conclusions": [[38, "conclusions"]], "How to Compress": [[39, "how-to-compress"]], "Types of Compression": [[39, "types-of-compression"]], "Effect on Runtime performance on Apple Silicon": [[39, "effect-on-runtime-performance-on-apple-silicon"]], "Availability of features": [[39, "availability-of-features"]], "Algorithms": [[42, "algorithms"], [47, "algorithms"]], "K-Means": [[42, "k-means"]], "Sensitive K-Means": [[42, "sensitive-k-means"]], "Differentiable K-Means": [[42, "differentiable-k-means"]], "Methodology": [[42, "methodology"], [45, "methodology"], [47, "methodology"], [50, "methodology"]], "API Overview": [[43, "api-overview"], [48, "api-overview"], [53, "api-overview"]], "Palettizing a Core ML model": [[43, "palettizing-a-core-ml-model"]], "Post-Training Palettization API example": [[43, "post-training-palettization-api-example"], [43, "id1"]], "Palettizing a Torch model": [[43, "palettizing-a-torch-model"]], "Sensitive K-Means Palettization API Example": [[43, "sensitive-k-means-palettization-api-example"]], "Differentiable K-Means Palettization API Example": [[43, "differentiable-k-means-palettization-api-example"]], "Converting the Palettized PyTorch Model": [[43, "converting-the-palettized-pytorch-model"]], "Palettization Overview": [[44, "palettization-overview"]], "Granularity": [[44, "granularity"]], "Per-channel scale": [[44, "per-channel-scale"]], "Vector Palettization": [[44, "vector-palettization"]], "Quantizing the LUT": [[44, "quantizing-the-lut"]], "Feature Availability": [[44, null], [49, null]], "Performance": [[45, "performance"], [50, "performance"], [55, "performance"]], "Performance Benchmarks": [[45, "performance-benchmarks"], [50, "performance-benchmarks"]], "Model Info": [[45, "model-info"], [55, "model-info"]], "Pruning": [[46, "pruning"]], "Post-Training Pruning": [[47, "post-training-pruning"]], "SparseGPT": [[47, "sparsegpt"]], "MagnitudePruner": [[47, "magnitudepruner"]], "Choosing an algorithm": [[47, "choosing-an-algorithm"]], "Accuracy Benchmarks": [[47, "accuracy-benchmarks"]], "Pruning APIs for Core ML model": [[48, "pruning-apis-for-core-ml-model"]], "Data free Pruning": [[48, "data-free-pruning"], [48, "id1"]], "Pruning APIs for Torch model": [[48, "pruning-apis-for-torch-model"]], "Calibration data based Pruning (SparseGPT)": [[48, "calibration-data-based-pruning-sparsegpt"]], "Training time Pruning": [[48, "training-time-pruning"]], "Converting Torch models to Core ML": [[48, "converting-torch-models-to-core-ml"]], "Linear Quantization": [[51, "linear-quantization"]], "Quantization Algorithms": [[52, "quantization-algorithms"]], "Post Training (data free) weight quantization": [[52, "post-training-data-free-weight-quantization"]], "Post Training (data calibration) activation quantization": [[52, "post-training-data-calibration-activation-quantization"]], "GPTQ algorithm for weight quantization (post training data calibration)": [[52, "gptq-algorithm-for-weight-quantization-post-training-data-calibration"]], "Fine tuning based algorithm for quantizing weight and/or activations": [[52, "fine-tuning-based-algorithm-for-quantizing-weight-and-or-activations"]], "PyTorch quantization APIs": [[52, null]], "Impact on accuracy with different modes": [[52, "impact-on-accuracy-with-different-modes"]], "Accuracy data": [[52, "accuracy-data"]], "Working with Core ML Models": [[53, "working-with-core-ml-models"]], "Quantizing weights": [[53, "quantizing-weights"], [53, "id1"]], "Quantizing weights and activations": [[53, "quantizing-weights-and-activations"], [53, "id2"]], "Working with PyTorch Models": [[53, "working-with-pytorch-models"]], "Data free quantization": [[53, "data-free-quantization"]], "Calibration data based quantization": [[53, "calibration-data-based-quantization"], [53, "id3"]], "Quantization Aware Training (QAT)": [[53, "quantization-aware-training-qat"]], "Converting quantized PyTorch models to Core ML": [[53, "converting-quantized-pytorch-models-to-core-ml"]], "How Quantization Works": [[54, "how-quantization-works"]], "Quantization precision": [[54, "quantization-precision"]], "Symmetric Quantization": [[54, "symmetric-quantization"]], "Quantization Granularity": [[54, "quantization-granularity"]], "Activation Quantization": [[54, "activation-quantization"]], "Performance Benchmarks:": [[55, "performance-benchmarks"]], "Methodology:": [[55, "methodology"]], "Optimizing ResNet50 Model": [[56, "optimizing-resnet50-model"]], "Scenario 1 : Minimizing model size": [[56, "scenario-1-minimizing-model-size"]], "Palettization using data free compression": [[56, "palettization-using-data-free-compression"]], "Palettization using fine tuning": [[56, "palettization-using-fine-tuning"]], "Summary": [[56, "summary"], [56, "id2"]], "Scenario 2: Minimizing latency": [[56, "scenario-2-minimizing-latency"]], "Latency reduction with pruning": [[56, "latency-reduction-with-pruning"]], "Latency reduction with activation quantization": [[56, "latency-reduction-with-activation-quantization"]], "Whats new": [[57, "whats-new"]], "Software Availability of Optimizations": [[57, "software-availability-of-optimizations"]], "Optimizations for iOS15 / macOS12 and lower": [[57, null]], "Core ML Tools Optimization APIs": [[57, "core-ml-tools-optimization-apis"]], "Core ML Tools 8": [[57, "core-ml-tools-8"]], "Core ML Tools 7": [[57, "core-ml-tools-7"]], "Optimization Workflow": [[58, "optimization-workflow"]], "Post training data free compression": [[58, "post-training-data-free-compression"]], "Post training calibration data based compression": [[58, "post-training-calibration-data-based-compression"]], "Model fine tuning based compression": [[58, "model-fine-tuning-based-compression"]], "APIs for each workflow": [[58, "apis-for-each-workflow"]], "Data free compression": [[58, "data-free-compression"]], "With calibration dataset": [[58, "with-calibration-dataset"]], "With fine tuning": [[58, "with-fine-tuning"]], "What Is Core ML Tools?": [[59, "what-is-core-ml-tools"]], "Additional Resources": [[59, "additional-resources"]], "Supported Libraries and Frameworks": [[59, "supported-libraries-and-frameworks"]], "Converting a PyTorch Segmentation Model": [[60, "converting-a-pytorch-segmentation-model"]], "Install the Required Software": [[60, "install-the-required-software"]], "Load the Model and Image": [[60, "load-the-model-and-image"]], "Normalize and Segment the Image": [[60, "normalize-and-segment-the-image"]], "Trace the Model with Sample Input": [[60, "trace-the-model-with-sample-input"]], "Set the Model\u2019s Metadata": [[60, "set-the-models-metadata"]], "Open the Model in Xcode": [[60, "open-the-model-in-xcode"], [74, "open-the-model-in-xcode"], [74, "id1"]], "Example Code": [[60, "example-code"]], "Compressing Neural Network Weights": [[61, "compressing-neural-network-weights"]], "For Neural Network Format Only": [[61, null]], "Quantize to Float 16 Weights": [[61, "quantize-to-float-16-weights"]], "Quantize to 1-8 Bits": [[61, "quantize-to-1-8-bits"]], "Quantization Options": [[61, "quantization-options"]], "Custom LUT Function": [[61, "custom-lut-function"]], "Control Which Layers are Quantized": [[61, "control-which-layers-are-quantized"]], "Scikit-learn": [[62, "scikit-learn"]], "Stateful Models": [[63, "stateful-models"]], "Example: A Simple Accumulator": [[63, "example-a-simple-accumulator"]], "Registering States for a PyTorch Model": [[63, "registering-states-for-a-pytorch-model"]], "Converting to a Stateful Core ML Model": [[63, "converting-to-a-stateful-core-ml-model"]], "Using States with Predictions": [[63, "using-states-with-predictions"]], "Creating a Stateful Model in MIL": [[63, "creating-a-stateful-model-in-mil"]], "Applications": [[63, "applications"]], "Source and Conversion Formats": [[64, "source-and-conversion-formats"]], "Supported Source Formats": [[64, "supported-source-formats"]], "TensorFlow versions 1.x Formats": [[64, "tensorflow-versions-1-x-formats"]], "TensorFlow versions 2.x Formats": [[64, "tensorflow-versions-2-x-formats"]], "PyTorch Formats": [[64, "pytorch-formats"]], "Target Conversion Formats": [[64, "target-conversion-formats"]], "Default Format": [[64, "default-format"]], "Format Differences": [[64, "format-differences"]], "Supported Core ML File Formats": [[64, "supported-core-ml-file-formats"]], "How to Produce": [[64, "how-to-produce"]], "Format Specification": [[64, "format-specification"]], "Supported Operations": [[64, "supported-operations"]], "Feature Development": [[64, "feature-development"]], "Performance Improvements": [[64, "performance-improvements"]], "TensorFlow 1 Workflow": [[65, "tensorflow-1-workflow"]], "Export as a Frozen Graph and Convert": [[65, "export-as-a-frozen-graph-and-convert"]], "Convert a Pre-trained Model": [[65, "convert-a-pre-trained-model"], [66, "convert-a-pre-trained-model"]], "Use Image Inputs": [[65, null]], "TensorFlow 2 Workflow": [[66, "tensorflow-2-workflow"]], "Recommended Format": [[66, null]], "Convert a User-defined Model": [[66, "convert-a-user-defined-model"]], "Convert a Sequential Model": [[66, "convert-a-sequential-model"]], "Convert a Keras Model With Subclassing": [[66, "convert-a-keras-model-with-subclassing"]], "Convert a TensorFlow Concrete Function": [[66, "convert-a-tensorflow-concrete-function"]], "Converting a BERT Transformer Model": [[66, null]], "Typed Execution": [[67, "typed-execution"]], "Choosing the Appropriate Precision": [[67, "choosing-the-appropriate-precision"]], "Neural Network Untyped Tensors": [[67, "neural-network-untyped-tensors"]], "ML Program Typed Tensors": [[67, "ml-program-typed-tensors"]], "Typed Execution Workflow Example": [[68, "typed-execution-workflow-example"]], "Download the Model and Install TensorFlow 1": [[68, "download-the-model-and-install-tensorflow-1"]], "Compute Precision Parameter": [[68, null]], "Make a Prediction": [[68, "make-a-prediction"]], "Make a Source Model Prediction for Comparison": [[68, "make-a-source-model-prediction-for-comparison"]], "Compare the Outputs": [[68, "compare-the-outputs"]], "Convert and Compare with Foat 32 Precision": [[68, "convert-and-compare-with-foat-32-precision"]], "Make a Visual Comparison": [[68, "make-a-visual-comparison"]], "Core ML Tools API Overview": [[69, "core-ml-tools-api-overview"]], "Nearest Neighbor Classifier": [[71, "nearest-neighbor-classifier"]], "Create the Classifier": [[71, "create-the-classifier"]], "Set the Number of Neighbors Value": [[71, "set-the-number-of-neighbors-value"]], "Set the Index Type": [[71, "set-the-index-type"]], "Neural Network Classifier": [[72, "neural-network-classifier"]], "Support": [[72, null]], "Create the Base Model": [[72, "create-the-base-model"]], "Convert the Model to the ML Model Format": [[72, "convert-the-model-to-the-ml-model-format"]], "Load the Spec and Apply its Settings": [[72, "load-the-spec-and-apply-its-settings"]], "Define make_updatable": [[72, "define-make-updatable"]], "Make the Model Updatable": [[72, "make-the-model-updatable"]], "Pipeline Classifier": [[73, "pipeline-classifier"]], "Get the Embedding Model": [[73, "get-the-embedding-model"]], "Create the Nearest Neighbor Classifier": [[73, "create-the-nearest-neighbor-classifier"]], "Create an Updatable Pipeline Model": [[73, "create-an-updatable-pipeline-model"]], "Segmentation Example": [[74, "segmentation-example"]], "Preview the Model in Xcode": [[74, "preview-the-model-in-xcode"], [74, "id2"]], "Body Pose Example": [[74, "body-pose-example"]], "XGBoost": [[75, "xgboost"]]}, "indexentries": {"pil": [[1, "index-1"]], "vision classifier observation api": [[1, "index-2"]], "classifier": [[1, "index-0"], [6, "index-0"], [71, "index-0"], [72, "index-0"], [73, "index-0"]], "preview and produce": [[1, "index-0"]], "core ml neuralnetwork": [[2, "index-2"]], "gpu runtime": [[2, "index-1"]], "mil": [[2, "index-3"], [30, "index-0"]], "ml program": [[2, "index-0"], [2, "index-1"], [14, "index-0"], [14, "index-1"], [14, "index-2"], [24, "index-0"], [24, "index-1"], [24, "index-2"], [24, "index-3"], [26, "index-3"], [35, "index-1"], [35, "index-2"], [64, "index-1"]], "metal performance shaders graph framework": [[2, "index-1"]], "model intermediate language": [[2, "index-3"], [30, "index-0"]], "compared to ml program": [[2, "index-0"]], "compared to neural network": [[2, "index-0"]], "compiling": [[2, "index-1"]], "compiling an ml program": [[2, "index-1"]], "neural network": [[2, "index-0"], [15, "index-0"], [35, "index-1"], [61, "index-0"], [64, "index-1"], [72, "index-0"]], "typed execution": [[2, "index-1"]], "mil operators": [[3, "index-1"]], "composite operators": [[3, "index-0"]], "tensorflow 1": [[5, "index-0"], [6, "index-0"], [65, "index-0"], [65, "index-1"]], "convert deepspeech model": [[5, "index-0"]], "convert tensorflow 1": [[6, "index-0"]], "convert image classifier": [[6, "index-0"], [24, "index-0"]], "image": [[6, "index-0"], [31, "index-0"]], "pytorch": [[7, "index-0"], [7, "index-1"], [7, "index-3"], [9, "index-0"], [11, "index-0"], [26, "index-2"], [29, "index-2"], [32, "index-0"], [33, "index-0"], [60, "index-0"], [60, "index-1"], [64, "index-0"]], "convert torchvision model": [[7, "index-0"]], "make prediction": [[7, "index-3"]], "preprocess image input": [[7, "index-1"]], "preprocessing for images": [[7, "index-1"], [22, "index-2"]], "protobuf spec": [[7, "index-2"]], "torchvision model": [[7, "index-0"]], "combine tracing and scripting": [[9, "index-0"]], "convert natural language processing model": [[9, "index-0"]], "torchscript": [[11, "index-0"], [32, "index-0"], [33, "index-0"]], "convert workflow": [[11, "index-0"], [65, "index-0"], [66, "index-0"]], "tensorflow 2": [[13, "index-0"], [66, "index-0"], [66, "index-1"], [66, "index-2"], [66, "index-3"], [66, "index-4"], [66, "index-5"]], "convert bert transformer models": [[13, "index-0"]], "convert to": [[14, "index-0"], [15, "index-0"], [26, "index-0"], [64, "index-1"]], "model package": [[14, "index-2"], [24, "index-2"]], "precision type": [[14, "index-1"]], "save a model package": [[14, "index-2"]], "save as model package": [[14, "index-2"]], "custom operators": [[17, "index-0"]], "rangedim": [[19, "index-2"]], "enumerated shapes": [[19, "index-1"]], "flexible input shapes": [[19, "index-0"]], "input shapes": [[19, "index-0"]], "shapes": [[19, "index-0"]], "graph passes": [[20, "index-0"]], "pass_pipeline": [[20, "index-0"]], "imagetype": [[22, "index-0"], [29, "index-0"]], "mlmultiarray": [[22, "index-0"], [29, "index-0"]], "images": [[22, "index-0"], [22, "index-1"], [22, "index-2"]], "input and output": [[22, "index-0"], [31, "index-0"]], "preprocessing": [[22, "index-2"]], "scalar type for imagetype": [[22, "index-1"]], "set the scalar type": [[22, "index-1"]], "tensorflow": [[24, "index-1"], [26, "index-1"], [64, "index-0"]], "tensorflow model": [[24, "index-1"]], "xcode": [[24, "index-3"], [60, "index-2"], [74, "index-0"]], "metadata": [[24, "index-1"], [60, "index-1"]], "open model": [[24, "index-3"]], "save and load": [[24, "index-2"]], "set model metadata": [[24, "index-1"], [60, "index-1"]], "use with xcode": [[24, "index-3"]], "libsvm": [[25, "index-0"]], "compute units": [[26, "index-3"]], "convert from": [[26, "index-1"], [26, "index-2"], [65, "index-0"], [66, "index-0"]], "workflow": [[26, "index-0"]], "mlmodel": [[27, "index-0"], [28, "index-0"]], "overview and spec": [[27, "index-0"]], "prediction": [[27, "index-0"], [31, "index-0"]], "with mlmodel": [[27, "index-0"]], "rename a feature": [[28, "index-0"]], "utilities": [[28, "index-0"]], "weight metadata": [[28, "index-1"]], "dtype": [[29, "index-1"]], "input type options": [[29, "index-0"], [35, "index-3"]], "output type options": [[29, "index-0"], [35, "index-3"]], "set names": [[29, "index-2"]], "specify compute units": [[31, "index-0"]], "jit script": [[32, "index-0"]], "model scripting": [[32, "index-0"]], "model tracing": [[33, "index-0"]], "multifunction model": [[34, "index-0"]], "compute precision": [[35, "index-2"]], "conversion options": [[35, "index-0"]], "convert_to parameter": [[35, "index-1"]], "minimum_deployment_target": [[35, "index-1"]], "overview": [[44, "index-0"], [49, "index-0"]], "palettization": [[44, "index-0"]], "pruning": [[49, "index-0"]], "pytorch model": [[60, "index-1"]], "convert segmentation model": [[60, "index-0"]], "preview": [[60, "index-2"]], "preview in xcode": [[60, "index-2"]], "compress weights": [[61, "index-0"]], "quantization": [[61, "index-0"]], "scikit-learn": [[62, "index-0"]], "stateful model": [[63, "index-0"]], "transformer": [[63, "index-0"]], "source formats": [[64, "index-0"]], "target format": [[64, "index-1"]], "convert pre-trained model": [[65, "index-1"], [66, "index-1"]], "convert a keras model": [[66, "index-4"]], "convert concrete function": [[66, "index-5"]], "convert sequential model": [[66, "index-3"]], "convert user-defined model": [[66, "index-2"]], "nearest neighbor classifier": [[71, "index-0"]], "nearest neighbor updatable": [[71, "index-0"]], "updatable nearest neighbor classifier": [[71, "index-0"]], "neural network updatable": [[72, "index-0"]], "updatable neural network classifier": [[72, "index-0"]], "pipeline classifier": [[73, "index-0"]], "pipeline updatable": [[73, "index-0"]], "updatable pipeline classifier": [[73, "index-0"]], "model preview types": [[74, "index-0"]], "model preview types in xcode": [[74, "index-0"]], "xgboost": [[75, "index-0"]]}})