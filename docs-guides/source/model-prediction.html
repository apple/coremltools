

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Model Prediction &#8212; Guide to Core ML Tools</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/imgstyle.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/model-prediction';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Updatable Models" href="updatable-model-examples.html" />
    <link rel="prev" title="MLModel Utilities" href="mlmodel-utilities.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Guide to Core ML Tools</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">coremltools API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="new-features.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-to-contribute.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-learning-models.html">Converting Deep Learning Models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="target-conversion-formats.html">Source and Conversion Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="load-and-convert-model.html">Load and Convert Model Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-ml-program.html">Convert Models to ML Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-neural-network.html">Convert Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="comparing-ml-programs-and-neural-networks.html">Comparing ML Programs and Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution.html">Typed Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution-example.html">Typed Execution Workflow Example</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-image-classifier.html">Converting a TensorFlow 1 Image Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-pytorch.html">Converting from PyTorch</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="convert-pytorch-workflow.html">PyTorch Conversion Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-tracing.html">Model Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-scripting.html">Model Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-nlp-model.html">Converting a Natural Language Processing Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-torchvision-model-from-pytorch.html">Converting a torchvision Model from PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch-conversion-examples.html">Converting a PyTorch Segmentation Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="conversion-options.html">Conversion Options</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="new-conversion-options.html">New Conversion Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-input-and-output-types.html">Model Input and Output Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-inputs.html">Image Input and Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-models.html">Stateful Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="flexible-inputs.html">Flexible Input Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="composite-operators.html">Composite Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-operators.html">Custom Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph-passes-intro.html">Graph Passes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="opt-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-whats-new.html">Whats new</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-overview-examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-resnet.html">Optimizing ResNet50 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-opt1_3.html">Optimizing OPT Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-workflow.html">Optimization Workflow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-palettization.html">Palettization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-overview.html">Palettization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-quantization.html">Linear Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-algos.html">Quantization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-pruning.html">Pruning</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-joint-compression.html">Combining compression types</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-conversion.html">Conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost-conversion.html">XGBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multifunction-models.html">Multifunction Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Model Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="updatable-model-examples.html">Updatable Models</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="updatable-neural-network-classifier-on-mnist-dataset.html">Neural Network Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-tiny-drawing-classifier-pipeline-model.html">Pipeline Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-nearest-neighbor-classifier.html">Nearest Neighbor Classifier</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apple/coremltools" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/source/model-prediction.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Model Prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-inputs-and-outputs">Types of Inputs and Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-compute-units">Specifying Compute Units</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-array-prediction">Multi-array Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-prediction">Image Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-prediction-for-a-multi-array-model">Image Prediction for a Multi-array Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-compiled-python-models-for-prediction">Using Compiled Python Models for Prediction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-a-compiled-model">Why Use a Compiled Model?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict-from-the-compiled-model">Predict From the Compiled Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#timing-example">Timing Example</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="model-prediction">
<span id="index-0"></span><h1>Model Prediction<a class="headerlink" href="#model-prediction" title="Permalink to this heading">#</a></h1>
<p>After converting a source model to a Core ML model, you can evaluate the Core ML model by verifying that the predictions made by the Core ML model match the predictions made by the source model.</p>
<p>The following example makes predictions for the <code class="docutils literal notranslate"><span class="pre">HousePricer.mlmodel</span></code> using the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel.predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="c1"># Load the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;HousePricer.mlmodel&#39;</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;bedroom&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;bath&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">1240</span><span class="p">})</span>
</pre></div>
</div>
<div class="admonition-macos-required-for-model-prediction admonition">
<p class="admonition-title">macOS Required for Model Prediction</p>
<p>For the prediction API, coremltools interacts with the Core ML framework which is available on macOS only. The prediction API is not available on Linux.</p>
<p>However, Core ML models can be <a class="reference external" href="https://tvm.apache.org/docs/tutorials/frontend/from_coreml.html">imported and executed with TVM</a>, which may provide a way to test Core ML models on non-macOS systems.</p>
</div>
<section id="types-of-inputs-and-outputs">
<h2>Types of Inputs and Outputs<a class="headerlink" href="#types-of-inputs-and-outputs" title="Permalink to this heading">#</a></h2>
<p>Core ML supports several <a class="reference external" href="https://apple.github.io/coremltools/mlmodel/Format/FeatureTypes.html">feature types</a> for inputs and outputs. The following are two feature types that are commonly used with neural network models:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ArrayFeatureType</span></code>, which maps to the MLMultiArray Feature Value in Swift</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ImageFeatureType</span></code>, which maps to the Image Feature Value in Swift</p></li>
</ul>
<p>When using the Core ML model in your Xcode app, use an <a class="reference external" href="https://developer.apple.com/documentation/coreml/mlfeaturevalue">MLFeatureValue</a>, which wraps an underlying value and bundles it with that value’s type, represented by <a class="reference external" href="https://developer.apple.com/documentation/coreml/mlfeaturetype">MLFeatureType</a>.</p>
<p>To evaluate a Core ML model in python using the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel.predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a> method, use one of the following inputs:</p>
<ul class="simple">
<li><p>For a multi-array, use a <a class="reference external" href="https://numpy.org">NumPy</a> array.</p></li>
<li><p>For an image, use a <a class="reference external" href="https://en.wikipedia.org/wiki/Python_Imaging_Library">PIL</a> image python object.</p></li>
</ul>
<div class="admonition-learn-more-about-image-input-and-output admonition">
<p class="admonition-title">Learn More About Image Input and Output</p>
<p>To learn how to work with images and achieve better performance and more convenience, see <a class="reference internal" href="image-inputs.html"><span class="doc std std-doc">Image Input and Output</span></a>.</p>
</div>
</section>
<section id="specifying-compute-units">
<h2>Specifying Compute Units<a class="headerlink" href="#specifying-compute-units" title="Permalink to this heading">#</a></h2>
<p>If you don’t specify compute units when converting or loading a model, all compute units available on the device are used for execution including the Neural Engine (NE), the CPU, and the graphics processing unit (GPU).</p>
<p>You can control which compute unit the model runs on by setting the <code class="docutils literal notranslate"><span class="pre">compute_units</span></code> argument when converting a model (with <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.convert.html#coremltools.converters._converters_entry.convert"><code class="docutils literal notranslate"><span class="pre">coremltools.convert()</span></code></a>) or loading a model (with <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#module-coremltools.models.model"><code class="docutils literal notranslate"><span class="pre">coremltools.models.MLModel</span></code></a>). Calling <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel.predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a> on the converted or loaded model restricts the model to use only the specific compute units for execution.</p>
<p>For example, the following sets the compute units to CPU only when loading the model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;path/to/the/saved/model.mlmodel&#39;</span><span class="p">,</span> <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_ONLY</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition-deprecated-flag admonition">
<p class="admonition-title">Deprecated Flag</p>
<p>In previous versions of coremltools, you would restrict execution to the CPU by specifying the <code class="docutils literal notranslate"><span class="pre">useCPUOnly=True</span></code> flag. This flag is now deprecated. Instead, use the <code class="docutils literal notranslate"><span class="pre">compute_units</span></code> parameter .</p>
</div>
<p>For more information and values for this parameter, see <a class="reference internal" href="load-and-convert-model.html#set-the-compute-units"><span class="std std-ref">Set the Compute Units</span></a>.</p>
</section>
<section id="multi-array-prediction">
<h2>Multi-array Prediction<a class="headerlink" href="#multi-array-prediction" title="Permalink to this heading">#</a></h2>
<p>A model that takes a <code class="docutils literal notranslate"><span class="pre">MultiArray</span></code> input requires a NumPy array as an input with the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> call. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;path/to/the/saved/model.mlmodel&#39;</span><span class="p">)</span>

<span class="c1"># Print input description to get input shape.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_spec</span><span class="p">()</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="c1"># insert correct shape of the input</span>

<span class="c1"># Call predict.</span>
<span class="n">output_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;input_name&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)})</span>
</pre></div>
</div>
</section>
<section id="image-prediction">
<h2>Image Prediction<a class="headerlink" href="#image-prediction" title="Permalink to this heading">#</a></h2>
<p>A model that takes an image input requires a PIL image as an input with the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> call. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">PIL.Image</span>

<span class="c1"># Load a model whose input type is &quot;Image&quot;.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;path/to/the/saved/model.mlmodel&#39;</span><span class="p">)</span>

<span class="n">Height</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># use the correct input image height</span>
<span class="n">Width</span> <span class="o">=</span> <span class="mi">60</span>  <span class="c1"># use the correct input image width</span>


<span class="c1"># Scenario 1: load an image from disk.</span>
<span class="k">def</span> <span class="nf">load_image</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">resize_to</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># resize_to: (Width, Height)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">resize_to</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">resize_to</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">img_np</span><span class="p">,</span> <span class="n">img</span>


<span class="c1"># Load the image and resize using PIL utilities.</span>
<span class="n">_</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s1">&#39;/path/to/image.jpg&#39;</span><span class="p">,</span> <span class="n">resize_to</span><span class="o">=</span><span class="p">(</span><span class="n">Width</span><span class="p">,</span> <span class="n">Height</span><span class="p">))</span>
<span class="n">out_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img</span><span class="p">})</span>

<span class="c1"># Scenario 2: load an image from a NumPy array.</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">Height</span><span class="p">,</span> <span class="n">Width</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># height x width x RGB</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="c1"># manipulate NumPy data</span>
<span class="n">pil_img</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">out_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">pil_img</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="image-prediction-for-a-multi-array-model">
<h2>Image Prediction for a Multi-array Model<a class="headerlink" href="#image-prediction-for-a-multi-array-model" title="Permalink to this heading">#</a></h2>
<p>If the Core ML model has a <code class="docutils literal notranslate"><span class="pre">MultiArray</span></code> input type that actually represents a JPEG image, you can still use the JPEG image for the prediction if you first convert the loaded image to a NumPy array, as shown in this example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Height</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># use the correct input image height</span>
<span class="n">Width</span> <span class="o">=</span> <span class="mi">60</span>  <span class="c1"># use the correct input image width</span>

<span class="c1"># Assumption: the mlmodel&#39;s input is of type MultiArray and of shape (1, 3, Height, Width).</span>
<span class="n">model_expected_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">Height</span><span class="p">,</span> <span class="n">Width</span><span class="p">)</span> <span class="c1"># depending on the model description, this could be (3, Height, Width)</span>

<span class="c1"># Load the model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;path/to/the/saved/model.mlmodel&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_image_as_numpy_array</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">resize_to</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># resize_to: (Width, Height)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">resize_to</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">resize_to</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># shape of this numpy array is (Height, Width, 3)</span>
    <span class="k">return</span> <span class="n">img_np</span>

<span class="c1"># Load the image and resize using PIL utilities.</span>
<span class="n">img_as_np_array</span> <span class="o">=</span> <span class="n">load_image_as_numpy_array</span><span class="p">(</span><span class="s1">&#39;/path/to/image.jpg&#39;</span><span class="p">,</span> <span class="n">resize_to</span><span class="o">=</span><span class="p">(</span><span class="n">Width</span><span class="p">,</span> <span class="n">Height</span><span class="p">))</span> <span class="c1"># shape (Height, Width, 3)</span>

<span class="c1"># PIL returns an image in the format in which the channel dimension is in the end,</span>
<span class="c1"># which is different than Core ML&#39;s input format, so that needs to be modified.</span>
<span class="n">img_as_np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img_as_np_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># shape (3, Height, Width)</span>

<span class="c1"># Add the batch dimension if the model description has it.</span>
<span class="n">img_as_np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img_as_np_array</span><span class="p">,</span> <span class="n">model_expected_input_shape</span><span class="p">)</span>

<span class="c1"># Now call predict.</span>
<span class="n">out_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img_as_np_array</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="using-compiled-python-models-for-prediction">
<h2>Using Compiled Python Models for Prediction<a class="headerlink" href="#using-compiled-python-models-for-prediction" title="Permalink to this heading">#</a></h2>
<p>You can use a <em>compiled</em> Core ML model (<a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.CompiledMLModel">CompiledMLModel</a>) rather than  <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel">MLModel</a> for making predictions. For large models, using a compiled model can save considerable time in initializing the model.</p>
<p>For example, <a class="reference external" href="https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon">Stable Diffusion</a>, adopted by a vibrant community of artists and developers, enables the creation of unprecedented visuals from a text prompt. When using <a class="reference external" href="https://github.com/apple/ml-stable-diffusion#core-ml-stable-diffusion">Core ML Stable Diffusion</a>, you can speed up the load time after the initial load by first copying and storing the location of the <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> compiled model to a fixed location, and then initializing the model from that location.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can’t modify a compiled model like you can an <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel">MLModel</a> loaded from a non-compiled <code class="docutils literal notranslate"><span class="pre">mlpackage</span></code> model file.</p>
</div>
<section id="why-use-a-compiled-model">
<h3>Why Use a Compiled Model?<a class="headerlink" href="#why-use-a-compiled-model" title="Permalink to this heading">#</a></h3>
<p>When you initialize a model using (in Python) <code class="docutils literal notranslate"><span class="pre">model=ct.models.MLModel(&quot;model.mlpackge&quot;)</span></code>, the Core ML Framework is invoked and the following steps occur, as shown in the following diagram.</p>
<figure class="align-center" id="id1">
<img alt="Initialize MLModel" class="imgnoborder" src="../_images/model-lifecycle.png" />
<figcaption>
<p><span class="caption-text">This diagram is from <a class="reference external" href="https://developer.apple.com/videos/play/wwdc2023/10049/">Improve Core ML integration with async prediction</a>,
presented at the Apple 2023 World Wide Developer Conference.</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">mlpackage</span></code> is <a class="reference external" href="https://developer.apple.com/documentation/coreml/mlmodel/3929553-compilemodelaturl">compiled</a> into a file with extension <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> . This step is usually very fast.</p></li>
<li><p>The compiled model is then <a class="reference external" href="https://developer.apple.com/documentation/coreml/mlmodel/3022229-modelwithcontentsofurl">instantiated</a> using the specified <code class="docutils literal notranslate"><span class="pre">compute_units</span></code> captured in the MLModelConfiguration config.</p></li>
<li><p>During instantiation, another compilation occurs for backend device specialization, such as for the Neural Engine (NE), which may take a few seconds or even minutes for large models.</p></li>
</ol>
<p>This device specialization step creates the final compiled asset ready to be run. This final compiled model is cached so that the expensive device optimization process does not need to run again. The cache entry is linked to the full file system path of the <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> folder.</p>
<p>As you create an MLModel object in Python using an <code class="docutils literal notranslate"><span class="pre">mlpackage</span></code>, it uses a temporary directory in a new location to place the <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> folder. The <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> file is then deleted after you have made predictions and the Python process has ended.</p>
<p>The next time you start a new Python process and create an MLModel, the compilation to <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> and the subsequent device specialization occurs again. The cached set can’t be used again, because the location of <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> has changed.</p>
<p>By storing the <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> file to a fixed location first, and then initializing the MLModel from that location, you can make sure that the cache model generated remains active for subsequent loads, thereby making them faster. Let’s see how you would do that in code.</p>
</section>
<section id="predict-from-the-compiled-model">
<h3>Predict From the Compiled Model<a class="headerlink" href="#predict-from-the-compiled-model" title="Permalink to this heading">#</a></h3>
<p>To use a compiled model file, follow these steps:</p>
<ol class="arabic">
<li><p>Load a saved MLModel, or convert a model from a training framework (such as TensorFlow or PyTorch).</p>
<p>For instructions on converting a model, see <a class="reference internal" href="load-and-convert-model.html"><span class="doc std std-doc">Load and Convert Model Workflow</span></a>. This example uses the <a class="reference external" href="https://pytorch.org/vision/main/models/generated/torchvision.models.regnet_y_128gf.html">regnet_y_128fg</a> torchvision model and assumes that you have already converted it to a Core ML <code class="docutils literal notranslate"><span class="pre">mlpackage</span></code>.</p>
</li>
<li><p>Get the compiled model directory by calling its <code class="docutils literal notranslate"><span class="pre">get_compiled_model_path</span></code> method.</p>
<p>For example, the following code snippet loads a saved MLModel (<code class="docutils literal notranslate"><span class="pre">&quot;regnet_y_128gf.mlpackage&quot;</span></code>) and gets the compiled path:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlpackage&quot;</span><span class="p">)</span>
<span class="n">compiled_model_path</span> <span class="o">=</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_compiled_model_path</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p>The returned directory in <code class="docutils literal notranslate"><span class="pre">compiled_model_path</span></code> is only temporary. Copy that directory to a new persistent location (as in the following example, <code class="docutils literal notranslate"><span class="pre">regnet_y_128gf</span></code> with the extension <code class="docutils literal notranslate"><span class="pre">.mlmodelc</span></code> in the same directory) using the <a class="reference external" href="https://docs.python.org/3/library/shutil.html"><code class="docutils literal notranslate"><span class="pre">shutil.copytree()</span></code></a> method. You can then use CompiledMLModel to load the compiled model from <code class="docutils literal notranslate"><span class="pre">&quot;regnet_y_128gf.mlmodelc&quot;</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copytree</span>
<span class="n">copytree</span><span class="p">(</span><span class="n">compiled_model_path</span><span class="p">,</span> <span class="s2">&quot;regnet_y_128gf.mlmodelc&quot;</span><span class="p">,</span> <span class="n">dirs_exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CompiledMLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlmodelc&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This step includes compiling for device specialization. Therefore, the first load can still take a long time. However, since the location of the <code class="docutils literal notranslate"><span class="pre">mlmodelc</span></code> folder is fixed, the cache is able to work, so subsequent calls to model using CompiledMLModel are quick.</p>
</li>
<li><p>For each prediction, use the <code class="docutils literal notranslate"><span class="pre">mlmodel</span></code> object to take advantage of this caching:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
</pre></div>
</div>
</li>
</ol>
<p>With most large models, it should be very quick to use the compiled model again after the first call.</p>
</section>
<section id="timing-example">
<h3>Timing Example<a class="headerlink" href="#timing-example" title="Permalink to this heading">#</a></h3>
<p>This example demonstrates timing differences with calling a large model. The results are based on running the example on a MacBook Pro M1 Max with macOS Sonoma. Your timing results will vary depending on your system configuration and other factors.</p>
<p>The following code snippet converts a relatively large model from torchvision:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copytree</span>

<span class="n">torch_model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">regnet_y_128gf</span><span class="p">()</span>
<span class="n">torch_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>

<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">traced_model</span><span class="p">,</span>
                     <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">ct</span><span class="o">.</span><span class="n">TensorType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">example_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span>
                     <span class="p">)</span>

<span class="n">mlmodel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlpackage&quot;</span><span class="p">)</span>

<span class="c1"># save the mlmodelc</span>
<span class="n">compiled_model_path</span> <span class="o">=</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_compiled_model_path</span><span class="p">()</span>
<span class="n">copytree</span><span class="p">(</span><span class="n">compiled_model_path</span><span class="p">,</span> <span class="s2">&quot;regnet_y_128gf.mlmodelc&quot;</span><span class="p">,</span> <span class="n">dirs_exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

</pre></div>
</div>
<p>The following code snippet measures load time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>

<span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlpackage&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time taken to load using ct.models.MLModel: </span><span class="si">{:.1f}</span><span class="s2"> secs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">tick</span><span class="p">))</span>

<span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlpackage&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time taken to load using ct.models.MLModel: </span><span class="si">{:.1f}</span><span class="s2"> secs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">tick</span><span class="p">))</span>

<span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CompiledMLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlmodelc&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time taken to load using ct.models.CompiledMLModel: </span><span class="si">{:.1f}</span><span class="s2"> secs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">tick</span><span class="p">))</span>

<span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CompiledMLModel</span><span class="p">(</span><span class="s2">&quot;regnet_y_128gf.mlmodelc&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time taken to load using ct.models.CompiledMLModel: </span><span class="si">{:.1f}</span><span class="s2"> secs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">tick</span><span class="p">))</span>
</pre></div>
</div>
<p>Running the code produces the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time</span> <span class="n">taken</span> <span class="n">to</span> <span class="n">load</span> <span class="n">using</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">:</span> <span class="mf">15.3</span> <span class="n">secs</span>
<span class="n">time</span> <span class="n">taken</span> <span class="n">to</span> <span class="n">load</span> <span class="n">using</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">:</span> <span class="mf">17.7</span> <span class="n">secs</span>
<span class="n">time</span> <span class="n">taken</span> <span class="n">to</span> <span class="n">load</span> <span class="n">using</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CompiledMLModel</span><span class="p">:</span> <span class="mf">14.7</span> <span class="n">secs</span>
<span class="n">time</span> <span class="n">taken</span> <span class="n">to</span> <span class="n">load</span> <span class="n">using</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CompiledMLModel</span><span class="p">:</span> <span class="mf">0.1</span> <span class="n">secs</span>
</pre></div>
</div>
<p>These results show that it takes relatively the same time to load an MLModel after the first load, while loading a CompiledMLModel takes much less time after the first load.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="mlmodel-utilities.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">MLModel Utilities</p>
      </div>
    </a>
    <a class="right-next"
       href="updatable-model-examples.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Updatable Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-inputs-and-outputs">Types of Inputs and Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-compute-units">Specifying Compute Units</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-array-prediction">Multi-array Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-prediction">Image Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-prediction-for-a-multi-array-model">Image Prediction for a Multi-array Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-compiled-python-models-for-prediction">Using Compiled Python Models for Prediction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-a-compiled-model">Why Use a Compiled Model?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict-from-the-compiled-model">Predict From the Compiled Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#timing-example">Timing Example</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apple
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Apple Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>