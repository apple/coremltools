

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Core ML Tools FAQs &#8212; Guide to Core ML Tools</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/imgstyle.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/faqs';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Examples" href="coremltools-examples.html" />
    <link rel="prev" title="New Features" href="new-features.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Guide to Core ML Tools</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">coremltools API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="new-features.html">New Features</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-to-contribute.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-learning-models.html">Converting Deep Learning Models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="target-conversion-formats.html">Source and Conversion Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="load-and-convert-model.html">Load and Convert Model Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-ml-program.html">Convert Models to ML Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-neural-network.html">Convert Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="comparing-ml-programs-and-neural-networks.html">Comparing ML Programs and Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution.html">Typed Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution-example.html">Typed Execution Workflow Example</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-image-classifier.html">Converting a TensorFlow 1 Image Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-pytorch.html">Converting from PyTorch</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="convert-pytorch-workflow.html">PyTorch Conversion Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-tracing.html">Model Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-scripting.html">Model Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-nlp-model.html">Converting a Natural Language Processing Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-torchvision-model-from-pytorch.html">Converting a torchvision Model from PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch-conversion-examples.html">Converting a PyTorch Segmentation Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="conversion-options.html">Conversion Options</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="new-conversion-options.html">New Conversion Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-input-and-output-types.html">Model Input and Output Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-inputs.html">Image Input and Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-models.html">Stateful Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="flexible-inputs.html">Flexible Input Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="composite-operators.html">Composite Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-operators.html">Custom Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph-passes-intro.html">Graph Passes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="opt-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-whats-new.html">Whats new</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-overview-examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-resnet.html">Optimizing ResNet50 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-opt1_3.html">Optimizing OPT Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-workflow.html">Optimization Workflow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-palettization.html">Palettization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-overview.html">Palettization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-quantization.html">Linear Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-algos.html">Quantization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-pruning.html">Pruning</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-algos.html">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-api.html">API Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opt-conversion.html">Conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost-conversion.html">XGBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multifunction-models.html">Multifunction Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-prediction.html">Model Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="updatable-model-examples.html">Updatable Models</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="updatable-neural-network-classifier-on-mnist-dataset.html">Neural Network Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-tiny-drawing-classifier-pipeline-model.html">Pipeline Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-nearest-neighbor-classifier.html">Nearest Neighbor Classifier</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apple/coremltools" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/source/faqs.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Core ML Tools FAQs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-ml-tools-versions">Core ML Tools Versions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-7">coremltools 7</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#previous-releases">Previous releases</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-6">coremltools 6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-5">coremltools 5</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-4">coremltools 4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-conversion">PyTorch Conversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#keras-conversion">Keras Conversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixing-high-numerical-error">Fixing High Numerical Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-preprocessing-for-converting-torchvision">Image Preprocessing for Converting torchvision</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-in-declaring-network-or-computing-nn-outputs">Error in Declaring Network or Computing NN Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-a-deep-learning-core-ml-model">Starting a Deep Learning Core ML Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-an-unsupported-op">Handling an Unsupported Op</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-custom-names-for-input-and-outputs">Choosing Custom Names for Input and Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-engine-with-flexible-input-shapes">Neural Engine With Flexible Input Shapes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-optimize-torch-is-better-than-pytorchs-default-quantization">Why <code class="docutils literal notranslate"><span class="pre">optimize.torch</span></code> is better than PyTorch’s default quantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#use-a-compiled-model-for-faster-initialization">Use a compiled model for faster initialization</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="core-ml-tools-faqs">
<h1>Core ML Tools FAQs<a class="headerlink" href="#core-ml-tools-faqs" title="Permalink to this heading">#</a></h1>
<p>This page offers frequently asked questions (FAQs):</p>
<ul class="simple">
<li><p><a class="reference internal" href="#core-ml-tools-versions">What are some major changes between versions of Core ML Tools?</a></p></li>
<li><p><a class="reference internal" href="#pytorch-conversion">How do I convert models from PyTorch?</a></p></li>
<li><p><a class="reference internal" href="#keras-conversion">How do I convert models from Keras?</a></p></li>
<li><p><a class="reference internal" href="#fixing-high-numerical-error">How do I fix a Core ML model prediction that has a high numerical error compared to the source model?</a></p></li>
<li><p><a class="reference internal" href="#image-preprocessing-for-converting-torchvision">How do I handle image preprocessing parameters when converting torchvision models?</a></p></li>
<li><p><a class="reference internal" href="#error-in-declaring-network-or-computing-nn-outputs">How do I handle an “Error in declaring network” or an “Error computing NN outputs”?</a></p></li>
<li><p><a class="reference internal" href="#starting-a-deep-learning-core-ml-model">Are TensorFlow or PyTorch the only starting points to make a deep learning Core ML model?</a></p></li>
<li><p><a class="reference internal" href="#handling-an-unsupported-op">How do I handle the unsupported op error “convert function for op not implemented”?</a></p></li>
<li><p><a class="reference internal" href="#choosing-custom-names-for-input-and-outputs">Can I choose custom names for the input and outputs of the model during conversion?</a></p></li>
<li><p><a class="reference internal" href="#neural-engine-with-flexible-input-shapes">If I change my fixed-shape model to use flexible inputs, will it still run on the  Neural Engine?</a></p></li>
<li><p><a class="reference internal" href="#why-optimize-torch-is-better-than-pytorchs-default-quantization">Why use <code class="docutils literal notranslate"><span class="pre">ct.optimize.torch</span></code> rather than PyTorch’s default quantization?</a></p></li>
<li><p><a class="reference internal" href="#use-a-compiled-model-for-faster-initialization">My model’s initialization in Python takes a long time. How can I speed it up?</a></p></li>
</ul>
<hr class="docutils" />
<section id="core-ml-tools-versions">
<h2>Core ML Tools Versions<a class="headerlink" href="#core-ml-tools-versions" title="Permalink to this heading">#</a></h2>
<section id="coremltools-7">
<h3>coremltools 7<a class="headerlink" href="#coremltools-7" title="Permalink to this heading">#</a></h3>
<p>For an overview, see <a class="reference internal" href="new-features.html"><span class="doc std std-doc">New Features</span></a>. This release includes more APIs for optimizing the models to use less storage space, reduce power consumption, and reduce latency during inference. Key optimization techniques include pruning, quantization, and palettization. For details, see <a class="reference internal" href="opt-overview.html"><span class="doc std std-doc">Optimizing Models</span></a>.</p>
<p>For details about the release, see <a class="reference external" href="https://github.com/apple/coremltools/releases/">Release Notes</a>.</p>
</section>
<section id="previous-releases">
<h3>Previous releases<a class="headerlink" href="#previous-releases" title="Permalink to this heading">#</a></h3>
<p>The following are highlights of previous releases:</p>
<section id="coremltools-6">
<h4>coremltools 6<a class="headerlink" href="#coremltools-6" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Added model compression utilities to compress the weights of a Core ML model, thereby reducing the space occupied by the model.</p></li>
<li><p>Enabled Float 16 input/output types including grayscale images and float 16 Multiarrays.</p></li>
</ul>
<p>For details, see <a class="reference external" href="https://github.com/apple/coremltools/releases/tag/6.3">Release Notes for coremltools 6.3</a>.</p>
</section>
<section id="coremltools-5">
<h4>coremltools 5<a class="headerlink" href="#coremltools-5" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Core ML models now also use a directory format, called <a class="reference external" href="https://developer.apple.com/documentation/coreml/core_ml_api/updating_a_model_file_to_a_model_package"><code class="docutils literal notranslate"><span class="pre">.mlpackage</span></code></a>, rather than just a protobuf file.</p></li>
<li><p>Added a new backend: <a class="reference internal" href="convert-to-ml-program.html"><span class="doc std std-doc">ML program</span></a>, which offers <a class="reference internal" href="typed-execution.html"><span class="doc std std-doc">typed execution</span></a> and a new GPU runtime backed by MPSGraph.</p></li>
</ul>
<p>For details, see the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases/tag/5.2">Release Notes for coremltools 5.2</a></p></li>
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases/tag/5.0">Release Notes for coremltools 5.0</a></p></li>
</ul>
</section>
</section>
<section id="coremltools-4">
<h3>coremltools 4<a class="headerlink" href="#coremltools-4" title="Permalink to this heading">#</a></h3>
<p>Major upgrade. Highlights:</p>
<ul class="simple">
<li><p>Introduced the <a class="reference internal" href="unified-conversion-api.html"><span class="doc std std-doc">Unified Conversion API</span></a> with the <code class="docutils literal notranslate"><span class="pre">convert()</span></code> method for converting models from TensorFlow 1, TensorFlow 2 (tf.keras), and PyTorch.</p></li>
<li><p>Introduced the <a class="reference internal" href="model-intermediate-language.html"><span class="doc std std-doc">Model Intermediate Language</span></a> (MIL) as an internal intermediate representation (IR) for unifying the conversion pipeline, and added graph passes to this common IR. Passes that improve performance continue to be added, so we recommend that you always use the latest version of coremltools to convert your models.</p></li>
</ul>
<p>For details, see the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases/tag/4.1">Release Notes for coremltools 4.1</a></p></li>
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases/tag/4.0">Release Notes for coremltools 4.0</a></p></li>
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases/tag/3.4">Release Notes for coremltools 3.4</a></p></li>
<li><p><a class="reference external" href="https://github.com/apple/coremltools/releases">All release notes</a></p></li>
</ul>
</section>
</section>
<section id="pytorch-conversion">
<h2>PyTorch Conversion<a class="headerlink" href="#pytorch-conversion" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Prior to Core ML Tools 4: Use <a class="reference external" href="https://github.com/onnx/onnx-coreml"><code class="docutils literal notranslate"><span class="pre">onnx-coreml</span></code></a>, which internally calls into <code class="docutils literal notranslate"><span class="pre">coremltools</span></code>.</p></li>
<li><p>Core ML Tools 4 and newer: Use the <a class="reference internal" href="unified-conversion-api.html"><span class="doc std std-doc">Unified Conversion API</span></a>. (The <code class="docutils literal notranslate"><span class="pre">onnx-coreml</span></code> converter is frozen and no longer updated or maintained.)</p></li>
</ul>
</section>
<section id="keras-conversion">
<h2>Keras Conversion<a class="headerlink" href="#keras-conversion" title="Permalink to this heading">#</a></h2>
<p>As of the Core ML Tools 4 release, the <code class="docutils literal notranslate"><span class="pre">coremltools.keras.convert</span></code> converter is no longer maintained, and is officially deprecated in Core ML Tools 5 . The <a class="reference internal" href="unified-conversion-api.html"><span class="doc std std-doc">Unified Conversion API</span></a> supports conversion of <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> models, using a TensorFlow 2 (TF2) backend.</p>
<p>If you have an older <a class="reference external" href="http://keras.io/">Keras.io</a> model that uses TensorFlow 1 (TF1), we recommend exporting it as a TF1 frozen graph def (<code class="docutils literal notranslate"><span class="pre">.pb</span></code>) file. You can then convert this file using the <a class="reference internal" href="unified-conversion-api.html"><span class="doc std std-doc">Unified Conversion API</span></a>. For an example of how to export the old keras model to <code class="docutils literal notranslate"><span class="pre">.pb</span></code>, see method <code class="docutils literal notranslate"><span class="pre">_save_h5_as_frozen_pb</span></code> in the <a class="reference external" href="https://github.com/apple/coremltools/blob/3.4/examples/NeuralNetworkGuide.md#troubleshooting">Troubleshooting section of the coremltools 3 Neural Network Guide</a>.</p>
</section>
<section id="fixing-high-numerical-error">
<h2>Fixing High Numerical Error<a class="headerlink" href="#fixing-high-numerical-error" title="Permalink to this heading">#</a></h2>
<p>For a neural network, set the compute unit to CPU as described in <a class="reference internal" href="load-and-convert-model.html#set-the-compute-units"><span class="std std-ref">Set the Compute Units</span></a>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural networks</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">source_model</span><span class="p">,</span>
                   <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_ONLY</span><span class="p">)</span>
<span class="c1"># or when loading the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s2">&quot;model.mlmodel&quot;</span><span class="p">,</span> <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_ONLY</span><span class="p">)</span>

<span class="c1"># now when prediction is called on this model, it will use the </span>
<span class="c1"># higher precision Float32 CPU path for execution. </span>

<span class="c1"># to check the compute unit of an already loaded model,</span>
<span class="c1"># simply check the property </span>
<span class="n">model</span><span class="o">.</span><span class="n">compute_unit</span>
</pre></div>
</div>
<p>For an ML program, set <code class="docutils literal notranslate"><span class="pre">compute_precision</span></code> to Float 32 as described in <a class="reference internal" href="convert-to-ml-program.html#set-the-ml-program-precision"><span class="std std-ref">Set the ML Program Precision</span></a>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ml programs</span>

<span class="c1"># provide a higher compute precision during conversion</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">source_model</span><span class="p">,</span> <span class="n">compute_precision</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">FLOAT32</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, see <a class="reference internal" href="typed-execution.html"><span class="doc std std-doc">Typed Execution</span></a>.</p>
</section>
<section id="image-preprocessing-for-converting-torchvision">
<h2>Image Preprocessing for Converting torchvision<a class="headerlink" href="#image-preprocessing-for-converting-torchvision" title="Permalink to this heading">#</a></h2>
<p>Preprocessing parameters differ between <a class="reference external" href="https://pytorch.org/vision/stable/index.html">torchvision</a> and Core ML Tools but can be easily translated, as described in <a class="reference internal" href="image-inputs.html#add-image-preprocessing-options"><span class="std std-ref">Add Image Preprocessing Options</span></a>. For example, you can set the scale and bias for an <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.input_types.html#coremltools.converters.mil.input_types.ImageType"><code class="docutils literal notranslate"><span class="pre">ImageType</span></code></a>, which corresponds to the torchvision parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mf">0.226</span><span class="o">*</span><span class="mf">255.0</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span> <span class="mf">0.485</span><span class="o">/</span><span class="p">(</span><span class="mf">0.229</span><span class="p">)</span> <span class="p">,</span> <span class="o">-</span> <span class="mf">0.456</span><span class="o">/</span><span class="p">(</span><span class="mf">0.224</span><span class="p">),</span> <span class="o">-</span> <span class="mf">0.406</span><span class="o">/</span><span class="p">(</span><span class="mf">0.225</span><span class="p">)]</span>
<span class="n">image_input</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">ImageType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">example_input</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
                           <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> 
                           <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="error-in-declaring-network-or-computing-nn-outputs">
<h2>Error in Declaring Network or Computing NN Outputs<a class="headerlink" href="#error-in-declaring-network-or-computing-nn-outputs" title="Permalink to this heading">#</a></h2>
<p>File an issue at the <a class="reference external" href="https://github.com/apple/coremltools"><code class="docutils literal notranslate"><span class="pre">coremltools</span></code> Github repository</a> by following the instructions in <a class="reference internal" href="how-to-contribute.html#issues-and-queries"><span class="std std-ref">Issues and Queries</span></a>. As a workaround, try using <code class="docutils literal notranslate"><span class="pre">CPUOnly</span></code> compute units during conversion, as described in <a class="reference internal" href="load-and-convert-model.html#set-the-compute-units"><span class="std std-ref">Set the Compute Units</span></a>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">tf_model</span><span class="p">,</span> <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_ONLY</span><span class="p">)</span>

<span class="c1"># or if loading a pre converted model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s2">&quot;model.mlmodel&quot;</span><span class="p">,</span> <span class="n">compute_units</span><span class="o">=</span><span class="n">ct</span><span class="o">.</span><span class="n">ComputeUnit</span><span class="o">.</span><span class="n">CPU_ONLY</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="starting-a-deep-learning-core-ml-model">
<h2>Starting a Deep Learning Core ML Model<a class="headerlink" href="#starting-a-deep-learning-core-ml-model" title="Permalink to this heading">#</a></h2>
<p>You can define a Core ML model directly by building it with the MIL builder API. This API is similar to the <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> or the <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> API for model construction. For an example, see <a class="reference internal" href="model-intermediate-language.html#create-a-mil-program"><span class="std std-ref">Create a MIL Program</span></a>.</p>
</section>
<section id="handling-an-unsupported-op">
<h2>Handling an Unsupported Op<a class="headerlink" href="#handling-an-unsupported-op" title="Permalink to this heading">#</a></h2>
<p>Be sure that you are using the newest version of Core ML Tools. If you still get this error, please file an issue in the <a class="reference external" href="https://github.com/apple/coremltools"><code class="docutils literal notranslate"><span class="pre">coremltools</span></code> Github repo</a> by following the instructions in <a class="reference internal" href="how-to-contribute.html#issues-and-queries"><span class="std std-ref">Issues and Queries</span></a>.</p>
<p>As a workaround, you may want to write a translation function from the missing op to the existing MIL ops. For examples, see <a class="reference internal" href="composite-operators.html"><span class="doc std std-doc">Composite Operators</span></a>.</p>
</section>
<section id="choosing-custom-names-for-input-and-outputs">
<h2>Choosing Custom Names for Input and Outputs<a class="headerlink" href="#choosing-custom-names-for-input-and-outputs" title="Permalink to this heading">#</a></h2>
<p>When using <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.html#coremltools.converters._converters_entry.convert"><code class="docutils literal notranslate"><span class="pre">ct.convert()</span></code></a>, the input names and output names are automatically picked up by the converter from the source model. After conversion you can see these names by doing one of the following:</p>
<ul class="simple">
<li><p>Saving the model and using it with Xcode, as described in <a class="reference internal" href="introductory-quickstart.html#save-and-load-the-model"><span class="std std-ref">Save and Load the Model</span></a> and <a class="reference internal" href="introductory-quickstart.html#use-the-model-with-xcode"><span class="std std-ref">Use the Model with Xcode</span></a>.</p></li>
<li><p>Getting the model spec object and printing the names, as shown in the following example:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MLModel</span><span class="p">(</span><span class="s1">&#39;MyModel.mlmodel&#39;</span><span class="p">)</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_spec</span><span class="p">()</span>

<span class="c1"># get input names</span>
<span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">inp</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">]</span>

<span class="c1"># get output names</span>
<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">out</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
</pre></div>
</div>
<p>You can update these names by using the <a class="reference internal" href="mlmodel-utilities.html#rename-a-feature"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">rename_feature</span></code></span></a> API.</p>
</section>
<section id="neural-engine-with-flexible-input-shapes">
<h2>Neural Engine With Flexible Input Shapes<a class="headerlink" href="#neural-engine-with-flexible-input-shapes" title="Permalink to this heading">#</a></h2>
<p>When converting a fixed-shape model that already runs on the Neural Engine (NE) to use flexible inputs, you should specify a flexible input shape with a set of predetermined shapes using <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.input_types.html#enumeratedshapes"><code class="docutils literal notranslate"><span class="pre">EnumeratedShapes</span></code></a>. The converted model will run on the NE, unless the conversion introduces dynamic layers not supported on the NE, such as converting a static reshape to a fully dynamic reshape.</p>
<p>With <code class="docutils literal notranslate"><span class="pre">EnumeratedShapes</span></code> the model can be optimized for the finite set of input shapes on the device during compilation. You can provide up to 128 different shapes. If you need more flexibility for inputs, consider setting the range for each dimension.</p>
<p>For details and examples of using flexible input shapes, see <a class="reference internal" href="flexible-inputs.html"><span class="doc std std-doc">Flexible Input Shapes</span></a>.</p>
</section>
<section id="why-optimize-torch-is-better-than-pytorchs-default-quantization">
<h2>Why <code class="docutils literal notranslate"><span class="pre">optimize.torch</span></code> is better than PyTorch’s default quantization<a class="headerlink" href="#why-optimize-torch-is-better-than-pytorchs-default-quantization" title="Permalink to this heading">#</a></h2>
<p>You can use PyTorch’s quantization APIs directly, and then convert the model to Core ML.
However, the converted model performance may not be optimal.
The PyTorch API default settings
(symmetric asymmetric quantization modes and which ops are quantized)
are not optimal for the Core ML stack and Apple hardware.
If you use the Core ML Tools <code class="docutils literal notranslate"><span class="pre">coremltools.optimize.torch</span></code> APIs
the correct default settings are applied automatically.</p>
</section>
<section id="use-a-compiled-model-for-faster-initialization">
<h2>Use a compiled model for faster initialization<a class="headerlink" href="#use-a-compiled-model-for-faster-initialization" title="Permalink to this heading">#</a></h2>
<p>If your model initialization in Python takes a long time, use a <em>compiled</em> Core ML model (<a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.CompiledMLModel">CompiledMLModel</a>) rather than  <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#coremltools.models.model.MLModel">MLModel</a> for making predictions. For large models, using a compiled model can save considerable time in initializing the model. For details, see <a class="reference internal" href="model-prediction.html#using-compiled-python-models-for-prediction"><span class="std std-ref">Using Compiled Python Models for Prediction</span></a>.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="new-features.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">New Features</p>
      </div>
    </a>
    <a class="right-next"
       href="coremltools-examples.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Examples</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-ml-tools-versions">Core ML Tools Versions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-7">coremltools 7</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#previous-releases">Previous releases</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-6">coremltools 6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-5">coremltools 5</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coremltools-4">coremltools 4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-conversion">PyTorch Conversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#keras-conversion">Keras Conversion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixing-high-numerical-error">Fixing High Numerical Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-preprocessing-for-converting-torchvision">Image Preprocessing for Converting torchvision</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-in-declaring-network-or-computing-nn-outputs">Error in Declaring Network or Computing NN Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-a-deep-learning-core-ml-model">Starting a Deep Learning Core ML Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-an-unsupported-op">Handling an Unsupported Op</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-custom-names-for-input-and-outputs">Choosing Custom Names for Input and Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-engine-with-flexible-input-shapes">Neural Engine With Flexible Input Shapes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-optimize-torch-is-better-than-pytorchs-default-quantization">Why <code class="docutils literal notranslate"><span class="pre">optimize.torch</span></code> is better than PyTorch’s default quantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#use-a-compiled-model-for-faster-initialization">Use a compiled model for faster initialization</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apple
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Apple Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>