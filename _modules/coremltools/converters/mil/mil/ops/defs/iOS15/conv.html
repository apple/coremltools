<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.converters.mil.mil.ops.defs.iOS15.conv &mdash; coremltools API Reference  documentation</title>
      <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/css/norightmargin.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../../../../" id="documentation_options" src="../../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../../../../../_static/doctools.js"></script>
        <script src="../../../../../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../../../../index.html" class="icon icon-home"> coremltools API Reference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../source/coremltools.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://coremltools.readme.io/docs">Guides and examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../../../../../index.html">Module code</a> &raquo;</li>
      <li>coremltools.converters.mil.mil.ops.defs.iOS15.conv</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.converters.mil.mil.ops.defs.iOS15.conv</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Copyright (c) 2020, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1">#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Operation</span><span class="p">,</span>
    <span class="n">types</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.block</span> <span class="kn">import</span> <span class="n">curr_opset_version</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.input_type</span> <span class="kn">import</span> <span class="n">InputSpec</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.input_type</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DefaultInputs</span><span class="p">,</span>
    <span class="n">InputSpec</span><span class="p">,</span>
    <span class="n">TensorInputType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.ops.defs._op_reqs</span> <span class="kn">import</span> <span class="n">register_op</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.ops.defs._utils</span> <span class="kn">import</span> <span class="n">spatial_dimensions_out_shape</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.ops.defs.iOS15</span> <span class="kn">import</span> <span class="n">_IOS15_TARGET</span>


<div class="viewcode-block" id="conv"><a class="viewcode-back" href="../../../../../../../../source/coremltools.converters.mil.mil.ops.defs.html#coremltools.converters.mil.mil.ops.defs.iOS15.conv.conv">[docs]</a><span class="nd">@register_op</span>
<span class="k">class</span> <span class="nc">conv</span><span class="p">(</span><span class="n">Operation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform convolution over input. Supports 1-D, 2-D, and 3-D convolution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: tensor&lt;[n, C_in, \*d_in], T&gt; (Required)</span>

<span class="sd">        * ``d_in`` are (possibly runtime-determined) spatial dimensions. For example,</span>
<span class="sd">          ``d_in = [224, 224]`` for 2D convolution.</span>
<span class="sd">        * ``1 &lt;= len(d_in) &lt;= 3``.</span>
<span class="sd">        * ``C_in`` is the number of input channels or depth dimensions.</span>
<span class="sd">        * ``n``  is the batch dimension.</span>

<span class="sd">    weight: tensor&lt;[C_out, C_in/groups, \*K], T&gt; (Required)</span>

<span class="sd">        * Filter weights.</span>
<span class="sd">        * ``C_in`` is the number of input channels.</span>
<span class="sd">        * ``C_in`` must be divisible by ``groups``.</span>
<span class="sd">        * ``K`` are kernel sizes. For example, ``K = [KH, KW]`` for 2-D convolution.</span>
<span class="sd">        * When ``dilations`` is not all ``1``, ``weight`` has to be ``const``</span>
<span class="sd">          at compile time</span>

<span class="sd">    strides: const tensor&lt;[S], i32&gt; (Optional)</span>

<span class="sd">        * Default to one vector of length equal to the number of spatial dimensions.</span>
<span class="sd">        * Strides along each of the spatial dimensions.</span>
<span class="sd">        * ``S == len(d_in)``.</span>

<span class="sd">    pad_type: const str (Required)</span>

<span class="sd">        Must be one of the following:</span>

<span class="sd">            * ``valid``: No padding. This is equivalent to custom pad with</span>
<span class="sd">              ``pad[2*i] == pad[2*i+1] == 0, for i=0,...,len(d_in)-1``.</span>
<span class="sd">            * ``custom``: Specify custom padding in the parameter ``pad``.</span>
<span class="sd">            * ``same``: Input is padded such that out spatial shapes are</span>
<span class="sd">              ``d_out[i] = ceil(d_in[i] / strides[i])``.</span>
<span class="sd">            * ``same_lower``: Similar to ``same`` but the padding</span>
<span class="sd">              will place extra rows/cols on the top/left if the padding amount is odd.</span>

<span class="sd">        Specifically, for ``i = 0,..,,len(d_in)-1``, the equivalent paddings are</span>
<span class="sd">        calculated as follows:</span>

<span class="sd">            * ``dilated_kernel = (K[i] - 1) * dilate[i] + 1``</span>
<span class="sd">            * If ``dilated_kernel`` is odd,</span>
<span class="sd">              ``padding[2*i] = padding[2*i+1] = floor(dilated_kernel / 2)``</span>
<span class="sd">            * Otherwise:</span>
<span class="sd">              ``padding[2*i] = ceil((dilated_kernel - 1) / 2)``,</span>
<span class="sd">              ``padding[2*i+1] = floor((dilated_kernel - 1) / 2)``</span>

<span class="sd">    pad: const tensor&lt;[P], i32&gt; (Optional. Default to all zeros)</span>

<span class="sd">        * ``len(P) = 2 * len(d_in)``</span>
<span class="sd">        * ``pad`` should be specified if and only if ``pad_type == custom``,</span>
<span class="sd">          otherwise errors occur.</span>
<span class="sd">        * ``pad`` represents the number of elements to pad before and after each</span>
<span class="sd">          dimension. Specifically, ``pad[0], pad[1]`` are the pad size before / after</span>
<span class="sd">          spatial dimension 0, ``pad[2], pad[3]`` are the pad size before / after</span>
<span class="sd">          spatial dimension 1, etc.</span>

<span class="sd">    dilations: const tensor&lt;[S], i32&gt; (Optional. Default to all 1s)</span>

<span class="sd">        * Dilation value along each spatial dimension in ``d_in``.</span>
<span class="sd">          See `visualization &lt;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&gt;`_.</span>
<span class="sd">        * ``S == len(d_in)``.</span>

<span class="sd">    groups: const tensor&lt;[], i32&gt; (Optional, default to 1)</span>

<span class="sd">        * Input and output channels are split by ``groups``.</span>
<span class="sd">        * ``C_in`` must be divisible by ``groups``.</span>
<span class="sd">        * Maximum value for group is ``C_in``, in which case it is a depthwise</span>
<span class="sd">          convolution.</span>

<span class="sd">        For examples (assuming ``C_in = 16, C_out = 32``):</span>

<span class="sd">            * ``groups == 1``, ``weight`` has shape ``[32, 16, KH, KW]``: All input</span>
<span class="sd">              channels are convolved with the ``weight`` kernel to produce all output</span>
<span class="sd">              channels.</span>
<span class="sd">            * ``groups == 2``, ``weight`` has shape ``[32, 8, KH, KW]``: Input</span>
<span class="sd">              channels 0~7 are convolved with half of the ``weight`` kernel to produce</span>
<span class="sd">              output channels 0~15. Similarly, input channels 8~15 are convolved with</span>
<span class="sd">              the other half of ``weight`` to product output channels 16~31.</span>
<span class="sd">            * ``groups == C_in``, ``weight`` has shape ``[32, 1, KH, KW]``: Each input</span>
<span class="sd">              channel is convolved with its own set of filters and each produce</span>
<span class="sd">              ``C_out / C_in = 2`` channels. This is equivalent to depthwise</span>
<span class="sd">              convolution.</span>

<span class="sd">    bias: const tensor&lt;[C_out],T&gt; (Optional, default to all 0)</span>
<span class="sd">        * Bias along output channels.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tensor&lt;[n, C_out, \*d_out], T&gt;</span>
<span class="sd">        * Output activation has the same rank and spatial dimension as the input.</span>
<span class="sd">          That is, ``len(d_out) == len(d_in)``.</span>
<span class="sd">        * For ``i=0,..,len(d_in)-1, d_out[i] = floor [(D_in[i] + pad[2*i] +</span>
<span class="sd">          pad[2*i+1] - (K[i]-1)*dilations[i] - 1) / strides[i] ] + 1``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    T: fp16, fp32</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    conv_transpose</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">pad_type</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">str</span><span class="p">),</span>
        <span class="n">pad</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="n">type_domains</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;T&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">fp16</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">fp32</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">default_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">num_spatial_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">DefaultInputs</span><span class="p">(</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="p">,</span>
            <span class="n">pad_type</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
            <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">dilations</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">type_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">inshape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">f_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="n">f_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">C_out</span> <span class="o">=</span> <span class="n">f_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">C_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">val</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">C_out</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;# of bias values </span><span class="si">{}</span><span class="s2"> not equal to # output channels </span><span class="si">{}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">C_in</span> <span class="o">%</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;# of input channels </span><span class="si">{}</span><span class="s2"> not divisible by groups </span><span class="si">{}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">C_in</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">C_in</span> <span class="o">//</span> <span class="n">groups</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;C_in / groups = </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> != weight[1] (</span><span class="si">{}</span><span class="s2">)&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">C_in</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="n">strides</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="o">.</span><span class="n">val</span>
        <span class="n">dilations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="o">.</span><span class="n">val</span>
        
        <span class="c1"># The same_lower padding is not supported in iOS15</span>
        <span class="k">if</span> <span class="n">curr_opset_version</span><span class="p">()</span> <span class="o">==</span> <span class="n">_IOS15_TARGET</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span> <span class="o">==</span> <span class="s2">&quot;same_lower&quot;</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;iOS15 version of conv does not support pad_type = `same_lower`&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># Ignore self.pad if pad_type != custom</span>
        <span class="n">custom_pad</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span> <span class="o">!=</span> <span class="s1">&#39;custom&#39;</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="o">.</span><span class="n">val</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">([</span><span class="kc">True</span> <span class="k">if</span> <span class="n">d</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dilations</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Convolution with dynamic weights does not support dilations!&quot;</span><span class="p">)</span>

        <span class="n">N</span> <span class="o">=</span> <span class="n">inshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">C_out</span> <span class="o">=</span> <span class="n">f_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># spatial dimensions</span>
        <span class="n">d_out_shape</span> <span class="o">=</span> <span class="n">spatial_dimensions_out_shape</span><span class="p">(</span>
            <span class="n">pad_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="o">=</span><span class="n">inshape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span>
            <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
            <span class="n">dilations</span><span class="o">=</span><span class="n">dilations</span><span class="p">,</span>
            <span class="n">custom_pad</span><span class="o">=</span><span class="n">custom_pad</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">retshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">C_out</span><span class="p">]</span> <span class="o">+</span> <span class="n">d_out_shape</span>
        <span class="k">return</span> <span class="n">types</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">retshape</span><span class="p">))</span></div>


<span class="nd">@register_op</span>
<span class="k">class</span> <span class="nc">conv_quantized</span><span class="p">(</span><span class="n">conv</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Note: This is experimental and may change in the future.</span>
<span class="sd">    Supports weight quantization for parameters while performing convolution over input.</span>
<span class="sd">    ``W_float = W_quantized * scale + bias``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    In addition to convolutional layer parameters, the following additional parameters</span>
<span class="sd">    are required.</span>

<span class="sd">    quantization_type: const str (Required)</span>
<span class="sd">        * One of ``linear``, or ``lut``.</span>

<span class="sd">    nbits: const tensor&lt;[], i32&gt; (Optional. Default to 8)</span>
<span class="sd">        * Denotes the bit-width of the quantization. ``1 &lt;= nbits &lt;= 8``.</span>

<span class="sd">    quant_scale: tensor&lt;*?, T&gt; (Required)</span>
<span class="sd">        * Denotes the scale of quantization.</span>

<span class="sd">    quant_bias: tensor&lt;*?, T&gt; (Required)</span>
<span class="sd">        * Denotes the bias that is used to quantize/dequantize.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tensor&lt;[n, C_out, *d_out], T&gt;</span>
<span class="sd">        * Output activation has the same rank and spatial dimension as the input.</span>
<span class="sd">          That is, ``len(d_out) == len(d_in)``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    T: fp16, fp32</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;U&quot;</span><span class="p">),</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;U&quot;</span><span class="p">),</span>
        <span class="n">quantization_type</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">str</span><span class="p">),</span>
        <span class="n">nbits</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">quant_scale</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">quant_bias</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">pad_type</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">str</span><span class="p">),</span>
        <span class="n">pad</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="p">)</span>
        
    <span class="n">type_domains</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;T&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">fp32</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">fp16</span><span class="p">),</span>
        <span class="s2">&quot;U&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">uint8</span><span class="p">,),</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">default_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">default_inputs</span><span class="p">()</span> <span class="o">+</span> \
            <span class="n">DefaultInputs</span><span class="p">(</span>
                <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="conv_transpose"><a class="viewcode-back" href="../../../../../../../../source/coremltools.converters.mil.mil.ops.defs.html#coremltools.converters.mil.mil.ops.defs.iOS15.conv.conv_transpose">[docs]</a><span class="nd">@register_op</span>
<span class="k">class</span> <span class="nc">conv_transpose</span><span class="p">(</span><span class="n">Operation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform transposed convolution (also known as deconvolution and fractionally</span>
<span class="sd">    stride convolution) over input. ``conv_transpose`` can also be used to compute</span>
<span class="sd">    the gradient of conv. Supports 1-D, 2-D, and 3-D convolution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    x: tensor&lt;[n,C_in,*D_in],T&gt; (Required)</span>
<span class="sd">        * Input data.</span>
<span class="sd">        * ``D_in`` are spatial dimensions.</span>
<span class="sd">        * ``1 &lt;= len(D_in) &lt;= 3``.</span>
<span class="sd">        * ``C_in`` is the number of input channels.</span>

<span class="sd">    weight: const tensor&lt;[C_in,C_out/groups,*D_in], T&gt; (Required)</span>
<span class="sd">        * Filter weights. ``C_in, C_out`` are the number of input and output channels</span>
<span class="sd">          respectively.</span>
<span class="sd">        * ``D_in`` are spatial dimensions. ``1 &lt;= len(D_in) &lt;= 2``.</span>

<span class="sd">    bias: const tensor&lt;[C_out],T&gt; (Optional, default to all 0)</span>
<span class="sd">        * Bias added along output channels.</span>

<span class="sd">    pad: const tensor&lt;[P],i32&gt; (Optional, default to all 0s)</span>
<span class="sd">        * Number of elements to pad before and after each dimension.</span>
<span class="sd">        * ``P == 2 * len(D_in)``.</span>
<span class="sd">        * ``pad[2*i], pad[2*i+1]`` are pad sizes before and after</span>
<span class="sd">          dimension ``i``, where ``0 &lt;= i &lt; len(D_in)``.</span>

<span class="sd">    output_shape: const tensor&lt;[P],i32&gt; (Optional, default None)</span>
<span class="sd">        * Expected output shape. The first two dimensions must be ``[n, C_out]``.</span>
<span class="sd">        * The output shape of ``conv_transpose`` is underdetermined in general,</span>
<span class="sd">          because ``conv`` can map multiple input shapes to a single output shape.</span>
<span class="sd">          For example, for ``same`` padding mode, ``conv_out = ceil(conv_in/stride)``.</span>
<span class="sd">          Hence we need ``output_shape`` when this occurs.</span>

<span class="sd">    pad_type: const tensor&lt;[P],i32&gt; (Optional, default valid)</span>
<span class="sd">        * One of ``same``, ``valid``, or ``custom``.</span>

<span class="sd">    strides: const tensor&lt;[S],i32&gt; (Optional. Default to all 1s)</span>
<span class="sd">        * Stride along each of the spatial dimensions.</span>
<span class="sd">        * ``S == len(D_in)``.</span>

<span class="sd">    dilations: const tensor&lt;[S],i32&gt; (Optional. Default to all 1s)</span>
<span class="sd">        * Dilation value along each spatial dimension in ``d_in``. See ``conv``.</span>
<span class="sd">        * ``S == len(D_in)``.</span>

<span class="sd">    groups: const tensor&lt;[], i32&gt; (Optional. Default to 1)</span>
<span class="sd">        * Input and output channels are separated into ``groups``.</span>
<span class="sd">        * ``C_in`` and ``C_out`` must be divisible by the number of groups.</span>
<span class="sd">          See ``conv`` for examples.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tensor&lt;[n,C_out,*D_out],T&gt;</span>
<span class="sd">		* If ``output_shape`` is not ``None``:</span>
<span class="sd">		  </span>
<span class="sd">		     ``Dout = output_shape``</span>

<span class="sd">		* If ``pad_type == &quot;custom&quot;``:</span>
<span class="sd">		  </span>
<span class="sd">		     ``Dout[i] = (D_in[i]-1)*stride[i] + (K[i]-1) * dilation[i] + 1 - pad[2*i] - pad[2*i-1]``</span>

<span class="sd">		* If ``pad_type == &quot;valid&quot;``:</span>
<span class="sd">		  </span>
<span class="sd">		     ``Dout[i] = (D_in[i]-1)*stride[i] + (K[i]-1) * dilation[i] + 1``</span>

<span class="sd">		* If ``pad_type == &quot;same&quot;``:</span>
<span class="sd">		  </span>
<span class="sd">		     ``Dout[i] = D_in[i] * stride[i]``</span>
<span class="sd">    </span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    T: fp16, fp32</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    conv</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>  <span class="c1"># [n, C_in, spatial_dims]</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>  <span class="c1"># [C_out, C_in, spatial_dims]</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
        <span class="n">pad</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">output_shape</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">pad_type</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">str</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">TensorInputType</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">type_domain</span><span class="o">=</span><span class="n">types</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="n">type_domains</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;T&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">fp16</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">fp32</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">default_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">num_spatial_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">DefaultInputs</span><span class="p">(</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">pad</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="p">,</span>
            <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">pad_type</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="p">,</span>
            <span class="n">dilations</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_spatial_dims</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">type_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Input shape is [n, C_in, spatial_dims]</span>
        <span class="n">in_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Weight shape is [C_in, C_out/group, spatial_dims]</span>
        <span class="n">f_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="n">f_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">spatial_dim_rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">C_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">val</span>
        <span class="n">C_out</span> <span class="o">=</span> <span class="n">f_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">C_out</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;# of bias values </span><span class="si">{}</span><span class="s2"> not equal to # output channels </span><span class="si">{}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">C_out</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">C_out</span> <span class="o">%</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;# of input channels </span><span class="si">{}</span><span class="s2"> not divisible by groups </span><span class="si">{}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">C_in</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>

        <span class="c1"># If output shape is given, return it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="o">.</span><span class="n">val</span>
            <span class="k">assert</span> <span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">N</span>
            <span class="k">assert</span> <span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">C_out</span>
            <span class="k">return</span> <span class="n">types</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">strides</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="o">.</span><span class="n">val</span>
        <span class="n">dilations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilations</span><span class="o">.</span><span class="n">val</span>
        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">kernel_shape</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dilations</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spatial_dim_rank</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">D_in</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>  <span class="c1"># spatial dimensions</span>

        <span class="c1"># Deconv&#39;s output shape is non-deterministic, we follow TF shape logic here.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
            <span class="n">d_out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">strides</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">*</span> <span class="n">D_in</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spatial_dim_rank</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span> <span class="o">==</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="n">d_out_shape</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">strides</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">D_in</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">kernel_shape</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spatial_dim_rank</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_type</span><span class="o">.</span><span class="n">val</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;self.pad must exist if pad_type is custom&quot;</span><span class="p">)</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="o">.</span><span class="n">val</span>
            <span class="n">d_out_shape</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">strides</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">D_in</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="n">kernel_shape</span><span class="p">[</span><span class="n">r</span><span class="p">]</span>
                <span class="o">-</span> <span class="n">pad</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">r</span><span class="p">]</span>
                <span class="o">-</span> <span class="n">pad</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">r</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spatial_dim_rank</span><span class="p">)</span>
            <span class="p">]</span>

        <span class="n">retshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">C_out</span><span class="p">]</span> <span class="o">+</span> <span class="n">d_out_shape</span>
        <span class="k">return</span> <span class="n">types</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">retshape</span><span class="p">))</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>