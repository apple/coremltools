

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>coremltools.converters.caffe.convert &mdash; coremltools 3.4 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
        <script type="text/javascript" src="../static/jquery.js"></script>
        <script type="text/javascript" src="../static/underscore.js"></script>
        <script type="text/javascript" src="../static/doctools.js"></script>
        <script type="text/javascript" src="../static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="coremltools.converters.libsvm.convert" href="coremltools.converters.libsvm.convert.html" />
    <link href="../static/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> coremltools
          

          
          </a>

          
            
            
              <div class="version">
                3.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../coremltools.converters.html">Converters</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">coremltools.converters.caffe.convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.converters.libsvm.convert.html">coremltools.converters.libsvm.convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.converters.sklearn.convert.html">coremltools.converters.sklearn.convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.converters.xgboost.convert.html">coremltools.converters.xgboost.convert</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../coremltools.models.html">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.MLModel.html">coremltools.models.MLModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.pipeline.html">coremltools.models.pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.tree_ensemble.html">coremltools.models.tree_ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.nearest_neighbors.builder.html">coremltools.models.nearest_neighbors.builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.neural_network.builder.html">coremltools.models.neural_network.builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.neural_network.flexible_shape_utils.html">coremltools.models.neural_network.flexible_shape_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.neural_network.quantization_utils.html">coremltools.models.neural_network.quantization_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="coremltools.models.neural_network.update_optimizer_utils.html">coremltools.models.neural_network.update_optimizer_utils</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../coremltools.utils.html">Utilities</a><ul class="simple">
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">coremltools</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../coremltools.converters.html">Converters</a> &raquo;</li>
        
      <li>coremltools.converters.caffe.convert</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../sources/generated/coremltools.converters.caffe.convert.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="coremltools-converters-caffe-convert">
<h1>coremltools.converters.caffe.convert<a class="headerlink" href="#coremltools-converters-caffe-convert" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="coremltools.converters.caffe.convert">
<code class="descclassname">coremltools.converters.caffe.</code><code class="descname">convert</code><span class="sig-paren">(</span><em>model</em>, <em>image_input_names=[]</em>, <em>is_bgr=False</em>, <em>red_bias=0.0</em>, <em>blue_bias=0.0</em>, <em>green_bias=0.0</em>, <em>gray_bias=0.0</em>, <em>image_scale=1.0</em>, <em>class_labels=None</em>, <em>predicted_feature_name=None</em>, <em>model_precision='float32'</em><span class="sig-paren">)</span><a class="headerlink" href="#coremltools.converters.caffe.convert" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a Caffe model to Core ML format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>model: str | (str, str) | (str, str, str) | (str, str, dict)</strong></dt>
<dd><p class="first">A trained Caffe neural network model which can be represented as:</p>
<ul class="last simple">
<li>Path on disk to a trained Caffe model (.caffemodel)</li>
<li>A tuple of two paths, where the first path is the path to the .caffemodel
file while the second is the path to the deploy.prototxt.</li>
<li>A tuple of three paths, where the first path is the path to the
trained .caffemodel file, the second is the path to the
deploy.prototxt while the third is a path to the mean image binary, data in
which is subtracted from the input image as a preprocessing step.</li>
<li>A tuple of two paths to .caffemodel and .prototxt and a dict with image input names
as keys and paths to mean image binaryprotos as values. The keys should be same as
the input names provided via the argument ‘image_input_name’.</li>
</ul>
</dd>
<dt><strong>image_input_names: [str] | str</strong></dt>
<dd><p class="first last">The name(s) of the input blob(s) in the Caffe model that can be treated
as images by Core ML. All other inputs are treated as MultiArrays (N-D
Arrays) by Core ML.</p>
</dd>
<dt><strong>is_bgr: bool | dict()</strong></dt>
<dd><p class="first last">Flag indicating the channel order the model internally uses to represent
color images. Set to True if the internal channel order is BGR,
otherwise it will be assumed RGB. This flag is applicable only if
image_input_names is specified. To specify a different value for each
image input, provide a dictionary with input names as keys.
Note that this flag is about the models internal channel order.
An input image can be passed to the model in any color pixel layout
containing red, green and blue values (e.g. 32BGRA or 32ARGB). This flag
determines how those pixel values get mapped to the internal multiarray
representation.</p>
</dd>
<dt><strong>red_bias: float | dict()</strong></dt>
<dd><p class="first last">Bias value to be added to the red channel of the input image.
Defaults to 0.0.
Applicable only if image_input_names is specified.
To specify different values for each image input provide a dictionary with input names as keys.</p>
</dd>
<dt><strong>blue_bias: float | dict()</strong></dt>
<dd><p class="first last">Bias value to be added to the the blue channel of the input image.
Defaults to 0.0.
Applicable only if image_input_names is specified.
To specify different values for each image input provide a dictionary with input names as keys.</p>
</dd>
<dt><strong>green_bias: float | dict()</strong></dt>
<dd><p class="first last">Bias value to be added to the green channel of the input image.
Defaults to 0.0.
Applicable only if image_input_names is specified.
To specify different values for each image input provide a dictionary with input names as keys.</p>
</dd>
<dt><strong>gray_bias: float | dict()</strong></dt>
<dd><p class="first last">Bias value to be added to the input image (in grayscale). Defaults to 0.0.
Applicable only if image_input_names is specified.
To specify different values for each image input provide a dictionary with input names as keys.</p>
</dd>
<dt><strong>image_scale: float | dict()</strong></dt>
<dd><p class="first last">Value by which the input images will be scaled before bias is added and 
Core ML model makes a prediction. Defaults to 1.0.
Applicable only if image_input_names is specified.
To specify different values for each image input provide a dictionary with input names as keys.</p>
</dd>
<dt><strong>class_labels: str</strong></dt>
<dd><p class="first last">Filepath where classes are parsed as a list of newline separated
strings. Class labels map the index of the output of a neural network to labels in a classifier.
Provide this argument to get a model of type classifier.</p>
</dd>
<dt><strong>predicted_feature_name: str</strong></dt>
<dd><p class="first last">Name of the output feature for the class labels exposed in the Core ML
model (applies to classifiers only). Defaults to ‘classLabel’</p>
</dd>
<dt><strong>model_precision: str</strong></dt>
<dd><p class="first last">Precision at which model will be saved. Currently full precision (float) and half precision
(float16) models are supported. Defaults to ‘_MLMODEL_FULL_PRECISION’ (full precision).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt>model: MLModel</dt>
<dd><p class="first last">Model in Core ML format.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert it with default input and output names</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">coremltools</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">)</span>

<span class="c1"># Saving the Core ML model to a file.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coreml_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.mlmodel&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Sometimes, critical information in the Caffe converter is missing from the
.caffemodel file. This information is present in the deploy.prototxt file.
You can provide us with both files in the conversion process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span> <span class="s1">&#39;my_deploy.prototxt&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Some models (like Resnet-50) also require a mean image file which is
subtracted from the input image before passing through the network. This
file can also be provided during conversion:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;my_deploy.prototxt&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_image.binaryproto&#39;</span><span class="p">),</span> <span class="n">image_input_names</span> <span class="o">=</span> <span class="s1">&#39;image_input&#39;</span><span class="p">)</span>

<span class="go"># Multiple mean images for preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;my_deploy.prototxt&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;image1&#39;</span><span class="p">:</span> <span class="s1">&#39;mean_image1.binaryproto&#39;</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">:</span> <span class="s1">&#39;mean_image2.binaryproto&#39;</span><span class="p">}),</span>
<span class="gp">... </span>                    <span class="n">image_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;image1&#39;</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">])</span>

<span class="go"># Multiple image inputs and bias/scale values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span> <span class="s1">&#39;my_deploy.prototxt&#39;</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="n">red_bias</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image1&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">110</span><span class="p">},</span>
<span class="gp">... </span>                    <span class="n">green_bias</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image1&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">125</span><span class="p">},</span>
<span class="gp">... </span>                    <span class="n">blue_bias</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image1&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">105</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">120</span><span class="p">},</span>
<span class="gp">... </span>                    <span class="n">image_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;image1&#39;</span><span class="p">,</span> <span class="s1">&#39;image2&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Input and output names used in the interface of the converted Core ML model are inferred from the .prototxt file,
which contains a description of the network architecture.
Input names are read from the input layer definition in the .prototxt. By default, they are of type MultiArray.
Argument “image_input_names” can be used to assign image type to specific inputs.
All the blobs that are “dangling”, i.e.
which do not feed as input to any other layer are taken as outputs. The .prototxt file can be modified to specify
custom input and output names.</p>
<p>The converted Core ML model is of type classifier when the argument “class_labels” is specified.</p>
<p>Advanced usage with custom classifiers, and images:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mark some inputs as Images</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span> <span class="s1">&#39;my_caffe_model.prototxt&#39;</span><span class="p">),</span>
<span class="o">...</span>                   <span class="n">image_input_names</span> <span class="o">=</span> <span class="s1">&#39;my_image_input&#39;</span><span class="p">)</span>

<span class="c1"># Export as a classifier with classes from a file</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coreml_model</span> <span class="o">=</span> <span class="n">coremltools</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">caffe</span><span class="o">.</span><span class="n">convert</span><span class="p">((</span><span class="s1">&#39;my_caffe_model.caffemodel&#39;</span><span class="p">,</span> <span class="s1">&#39;my_caffe_model.prototxt&#39;</span><span class="p">),</span>
<span class="o">...</span>         <span class="n">image_input_names</span> <span class="o">=</span> <span class="s1">&#39;my_image_input&#39;</span><span class="p">,</span> <span class="n">class_labels</span> <span class="o">=</span> <span class="s1">&#39;labels.txt&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Sometimes the converter might return a message about not able to infer input data dimensions. 
This happens when the input size information is absent from the deploy.prototxt file. This can be easily provided by editing 
the .prototxt in a text editor. Simply add a snippet in the beginning, similar to the following, for each of the inputs to the model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>input: <span class="s2">&quot;my_image_input&quot;</span>
input_dim: <span class="m">1</span>
input_dim: <span class="m">3</span>
input_dim: <span class="m">227</span>
input_dim: <span class="m">227</span>
</pre></div>
</div>
<p>Here we have specified an input with dimensions (1,3,227,227), using Caffe’s convention, in the order (batch, channel, height, width). 
Input name string (“my_image_input”) must also match the name of the input (or “bottom”, as inputs are known in Caffe) of the first layer in the .prototxt.</p>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="coremltools.converters.libsvm.convert.html" class="btn btn-neutral float-right" title="coremltools.converters.libsvm.convert" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2019, Apple Inc

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>