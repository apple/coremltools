<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.optimize.coreml._quantization_passes &mdash; coremltools API Reference  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/norightmargin.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            coremltools API Reference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.models.html">Model APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.mil.passes.defs.html">MIL Graph Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.optimize.html">Optimizers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://coremltools.readme.io/docs">Guides and examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">coremltools.optimize.coreml._quantization_passes</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.optimize.coreml._quantization_passes</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2023, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1"># found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">coremltools</span> <span class="kn">import</span> <span class="n">_logger</span> <span class="k">as</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.backend.mil.load</span> <span class="kn">import</span> <span class="n">should_use_weight_file</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Builder</span> <span class="k">as</span> <span class="n">mb</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil</span> <span class="kn">import</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">Program</span><span class="p">,</span> <span class="n">types</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.ops.defs.iOS16</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">constexpr_affine_dequantize</span><span class="p">,</span>
    <span class="n">constexpr_lut_to_dense</span><span class="p">,</span>
    <span class="n">constexpr_sparse_to_dense</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.defs.quantization</span> <span class="kn">import</span> <span class="n">AbstractQuantizationPass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.helper</span> <span class="kn">import</span> <span class="n">block_context_manager</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.passes.pass_registry</span> <span class="kn">import</span> <span class="n">register_pass</span>
<span class="kn">from</span> <span class="nn">coremltools.converters.mil.mil.types.type_mapping</span> <span class="kn">import</span> <span class="n">nptype_from_builtin</span>
<span class="kn">from</span> <span class="nn">coremltools.models.neural_network.quantization_utils</span> <span class="kn">import</span> <span class="n">_get_kmeans_lookup_table_and_weight</span>
<span class="kn">from</span> <span class="nn">coremltools.optimize.coreml._config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OpLinearQuantizerConfig</span><span class="p">,</span>
    <span class="n">OpMagnitudePrunerConfig</span><span class="p">,</span>
    <span class="n">OpPalettizerConfig</span><span class="p">,</span>
    <span class="n">OpThresholdPrunerConfig</span><span class="p">,</span>
    <span class="n">OptimizationConfig</span><span class="p">,</span>
<span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">--------------------------------</span>
<span class="sd">Compression parameters wrapper -</span>
<span class="sd">--------------------------------</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">class</span> <span class="nc">SparseParams</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nonzero_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_data</span> <span class="o">=</span> <span class="n">nonzero_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>

<span class="k">class</span> <span class="nc">LutParams</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lut</span> <span class="o">=</span> <span class="n">lut</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>

<span class="k">class</span> <span class="nc">AffineQuantParams</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantized_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">zero_point</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">quantized_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="n">zero_point</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">------------------------</span>
<span class="sd">Compression graph pass -</span>
<span class="sd">------------------------</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">class</span> <span class="nc">AbstractCompressionPass</span><span class="p">(</span><span class="n">AbstractQuantizationPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The abstract class for the compression graph passes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">OptimizationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fake_compression</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="p">(</span><span class="n">OptimizationConfig</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;config must be of type OptimizationConfig. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">op_selector</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">_op_selector</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">op_selector</span><span class="o">=</span><span class="n">op_selector</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fake_compression</span> <span class="o">=</span> <span class="n">fake_compression</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_config_type</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prog</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">Program</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Transform &quot;</span><span class="si">{}</span><span class="s1">&quot; can only be applied on PyMIL programs.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>

        <span class="nd">@block_context_manager</span>
        <span class="k">def</span> <span class="nf">apply_block</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
            <span class="n">valid_consts</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
                    <span class="n">apply_block</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_valid_op</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                    <span class="n">need_transform</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_selector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">need_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_selector</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">need_transform</span><span class="p">:</span>
                        <span class="n">valid_consts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
                <span class="n">valid_consts</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Running compression pass </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; ops&quot;</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transform_op</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">prog</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">apply_block</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span>

    <span class="nd">@config</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_config_type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">need_compress_const</span><span class="p">(</span><span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">_is_deprecated</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">weight_threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The utility function is checking whether a const op can be compressed.</span>
<span class="sd">        If ``_is_deprecated = True``, the user is using the ``ct.compression_utils``, in which the ops are already filtered by ``op_selector``.</span>
<span class="sd">        For the new ``ct.optimize.coreml`` API, ``op_selector`` is no longer supported, so the ``weight_threshold`` is checked explicitly instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span>
        <span class="k">if</span> <span class="n">_is_deprecated</span> <span class="ow">and</span> <span class="n">weight_threshold</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;weight_threshold cannot be set through the deprecated ct.compression_util API&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_is_deprecated</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">should_use_weight_file</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

        <span class="c1"># const fed into constexpr ops cannot be compressed</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">child_op</span><span class="o">.</span><span class="n">op_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;constexpr&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">child_op</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child_ops</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">weight_threshold</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;weight_threshold cannot be None&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">should_use_weight_file</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="n">weight_threshold</span>

    <span class="k">def</span> <span class="nf">_check_config_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">OptimizationConfig</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The utility function is checking the OptimizationConfig is holding correct type of op config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">get_supported_types_as_str</span><span class="p">(</span><span class="n">supported_type</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">supported_type</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="n">supported_type</span> <span class="o">=</span> <span class="p">[</span><span class="n">supported_type</span><span class="p">]</span>
            <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">supported_type</span><span class="p">])</span>

        <span class="n">all_configs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">global_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_configs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">global_config</span><span class="p">)</span>
        <span class="n">all_configs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">op_type_configs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">all_configs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">op_name_configs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">all_configs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_SUPPORTED_CONFIG_TYPE</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">supported_type_str</span> <span class="o">=</span> <span class="n">get_supported_types_as_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_SUPPORTED_CONFIG_TYPE</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> only accept </span><span class="si">{</span><span class="n">supported_type_str</span><span class="si">}</span><span class="s2"> type config. Got </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;compression&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">prune_weights</span><span class="p">(</span><span class="n">AbstractCompressionPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This transform works for each ``const`` op if:</span>
<span class="sd">    </span>
<span class="sd">    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.</span>
<span class="sd">    - ``_is_deprecated=False`` and the ``const`` value size ``&gt; weight_threshold``.</span>

<span class="sd">    The transform performs the following:</span>
<span class="sd">    </span>
<span class="sd">    - The fraction of values with the least absolute value are zeroed out (self.sparsity).</span>
<span class="sd">    - If ``fake_compression=False``, the zeroed-out value is encoded using the ``constexpr_sparse_to_dense`` op.</span>
<span class="sd">    - If ``fake_compression=True``, the zeroed-out value is encoded using the ``const`` op.</span>
<span class="sd">    - Old ``const`` is replaced by a new operation with zeroed-out value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_SUPPORTED_CONFIG_TYPE</span> <span class="o">=</span> <span class="p">(</span><span class="n">OpMagnitudePrunerConfig</span><span class="p">,</span> <span class="n">OpThresholdPrunerConfig</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_valid_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span> <span class="ow">and</span> <span class="n">should_use_weight_file</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_pack_val_to_sparse_param</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
        <span class="n">flattened_val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">SparseParams</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">nonzero_data</span> <span class="o">=</span> <span class="n">flattened_val</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">flattened_val</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)]</span>
        <span class="n">params</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">packbits</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">flattened_val</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">bitorder</span><span class="o">=</span><span class="s2">&quot;little&quot;</span><span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">params</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compress_by_threshold</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">minimum_sparsity_percentile</span><span class="p">):</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="n">sparsity_percentile</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">val</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">sparsity_percentile</span> <span class="o">&lt;</span> <span class="n">minimum_sparsity_percentile</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;weight value has sparsity of </span><span class="si">{</span><span class="n">sparsity_percentile</span><span class="si">}</span><span class="s2"> &lt; &quot;</span>
                   <span class="sa">f</span><span class="s2">&quot;minimum_sparsity_percentile </span><span class="si">{</span><span class="n">minimum_sparsity_percentile</span><span class="si">}</span><span class="s2">. Skipped.&quot;</span>
                  <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">prune_weights</span><span class="o">.</span><span class="n">_pack_val_to_sparse_param</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compress_by_magnitude</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">target_sparsity</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_apply_block_sparsity</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">dim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;bock sparsity pruning only supports dim [0, 1].&quot;</span>
            <span class="k">assert</span> <span class="n">rank</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="s2">&quot;block sparsity only supports weights of rank [2, 3, 4, 5]&quot;</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Block sparsity follows these steps:</span>
<span class="sd">            </span>
<span class="sd">            1. Input tensor with shape of ``[C_out, Cin, *K]``.</span>
<span class="sd">            2. If ``dim = 1``, the tensor is transposed to ``[Cin, C_out, *K]``. The following example assumes ``dim = 0``.</span>
<span class="sd">            3. Pad ``C_out`` so that it can be divided by ``block_size``: ``[C_out_pad, Cin, *K]``.</span>
<span class="sd">            4. Divide the output channel by ``block_size`` and reshape: ``[C_out_pad // block_size, block_size, C_in, *K]``.</span>
<span class="sd">            5. Compute the magnitude for each block: ``[C_out_pad // block_size, 1, C_in, *K]``.</span>
<span class="sd">            6. Replicate the magnitude values for each block: ``[C_out_pad // block_size, block_size, C_in, *K]``.</span>
<span class="sd">            7. Reshape the tensor back to ``[Cout_pad, C_in, *K]``.</span>
<span class="sd">            8. Crop the tensor to ``[C_out, C_in, *K]``.</span>
<span class="sd">            9. If ``dim = 1``, tranpose the tensor back to the original layout.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">perm</span><span class="p">)</span>

            <span class="n">channel</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">channel</span> <span class="o">%</span> <span class="n">block_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">pad_size</span> <span class="o">=</span> <span class="n">block_size</span> <span class="o">-</span> <span class="n">channel</span> <span class="o">%</span> <span class="n">block_size</span>
                <span class="n">pad_value</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">pad_value</span><span class="p">)</span>
            <span class="n">shape_padded</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">assert</span> <span class="n">shape_padded</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">block_size</span> <span class="o">==</span> <span class="mi">0</span>

            <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape_padded</span><span class="p">)</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
            <span class="n">new_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">block_size</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>

            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">val</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

            <span class="n">reps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">reps</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_size</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">reps</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">shape_padded</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="p">[:</span><span class="n">channel</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">perm</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">val</span>

        <span class="n">magnitude_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">block_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">channel</span> <span class="o">=</span> <span class="n">magnitude_map</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">block_size</span> <span class="o">&gt;</span> <span class="n">channel</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;block_size &gt; channel / 2 is not applicable for block sparsity. Got block_size = </span><span class="si">{</span><span class="n">block_size</span><span class="si">}</span><span class="s2">, channel = </span><span class="si">{</span><span class="n">channel</span><span class="si">}</span><span class="s2">. Skipped.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>

            <span class="n">magnitude_map</span> <span class="o">=</span> <span class="n">_apply_block_sparsity</span><span class="p">(</span><span class="n">magnitude_map</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">target_sparsity</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="k">if</span> <span class="n">q</span> <span class="o">==</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">val</span>
        <span class="k">elif</span> <span class="n">q</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">magnitude_map</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">magnitude_map</span><span class="p">,</span> <span class="n">q</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prune_weights</span><span class="o">.</span><span class="n">_pack_val_to_sparse_param</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compress_by_nm_sparsity</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">n_m_ratio</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">n_m_ratio</span>
        <span class="k">assert</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">m</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">dim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;n:m pruning only supports dim [0, 1].&quot;</span>
        <span class="k">assert</span> <span class="n">rank</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="s2">&quot;m:m pruning only supports weights of rank [2, 3, 4, 5]&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The `n-m` pruning process follows these steps:</span>
<span class="sd">        1. Input tensor with shape of ``[C_out, C_in, *K]``, where ``K`` is the spatial dimension from ``0`` to ``3``.</span>
<span class="sd">        2. If ``axis = 1``, tranpose the tensor to shape ``[*K, C_out, C_in]``; otherwise, ``(axis = 0)`` to ``[*K, C_in, C_out]``.</span>
<span class="sd">        3. For the case of ``axis = 1``, reshape input to a 2D tensor ``[*K*C_out, C_in]``. Similar for ``axis = 0``.</span>
<span class="sd">        4. Pad the last dimension with ``0`` so that it can be divided by ``m``: ``[*K*C_out, C_in_pad]``.</span>
<span class="sd">        5. Reshape the tensor to have the last dimension ``m``: ``[*K*C_out*C_in_pad//m, m]``.</span>
<span class="sd">        6. For each vector of length ``m``, we set the lowest ``n`` magnitute elements to ``0``.</span>
<span class="sd">        7. Reshape the tensor back to the shape of ``[*K*C_out, C_in_pad]``.</span>
<span class="sd">        8. Crop the last dimension to match the original shape of ``[*K*C_out, C_in]``.</span>
<span class="sd">        9. Reshape the tensor to shape ``[*K, C_out, C_in]``.</span>
<span class="sd">        10. Tranpose the tensor back to ``[C_out, C_in, K]``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">perm</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">perm</span><span class="p">))</span>
        <span class="n">shape_begin</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">channel</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">channel</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;m &gt; channel / 2 is not applicable for n:m pruning. Got m = </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2">, channel = </span><span class="si">{</span><span class="n">channel</span><span class="si">}</span><span class="s2">. Skipped.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">channel</span> <span class="o">%</span> <span class="n">m</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_size</span> <span class="o">=</span> <span class="n">m</span> <span class="o">-</span> <span class="n">channel</span> <span class="o">%</span> <span class="n">m</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">)))</span>
        <span class="n">shape_padded</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">shape_padded</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
        <span class="n">magnitute</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">magnitute</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span>

        <span class="n">n_m_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">put_along_axis</span><span class="p">(</span><span class="n">n_m_mask</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">n_m_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_m_mask</span><span class="p">,</span> <span class="n">shape_padded</span><span class="p">)</span>
        <span class="n">n_m_mask</span> <span class="o">=</span> <span class="n">n_m_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">channel</span><span class="p">]</span>

        <span class="n">n_m_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_m_mask</span><span class="p">,</span> <span class="n">shape_begin</span><span class="p">)</span>
        <span class="n">perm_back</span> <span class="o">=</span> <span class="p">[</span><span class="n">perm</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span>
        <span class="n">n_m_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">n_m_mask</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">perm_back</span><span class="p">)</span>

        <span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">n_m_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prune_weights</span><span class="o">.</span><span class="n">_pack_val_to_sparse_param</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">decompress</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">SparseParams</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid type of params&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">constexpr_sparse_to_dense</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">nonzero_data</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="n">op_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_get_const_op_config</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">op_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">need_compress_const</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_is_deprecated</span><span class="p">,</span> <span class="n">op_config</span><span class="o">.</span><span class="n">weight_threshold</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only numpy arrays are supported&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op_config</span><span class="p">,</span> <span class="n">OpThresholdPrunerConfig</span><span class="p">):</span>
            <span class="n">sparse_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compress_by_threshold</span><span class="p">(</span>
                                <span class="n">val</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                                <span class="n">threshold</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span>
                                <span class="n">minimum_sparsity_percentile</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">minimum_sparsity_percentile</span>
                            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op_config</span><span class="p">,</span> <span class="n">OpMagnitudePrunerConfig</span><span class="p">):</span>
            <span class="c1"># Structural sparsity can only be applied to conv / linear weight</span>
            <span class="c1"># For non applicable constant, we skip the compression,</span>
            <span class="c1"># we do allow the user to do structural pruning for non applicable constant,</span>
            <span class="c1"># if it is explicitly set by set_op_name,</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">op_config</span><span class="o">.</span><span class="n">_check_const_op_is_valid</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">op_name_configs</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;op named </span><span class="si">{</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> not applicable for </span><span class="si">{</span><span class="n">OpMagnitudePrunerConfig</span><span class="si">}</span><span class="s2"> configuration. Skipped.&quot;</span><span class="p">)</span>
                    <span class="k">return</span>

            <span class="k">if</span> <span class="n">op_config</span><span class="o">.</span><span class="n">target_sparsity</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sparse_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compress_by_magnitude</span><span class="p">(</span>
                                    <span class="n">val</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                                    <span class="n">target_sparsity</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">target_sparsity</span><span class="p">,</span>
                                    <span class="n">block_size</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span>
                                    <span class="n">dim</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span>
                                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">op_config</span><span class="o">.</span><span class="n">n_m_ratio</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sparse_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compress_by_nm_sparsity</span><span class="p">(</span>
                                    <span class="n">val</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                                    <span class="n">n_m_ratio</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">n_m_ratio</span><span class="p">,</span>
                                    <span class="n">dim</span><span class="o">=</span><span class="n">op_config</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span>
                                <span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fake_compression</span><span class="p">:</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">constexpr_sparse_to_dense</span><span class="p">(</span>
                <span class="n">nonzero_data</span><span class="o">=</span><span class="n">sparse_params</span><span class="o">.</span><span class="n">nonzero_data</span><span class="p">,</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">sparse_params</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="n">sparse_params</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_sparsified&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">decompressed_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">sparse_params</span><span class="p">)</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span>
                <span class="n">val</span><span class="o">=</span><span class="n">decompressed_val</span><span class="p">,</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_fake_sparsified&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">op</span><span class="p">])</span>

<div class="viewcode-block" id="palettize_weights"><a class="viewcode-back" href="../../../../source/coremltools.optimize.coreml.graph.html#coremltools.optimize.coreml._quantization_passes.palettize_weights">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;compression&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">palettize_weights</span><span class="p">(</span><span class="n">AbstractCompressionPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This transform works for each ``const`` op if:</span>

<span class="sd">    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.</span>
<span class="sd">    - ``_is_deprecated=False`` and the ``const`` value size ``&gt; weight_threshold``.</span>

<span class="sd">    The transform performs the following:</span>
<span class="sd">    </span>
<span class="sd">    - A linear look-up table (LUT) with 2\ :sup:`nbits` entries is created with values represented by indexing into this LUT.</span>
<span class="sd">    - If ``fake_compression=False``, compressed value is encoded using the ``constexpr_lut_to_dense`` op.</span>
<span class="sd">    - If ``fake_compression=True``,  compressed value is decompressed and then encoded using the ``const`` op.</span>
<span class="sd">    - Old ``const`` op is replaced by a newly created operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_SUPPORTED_CONFIG_TYPE</span> <span class="o">=</span> <span class="n">OpPalettizerConfig</span>

    <span class="k">def</span> <span class="nf">is_valid_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span> <span class="ow">and</span> <span class="n">should_use_weight_file</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compress</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">nbits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lut_function</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">compress_kmeans</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">):</span>
            <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">_get_kmeans_lookup_table_and_weight</span><span class="p">(</span><span class="n">nbits</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
            <span class="n">lut</span> <span class="o">=</span> <span class="n">lut</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span>

        <span class="k">def</span> <span class="nf">compress_uniform</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">val_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="n">val_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_max</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(((</span><span class="n">val</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">val_max</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">))</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">uint8</span>
            <span class="p">)</span>
            <span class="n">lut</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">))</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">val_min</span>
            <span class="n">lut</span> <span class="o">=</span> <span class="n">lut</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span>

        <span class="k">def</span> <span class="nf">get_nbits_for_unique_mode</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">nbits</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">nbits</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;weight value cannot be represented in an 8 bits palettization. Skipped.&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">def</span> <span class="nf">compress_unique</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Too many unique values </span><span class="si">{}</span><span class="s2"> in the weight. Couldn&#39;t represented in </span><span class="si">{}</span><span class="s2"> bits.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">),</span> <span class="n">nbits</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">lut</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">nbits</span><span class="p">)</span>
            <span class="n">lut</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)]</span> <span class="o">=</span> <span class="n">unique_vals</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">),))</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lut</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)]):</span>
                <span class="n">indices</span> <span class="o">+=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">val</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">indices</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;weight must be corresponding to one existing indice&quot;</span>

            <span class="n">lut</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lut</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span>

        <span class="k">def</span> <span class="nf">pack_indices_into_bytes_array</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">nbits</span><span class="p">):</span>
            <span class="n">bitarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unpackbits</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bitorder</span><span class="o">=</span><span class="s2">&quot;little&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="p">:</span><span class="n">nbits</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">packbits</span><span class="p">(</span><span class="n">bitarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bitorder</span><span class="o">=</span><span class="s2">&quot;little&quot;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">check_lut_parameters_are_valid</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lut</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;LUT and indices must be type of numpy array.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">indices</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">val</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Indices size (</span><span class="si">{}</span><span class="s2">) mismatched with the original weight(</span><span class="si">{}</span><span class="s2">).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">size</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">indices</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Indices must be a numpy vector of type uint8. Found shape </span><span class="si">{}</span><span class="s2"> with type </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">lut</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Dtype mismatched between LUT (</span><span class="si">{}</span><span class="s2">) and weight (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">lut</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Only numpy arrays are supported. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;KMEANS&quot;</span><span class="p">:</span>
            <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">compress_kmeans</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UNIFORM&quot;</span><span class="p">:</span>
            <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">compress_uniform</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UNIQUE&quot;</span><span class="p">:</span>
            <span class="n">nbits</span> <span class="o">=</span> <span class="n">get_nbits_for_unique_mode</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nbits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">compress_unique</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">nbits</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;CUSTOM&quot;</span><span class="p">:</span>
            <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">lut_function</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

        <span class="n">check_lut_parameters_are_valid</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">lut</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">LutParams</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">lut</span> <span class="o">=</span> <span class="n">lut</span>
        <span class="n">params</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">params</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">pack_indices_into_bytes_array</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">lut</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="k">return</span> <span class="n">params</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">decompress</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">LutParams</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid type of params&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">constexpr_lut_to_dense</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">lut</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="n">op_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_get_const_op_config</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">op_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">need_compress_const</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_is_deprecated</span><span class="p">,</span> <span class="n">op_config</span><span class="o">.</span><span class="n">weight_threshold</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">lut_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compress</span><span class="p">(</span>
            <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
            <span class="n">op_config</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">op_config</span><span class="o">.</span><span class="n">nbits</span><span class="p">,</span>
            <span class="n">op_config</span><span class="o">.</span><span class="n">lut_function</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">lut_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fake_compression</span><span class="p">:</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">constexpr_lut_to_dense</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">lut_params</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
                <span class="n">lut</span><span class="o">=</span><span class="n">lut_params</span><span class="o">.</span><span class="n">lut</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="n">lut_params</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_palettized&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">decompressed_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">lut_params</span><span class="p">)</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span>
                <span class="n">val</span><span class="o">=</span><span class="n">decompressed_val</span><span class="p">,</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_fake_palettized&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">op</span><span class="p">])</span></div>

<div class="viewcode-block" id="linear_quantize_weights"><a class="viewcode-back" href="../../../../source/coremltools.optimize.coreml.graph.html#coremltools.optimize.coreml._quantization_passes.linear_quantize_weights">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;compression&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">linear_quantize_weights</span><span class="p">(</span><span class="n">AbstractCompressionPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This transform works for each ``const`` op if:</span>

<span class="sd">    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.</span>
<span class="sd">    - ``_is_deprecated=False`` and the ``const`` value size ``&gt; weight_threshold``.</span>

<span class="sd">    The transform performs the following:</span>

<span class="sd">    - Values are linearly quantized into unsigned 8-bits.</span>
<span class="sd">    - If ``fake_compression=False``, compressed value is encoded using the ``constexpr_affine_dequantize`` op.</span>
<span class="sd">    - If ``fake_compression=True``, compressed value is decompressed and then encoded using the ``const`` op.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_SUPPORTED_CONFIG_TYPE</span> <span class="o">=</span> <span class="n">OpLinearQuantizerConfig</span>

    <span class="k">def</span> <span class="nf">is_valid_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;const&quot;</span> <span class="ow">and</span> <span class="n">should_use_weight_file</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_axis</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">child_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">var</span><span class="o">.</span><span class="n">child_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;conv_transpose&quot;</span><span class="p">:</span>
            <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">axis</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compress</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">_ensure_numerical_range_and_cast</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">np_dtype</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            For some cases, the computed quantized data might exceed the data range.</span>
<span class="sd">            For instance, after rounding and addition, we might get `128` for the int8 quantization.</span>
<span class="sd">            This utility function ensures the val in the data range before doing the cast.</span>
<span class="sd">            &#39;&#39;&#39;</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">low</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np_dtype</span><span class="p">)</span>

        <span class="n">mode_dtype_to_range</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">):</span> <span class="p">(</span><span class="o">-</span><span class="mi">128</span><span class="p">,</span> <span class="mi">127</span><span class="p">),</span>
            <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="s2">&quot;LINEAR_SYMMETRIC&quot;</span><span class="p">):</span> <span class="p">(</span><span class="o">-</span><span class="mi">127</span><span class="p">,</span> <span class="mi">127</span><span class="p">),</span>
            <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">):</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
            <span class="p">(</span><span class="n">types</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="s2">&quot;LINEAR_SYMMETRIC&quot;</span><span class="p">):</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">254</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only numpy arrays are supported&quot;</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">AffineQuantParams</span><span class="p">()</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">axis</span><span class="p">])</span>
        <span class="n">val_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">val_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR_SYMMETRIC&quot;</span><span class="p">:</span>
            <span class="c1"># For the linear_symmetric mode, the range is symmetrical to 0</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val_min</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val_max</span><span class="p">))</span>
            <span class="n">val_min</span> <span class="o">=</span> <span class="o">-</span><span class="n">max_abs</span>
            <span class="n">val_max</span> <span class="o">=</span> <span class="n">max_abs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span>
            <span class="c1"># For the linear mode, we need to make sure the data range contains `0`</span>
            <span class="n">val_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">val_min</span><span class="p">)</span>
            <span class="n">val_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">val_max</span><span class="p">)</span>

        <span class="n">q_val_min</span><span class="p">,</span> <span class="n">q_val_max</span> <span class="o">=</span> <span class="n">mode_dtype_to_range</span><span class="p">[(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">mode</span><span class="p">)]</span>

        <span class="c1"># Set the zero point to symmetric mode</span>
        <span class="n">np_dtype</span> <span class="o">=</span> <span class="n">nptype_from_builtin</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR_SYMMETRIC&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">types</span><span class="o">.</span><span class="n">int8</span><span class="p">:</span>
                <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">val_min</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">types</span><span class="o">.</span><span class="n">uint8</span>
                <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="p">(</span><span class="mi">127</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">val_min</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span>
            <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_val_min</span> <span class="o">*</span> <span class="n">val_max</span> <span class="o">-</span> <span class="n">q_val_max</span> <span class="o">*</span> <span class="n">val_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">val_max</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">)</span>
            <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">zero_point</span><span class="p">)</span>
            <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="n">_ensure_numerical_range_and_cast</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">zero_point</span><span class="p">,</span> <span class="n">q_val_min</span><span class="p">,</span> <span class="n">q_val_max</span><span class="p">,</span> <span class="n">np_dtype</span><span class="p">)</span>

        <span class="c1"># compute the params</span>
        <span class="n">params</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_max</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">q_val_max</span> <span class="o">-</span> <span class="n">q_val_min</span><span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
            <span class="n">val</span> <span class="o">*</span> <span class="p">(</span><span class="n">q_val_max</span> <span class="o">-</span> <span class="n">q_val_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">val_max</span> <span class="o">-</span> <span class="n">val_min</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span><span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">_ensure_numerical_range_and_cast</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span><span class="p">,</span> <span class="n">q_val_min</span><span class="p">,</span> <span class="n">q_val_max</span><span class="p">,</span> <span class="n">np_dtype</span><span class="p">)</span>

        <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

        <span class="k">return</span> <span class="n">params</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">decompress</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">AffineQuantParams</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid type of params&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">constexpr_affine_dequantize</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span>
            <span class="n">params</span><span class="o">.</span><span class="n">quantized_data</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">zero_point</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">axis</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="n">op_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_get_const_op_config</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">op_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">need_compress_const</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_is_deprecated</span><span class="p">,</span> <span class="n">op_config</span><span class="o">.</span><span class="n">weight_threshold</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">quant_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compress</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_axis</span><span class="p">(</span><span class="n">op</span><span class="p">),</span> <span class="n">op_config</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span> <span class="n">op_config</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fake_compression</span><span class="p">:</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">constexpr_affine_dequantize</span><span class="p">(</span>
                <span class="n">quantized_data</span><span class="o">=</span><span class="n">quant_params</span><span class="o">.</span><span class="n">quantized_data</span><span class="p">,</span>
                <span class="n">zero_point</span><span class="o">=</span><span class="n">quant_params</span><span class="o">.</span><span class="n">zero_point</span><span class="p">,</span>
                <span class="n">scale</span><span class="o">=</span><span class="n">quant_params</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span>
                <span class="n">axis</span><span class="o">=</span><span class="n">quant_params</span><span class="o">.</span><span class="n">axis</span><span class="p">,</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_affine_quantized&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">decompressed_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">quant_params</span><span class="p">)</span>
            <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span>
                <span class="n">val</span><span class="o">=</span><span class="n">decompressed_val</span><span class="p">,</span>
                <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_fake_affine_quantized&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">op</span><span class="p">])</span></div>

<div class="viewcode-block" id="WeightDecompressor"><a class="viewcode-back" href="../../../../source/coremltools.optimize.coreml.graph.html#coremltools.optimize.coreml._quantization_passes.WeightDecompressor">[docs]</a><span class="nd">@register_pass</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s2">&quot;compression&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">WeightDecompressor</span><span class="p">(</span><span class="n">AbstractQuantizationPass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This graph pass transforms the ``constexpr`` op back into ``mb.const`` op.</span>
<span class="sd">    The ``constexpr`` op includes:</span>

<span class="sd">    - ``constexpr_affine_dequantize``</span>
<span class="sd">    - ``constexpr_lut_to_dense``</span>
<span class="sd">    - ``constexpr_sparse_to_dense``</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_selector</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">op_selector</span><span class="o">=</span><span class="n">op_selector</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_valid_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">op</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="s2">&quot;constexpr_affine_dequantize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;constexpr_lut_to_dense&quot;</span><span class="p">,</span>
            <span class="s2">&quot;constexpr_sparse_to_dense&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
        <span class="n">decompressed_val</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">value_inference</span><span class="p">()</span>
        <span class="n">new_var</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">const</span><span class="p">(</span>
            <span class="n">val</span><span class="o">=</span><span class="n">decompressed_val</span><span class="p">,</span>
            <span class="n">before_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">replace_uses_of_var_after_op</span><span class="p">(</span>
            <span class="n">anchor_op</span><span class="o">=</span><span class="n">op</span><span class="p">,</span>
            <span class="n">old_var</span><span class="o">=</span><span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">no_check_var_types</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">force_replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">op</span><span class="o">.</span><span class="n">enclosing_block</span><span class="o">.</span><span class="n">remove_ops</span><span class="p">([</span><span class="n">op</span><span class="p">])</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>