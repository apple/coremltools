<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>coremltools.models.neural_network.builder &mdash; coremltools API Reference 8.0b1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/norightmargin.css?v=eea1f72d" />

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../../_static/documentation_options.js?v=d50bc636"></script>
        <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            coremltools API Reference
          </a>
              <div class="version">
                8.0b1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.models.html">Model APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.html">MIL Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.input_types.html">MIL Input Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.mil.ops.defs.html">MIL Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.converters.mil.mil.passes.defs.html">MIL Graph Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/coremltools.optimize.html">Optimizers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/docs-guides/index.html">Guide and Examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Format Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/api-versions.html">Previous Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">GitHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">coremltools API Reference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">coremltools.models.neural_network.builder</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for coremltools.models.neural_network.builder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2017, Apple Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Use of this source code is governed by a BSD-3-clause license that can be</span>
<span class="c1"># found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Neural network builder class to construct Core ML models.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">floor</span> <span class="k">as</span> <span class="n">_math_floor</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">_np</span>

<span class="kn">from</span> <span class="nn">...</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_MINIMUM_NDARRAY_SPEC_VERSION</span><span class="p">,</span>
    <span class="n">_MINIMUM_UPDATABLE_SPEC_VERSION</span><span class="p">,</span>
    <span class="n">_SPECIFICATION_VERSION_IOS_14</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">...</span> <span class="kn">import</span> <span class="n">SPECIFICATION_VERSION</span> <span class="k">as</span> <span class="n">_SPECIFICATION_VERSION</span>
<span class="kn">from</span> <span class="nn">...</span> <span class="kn">import</span> <span class="n">proto</span> <span class="k">as</span> <span class="n">_proto</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">datatypes</span>
<span class="kn">from</span> <span class="nn">.._interface_management</span> <span class="kn">import</span> <span class="n">set_training_features</span><span class="p">,</span> <span class="n">set_transform_interface_params</span>
<span class="kn">from</span> <span class="nn">.quantization_utils</span> <span class="kn">import</span> <span class="n">_convert_array_to_nbit_quantized_bytes</span><span class="p">,</span> <span class="n">_unpack_to_bytes</span>
<span class="kn">from</span> <span class="nn">.spec_inspection_utils</span> <span class="kn">import</span> <span class="n">_summarize_network_layer_info</span>
<span class="kn">from</span> <span class="nn">.update_optimizer_utils</span> <span class="kn">import</span> <span class="n">AdamParams</span><span class="p">,</span> <span class="n">SgdParams</span>

<span class="n">_SUPPORTED_UPDATABLE_LAYERS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;innerProduct&quot;</span><span class="p">,</span> <span class="s2">&quot;convolution&quot;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_set_recurrent_activation</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span>

    <span class="n">activation</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">activation</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">activation</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;SIGMOID&quot;</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;TANH&quot;</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">tanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;SIGMOID_HARD&quot;</span> <span class="ow">or</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;HARD_SIGMOID&quot;</span><span class="p">:</span>
        <span class="c1"># The standard name is &quot;hard_sigmoid&quot;, but in nn there are still usages of &quot;sigmoid_hard&quot;.</span>
        <span class="n">param</span><span class="o">.</span><span class="n">sigmoidHard</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;SCALED_TANH&quot;</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">scaledTanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;RELU&quot;</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">ReLU</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;Unsupported activation type with Recurrent layer: </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">activation</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_verify_quantization_arguments</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="nb">bytes</span><span class="p">(),</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">quantization_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quantization_type&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">nbits</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;nbits&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">quant_scale</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">quant_bias</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_bias&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">quant_lut</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_lut&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">int_8_dynamic_quantize</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;int_8_dynamic_quantize&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">int_8_dynamic_quantize</span> <span class="ow">and</span> <span class="n">nbits</span> <span class="o">!=</span> <span class="mi">8</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;nbits must be 8 when &#39;int_8_dynamic_quantize&#39; is true &quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">int_8_dynamic_quantize</span> <span class="ow">and</span> <span class="n">quant_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;quant_bias must be empty when &#39;int_8_dynamic_quantize&#39; is true &quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">int_8_dynamic_quantize</span> <span class="ow">and</span> <span class="n">quant_scale</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;quant_scale must be of size 1 when &#39;int_8_dynamic_quantize&#39; is true &quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Weight must be of type bytes() for quantization&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">quantization_type</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">int_8_dynamic_quantize</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quant_scale</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">quant_bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;quant_scale and quant_bias parameters must be provided for linear quantization type&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">quant_scale</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">quant_scale</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">quant_scale</span><span class="p">)</span> <span class="o">!=</span> <span class="n">output_channels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;quant_scale should be of type float or an array of length outputChannels&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">int_8_dynamic_quantize</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">_np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">quant_scale</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">quant_bias</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">quant_bias</span><span class="p">)</span> <span class="o">!=</span> <span class="n">output_channels</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;quant_bias should be of type float or an array of length outputChannels&quot;</span>
                <span class="p">)</span>
    <span class="k">elif</span> <span class="n">quantization_type</span> <span class="o">==</span> <span class="s2">&quot;lut&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">quant_lut</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;quant_lut must be provided for look up table quantization type&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">quant_lut</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">nbits</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;quant_lut must be an array of length 2^nbits&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;quantization_type must be either linear or lut&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">quantization_type</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span> <span class="ow">or</span> <span class="s2">&quot;lut&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">nbits</span> <span class="o">&gt;</span> <span class="mi">8</span> <span class="ow">or</span> <span class="n">nbits</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;nbits must be between 1 and 8&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_fill_quantized_weights</span><span class="p">(</span><span class="n">weights_message</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="nb">bytes</span><span class="p">(),</span> <span class="n">use_int_8</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">use_int_8</span><span class="p">:</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">int8RawValue</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">()</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">int8RawValue</span> <span class="o">+=</span> <span class="n">W</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">rawValue</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">()</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">rawValue</span> <span class="o">+=</span> <span class="n">W</span>
    <span class="n">nbits</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;nbits&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">weights_message</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">numberOfBits</span> <span class="o">=</span> <span class="n">nbits</span>
    <span class="n">quantization_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quantization_type&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">quantization_type</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
        <span class="n">quant_scale</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_scale&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">])</span>
        <span class="n">quant_bias</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_bias&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">])</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">linearQuantization</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">quant_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_int_8</span><span class="p">:</span>
            <span class="n">weights_message</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">linearQuantization</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">quant_bias</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">quant_lut</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;quant_lut&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
        <span class="n">weights_message</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">lookupTableQuantization</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="n">quant_lut</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_nn_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;neuralNetworkClassifier&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span><span class="o">.</span><span class="n">neuralNetworkClassifier</span>
    <span class="k">elif</span> <span class="n">spec</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;neuralNetworkRegressor&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span><span class="o">.</span><span class="n">neuralNetworkRegressor</span>
    <span class="k">elif</span> <span class="n">spec</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;neuralNetwork&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">spec</span><span class="o">.</span><span class="n">neuralNetwork</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_get_lstm_weight_fields</span><span class="p">(</span><span class="n">lstm_wp</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get LSTM weight fields.</span>
<span class="sd">    lstm_wp: _proto.NeuralNetwork_pb2.LSTMWeightParams</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGateWeightMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">blockInputWeightMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateRecursionMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGateRecursionMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">blockInputRecursionMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateBiasVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGateBiasVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">blockInputBiasVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGatePeepholeVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGatePeepholeVector</span><span class="p">,</span>
        <span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGatePeepholeVector</span><span class="p">,</span>
    <span class="p">]</span>


<span class="k">def</span> <span class="nf">_fill_tensor_fields</span><span class="p">(</span><span class="n">tensor_field</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shapes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fill the tensor fields.</span>
<span class="sd">    ranks - ``NONE`` or a list of integers with the same length of number of inputs/outputs</span>
<span class="sd">    shapes - ``NONE`` or a list of shapes the same length of number of inputs/outputs. Each shape is a list or tuple</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ranks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shapes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">if</span> <span class="n">ranks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ranks</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">]</span>

    <span class="c1"># Fill ranks only</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">rank</span><span class="p">),</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">_np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># Variable rank set to -1</span>

        <span class="n">field</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">field</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>

    <span class="k">if</span> <span class="n">ranks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of rank and shape of tensor field does not match.&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">ranks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Ignore incomplete info</span>
            <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Raise error on inconsistent input</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Rank and shape does not match&quot;</span><span class="p">)</span>

            <span class="c1"># Add the shape to the proto</span>
            <span class="n">is_symbolic</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">_np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
                    <span class="n">s</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># Symbolic shape set to -1</span>
                <span class="n">tensor_field</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dimValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>


<div class="viewcode-block" id="NeuralNetworkBuilder">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder">[docs]</a>
<span class="k">class</span> <span class="nc">NeuralNetworkBuilder</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural network builder class to construct Core ML models.</span>

<span class="sd">    The NeuralNetworkBuilder constructs a Core ML neural network specification</span>
<span class="sd">    layer by layer. The layers should be added in such an order that the inputs</span>
<span class="sd">    to each layer (referred to as blobs of each layer) have been previously</span>
<span class="sd">    defined. The builder can also set preprocessing steps to handle</span>
<span class="sd">    specialized input formats (such as images), and set class labels for neural</span>
<span class="sd">    network classifiers.</span>

<span class="sd">    Refer to the protobuf messages in the specification (NeuralNetwork.proto)</span>
<span class="sd">    for more details.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. sourcecode:: python</span>

<span class="sd">        import numpy as np</span>

<span class="sd">        from coremltools.models import datatypes</span>
<span class="sd">        from coremltools.models.neural_network import NeuralNetworkBuilder</span>
<span class="sd">        from coremltools.models.utils import save_spec</span>

<span class="sd">        # Create a neural network binary classifier that classifies</span>
<span class="sd">        # 3-dimensional data points</span>
<span class="sd">        # Specify input and output dimensions</span>
<span class="sd">        input_dim = (3,)</span>
<span class="sd">        output_dim = (2,)</span>

<span class="sd">        # Specify input and output features</span>
<span class="sd">        input_features = [(&quot;data&quot;, datatypes.Array(*input_dim))]</span>
<span class="sd">        output_features = [(&quot;probs&quot;, datatypes.Array(*output_dim))]</span>

<span class="sd">        # Create random weights and bias</span>
<span class="sd">        weights = np.random.rand(2, 3)</span>
<span class="sd">        bias = np.random.rand(2)</span>

<span class="sd">        # Build a simple neural network with 1 inner product layer</span>
<span class="sd">        builder = NeuralNetworkBuilder(input_features, output_features)</span>
<span class="sd">        builder.add_inner_product(</span>
<span class="sd">            name=&quot;ip_layer&quot;,</span>
<span class="sd">            W=weights,</span>
<span class="sd">            b=bias,</span>
<span class="sd">            input_channels=3,</span>
<span class="sd">            output_channels=2,</span>
<span class="sd">            has_bias=True,</span>
<span class="sd">            input_name=&quot;data&quot;,</span>
<span class="sd">            output_name=&quot;probs&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        # save the spec by the builder</span>
<span class="sd">        save_spec(builder.spec, &quot;network.mlmodel&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="NeuralNetworkBuilder.__init__">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">nn_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">disable_rank5_shape_mapping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">training_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">use_float_arraytype</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct a NeuralNetworkBuilder object to build an MLModel specification with a</span>
<span class="sd">        model interface, or a NeuralNetwork protobuf message, either from scratch or using an</span>
<span class="sd">        existing specification.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        input_features: [(str, datatypes.Array)] or None</span>
<span class="sd">            List of input feature of the network.</span>
<span class="sd">            Each feature is a ``(name, array)`` tuple, where ``name`` is the</span>
<span class="sd">            name of the feature, and ``array`` is a ``datatype.Array`` object</span>
<span class="sd">            describing the feature type.</span>

<span class="sd">            * When ``spec`` is ``None`` (building from scratch), ``input_features`` must not be ``None``.</span>

<span class="sd">        output_features: [(str, datatypes.Array or None)] or None</span>
<span class="sd">            List of output feature of the network. Each feature is a</span>
<span class="sd">            ``(name, array)`` tuple, where ``name`` is the name of the feature,</span>
<span class="sd">            and ``array`` is a ``datatypes.Array`` object describing the feature type.</span>

<span class="sd">            * The ``array`` can be ``None`` if not known.</span>

<span class="sd">            * When ``spec`` is ``None`` (building from scratch), ``output_features`` must not be ``None``.</span>

<span class="sd">        mode: str (&#39;classifier&#39;, &#39;regressor&#39; or None)</span>
<span class="sd">            Mode (one of ``&#39;classifier&#39;``, ``&#39;regressor&#39;``, or ``None``).</span>

<span class="sd">            When ``mode = &#39;classifier&#39;``, a NeuralNetworkClassifier spec will be</span>
<span class="sd">            constructed.  When ``mode = &#39;regressor&#39;``, a NeuralNetworkRegressor</span>
<span class="sd">            spec will be constructed.</span>

<span class="sd">        disable_rank5_shape_mapping: bool</span>
<span class="sd">            Only applicable for neural networks.</span>

<span class="sd">            If True, inputs are no longer forced to map to rank 5 tensors</span>
<span class="sd">            (rank is equal to the length of the shape of the tensor).</span>
<span class="sd">            Instead, for multi-array inputs ``&quot;EXACT_ARRAY_MAPPING&quot;`` mapping is used, whereas</span>
<span class="sd">            for image inputs ``&quot;RANK4_IMAGE_MAPPING&quot;`` is used. For details,</span>
<span class="sd">            see description of enums ``NeuralNetworkMultiArrayShapeMapping``</span>
<span class="sd">            and ``NeuralNetworkImageShapeMapping`` in NeuralNetwork.proto.</span>

<span class="sd">            When ``spec`` is not ``None``, this argument will be ignored.</span>

<span class="sd">        spec: None or coremltools.proto.Model_pb2</span>
<span class="sd">            If ``None``, a new MLModel spec will be created by the builder with</span>
<span class="sd">            input and output features.</span>

<span class="sd">            Otherwise, the builder will continue to build on ``spec``.</span>
<span class="sd">            This is useful when the MLModel is built incrementally.</span>

<span class="sd">        nn_spec: None or coremltools.proto.NeuralNetwork_pb2</span>
<span class="sd">            If ``None``, a new, empty NeuralNetwork proto will be created for spec.</span>

<span class="sd">            If ``nn_spec`` is not ``None`` and ``spec`` is ``None``, the builder will</span>
<span class="sd">            build a NeuralNetwork spec without wrapping it within an MLModel.</span>
<span class="sd">            This is useful to create nested NeuralNetworks for models</span>
<span class="sd">            with control flow operations.</span>

<span class="sd">        use_float_arraytype: bool</span>
<span class="sd">            If true, the datatype of input/output multiarrays is set to Float32 instead</span>
<span class="sd">            of double.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. sourcecode:: python</span>

<span class="sd">            # Construct a builder that builds a neural network classifier with a 299 x 299 x 3</span>
<span class="sd">            # dimensional input and 1000 dimensional output</span>
<span class="sd">            input_features = [(&quot;data&quot;, datatypes.Array((299, 299, 3)))]</span>
<span class="sd">            output_features = [(&quot;probs&quot;, datatypes.Array((1000,)))]</span>
<span class="sd">            builder = NeuralNetworkBuilder(input_features, output_features, mode=&quot;classifier&quot;)</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_input, set_output, set_class_labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="o">=</span> <span class="n">nn_spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_disable_rank5_shape_mapping</span> <span class="o">=</span> <span class="n">disable_rank5_shape_mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Existing spec</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="o">=</span> <span class="n">_get_nn_spec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">layer_spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_spec</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">layer_spec</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer_spec</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Both spec and nn_spec are not None</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Attempting to assign another NeuralNetwork Spec to an existing MLModel Spec&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">input_features</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">output_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>  <span class="c1"># Building nested Neural Network</span>
            <span class="k">return</span>

        <span class="c1"># Set the interface params.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION</span>
        <span class="k">if</span> <span class="n">disable_rank5_shape_mapping</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_MINIMUM_NDARRAY_SPEC_VERSION</span>

        <span class="c1"># When output_features in None, use some dummy sized type</span>
        <span class="n">out_features_with_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">out_feature</span> <span class="ow">in</span> <span class="n">output_features</span><span class="p">:</span>
            <span class="n">feat_name</span><span class="p">,</span> <span class="n">feat_type</span> <span class="o">=</span> <span class="n">out_feature</span>
            <span class="k">if</span> <span class="n">feat_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out_features_with_shape</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">str</span><span class="p">(</span><span class="n">feat_name</span><span class="p">),</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out_features_with_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_feature</span><span class="p">)</span>

        <span class="c1"># Set interface inputs and outputs</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[:]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[:]</span>

        <span class="k">if</span> <span class="n">use_float_arraytype</span><span class="p">:</span>
            <span class="n">array_datatype</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">FLOAT32</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">array_datatype</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">set_transform_interface_params</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">input_features</span><span class="p">,</span>
            <span class="n">out_features_with_shape</span><span class="p">,</span>
            <span class="n">training_features</span><span class="o">=</span><span class="n">training_features</span><span class="p">,</span>
            <span class="n">array_datatype</span><span class="o">=</span><span class="n">array_datatype</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_features</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dimensions</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output_feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">output_features</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span>
                    <span class="s2">&quot;shape&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;classifier&quot;</span><span class="p">:</span>
                <span class="n">nn_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">neuralNetworkClassifier</span>
            <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;regressor&quot;</span><span class="p">:</span>
                <span class="n">nn_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">neuralNetworkRegressor</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nn_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">neuralNetwork</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span> <span class="o">=</span> <span class="n">nn_spec</span>

        <span class="k">if</span> <span class="n">disable_rank5_shape_mapping</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">arrayInputShapeMapping</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">NeuralNetworkMultiArrayShapeMapping</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;EXACT_ARRAY_MAPPING&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">imageInputShapeMapping</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">NeuralNetworkImageShapeMapping</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;RANK4_IMAGE_MAPPING&quot;</span><span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_input">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_input">[docs]</a>
    <span class="k">def</span> <span class="nf">set_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">input_dims</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the inputs of the network spec.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input names of the network.</span>

<span class="sd">        input_dims: [tuple]</span>
<span class="sd">            The input dimensions of the network. The ordering of ``input_dims``</span>
<span class="sd">            is the same as ``input_names``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. sourcecode:: python</span>

<span class="sd">            # Set the neural network spec inputs to be 3 dimensional vector data1 and</span>
<span class="sd">            # 4 dimensional vector data2.</span>
<span class="sd">            builder.set_input(input_names=[&quot;data1&quot;, &quot;data2&quot;], input_dims=[(3,), (4,)])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_output, set_class_labels</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;input_names and input_dims must be of the same sizes.&quot;</span><span class="p">)</span>

        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_dims</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_disable_rank5_shape_mapping&quot;</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_disable_rank5_shape_mapping</span>
            <span class="p">):</span>
                <span class="n">input_shape</span> <span class="o">=</span> <span class="n">dim</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">dim</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Attempting to add a neural network &quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;input with rank &quot;</span>
                        <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
                        <span class="o">+</span> <span class="s2">&quot;. All networks should take inputs of rank 1 or 3.&quot;</span>
                    <span class="p">)</span>

            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

            <span class="c1"># TODO: if it&#39;s an embedding, this should be integer</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span>
                <span class="n">idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span>

            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">input_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_output">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_output">[docs]</a>
    <span class="k">def</span> <span class="nf">set_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">output_dims</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the outputs of the network spec.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output names of the network.</span>

<span class="sd">        output_dims: [tuple]</span>
<span class="sd">            The output dimensions of the network. The ordering of ``output_dims`` is the same</span>
<span class="sd">            as ``output_names``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. sourcecode:: python</span>

<span class="sd">            # Set the neural network spec outputs to be 3 dimensional vector feature1 and</span>
<span class="sd">            # 4 dimensional vector feature2.</span>
<span class="sd">            builder.set_output(output_names=[&quot;feature1&quot;, &quot;feature2&quot;], output_dims=[(3,), (4,)])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_input, set_class_labels</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_dims</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;output_names and output_dims must be of the same sizes.&quot;</span><span class="p">)</span>

        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_dims</span><span class="p">):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span>
                <span class="n">idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span>

            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">output_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_training_input">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_training_input">[docs]</a>
    <span class="k">def</span> <span class="nf">set_training_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_input</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the training inputs of the network spec.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        training_input: [tuple]</span>
<span class="sd">            The training input names and type of the network.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. sourcecode:: python</span>

<span class="sd">            # Set the neural network spec training inputs to be 3 dimensional vector for &#39;input&#39; and</span>
<span class="sd">            # Double for &#39;target&#39;.</span>
<span class="sd">            builder.set_training_input([(&quot;input&quot;, datatypes.Array(3)), (&quot;target&quot;, &quot;Double&quot;)])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
        <span class="n">set_training_features</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">training_input</span><span class="p">)</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_class_labels">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_class_labels">[docs]</a>
    <span class="k">def</span> <span class="nf">set_class_labels</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">class_labels</span><span class="p">,</span> <span class="n">predicted_feature_name</span><span class="o">=</span><span class="s2">&quot;classLabel&quot;</span><span class="p">,</span> <span class="n">prediction_blob</span><span class="o">=</span><span class="s2">&quot;&quot;</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set class labels to the model spec to make it a neural network classifier.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        class_labels: list of int or list of str</span>
<span class="sd">            A list of integers or strings that map the index of the output of a</span>
<span class="sd">            neural network to labels in a classifier.</span>

<span class="sd">        predicted_feature_name: str</span>
<span class="sd">            Name of the output feature for the class labels exposed in the</span>
<span class="sd">            Core ML neural network classifier, defaults: ``&#39;classLabel&#39;``.</span>

<span class="sd">        prediction_blob: str</span>
<span class="sd">            If provided, then this is the name of the neural network blob which</span>
<span class="sd">            generates the probabilities for each class label (typically the output</span>
<span class="sd">            of a softmax layer). If not provided, then the last output layer is</span>
<span class="sd">            assumed.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_input, set_output, set_pre_processing_parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
        <span class="n">nn_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Model should have at least one output (the probabilities) to automatically make it a classifier.&quot;</span>
            <span class="p">)</span>
        <span class="n">probOutput</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">probOutput</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">dictionaryType</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">class_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">class_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">class_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Class labels must be of type Integer or String. (not </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">class_type</span>
            <span class="p">)</span>

        <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">predictedProbabilitiesName</span> <span class="o">=</span> <span class="n">probOutput</span><span class="o">.</span><span class="n">name</span>
        <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">predictedFeatureName</span> <span class="o">=</span> <span class="n">predicted_feature_name</span>

        <span class="n">classLabel</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">classLabel</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">predicted_feature_name</span>
        <span class="k">if</span> <span class="n">class_type</span> <span class="o">==</span> <span class="nb">int</span><span class="p">:</span>
            <span class="n">nn_spec</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span><span class="s2">&quot;int64ClassLabels&quot;</span><span class="p">)</span>
            <span class="n">probOutput</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">dictionaryType</span><span class="o">.</span><span class="n">int64KeyType</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="n">classLabel</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">int64Type</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">class_labels</span><span class="p">:</span>
                <span class="n">nn_spec</span><span class="o">.</span><span class="n">int64ClassLabels</span><span class="o">.</span><span class="n">vector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nn_spec</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span><span class="s2">&quot;stringClassLabels&quot;</span><span class="p">)</span>
            <span class="n">probOutput</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">dictionaryType</span><span class="o">.</span><span class="n">stringKeyType</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="n">classLabel</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">stringType</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">class_labels</span><span class="p">:</span>
                <span class="n">nn_spec</span><span class="o">.</span><span class="n">stringClassLabels</span><span class="o">.</span><span class="n">vector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">prediction_blob</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="c1"># correctness here will be checked in the validator -- i.e. to</span>
            <span class="c1"># make sure this string corresponds to a real blob</span>
            <span class="n">nn_spec</span><span class="o">.</span><span class="n">labelProbabilityLayerName</span> <span class="o">=</span> <span class="n">prediction_blob</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># not provided</span>
            <span class="c1"># assume it&#39;s the last blob produced in the network</span>
            <span class="n">nn_spec</span><span class="o">.</span><span class="n">labelProbabilityLayerName</span> <span class="o">=</span> <span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_optional_input">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_optional_input">[docs]</a>
    <span class="k">def</span> <span class="nf">set_optional_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_idx</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Marks given input as optional input.</span>
<span class="sd">        Optionally, sets default value for optional input if value is not ``None``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_idx: int</span>
<span class="sd">            Index of input to be marked and fill with default value.</span>
<span class="sd">        value: int/double/float/None</span>
<span class="sd">            Value to be fill as default value.</span>
<span class="sd">        format: str</span>
<span class="sd">            Format of default value.</span>
<span class="sd">            Must be one of ``&#39;float&#39;``, ``&#39;double&#39;``, or ``&#39;int&#39;``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">input_idx</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot; out of &quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">))</span>
                <span class="o">+</span> <span class="s2">&quot; inputs!&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting invalid input as optional! </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msg</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">input_idx</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">isOptional</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># Default value is supported from CoreML 4 onwards.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span><span class="p">,</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">)</span>
        <span class="nb">format</span> <span class="o">=</span> <span class="nb">format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span>
                <span class="n">input_idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">floatDefaultValue</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;double&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span>
                <span class="n">input_idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">doubleDefaultValue</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span>
                <span class="n">input_idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">intDefaultValue</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Incorrect format for optional inputs! Expecting int/float/double, got </span><span class="si">{}</span><span class="s2">!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">format</span>
                <span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_optionals">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_optionals">[docs]</a>
    <span class="k">def</span> <span class="nf">add_optionals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optionals_in</span><span class="p">,</span> <span class="n">optionals_out</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add optional inputs and outputs to the model spec.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optionals_in: list of str</span>
<span class="sd">            List of inputs that are optionals.</span>

<span class="sd">        optionals_out: list of str</span>
<span class="sd">            List of outputs that are optionals.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_input, set_output</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">optionals_in</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">optionals_out</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">input_types</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="o">*</span><span class="n">dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="n">optionals_in</span>
        <span class="p">]</span>
        <span class="n">output_types</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">optionals_out</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">dim</span><span class="p">:</span>
                <span class="n">output_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">output_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="o">*</span><span class="n">dim</span><span class="p">))</span>

        <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="n">optionals_in</span><span class="p">]</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="n">optionals_out</span><span class="p">]</span>

        <span class="n">input_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">input_types</span><span class="p">))</span>
        <span class="n">output_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">output_names</span><span class="p">,</span> <span class="n">output_types</span><span class="p">))</span>

        <span class="n">len_before_in</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">len_before_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="c1"># this appends to the existing model interface</span>
        <span class="n">set_transform_interface_params</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">input_features</span><span class="p">,</span> <span class="n">output_features</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># add types for any extra hidden inputs</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_before_in</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">[</span>
                <span class="n">idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_before_out</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">)):</span>
            <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">[</span>
                <span class="n">idx</span>
            <span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span></div>



    <span class="k">def</span> <span class="nf">_check_fp16_weight_params_lstms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lstm_wp</span><span class="p">,</span> <span class="n">has_peephole</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if an LSTM layer has at least one ``weight_param`` which is in FP16 format.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lstm_wp: LSTM weights.</span>
<span class="sd">        has_peephole: if the LSTM has a peephole.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGateWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">blockInputWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateRecursionMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGateRecursionMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">blockInputRecursionMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">has_peephole</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">inputGatePeepholeVector</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">forgetGatePeepholeVector</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">.</span><span class="n">outputGatePeepholeVector</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>


    <span class="k">def</span> <span class="nf">_check_fp16_weight_param_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if the network has at least one ``weight_param`` which is in FP16 format.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        layers: list of nn_spec.layer</span>
<span class="sd">            List of layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="n">layer_type</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">)</span>

            <span class="c1"># Convolution</span>
            <span class="k">if</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;convolution&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">convolution</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">convolution</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">convolution</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="c1"># Batchnorm</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;batchnorm&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">batchnorm</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># InnerProduct</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;innerProduct&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">innerProduct</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">innerProduct</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">innerProduct</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># BatchedMatmul</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;batchedMatmul&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">batchedMatmul</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">batchedMatmul</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">batchedMatmul</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># Embedding layer</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;embedding&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># Embedding ND layer</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;embeddingND&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">embeddingND</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">embeddingND</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">embeddingND</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># Scale layer</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;scale&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">shapeScale</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">hasBias</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># Bias layer</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># LoadConstant layer</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;loadConstant&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">loadConstant</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># Simple Recurrent</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;simpleRecurrent&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">simpleRecurrent</span><span class="o">.</span><span class="n">weightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">simpleRecurrent</span><span class="o">.</span><span class="n">hasBiasVector</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">simpleRecurrent</span><span class="o">.</span><span class="n">biasVector</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># GRU</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;gru&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">gru</span><span class="o">.</span><span class="n">updateGateWeightMatrix</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">gru</span><span class="o">.</span><span class="n">hasBiasVectors</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">gru</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># uniDirectionalLSTM Layers</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;uniDirectionalLSTM&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_fp16_weight_params_lstms</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">uniDirectionalLSTM</span><span class="o">.</span><span class="n">weightParams</span><span class="p">,</span>
                                                            <span class="n">has_peephole</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">uniDirectionalLSTM</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">hasPeepholeVectors</span><span class="p">)</span>

            <span class="c1"># biDirectionalLSTM Layers</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;biDirectionalLSTM&quot;</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">lstm_wp</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">biDirectionalLSTM</span><span class="o">.</span><span class="n">weightParams</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_fp16_weight_params_lstms</span><span class="p">(</span><span class="n">lstm_wp</span><span class="o">=</span><span class="n">lstm_wp</span><span class="p">,</span>
                                                            <span class="n">has_peephole</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">biDirectionalLSTM</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">hasPeepholeVectors</span><span class="p">):</span>
                        <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># branch Layers</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;branch&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">branch</span><span class="o">.</span><span class="n">ifBranch</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">branch</span><span class="o">.</span><span class="n">elseBranch</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="c1"># loop Layers</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;loop&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">loop</span><span class="o">.</span><span class="n">conditionNetwork</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">loop</span><span class="o">.</span><span class="n">bodyNetwork</span><span class="o">.</span><span class="n">float16Value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>

            <span class="k">return</span> <span class="kc">False</span>

<div class="viewcode-block" id="NeuralNetworkBuilder.make_updatable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.make_updatable">[docs]</a>
    <span class="k">def</span> <span class="nf">make_updatable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainables</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make the builder&#39;s NeuralNetwork spec updatable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        trainables: list of str</span>
<span class="sd">            List of layer names to be set trainable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># check if any layer weights/biases is in FP16 format</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_fp16_weight_param_exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;This model has at least one layer with FP16 weights or bias formats. These networks will &quot;</span>
                             <span class="s2">&quot;always be optimized to a full FP16 model format which is not supported to be marked &quot;</span>
                             <span class="s2">&quot;updatable. Either make sure the model has no FP16 WeightParams or split the &quot;</span>
                             <span class="s2">&quot;network to two models with updatable part of the model as a separate model with no FP16 &quot;</span>
                             <span class="s2">&quot;WeightParams. Note that updatable pipelines model can only have the last sub model marked &quot;</span>
                             <span class="s2">&quot;as updatable.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">isUpdatable</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_MINIMUM_UPDATABLE_SPEC_VERSION</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_MINIMUM_UPDATABLE_SPEC_VERSION</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_shuffle</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">trainable</span> <span class="ow">in</span> <span class="n">trainables</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">trainable</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> does not exist.&quot;</span> <span class="o">%</span> <span class="n">trainable</span><span class="p">)</span>
            <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">trainable</span><span class="p">]</span>
            <span class="n">spec_layer_type</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">spec_layer_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SUPPORTED_UPDATABLE_LAYERS</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> is not supported to be marked as updatable. Only </span><span class="si">%s</span><span class="s2"> layers &quot;</span>
                    <span class="s2">&quot;are supported to be marked updatable.&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">trainable</span><span class="p">,</span> <span class="n">_SUPPORTED_UPDATABLE_LAYERS</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">isUpdatable</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">typed_layer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">spec_layer</span><span class="p">,</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">fd</span> <span class="ow">in</span> <span class="n">typed_layer</span><span class="o">.</span><span class="n">DESCRIPTOR</span><span class="o">.</span><span class="n">fields</span><span class="p">:</span>
                <span class="n">field</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">typed_layer</span><span class="p">,</span> <span class="n">fd</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">field</span><span class="p">)</span> <span class="o">==</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">LSTMWeightParams</span><span class="p">:</span>
                    <span class="n">wfs</span> <span class="o">=</span> <span class="n">_get_lstm_weight_fields</span><span class="p">(</span><span class="n">field</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">wf</span> <span class="ow">in</span> <span class="n">wfs</span><span class="p">:</span>
                        <span class="n">wf</span><span class="o">.</span><span class="n">isUpdatable</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">field</span><span class="p">)</span> <span class="o">==</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">:</span>
                    <span class="n">field</span><span class="o">.</span><span class="n">isUpdatable</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">pass</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_categorical_cross_entropy_loss">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_categorical_cross_entropy_loss">[docs]</a>
    <span class="k">def</span> <span class="nf">set_categorical_cross_entropy_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Categorical Cross Entropy is used for single label categorization</span>
<span class="sd">        (only one category is applicable for each data point).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: The name of the loss layer</span>
<span class="sd">        input: The name of the input</span>
<span class="sd">                The ``input`` should be a vector of length N representing the</span>
<span class="sd">                distribution over N categories. This must be the output of a softmax.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>

<span class="sd">        .. math::</span>
<span class="sd">           Loss_ {CCE}(input, target) = -\sum_{i = 1} ^ {N}(target == i) log(input[i]) = - log(input[target])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Name </span><span class="si">%s</span><span class="s2"> is already used.&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss Layer input must be specified&quot;</span><span class="p">)</span>

        <span class="n">target</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">+</span> <span class="s2">&quot;_true&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss layer (</span><span class="si">%s</span><span class="s2">) cannot be attached to an empty model.&quot;</span> <span class="o">%</span> <span class="n">name</span>
            <span class="p">)</span>

        <span class="c1"># validate input</span>
        <span class="c1"># input must be a softmax layer output</span>
        <span class="n">input_validated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">layer_outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
            <span class="n">layer_type</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">layer_outputs</span> <span class="ow">and</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s2">&quot;softmax&quot;</span><span class="p">:</span>
                <span class="n">input_validated</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">input_validated</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Categorical Cross Entropy loss layer input (</span><span class="si">%s</span><span class="s2">) must be a softmax layer output.&quot;</span>
                <span class="o">%</span> <span class="nb">input</span>
            <span class="p">)</span>

        <span class="c1"># validate target</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">output_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss layer target (</span><span class="si">%s</span><span class="s2">) must not be a model output.&quot;</span> <span class="o">%</span> <span class="n">target</span>
            <span class="p">)</span>

        <span class="n">updating_classifier</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">predicted_probabilities_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">predictedProbabilitiesName</span>
        <span class="n">predicted_feature_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">predictedFeatureName</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;neuralNetworkClassifier&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">input</span> <span class="o">==</span> <span class="n">predicted_probabilities_name</span>
        <span class="p">):</span>
            <span class="n">updating_classifier</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">loss_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">lossLayers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_layer</span>
        <span class="n">loss_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">loss_layer</span><span class="o">.</span><span class="n">categoricalCrossEntropyLossLayer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="n">loss_layer</span><span class="o">.</span><span class="n">categoricalCrossEntropyLossLayer</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>

        <span class="n">training_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">trainingInput</span>
        <span class="n">training_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">training_input</span> <span class="o">=</span> <span class="n">training_inputs</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">updating_classifier</span><span class="p">:</span>
            <span class="n">training_input</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">predicted_feature_name</span>
            <span class="n">classifier_output_type</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">x</span><span class="o">.</span><span class="n">type</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span>
                <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">predicted_feature_name</span>
            <span class="p">]</span>

            <span class="n">model_type</span> <span class="o">=</span> <span class="n">classifier_output_type</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;Type&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;stringType&quot;</span><span class="p">:</span>
                <span class="n">datatypes</span><span class="o">.</span><span class="n">_set_datatype</span><span class="p">(</span><span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">String</span><span class="p">())</span>
            <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;int64Type&quot;</span><span class="p">:</span>
                <span class="n">datatypes</span><span class="o">.</span><span class="n">_set_datatype</span><span class="p">(</span><span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">Int64</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">training_input</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">target</span>
            <span class="n">datatypes</span><span class="o">.</span><span class="n">_set_datatype</span><span class="p">(</span><span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">INT32</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Now adding input </span><span class="si">{}</span><span class="s2"> as target for categorical cross-entropy loss layer.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">target</span>
            <span class="p">)</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_mean_squared_error_loss">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_mean_squared_error_loss">[docs]</a>
    <span class="k">def</span> <span class="nf">set_mean_squared_error_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_feature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        input_feature: [(str, datatypes.Array)] or None</span>
<span class="sd">            The input feature of the loss layer. Each feature is a</span>
<span class="sd">            ``(name, array)`` tuple, where ``name`` is the name of the model&#39;s</span>
<span class="sd">            tensor our loss will be attached to, and ``array`` is a</span>
<span class="sd">            ``datatypes.Array`` object describing the shape of that tensor.</span>
<span class="sd">            Both the name and the array&#39;s shape must be provided in the tuple.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">            feature = [(&#39;output_tensor&#39;, datatypes.Array((299, 299, 3)))]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Name </span><span class="si">%s</span><span class="s2"> is already used.&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss Layer input must be specified&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_feature</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss layer input must be a tuple of type (string, datatype)&quot;</span>
            <span class="p">)</span>

        <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">ftype</span><span class="p">)</span> <span class="o">=</span> <span class="n">input_feature</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss layer input must be a tuple of type (string, datatype)&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ftype</span><span class="p">,</span> <span class="n">datatypes</span><span class="o">.</span><span class="n">Array</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss layer input must be a tuple of type (string, datatype)&quot;</span>
            <span class="p">)</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">fname</span> <span class="o">+</span> <span class="s2">&quot;_true&quot;</span>

        <span class="n">loss_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">lossLayers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_layer</span>
        <span class="n">loss_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">output_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Loss Layer target (</span><span class="si">%s</span><span class="s2">) must not be a model output&quot;</span> <span class="o">%</span> <span class="n">target</span>
            <span class="p">)</span>

        <span class="n">loss_layer</span><span class="o">.</span><span class="n">meanSquaredErrorLossLayer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">input_feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss_layer</span><span class="o">.</span><span class="n">meanSquaredErrorLossLayer</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>

        <span class="n">training_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">trainingInput</span>
        <span class="n">training_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">training_input</span> <span class="o">=</span> <span class="n">training_inputs</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">training_input</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">target</span>

        <span class="n">datatypes</span><span class="o">.</span><span class="n">_set_datatype</span><span class="p">(</span><span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">input_feature</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">training_input</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">Model_pb2</span><span class="o">.</span><span class="n">ArrayFeatureType</span><span class="o">.</span><span class="n">DOUBLE</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Now adding input </span><span class="si">{}</span><span class="s2"> as target for mean squared error loss layer.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">target</span>
            <span class="p">)</span>
        <span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">set_sgd_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sgd_params</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sgd_params</span><span class="p">,</span> <span class="n">SgdParams</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;sgd_params must be of instance SgdParams&quot;</span><span class="p">)</span>

        <span class="n">sgd_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">sgdOptimizer</span>

        <span class="c1"># set learning rate</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">value</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">min</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">max</span>

        <span class="c1"># set mini batch size</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">miniBatchSize</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">value</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">miniBatchSize</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sgd_params</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">allowed_set</span><span class="p">)</span>

        <span class="c1"># set momentum</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">value</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">min</span>
        <span class="n">sgd_optimizer</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">sgd_params</span><span class="o">.</span><span class="n">momentum</span><span class="o">.</span><span class="n">max</span>

    <span class="k">def</span> <span class="nf">set_adam_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adam_params</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adam_params</span><span class="p">,</span> <span class="n">AdamParams</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;adam_params must be of instance AdamParams&quot;</span><span class="p">)</span>

        <span class="n">adam_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span>

        <span class="c1"># set learning rate</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">value</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">min</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">learningRate</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">max</span>

        <span class="c1"># set mini batch size</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">miniBatchSize</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">value</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">miniBatchSize</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">adam_params</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">allowed_set</span><span class="p">)</span>

        <span class="c1"># set beta1</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">value</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">min</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta1</span><span class="o">.</span><span class="n">max</span>

        <span class="c1"># set beta2</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">value</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">min</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">beta2</span><span class="o">.</span><span class="n">max</span>

        <span class="c1"># set eps</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">value</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">min</span>
        <span class="n">adam_optimizer</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span> <span class="o">=</span> <span class="n">adam_params</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">max</span>

    <span class="k">def</span> <span class="nf">set_epochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">allowed_set</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">epochs</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">epochs</span>

        <span class="k">if</span> <span class="n">allowed_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">epochs</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">epochs</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">epochs</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">allowed_set</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Validate that seed passed in is integer</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Shuffle seed value must be integer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">shuffle</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">seed</span><span class="o">.</span><span class="n">defaultValue</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">def</span> <span class="nf">_add_generic_layer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">input_ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_shapes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_shapes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">generic_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">generic_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="k">if</span> <span class="n">input_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">generic_layer</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span>
        <span class="n">generic_layer</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Layer with name &quot;</span><span class="si">%s</span><span class="s1">&quot; has already been added. Please use a unique name.&#39;</span>
                <span class="o">%</span> <span class="n">name</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">generic_layer</span>
        <span class="n">_fill_tensor_fields</span><span class="p">(</span><span class="n">generic_layer</span><span class="o">.</span><span class="n">inputTensor</span><span class="p">,</span> <span class="n">input_ranks</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">)</span>
        <span class="n">_fill_tensor_fields</span><span class="p">(</span><span class="n">generic_layer</span><span class="o">.</span><span class="n">outputTensor</span><span class="p">,</span> <span class="n">output_ranks</span><span class="p">,</span> <span class="n">output_shapes</span><span class="p">)</span>

        <span class="c1"># Pass Rank Information</span>
        <span class="c1"># Generic Layer copies rank of first input to all of its output</span>
        <span class="c1"># All the layers that modifies rank apart from first input must override</span>
        <span class="k">if</span> <span class="n">input_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">output_</span> <span class="ow">in</span> <span class="n">output_names</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">generic_layer</span>

<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_layers">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_layers">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">last</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the summary for last &quot;last&quot; number of layers.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        last: int</span>
<span class="sd">             The numbers of layers to inspect, starting from the last one.</span>
<span class="sd">        verbose: bool</span>
<span class="sd">            Whether to display layer-specific parameters or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">last</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">last</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">alayer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">last</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="p">(</span>
                <span class="n">layer_type</span><span class="p">,</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">in_blobs</span><span class="p">,</span>
                <span class="n">out_blobs</span><span class="p">,</span>
                <span class="n">params_info</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">_summarize_network_layer_info</span><span class="p">(</span><span class="n">alayer</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;[Id: </span><span class="si">{}</span><span class="s2">], Name: </span><span class="si">{}</span><span class="s2"> (Type: </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">n_layers</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer_type</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Updatable: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">alayer</span><span class="o">.</span><span class="n">isUpdatable</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Input blobs: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_blobs</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Output blobs: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">out_blobs</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">params_info</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Parameters: &quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params_info</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">14</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_loss_layers">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_loss_layers">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_loss_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the summary for the loss layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_loss_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">lossLayers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_loss_layers</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;no loss layer detected.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">loss_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">lossLayers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">loss_type</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;LossLayerType&quot;</span><span class="p">)</span>
            <span class="n">loss_name</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">name</span>
            <span class="n">loss_input</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">loss_target</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s2">&quot;categoricalCrossEntropyLossLayer&quot;</span><span class="p">:</span>
                <span class="n">loss_input</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">categoricalCrossEntropyLossLayer</span><span class="o">.</span><span class="n">input</span>
                <span class="n">loss_target</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">categoricalCrossEntropyLossLayer</span><span class="o">.</span><span class="n">target</span>
            <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s2">&quot;meanSquaredErrorLossLayer&quot;</span><span class="p">:</span>
                <span class="n">loss_input</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">meanSquaredErrorLossLayer</span><span class="o">.</span><span class="n">input</span>
                <span class="n">loss_target</span> <span class="o">=</span> <span class="n">loss_layer</span><span class="o">.</span><span class="n">meanSquaredErrorLossLayer</span><span class="o">.</span><span class="n">target</span>

            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;[Id: </span><span class="si">{}</span><span class="s2">], Name: </span><span class="si">{}</span><span class="s2"> (Type: </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">n_loss_layers</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss_name</span><span class="p">,</span> <span class="n">loss_type</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Loss Input: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_input</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Loss Target: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_target</span><span class="p">))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_optimizer">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_optimizer">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the summary for the optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">updateParams</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="n">optimizer_type</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;OptimizerType&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimizer Type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">optimizer_type</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">optimizer_type</span> <span class="o">==</span> <span class="s2">&quot;sgdOptimizer&quot;</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">sgdOptimizer</span><span class="o">.</span><span class="n">learningRate</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">sgdOptimizer</span><span class="o">.</span><span class="n">miniBatchSize</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">sgdOptimizer</span><span class="o">.</span><span class="n">momentum</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;lr: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">lr</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;batch: </span><span class="si">{}</span><span class="s2">, allowed_set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;momentum: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">momentum</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span>
                    <span class="n">momentum</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span>
                    <span class="n">momentum</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">optimizer_type</span> <span class="o">==</span> <span class="s2">&quot;adamOptimizer&quot;</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">learningRate</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">miniBatchSize</span>
            <span class="n">beta1</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">beta1</span>
            <span class="n">beta2</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">beta2</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">adamOptimizer</span><span class="o">.</span><span class="n">eps</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;lr: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">lr</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;batch: </span><span class="si">{}</span><span class="s2">, allowed_set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">set</span><span class="o">.</span><span class="n">values</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;beta1: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">beta1</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">beta1</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span> <span class="n">beta1</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;beta2: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">beta2</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">beta2</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span> <span class="n">beta2</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;epsilon: </span><span class="si">{}</span><span class="s2">, min: </span><span class="si">{}</span><span class="s2">, max: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">eps</span><span class="o">.</span><span class="n">defaultValue</span><span class="p">,</span> <span class="n">eps</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">minValue</span><span class="p">,</span> <span class="n">eps</span><span class="o">.</span><span class="n">range</span><span class="o">.</span><span class="n">maxValue</span>
                <span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_updatable_layers">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_updatable_layers">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_updatable_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints all updatable layers with their inputs and outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">isUpdatable</span><span class="p">:</span>
                <span class="p">(</span>
                    <span class="n">layer_type</span><span class="p">,</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="n">in_blobs</span><span class="p">,</span>
                    <span class="n">out_blobs</span><span class="p">,</span>
                    <span class="n">_</span><span class="p">,</span>
                <span class="p">)</span> <span class="o">=</span> <span class="n">_summarize_network_layer_info</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Name: </span><span class="si">{}</span><span class="s2"> (Type: </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer_type</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Input blobs: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_blobs</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Output blobs: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">out_blobs</span><span class="p">))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_input_features">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_input_features">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_input_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the name and type of input features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span>
        <span class="n">n_input_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_input_features</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_features</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;[Id: </span><span class="si">{}</span><span class="s2">] Name: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">input_feature</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_feature</span><span class="o">.</span><span class="n">type</span><span class="p">))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_output_features">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_output_features">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_output_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the name and type of output features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">output</span>
        <span class="n">n_output_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_output_features</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">output_feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_features</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;[Id: </span><span class="si">{}</span><span class="s2">] Name: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">n_output_features</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">output_feature</span><span class="o">.</span><span class="n">name</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;Type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_feature</span><span class="o">.</span><span class="n">type</span><span class="p">))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_conv_channels">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_conv_channels">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_conv_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the output and kernel channels of a convolution layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> does not exist.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layer_name</span><span class="p">))</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;convolution&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> is not a convolution layer.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layer_name</span><span class="p">))</span>

        <span class="n">output_channels</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">convolution</span><span class="o">.</span><span class="n">outputChannels</span>
        <span class="n">kernel_channels</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">convolution</span><span class="o">.</span><span class="n">kernelChannels</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;outputChannels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;kernelChannels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kernel_channels</span><span class="p">))</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.inspect_innerproduct_channels">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.inspect_innerproduct_channels">[docs]</a>
    <span class="k">def</span> <span class="nf">inspect_innerproduct_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Prints the output and kernel channels of an innerProduct layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> does not exist.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layer_name</span><span class="p">))</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_specs</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;layer&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;innerProduct&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> is not an innerProduct layer.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">layer_name</span><span class="p">))</span>

        <span class="n">input_channels</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">innerProduct</span><span class="o">.</span><span class="n">inputChannels</span>
        <span class="n">output_channels</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">innerProduct</span><span class="o">.</span><span class="n">outputChannels</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inputChannels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_channels</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;outputChannels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span></div>


    <span class="k">def</span> <span class="nf">_get_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_set_max_input_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input name list empty for collecting rank information&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)):</span>
            <span class="n">input_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">input_rank</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">output_name</span><span class="p">),</span> <span class="n">input_rank</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_rank_for_reduce_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">reduce_all</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span> <span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Reduce Ops must provide axes to reduce on if reduce_all is False&quot;</span>
                <span class="p">)</span>

<div class="viewcode-block" id="NeuralNetworkBuilder.add_inner_product">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_inner_product">[docs]</a>
    <span class="k">def</span> <span class="nf">add_inner_product</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">input_channels</span><span class="p">,</span>
        <span class="n">output_channels</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">int_8_dynamic_quantize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">is_quantized_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">quant_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_lut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an inner product layer to the model.</span>
<span class="sd">        Refer to the ``InnerProductLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W: numpy.array or bytes()</span>
<span class="sd">            Weight matrix of shape ``(output_channels, input_channels)``.</span>
<span class="sd">            If ``W`` is of type ``bytes()`` (quantized), other quantization</span>
<span class="sd">            related arguments must be provided as well (see below).</span>
<span class="sd">        b: numpy.array</span>
<span class="sd">            Bias vector of shape: ``(output_channels, )``.</span>
<span class="sd">        input_channels: int</span>
<span class="sd">            Number of input channels.</span>
<span class="sd">        output_channels: int</span>
<span class="sd">            Number of output channels.</span>
<span class="sd">        has_bias: boolean</span>
<span class="sd">            Whether the bias vector of this layer is ignored in the spec.</span>

<span class="sd">            - If True, the bias vector of this layer is not ignored.</span>
<span class="sd">            - If False, the bias vector is ignored.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        Quantization arguments, used when ``W`` is of type ``bytes()``:</span>
<span class="sd">            int_8_dynamic_quantize: boolean</span>
<span class="sd">                Whether to quantize and dequantize before and after inner product, respectively.</span>
<span class="sd">                Expects byte weights, representing int8 values, if True.</span>
<span class="sd">                See NeuralNetwork.proto for other validation conditions.</span>

<span class="sd">            is_quantized_weight: bool, optional</span>
<span class="sd">                Set it to true when ``W`` is of type ``bytes()``, representing</span>
<span class="sd">                quantized weights, default: false.</span>

<span class="sd">            quantization_type: str</span>
<span class="sd">                When weights are quantized (that is, ``W`` is of type ``bytes()``),</span>
<span class="sd">                this should be either ``&quot;linear&quot;`` or ``&quot;lut&quot;``.</span>

<span class="sd">            nbits: int</span>
<span class="sd">                Should be between 1 and 8 (inclusive). Number of bits per weight</span>
<span class="sd">                value. Only applicable when weights are quantized.</span>

<span class="sd">            quant_scale: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                scale vector to be used with linear quantization. Must be of</span>
<span class="sd">                length either 1 or output_channels.</span>

<span class="sd">            quant_bias: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                bias vector to be used with linear quantization. Must be of</span>
<span class="sd">                length either 1 or output_channels.</span>

<span class="sd">            quant_lut: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                the LUT (look up table) to be used with LUT quantization.</span>
<span class="sd">                Must be of length 2^n bits.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_embedding, add_convolution, add_batched_mat_mul</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">innerProduct</span>

        <span class="c1"># Fill in the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputChannels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputChannels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">has_bias</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">int8DynamicQuantize</span> <span class="o">=</span> <span class="n">int_8_dynamic_quantize</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_quantized_weight</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">_np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>

            <span class="n">_verify_quantization_arguments</span><span class="p">(</span>
                <span class="n">weight</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
                <span class="n">int_8_dynamic_quantize</span><span class="o">=</span><span class="n">int_8_dynamic_quantize</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">_fill_quantized_weights</span><span class="p">(</span>
                <span class="n">weights_message</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">use_int_8</span><span class="o">=</span><span class="n">int_8_dynamic_quantize</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_embedding">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_embedding">[docs]</a>
    <span class="k">def</span> <span class="nf">add_embedding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">input_dim</span><span class="p">,</span>
        <span class="n">output_channels</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">is_quantized_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">quant_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_lut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an embedding layer to the model.</span>
<span class="sd">        Refer to the ``EmbeddingLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W: float32 numpy.array or bytes()</span>
<span class="sd">            Weight matrix of shape ``(output_channels, input_dim)``.</span>
<span class="sd">            If ``W`` is of type ``bytes()`` (quantized to 1-8 bits), other</span>
<span class="sd">            quantization related arguments must be provided as well (see below).</span>
<span class="sd">        b: numpy.array</span>
<span class="sd">            Bias vector of shape ``(output_channels, )``.</span>
<span class="sd">        input_dim: int</span>
<span class="sd">            Size of the vocabulary (1 + maximum integer index of the words).</span>
<span class="sd">        output_channels: int</span>
<span class="sd">            Number of output channels.</span>
<span class="sd">        has_bias: boolean</span>
<span class="sd">            Whether the bias vector of this layer is ignored in the ``spec``.</span>

<span class="sd">            - If True, the bias vector of this layer is not ignored.</span>
<span class="sd">            - If False, the bias vector is ignored.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>


<span class="sd">        Quantization arguments expected, when ``W`` is of type ``bytes()``:</span>

<span class="sd">        is_quantized_weight: bool</span>
<span class="sd">            Set it to true when ``W`` is of type ``bytes()``, representing quantized weights.</span>

<span class="sd">        quantization_type: str</span>
<span class="sd">            When weights are quantized (that is, ``W`` is of type ``bytes()``),</span>
<span class="sd">            this should be either ``&quot;linear&quot;`` or ``&quot;lut&quot;``.</span>

<span class="sd">        nbits: int</span>
<span class="sd">            Should be between 1 and 8 (inclusive). Number of bits per weight value.</span>

<span class="sd">        quant_scale: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            Scale vector to be used with linear quantization.</span>
<span class="sd">            Must be of length either 1 or output_channels.</span>

<span class="sd">        quant_bias: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            Bias vector to be used with linear quantization.</span>
<span class="sd">            Must be of length either 1 or output_channels.</span>

<span class="sd">        quant_lut: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            The LUT (look up table) to be used with LUT quantization.</span>
<span class="sd">            Must be of length 2^n bits.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_inner_product</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="c1"># Fill in the parameters</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">embedding</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputDim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputChannels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">has_bias</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_quantized_weight</span><span class="p">:</span>
            <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_verify_quantization_arguments</span><span class="p">(</span>
                <span class="n">weight</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">_fill_quantized_weights</span><span class="p">(</span>
                <span class="n">weights_message</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_softmax">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_softmax">[docs]</a>
    <span class="k">def</span> <span class="nf">add_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a softmax layer to the model.</span>
<span class="sd">        Refer to the ``SoftmaxLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation, add_inner_product, add_convolution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_activation">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_activation">[docs]</a>
    <span class="k">def</span> <span class="nf">add_activation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">non_linearity</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an activation layer to the model.</span>
<span class="sd">        Refer to the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        non_linearity: str</span>
<span class="sd">            The ``non_linearity`` (activation) function of this layer.</span>
<span class="sd">            It can be one of the following:</span>

<span class="sd">                - ``&#39;RELU&#39;``: Rectified Linear Unit (ReLU) function.</span>
<span class="sd">                - ``&#39;SIGMOID&#39;``: sigmoid function.</span>
<span class="sd">                - ``&#39;TANH&#39;``: tanh function.</span>
<span class="sd">                - ``&#39;SCALED_TANH&#39;``: scaled tanh function, defined as:</span>

<span class="sd">                  ``f(x) = alpha * tanh(beta * x)``</span>

<span class="sd">                  where ``alpha`` and ``beta`` are constant scalars.</span>

<span class="sd">                - ``&#39;SOFTPLUS&#39;``: softplus function.</span>
<span class="sd">                - ``&#39;SOFTSIGN&#39;``: softsign function.</span>
<span class="sd">                - ``&#39;SIGMOID_HARD&#39;``: hard sigmoid function, defined as:</span>

<span class="sd">                  ``f(x) = min(max(alpha * x + beta, -1), 1)``</span>

<span class="sd">                  where ``alpha`` and ``beta`` are constant scalars.</span>

<span class="sd">                - ``&#39;LEAKYRELU&#39;``: leaky relu function, defined as:</span>

<span class="sd">                  ``f(x) = (x &gt;= 0) * x + (x &lt; 0) * alpha * x``</span>

<span class="sd">                  where ``alpha`` is a constant scalar.</span>

<span class="sd">                - ``&#39;PRELU&#39;``: Parametric ReLU function, defined as:</span>

<span class="sd">                  ``f(x) = (x &gt;= 0) * x + (x &lt; 0) * alpha * x``</span>

<span class="sd">                  where ``alpha`` is a multi-dimensional array of same size as ``x``.</span>

<span class="sd">                - ``&#39;ELU&#39;``: Exponential linear unit function, defined as:</span>

<span class="sd">                  ``f(x) = (x &gt;= 0) * x + (x &lt; 0) * (alpha * exp(x) - 1)``</span>

<span class="sd">                  where ``alpha`` is a constant scalar.</span>

<span class="sd">                - ``&#39;PARAMETRICSOFTPLUS&#39;``: Parametric softplus function, defined as:</span>

<span class="sd">                  ``f(x) = alpha * log(1 + exp(beta * x))``</span>

<span class="sd">                  where ``alpha`` and ``beta`` are two multi-dimensional arrays</span>
<span class="sd">                  of same size as ``x``.</span>

<span class="sd">                - ``&#39;THRESHOLDEDRELU&#39;``: Thresholded ReLU function, defined as:</span>

<span class="sd">                  ``f(x) = (x &gt;= alpha) * x``</span>

<span class="sd">                  where ``alpha`` is a constant scalar.</span>

<span class="sd">                - ``&#39;LINEAR&#39;``: linear function.</span>

<span class="sd">                   ``f(x) = alpha * x + beta``</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        params: list of float or numpy.array</span>
<span class="sd">            Parameters for the activation, depending on non_linearity.</span>

<span class="sd">                - When ``non_linearity`` is one of [``&#39;RELU&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;TANH&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SOFTPLUS&#39;``, ``&#39;SOFTSIGN&#39;``],</span>
<span class="sd">                  params is ignored.</span>
<span class="sd">                - When ``non_linearity`` is one of [``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``],</span>
<span class="sd">                  param is a list of 2 floats ``[alpha, beta]``.</span>
<span class="sd">                - When ``non_linearity`` is one of [``&#39;LEAKYRELU&#39;``, ``&#39;ELU&#39;``, ``&#39;THRESHOLDEDRELU&#39;``],</span>
<span class="sd">                  param is a list of 1 float ``[alpha]``.</span>
<span class="sd">                - When ``non_linearity`` is ``&#39;PRELU&#39;``, param is a list of 1 numpy array ``[alpha]``.</span>
<span class="sd">                  The shape of ``alpha`` is ``(C,)``, where ``C`` is either the number of input channels or</span>
<span class="sd">                  1. When ``C = 1``, same ``alpha`` is applied to all channels.</span>
<span class="sd">                - When ``non_linearity`` is ``&#39;PARAMETRICSOFTPLUS&#39;``, param is a</span>
<span class="sd">                  list of 2 numpy arrays ``[alpha, beta]``. The shape of ``alpha`` and</span>
<span class="sd">                  `beta` is ``(C, )``, where ``C`` is either</span>
<span class="sd">                  the number of input channels or 1. When ``C = 1``, same ``alpha`` and</span>
<span class="sd">                  ``beta`` are applied to all channels.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_convolution, add_softmax</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_rank</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">input_shape</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">input_rank</span><span class="p">)</span> <span class="k">else</span> <span class="n">input_rank</span>
        <span class="p">)</span>
        <span class="n">output_rank</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">output_shape</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">output_rank</span><span class="p">)</span> <span class="k">else</span> <span class="n">output_rank</span>
        <span class="p">)</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">output_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">input_rank</span><span class="p">]</span> <span class="k">if</span> <span class="n">input_rank</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_shape</span><span class="p">]</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">[</span><span class="n">output_rank</span><span class="p">]</span> <span class="k">if</span> <span class="n">output_rank</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">[</span><span class="n">output_shape</span><span class="p">]</span> <span class="k">if</span> <span class="n">output_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">activation</span>

        <span class="c1"># Fill in the parameters</span>
        <span class="n">non_linearity</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">non_linearity</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">non_linearity</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">non_linearity</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;RELU&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">ReLU</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;SIGMOID&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;TANH&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">tanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;SCALED_TANH&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scaledTanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scaledTanh</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scaledTanh</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;SOFTPLUS&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">softplus</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;SOFTSIGN&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">softsign</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;SIGMOID_HARD&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">sigmoidHard</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">sigmoidHard</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;LEAKYRELU&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">alpha</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">leakyReLU</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;PRELU&quot;</span><span class="p">:</span>
            <span class="c1"># PReLU must provide an np array in params[0]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">PReLU</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;ELU&quot;</span><span class="p">:</span>
            <span class="c1"># ELU must provide an alpha in params[0]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">ELU</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;PARAMETRICSOFTPLUS&quot;</span><span class="p">:</span>
            <span class="c1"># Parametric softplus must provide two np arrays for alpha and beta</span>
            <span class="n">alphas</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># Weight alignment: Keras [H,W,C,F]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">parametricSoftplus</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">alphas</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">parametricSoftplus</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">betas</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;THRESHOLDEDRELU&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">theta</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">thresholdedReLU</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">non_linearity</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unknown activation type </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">non_linearity</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_elementwise">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_elementwise">[docs]</a>
    <span class="k">def</span> <span class="nf">add_elementwise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an element-wise operation layer to the model.</span>
<span class="sd">        Refer to the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            A list of input blob names of this layer. The input blobs should have the same shape.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mode: str</span>
<span class="sd">            A string specifying the mode of the elementwise layer. It can be one of the following:</span>

<span class="sd">            - ``&#39;CONCAT&#39;``: Concatenate input blobs along the channel axis.</span>
<span class="sd">            - ``&#39;SEQUENCE_CONCAT&#39;``: Concatenate input blobs along the sequence axis.</span>
<span class="sd">            - ``&#39;ADD&#39;``: Perform an element-wise summation over the input blobs.</span>
<span class="sd">            - ``&#39;MULTIPLY&#39;``: Perform an element-wise multiplication over the input blobs.</span>
<span class="sd">            - ``&#39;DOT&#39;``: Compute the dot product of the two input blobs.</span>
<span class="sd">              In this mode, the length of ``input_names`` should be 2.</span>
<span class="sd">            - ``&#39;COS&#39;``: Compute the cosine similarity of the two input blobs.</span>
<span class="sd">              In this mode, the length of ``input_names`` should be 2.</span>
<span class="sd">            - ``&#39;MAX&#39;``: Compute the element-wise maximum over the input blobs.</span>
<span class="sd">            - ```&#39;MIN&#39;```: Compute the element-wise minimum over the input blobs.</span>
<span class="sd">            - ``&#39;AVE&#39;``: Compute the element-wise average over the input blobs.</span>

<span class="sd">        alpha: float</span>
<span class="sd">            * if ``mode == &#39;ADD&#39;`` and there is only one ``input_name``,</span>
<span class="sd">              ``alpha`` is added to the input.</span>
<span class="sd">            * if ``mode == &#39;MULTIPLY&#39;`` and there is only one ``input_name``,</span>
<span class="sd">              ``alpha`` is multiplied to the input.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_upsample, add_sequence_repeat</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_names</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="c1"># add one of the following layers</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;CONCAT&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">concat</span><span class="o">.</span><span class="n">sequenceConcat</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SEQUENCE_CONCAT&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">concat</span><span class="o">.</span><span class="n">sequenceConcat</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ADD&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">alpha</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MULTIPLY&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">alpha</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;COS&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">dot</span><span class="o">.</span><span class="n">cosineSimilarity</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;DOT&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">dot</span><span class="o">.</span><span class="n">cosineSimilarity</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MIN&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;AVE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">average</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported elementwise mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_upsample">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_upsample">[docs]</a>
    <span class="k">def</span> <span class="nf">add_upsample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">scaling_factor_h</span><span class="p">,</span>
        <span class="n">scaling_factor_w</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;NN&quot;</span><span class="p">,</span>
        <span class="n">linear_upsample_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an upsample layer to the model.</span>
<span class="sd">        Refer to the ``UpsampleLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        scaling_factor_h: int or float</span>
<span class="sd">            Scaling factor on the vertical direction. Float values only</span>
<span class="sd">            supported with ``BILINEAR`` and ``ALIGN_CORNERS_*``.</span>
<span class="sd">        scaling_factor_w: int or float</span>
<span class="sd">            Scaling factor on the horizontal direction. Float values only</span>
<span class="sd">            supported with ``BILINEAR`` and ``ALIGN_CORNERS_*``.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mode: str</span>
<span class="sd">            Overall interpolation mode. The following values are supported:</span>

<span class="sd">            * ``&#39;NN&#39;``: nearest neighbour</span>
<span class="sd">            * ``&#39;BILINEAR&#39;``: bilinear interpolation</span>

<span class="sd">        linear_upsample_mode: str</span>
<span class="sd">            Specifies the behavior for linear upsampling. Only valid when</span>
<span class="sd">            Interpolation Mode is ``BILINEAR``.</span>

<span class="sd">            If input grid is ``[0, Xin-1]`` (corresponding to an input size of</span>
<span class="sd">            ``Xin``), and if the output size is ``Xout``,</span>
<span class="sd">            then the grid points are sampled in the following manner:</span>

<span class="sd">            &#39;DEFAULT&#39;:</span>
<span class="sd">                - ``spacing = (Xin-Xin/Xout) / (Xout-1)``</span>
<span class="sd">                - ``grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,..,Xout-1``</span>

<span class="sd">            &#39;ALIGN_CORNERS_TRUE&#39;:</span>
<span class="sd">                - ``spacing = (Xin-1) / (Xout-1)``</span>
<span class="sd">                - ``grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,..,Xout-1``</span>

<span class="sd">            &#39;ALIGN_CORNERS_FALSE&#39;:</span>
<span class="sd">                - ``spacing = Xin / Xout``</span>
<span class="sd">                - ``grid_point[i] = min(Xin-1, max(0, i * spacing + 0.5 * spacing - 0.5)), for i = 0,1,2,..,Xout-1``</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_resize_bilinear</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="n">linear_upsample_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">linear_upsample_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">linear_upsample_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">linear_upsample_mode</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;NN&quot;</span><span class="p">,</span> <span class="s2">&quot;BILINEAR&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported upsampling mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">linear_upsample_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span> <span class="s2">&quot;ALIGN_CORNERS_TRUE&quot;</span><span class="p">,</span> <span class="s2">&quot;ALIGN_CORNERS_FALSE&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported linear upsampling mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">linear_upsample_mode</span>
            <span class="p">)</span>

        <span class="c1"># Default linear upsample mode is backwards compatible, else set spec to iOS14</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">linear_upsample_mode</span> <span class="o">!=</span> <span class="s2">&quot;DEFAULT&quot;</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">upsample</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">scaling_factor_h</span> <span class="o">-</span> <span class="n">_math_floor</span><span class="p">(</span><span class="n">scaling_factor_h</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.001</span>
            <span class="ow">or</span> <span class="n">scaling_factor_w</span> <span class="o">-</span> <span class="n">_math_floor</span><span class="p">(</span><span class="n">scaling_factor_w</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.001</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="s2">&quot;BILINEAR&quot;</span> <span class="ow">or</span> <span class="n">linear_upsample_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">&quot;ALIGN_CORNERS_TRUE&quot;</span><span class="p">,</span>
                <span class="s2">&quot;ALIGN_CORNERS_FALSE&quot;</span><span class="p">,</span>
            <span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Fractional upsampling only compatible with BILINEAR and ALIGN_CORNERS_TRUE or ALIGN_CORNERS_FALSE&quot;</span>
                <span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">fractionalScalingFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">scaling_factor_h</span><span class="p">))</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">fractionalScalingFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">scaling_factor_w</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scalingFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">scaling_factor_h</span><span class="p">))</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scalingFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">scaling_factor_w</span><span class="p">))</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UpsampleLayerParams</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">linearUpsampleMode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UpsampleLayerParams</span><span class="o">.</span><span class="n">LinearUpsampleMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="n">linear_upsample_mode</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_scale">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_scale">[docs]</a>
    <span class="k">def</span> <span class="nf">add_scale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">shape_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">shape_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a scale layer to the model.</span>
<span class="sd">        Refer to the ``ScaleLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W: int or numpy.array</span>
<span class="sd">            Scale of the input.</span>
<span class="sd">        b: int or numpy.array</span>
<span class="sd">            Bias to add to the input.</span>
<span class="sd">        has_bias: boolean</span>
<span class="sd">            Whether the bias vector of this layer is ignored in the ``spec``.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        shape_scale: list of int or tuple of int</span>
<span class="sd">            List of ints that specifies the shape of the scale parameter.</span>
<span class="sd">            Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.</span>
<span class="sd">        shape_bias: list of int</span>
<span class="sd">            List of ints that specifies the shape of the bias parameter</span>
<span class="sd">            (if present). Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_bias</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">shape_scale</span><span class="p">:</span>
            <span class="n">shape_scale</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">shape_bias</span><span class="p">:</span>
            <span class="n">shape_bias</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">scale</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">has_bias</span>

        <span class="c1"># add scale and its shape</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shapeScale</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">shape_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">scale</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="o">.</span><span class="n">floatValue</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape_scale</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dimensions of &#39;shape_scale&#39; do not match the size of the provided &#39;scale&#39; parameter&quot;</span>
            <span class="p">)</span>

        <span class="c1"># add bias and its shape</span>
        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shapeBias</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Dimensions of &#39;shape_bias&#39; do not match the size of the provided &#39;b&#39; parameter&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_bias">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_bias">[docs]</a>
    <span class="k">def</span> <span class="nf">add_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">shape_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a bias layer to the model.</span>
<span class="sd">        Refer to the ``BiasLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        b: int or numpy.array</span>
<span class="sd">            Bias to add to the input.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        shape_bias: list of int</span>
<span class="sd">            List of ints that specifies the shape of the bias parameter</span>
<span class="sd">            (if present). Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_scale</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">shape_bias</span><span class="p">:</span>
            <span class="n">shape_bias</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">bias</span>

        <span class="c1"># add bias and its shape</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape of bias layer must have length 1 or 3.&quot;</span><span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape_bias</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dimensions of &#39;shape_bias&#39; do not match the size&quot;</span>
                <span class="s2">&quot;of the provided &#39;b&#39; parameter&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_sequence_repeat">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_sequence_repeat">[docs]</a>
    <span class="k">def</span> <span class="nf">add_sequence_repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">nrep</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a sequence repeat layer to the model.</span>
<span class="sd">        Refer to the ``SequenceRepeatLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        nrep: int</span>
<span class="sd">            Number of repetitions of the input blob along the sequence axis.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_upsample, add_elementwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">sequenceRepeat</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">nRepetitions</span> <span class="o">=</span> <span class="n">nrep</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_convolution">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_convolution">[docs]</a>
    <span class="k">def</span> <span class="nf">add_convolution</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">kernel_channels</span><span class="p">,</span>
        <span class="n">output_channels</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">stride_height</span><span class="p">,</span>
        <span class="n">stride_width</span><span class="p">,</span>
        <span class="n">border_mode</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="p">,</span>
        <span class="n">is_deconv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;out&quot;</span><span class="p">,</span>
        <span class="n">dilation_factors</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">padding_top</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_right</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">same_padding_asymmetry_mode</span><span class="o">=</span><span class="s2">&quot;BOTTOM_RIGHT_HEAVY&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a convolution layer to the network.</span>
<span class="sd">        Refer to the ``ConvolutionLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        kernel_channels: int</span>
<span class="sd">            Number of channels for the convolution kernels.</span>

<span class="sd">        output_channels: int</span>
<span class="sd">            Number of filter kernels. This is equal to the number of channels in the output blob.</span>

<span class="sd">        height: int</span>
<span class="sd">            Height of each kernel.</span>

<span class="sd">        width: int</span>
<span class="sd">            Width of each kernel.</span>

<span class="sd">        stride_height: int</span>
<span class="sd">            Stride along the height direction.</span>

<span class="sd">        stride_width: int</span>
<span class="sd">            Stride along the height direction.</span>

<span class="sd">        border_mode: str</span>
<span class="sd">            Option for the padding type and output blob shape. Can be either &#39;valid&#39; or &#39;same&#39;.</span>

<span class="sd">        groups: int</span>
<span class="sd">            Number of kernel groups. Input is divided into groups along the channel axis.</span>
<span class="sd">            Each kernel group share the same weights.</span>

<span class="sd">        W: numpy.array or bytes() or None</span>

<span class="sd">            Weight of the convolution kernels.</span>

<span class="sd">            * If ``is_deconv`` is False, ``W`` should have</span>
<span class="sd">              shape ``(height, width, kernel_channels, output_channels)``, where::</span>

<span class="sd">                 kernel_channel = input_channels / groups</span>

<span class="sd">            * If ``is_deconv`` is True, ``W`` should have</span>
<span class="sd">              shape ``(height, width, kernel_channels, output_channels / groups)``, where::</span>

<span class="sd">                 kernel_channel = input_channels</span>

<span class="sd">            * If ``W`` is of type ``bytes()`` (quantized), other quantization-related</span>
<span class="sd">              arguments must be provided as well (see below).</span>

<span class="sd">            * For Core ML specification version &gt;=4, ``W`` can be ``None``. In this case,</span>
<span class="sd">              the convolution layer takes 2 inputs, where the 1st input represents</span>
<span class="sd">              the input feature map, and the 2nd input represents the weight blob.</span>

<span class="sd">        b: numpy.array</span>
<span class="sd">            Biases of the convolution kernels. ``b`` should have shape ``(outputChannels, )``.</span>

<span class="sd">        has_bias: boolean</span>
<span class="sd">            Whether bias is ignored.</span>

<span class="sd">            - If True, bias is not ignored.</span>
<span class="sd">            - If False, bias is ignored.</span>

<span class="sd">        is_deconv: boolean</span>
<span class="sd">            Whether the convolution layer is performing a convolution or a transposed convolution (deconvolution).</span>

<span class="sd">            - If True, the convolution layer is performing transposed convolution.</span>
<span class="sd">            - If False, the convolution layer is performing regular convolution.</span>

<span class="sd">        output_shape: tuple or None</span>
<span class="sd">            Either ``None`` or a 2-tuple, specifying the output shape ``(output_height, output_width)``.</span>

<span class="sd">            - Used only when ``is_deconv == True``.</span>
<span class="sd">            - When ``is_deconv == False``, this parameter is ignored.</span>
<span class="sd">            - If it is ``None``, the output shape is calculated automatically using the ``border_mode``.</span>

<span class="sd">        input_name: str or list of str</span>
<span class="sd">            The input blob name(s) of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        dilation_factors: list of int</span>
<span class="sd">            Dilation factors across height and width directions. Must be a list of two</span>
<span class="sd">            positive integers. Defaults to ``[1, 1]``.</span>

<span class="sd">        padding_top, padding_bottom, padding_left, padding_right: int</span>
<span class="sd">            Values of height (top, bottom) and width (left, right) padding</span>
<span class="sd">            to be used if ``border_more`` is ``&quot;valid&quot;``.</span>

<span class="sd">        same_padding_asymmetry_mode: str</span>
<span class="sd">            Type of asymmetric padding to be used when  ``border_mode`` is ``&#39;same&#39;``.</span>
<span class="sd">            Can be either ``&#39;BOTTOM_RIGHT_HEAVY&#39;`` or  ``&#39;TOP_LEFT_HEAVY&#39;``.</span>

<span class="sd">                Quantization</span>
<span class="sd">                        Quantization arguments expected in ``kwargs``, when ``W`` is of type ``bytes()``.</span>

<span class="sd">                                quantization_type: str</span>
<span class="sd">                                        When weights are quantized (that is, ``W`` is of type ``bytes()``),</span>
<span class="sd">                                        this should be either ``&quot;linear&quot;`` or ``&quot;lut&quot;``.</span>

<span class="sd">                                nbits: int</span>
<span class="sd">                                        Should be between 1 and 8 (inclusive). Number of bits per weight</span>
<span class="sd">                                        value. Only applicable when weights are quantized.</span>

<span class="sd">                                quant_scale: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                                        scale vector to be used with linear quantization. Must be of</span>
<span class="sd">                                        length either 1 or ``output_channels``.</span>

<span class="sd">                                quant_bias: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                                        bias vector to be used with linear quantization. Must be of</span>
<span class="sd">                                        length either 1 or ``output_channels``.</span>

<span class="sd">                                quant_lut: numpy.array(dtype=numpy.float32)</span>
<span class="sd">                                        the LUT (look up table) to be used with LUT quantization.</span>
<span class="sd">                                        Must be of length 2^n bits.</span>

<span class="sd">        Depthwise convolution</span>
<span class="sd">                Depthwise convolution is a special case of convolution, in which:</span>

<span class="sd">                  * ``kernel_channels = 1 (== input_channels / groups)``</span>
<span class="sd">                  * ``output_channels = channel_multiplier * input_channels``</span>
<span class="sd">                  * ``groups = input_channels``</span>
<span class="sd">                  * ``W``: ``[Kernel_height, Kernel_width, 1, channel_multiplier * input_channels]``</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_convolution3d, add_pooling, add_activation, add_batchnorm</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_name</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="c1"># Set the layer params</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">convolution</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">isDeconvolution</span> <span class="o">=</span> <span class="n">is_deconv</span>

        <span class="k">if</span> <span class="n">is_deconv</span> <span class="ow">and</span> <span class="n">output_shape</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputChannels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelChannels</span> <span class="o">=</span> <span class="n">kernel_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stride_height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stride_width</span><span class="p">)</span>

        <span class="n">border_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">border_mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">border_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">border_mode</span>
        <span class="p">)</span>
        <span class="n">same_padding_asymmetry_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">same_padding_asymmetry_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">same_padding_asymmetry_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">same_padding_asymmetry_mode</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">==</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="n">height_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
            <span class="n">height_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">padding_top</span>
            <span class="n">height_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">padding_bottom</span>
            <span class="n">width_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
            <span class="n">width_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">padding_left</span>
            <span class="n">width_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">padding_right</span>
        <span class="k">elif</span> <span class="n">border_mode</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">same_padding_asymmetry_mode</span> <span class="o">==</span> <span class="s2">&quot;BOTTOM_RIGHT_HEAVY&quot;</span>
                <span class="ow">or</span> <span class="n">same_padding_asymmetry_mode</span> <span class="o">==</span> <span class="s2">&quot;TOP_LEFT_HEAVY&quot;</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid value </span><span class="si">%d</span><span class="s2"> of same_padding_asymmetry_mode parameter&quot;</span>
                    <span class="o">%</span> <span class="n">same_padding_asymmetry_mode</span>
                <span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">same</span><span class="o">.</span><span class="n">asymmetryMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamePadding</span><span class="o">.</span><span class="n">SamePaddingMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="n">same_padding_asymmetry_mode</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Border mode </span><span class="si">%s</span><span class="s2"> is not implemented.&quot;</span> <span class="o">%</span> <span class="n">border_mode</span>
            <span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">nGroups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">has_bias</span>

        <span class="c1"># add dilation factors</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">dilationFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dilation_factors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">dilationFactor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dilation_factors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># If weight comes from another tensor just return</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Weight assignments</span>
        <span class="n">quantization</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;quantization_type&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;quantization_type&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">quantization</span><span class="p">:</span>
            <span class="n">_verify_quantization_arguments</span><span class="p">(</span>
                <span class="n">weight</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

            <span class="n">nbits</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;nbits&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
            <span class="n">num_weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span> <span class="o">*</span> <span class="n">kernel_channels</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span> <span class="o">/</span> <span class="n">groups</span>
            <span class="k">if</span> <span class="n">nbits</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
                <span class="n">byte_arr</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_unpack_to_bytes</span><span class="p">(</span><span class="n">byte_arr</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">nbits</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">kernel_channels</span><span class="p">,</span> <span class="n">output_channels</span> <span class="o">/</span> <span class="n">groups</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">kernel_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">))</span>

        <span class="c1"># Weight alignment: MLModel Spec requires following weight arrangement:</span>
        <span class="c1"># is_deconv == False ==&gt; (output_channels, kernel_channels, height, width), where kernel_channel = input_channels / groups</span>
        <span class="c1"># is_deconv == True ==&gt; (kernel_channels, output_channels / groups, height, width), where kernel_channel = input_channels</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">Wt</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">Wt</span> <span class="o">=</span> <span class="n">Wt</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Wt</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="c1"># Assign weights</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">quantization</span><span class="p">:</span>  <span class="c1"># no quantization</span>
            <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">Wt</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># there is quantization</span>
            <span class="n">W_bytes</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">nbits</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="n">W_bytes</span> <span class="o">+=</span> <span class="n">Wt</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W_bytes</span> <span class="o">+=</span> <span class="n">_convert_array_to_nbit_quantized_bytes</span><span class="p">(</span>
                    <span class="n">Wt</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">nbits</span>
                <span class="p">)</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>
            <span class="n">_fill_quantized_weights</span><span class="p">(</span><span class="n">weights_message</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W_bytes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Assign biases</span>
        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_channels</span><span class="p">):</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">f</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_convolution3d">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_convolution3d">[docs]</a>
    <span class="k">def</span> <span class="nf">add_convolution3d</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_channels</span><span class="p">,</span>
        <span class="n">output_channels</span><span class="p">,</span>
        <span class="n">depth</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">stride_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">stride_height</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">stride_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dilation_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dilation_height</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dilation_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">is_deconv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
        <span class="n">padding_front</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_back</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_top</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_right</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;out&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a 3 dimensional convolution layer to the network.</span>
<span class="sd">        Refer to the ``Convolution3DLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_channels: int</span>
<span class="sd">            Number of input channels.</span>

<span class="sd">        output_channels: int</span>
<span class="sd">            Number of filter kernels. This is equal to the number of channels in the output blob.</span>

<span class="sd">        depth: int</span>
<span class="sd">            Depth of each kernel.</span>

<span class="sd">        height: int</span>
<span class="sd">            Height of each kernel.</span>

<span class="sd">        width: int</span>
<span class="sd">            Width of each kernel.</span>

<span class="sd">        W: numpy.array or bytes()</span>
<span class="sd">            Weight of the convolution kernels. ``W`` should have shape:</span>

<span class="sd">            - If ``deconv`` is False:</span>

<span class="sd">                 ``(output_channels, kernel_channels, depth, height, width)``, where:</span>

<span class="sd">                 ``kernel_channels = input_channels / groups``</span>

<span class="sd">            - If ``deconv`` is True:</span>

<span class="sd">                 ``(output_channels / groups, kernel_channels, depth, height, width)``, where:</span>

<span class="sd">                 ``kernel_channels = input_channels``</span>

<span class="sd">        b: numpy.array</span>
<span class="sd">            Biases of the convolution kernels. ``b`` should have shape ``(outputChannels, )``.</span>

<span class="sd">        has_bias: boolean</span>
<span class="sd">            Whether bias is ignored.</span>
<span class="sd">            - If True, bias is not ignored.</span>
<span class="sd">            - If False, bias is ignored.</span>

<span class="sd">        groups: int</span>
<span class="sd">            Number of kernel groups. Input is divided into groups along the channel axis. Each</span>
<span class="sd">            kernel group share the same weights. Defaults to 1.</span>

<span class="sd">        stride_depth, stride_height, stride_width: int</span>
<span class="sd">            Stride along the depth, height, and width directions, respectively. Must all be positive</span>
<span class="sd">            integers. Defaults to 1.</span>

<span class="sd">        dilation_depth, dilation_width, dilation_height: int</span>
<span class="sd">            Dilation factors across depth, height, and width directions. Must all be positive</span>
<span class="sd">            integers. Defaults to 1 in each dimension.</span>

<span class="sd">        is_deconv: bool</span>
<span class="sd">            True if this is Convolution Transpose, otherwise False.</span>

<span class="sd">        output_shape: None or Tuple of int</span>
<span class="sd">            Applicable only for Deconvolution layer.</span>
<span class="sd">            ``None`` if Convolution.</span>
<span class="sd">            Tuple of length 3 if Convolution Transpose.</span>

<span class="sd">        padding_mode: str</span>
<span class="sd">            Option for the padding type and output blob shape.</span>
<span class="sd">            Can be ``&#39;custom&#39;``, ``&#39;valid&#39;``, or ``&#39;same&#39;``.</span>
<span class="sd">            Defaults to ``&#39;valid&#39;``. Case-insensitive.</span>

<span class="sd">        padding_front, padding_back, padding_top, padding_bottom, padding_left, padding_right: int</span>
<span class="sd">            Values of depth (front, back), height (top, bottom), and width (left, right) padding to</span>
<span class="sd">            be used. Must all be positive integers. All default to 0.</span>

<span class="sd">        input_name: str or list of str</span>
<span class="sd">            The input blob name(s) of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        Depthwise convolution</span>
<span class="sd">                Depthwise convolution is a special case of convolution, in which:</span>

<span class="sd">            * ``kernel_channels = 1`` (``== input_channels / groups``)</span>
<span class="sd">            * ``output_channels = channel_multiplier * input_channels``</span>
<span class="sd">            * ``groups = input_channels``</span>
<span class="sd">            * ``W``: ``[Kernel_depth, Kernel_height, Kernel_width, 1, channel_multiplier * input_channels]``</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_convolution, add_pooling, add_activation, add_batchnorm</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Update spec version if necessary</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_name</span><span class="p">]</span>

        <span class="c1"># 3D convolution doesn&#39;t currently support 2-inputs</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;3D convolution only supports 1 input.&quot;</span><span class="p">)</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="c1"># Set the layer params</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">convolution3d</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">isDeconvolution</span> <span class="o">=</span> <span class="n">is_deconv</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">nGroups</span> <span class="o">=</span> <span class="n">groups</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputChannels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputChannels</span> <span class="o">=</span> <span class="n">input_channels</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelDepth</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelHeight</span> <span class="o">=</span> <span class="n">height</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelWidth</span> <span class="o">=</span> <span class="n">width</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideDepth</span> <span class="o">=</span> <span class="n">stride_depth</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideHeight</span> <span class="o">=</span> <span class="n">stride_height</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideWidth</span> <span class="o">=</span> <span class="n">stride_width</span>

        <span class="k">if</span> <span class="n">is_deconv</span> <span class="ow">and</span> <span class="n">output_shape</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

        <span class="n">supported_padding_modes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;CUSTOM&quot;</span><span class="p">,</span> <span class="s2">&quot;VALID&quot;</span><span class="p">,</span> <span class="s2">&quot;SAME&quot;</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_padding_modes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported padding mode: </span><span class="si">%s</span><span class="s2">.  Must be one of </span><span class="si">%s</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">padding_mode</span><span class="p">,</span> <span class="n">supported_padding_modes</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;CUSTOM&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingFront</span> <span class="o">=</span> <span class="n">padding_front</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingBack</span> <span class="o">=</span> <span class="n">padding_back</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingTop</span> <span class="o">=</span> <span class="n">padding_top</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingBottom</span> <span class="o">=</span> <span class="n">padding_bottom</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingLeft</span> <span class="o">=</span> <span class="n">padding_left</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingRight</span> <span class="o">=</span> <span class="n">padding_right</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">paddingType</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">Convolution3DLayerParams</span><span class="o">.</span><span class="n">PaddingType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">dilationDepth</span> <span class="o">=</span> <span class="n">dilation_depth</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">dilationHeight</span> <span class="o">=</span> <span class="n">dilation_height</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">dilationWidth</span> <span class="o">=</span> <span class="n">dilation_width</span>

        <span class="c1"># Weight alignment: MLModel Spec requires following weight arrangement:</span>
        <span class="c1"># is_deconv == False ==&gt; (output_channels, kernel_channels, depth, height, width), where kernel_channel = input_channels / groups</span>
        <span class="c1"># is_deconv == True ==&gt; (kernel_channels, output_channels / groups, height, width), where kernel_channel = input_channels</span>
        <span class="k">if</span> <span class="n">is_deconv</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

        <span class="c1"># Assign weights</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># Assign biases</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">has_bias</span>
        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_channels</span><span class="p">):</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">f</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_pooling">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_pooling">[docs]</a>
    <span class="k">def</span> <span class="nf">add_pooling</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">stride_height</span><span class="p">,</span>
        <span class="n">stride_width</span><span class="p">,</span>
        <span class="n">layer_type</span><span class="p">,</span>
        <span class="n">padding_type</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">exclude_pad_area</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">is_global</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">padding_top</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">padding_right</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">same_padding_asymmetry_mode</span><span class="o">=</span><span class="s2">&quot;BOTTOM_RIGHT_HEAVY&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a pooling layer to the model that performs spatial pooling.</span>
<span class="sd">        Refer to the ``PoolingLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        height: int</span>
<span class="sd">            Height of pooling region.</span>

<span class="sd">        width: int</span>
<span class="sd">            Width of pooling region.</span>

<span class="sd">        stride_height: int</span>
<span class="sd">            Stride along the height direction.</span>

<span class="sd">        stride_width: int</span>
<span class="sd">            Stride along the width direction.</span>

<span class="sd">        layer_type: str</span>
<span class="sd">            Type of pooling performed. Can either be ``&#39;MAX&#39;``, ``&#39;AVERAGE&#39;``, or ``&#39;L2&#39;``.</span>

<span class="sd">        padding_type: str</span>
<span class="sd">            Option for the type of padding and output blob shape. Can be either</span>
<span class="sd">            ``&#39;VALID&#39;``, ``&#39;SAME&#39;``, or ``&#39;INCLUDE_LAST_PIXEL&#39;``.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        exclude_pad_area: boolean</span>
<span class="sd">            Whether to exclude padded area in the ``&#39;AVERAGE&#39;`` pooling operation,</span>
<span class="sd">            default: true. This flag is only used with average pooling.</span>

<span class="sd">            - If True, the value of the padded area will be excluded.</span>
<span class="sd">            - If False, the padded area will be included.</span>

<span class="sd">        is_global: boolean</span>
<span class="sd">            Whether the pooling operation is global. Defaults to False.</span>

<span class="sd">            - If True, the pooling operation is global. The pooling region</span>
<span class="sd">              is of the same size of the input blob.</span>
<span class="sd">              Parameters ``height``, ``width``, ``stride_height``, and ``stride_width`` will be ignored.</span>
<span class="sd">            - If False, the pooling operation is not global.</span>

<span class="sd">        padding_top, padding_bottom, padding_left, padding_right: int</span>
<span class="sd">            Values of height (top, bottom) and width (left, right) padding</span>
<span class="sd">            to be used if padding type is ``&quot;VALID&quot;`` or ``&quot;INCLUDE_LAST_PIXEL&quot;``.</span>

<span class="sd">        same_padding_asymmetry_mode: str.</span>
<span class="sd">            Type of asymmetric padding to be used when ``padding_type = &#39;SAME&#39;``.</span>
<span class="sd">            Can be either ``&#39;BOTTOM_RIGHT_HEAVY&#39;`` or ``&#39;TOP_LEFT_HEAVY&#39;``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_pooling3d, add_convolution, add_activation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create spec layer</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">pooling</span>

        <span class="c1"># Set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">PoolingLayerParams</span><span class="o">.</span><span class="n">PoolingType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
            <span class="n">layer_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">padding_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">padding_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding_type</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">padding_type</span>
        <span class="p">)</span>
        <span class="n">same_padding_asymmetry_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">same_padding_asymmetry_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">same_padding_asymmetry_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">same_padding_asymmetry_mode</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;VALID&quot;</span><span class="p">:</span>
            <span class="n">height_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
            <span class="n">height_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">padding_top</span>
            <span class="n">height_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">padding_bottom</span>
            <span class="n">width_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
            <span class="n">width_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">padding_left</span>
            <span class="n">width_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">padding_right</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;SAME&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">same_padding_asymmetry_mode</span> <span class="o">==</span> <span class="s2">&quot;BOTTOM_RIGHT_HEAVY&quot;</span>
                <span class="ow">or</span> <span class="n">same_padding_asymmetry_mode</span> <span class="o">==</span> <span class="s2">&quot;TOP_LEFT_HEAVY&quot;</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid value </span><span class="si">%d</span><span class="s2"> of same_padding_asymmetry_mode parameter&quot;</span>
                    <span class="o">%</span> <span class="n">same_padding_asymmetry_mode</span>
                <span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">same</span><span class="o">.</span><span class="n">asymmetryMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamePadding</span><span class="o">.</span><span class="n">SamePaddingMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="n">same_padding_asymmetry_mode</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;INCLUDE_LAST_PIXEL&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">padding_top</span> <span class="o">!=</span> <span class="n">padding_bottom</span> <span class="ow">or</span> <span class="n">padding_left</span> <span class="o">!=</span> <span class="n">padding_right</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Only symmetric padding is supported with the INCLUDE_LAST_PIXEL padding type&quot;</span>
                <span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">includeLastPixel</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">padding_top</span><span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">includeLastPixel</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">padding_left</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown padding_type </span><span class="si">%s</span><span class="s2"> in pooling&quot;</span> <span class="o">%</span> <span class="n">padding_type</span><span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stride_height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stride_width</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">avgPoolExcludePadding</span> <span class="o">=</span> <span class="n">exclude_pad_area</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">globalPooling</span> <span class="o">=</span> <span class="n">is_global</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_pooling3d">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_pooling3d">[docs]</a>
    <span class="k">def</span> <span class="nf">add_pooling3d</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">pooling_type</span><span class="p">,</span>
        <span class="n">kernel_depth</span><span class="p">,</span>
        <span class="n">kernel_height</span><span class="p">,</span>
        <span class="n">kernel_width</span><span class="p">,</span>
        <span class="n">stride_depth</span><span class="p">,</span>
        <span class="n">stride_height</span><span class="p">,</span>
        <span class="n">stride_width</span><span class="p">,</span>
        <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
        <span class="n">custom_padding_front</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">custom_padding_back</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">custom_padding_top</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">custom_padding_bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">custom_padding_left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">custom_padding_right</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">average_pooling_count_excludes_padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a pooling layer to the model that performs spatial pooling across three dimensions.</span>
<span class="sd">        Refer to the ``Pooling3DLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        pooling_type: str</span>
<span class="sd">            Type of pooling performed. Can either be ``&#39;MAX&#39;`` OR ``&#39;AVERAGE&#39;``.</span>
<span class="sd">        kernel_depth: int</span>
<span class="sd">            Depth of the pooling region.</span>
<span class="sd">        kernel_height: int</span>
<span class="sd">            Height of pooling region.</span>
<span class="sd">        kernel_width: int</span>
<span class="sd">            Width of pooling region.</span>
<span class="sd">        stride_depth: int</span>
<span class="sd">            Stride along the depth direction</span>
<span class="sd">        stride_height: int</span>
<span class="sd">            Stride along the height direction.</span>
<span class="sd">        stride_width: int</span>
<span class="sd">            Stride along the width direction.</span>
<span class="sd">        padding_mode: str</span>
<span class="sd">            Option for the padding type and output blob shape.</span>
<span class="sd">            Can be ``&#39;VALID&#39;``, ``&#39;SAME&#39;``, or ``&#39;CUSTOM&#39;``.</span>
<span class="sd">        custom_padding_front: int</span>
<span class="sd">            Padding before the input in the depth direction.</span>
<span class="sd">        custom_padding_back: int</span>
<span class="sd">            Padding after the input in the depth direction.</span>
<span class="sd">        custom_padding_top: int</span>
<span class="sd">            Padding before the input in the height direction.</span>
<span class="sd">        custom_padding_bottom: int</span>
<span class="sd">            Padding after the input in the height direction.</span>
<span class="sd">        custom_padding_left: int</span>
<span class="sd">            Padding before the input in the width direction.</span>
<span class="sd">        custom_padding_right: int</span>
<span class="sd">            Padding after the input in the width direction.</span>
<span class="sd">        average_pooling_count_excludes_padding: boolean</span>
<span class="sd">            If true, exclude zeros from padding in average pooling.</span>
<span class="sd">            Can only be true for ``AVERAGE`` padding.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_pooling, add_global_pooling3d</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">pooling3d</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">Pooling3DLayerParams</span><span class="o">.</span><span class="n">PoolingType3D</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
            <span class="n">pooling_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelDepth</span> <span class="o">=</span> <span class="n">kernel_depth</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelHeight</span> <span class="o">=</span> <span class="n">kernel_height</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">kernelWidth</span> <span class="o">=</span> <span class="n">kernel_width</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideDepth</span> <span class="o">=</span> <span class="n">stride_depth</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideHeight</span> <span class="o">=</span> <span class="n">stride_height</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strideWidth</span> <span class="o">=</span> <span class="n">stride_width</span>

        <span class="n">supported_padding_modes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;CUSTOM&quot;</span><span class="p">,</span> <span class="s2">&quot;VALID&quot;</span><span class="p">,</span> <span class="s2">&quot;SAME&quot;</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_padding_modes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported padding mode: </span><span class="si">%s</span><span class="s2">.  Must be one of </span><span class="si">%s</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">padding_mode</span><span class="p">,</span> <span class="n">supported_padding_modes</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;CUSTOM&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingFront</span> <span class="o">=</span> <span class="n">custom_padding_front</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingBack</span> <span class="o">=</span> <span class="n">custom_padding_back</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingTop</span> <span class="o">=</span> <span class="n">custom_padding_top</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingBottom</span> <span class="o">=</span> <span class="n">custom_padding_bottom</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingLeft</span> <span class="o">=</span> <span class="n">custom_padding_left</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">customPaddingRight</span> <span class="o">=</span> <span class="n">custom_padding_right</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">paddingType</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">Pooling3DLayerParams</span><span class="o">.</span><span class="n">Pooling3DPaddingType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="n">padding_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">countExcludePadding</span> <span class="o">=</span> <span class="n">average_pooling_count_excludes_padding</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_global_pooling3d">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_global_pooling3d">[docs]</a>
    <span class="k">def</span> <span class="nf">add_global_pooling3d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">pooling_type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a layer to pool three spatial dimensions down to one value.</span>
<span class="sd">        This behaves like a special case of Pooling3DLayerParams in which</span>
<span class="sd">        the Kernel is the size of the input and there is no padding.</span>

<span class="sd">        Refer to the ``GlobalPooling3DLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        pooling_type: str</span>
<span class="sd">            Type of pooling performed. Can either be ``&#39;MAX&#39;`` OR ``&#39;AVERAGE&#39;``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_pooling, add_pooling3d</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">globalPooling3d</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">GlobalPooling3DLayerParams</span><span class="o">.</span><span class="n">GlobalPoolingType3D</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="n">pooling_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_padding">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_padding">[docs]</a>
    <span class="k">def</span> <span class="nf">add_padding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">right</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">top</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;out&quot;</span><span class="p">,</span>
        <span class="n">padding_type</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>


<span class="sd">        Add a padding layer to the model that performs padding along spatial dimensions.</span>

<span class="sd">        Refer to the ``PaddingLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        left: int</span>
<span class="sd">            Number of elements to be padded on the left side of the input blob.</span>
<span class="sd">        right: int</span>
<span class="sd">            Number of elements to be padded on the right side of the input blob.</span>
<span class="sd">        top: int</span>
<span class="sd">            Number of elements to be padded on the top of the input blob.</span>
<span class="sd">        bottom: int</span>
<span class="sd">            Number of elements to be padded on the bottom of the input blob.</span>
<span class="sd">        value: float</span>
<span class="sd">            Value of the elements padded. Used only when ``padding_type = &#39;constant&#39;``.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        padding_type: str</span>
<span class="sd">            Type of the padding. Can be one of ``&#39;constant&#39;``, ``&#39;reflection&#39;``, or ``&#39;replication&#39;``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_crop, add_convolution, add_pooling, add_constant_pad</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">padding</span>

        <span class="c1"># Set the parameters</span>
        <span class="n">padding_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">padding_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding_type</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">padding_type</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;reflection&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reflection</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s2">&quot;replication&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown padding_type </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">padding_type</span><span class="p">)</span>

        <span class="n">height_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">height_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">top</span>
        <span class="n">height_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">bottom</span>
        <span class="n">width_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">paddingAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">width_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">left</span>
        <span class="n">width_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">right</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_crop">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_crop">[docs]</a>
    <span class="k">def</span> <span class="nf">add_crop</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">top</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a cropping layer to the model.</span>
<span class="sd">        The cropping layer have two functional modes:</span>

<span class="sd">            - When it has 1 input blob, it crops the input blob based</span>
<span class="sd">              on the 4 parameters ``[left, right, top, bottom]``.</span>
<span class="sd">            - When it has 2 input blobs, it crops the first input blob based</span>
<span class="sd">              on the dimension of the second blob with an offset.</span>

<span class="sd">        Refer to the ``CropLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        left: int</span>
<span class="sd">            Number of elements to be cropped on the left side of the input blob.</span>
<span class="sd">            When the crop layer takes 2 inputs, this parameter is ignored.</span>
<span class="sd">        right: int</span>
<span class="sd">            Number of elements to be cropped on the right side of the input blob.</span>
<span class="sd">            When the crop layer takes 2 inputs, this parameter is ignored.</span>
<span class="sd">        top: int</span>
<span class="sd">            Number of elements to be cropped on the top of the input blob.</span>
<span class="sd">            When the crop layer takes 2 inputs, this parameter is ignored.</span>
<span class="sd">        bottom: int</span>
<span class="sd">            Number of elements to be cropped on the bottom of the input blob.</span>
<span class="sd">            When the crop layer takes 2 inputs, this parameter is ignored.</span>
<span class="sd">        offset: list of int</span>
<span class="sd">            Offset along the height and width directions when the crop layer takes 2 inputs. Must be a list of length 2.</span>
<span class="sd">            When the crop layer takes 1 input, this parameter is ignored.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer. Must be either a list of 1 string (1 input crop layer),</span>
<span class="sd">            or a list of 2 strings (2-input crop layer).</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_padding, add_convolution, add_pooling</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">crop</span>

        <span class="c1"># Set the parameters</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">offset</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">offset</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
        <span class="n">height_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">cropAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">height_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">top</span>
        <span class="n">height_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">bottom</span>
        <span class="n">width_border</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">cropAmounts</span><span class="o">.</span><span class="n">borderAmounts</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">width_border</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">=</span> <span class="n">left</span>
        <span class="n">width_border</span><span class="o">.</span><span class="n">endEdgeSize</span> <span class="o">=</span> <span class="n">right</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_simple_rnn">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_simple_rnn">[docs]</a>
    <span class="k">def</span> <span class="nf">add_simple_rnn</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W_h</span><span class="p">,</span>
        <span class="n">W_x</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">output_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">reverse_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a simple recurrent layer to the model.</span>
<span class="sd">        Refer to the ``SimpleRecurrentLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W_h: numpy.array</span>
<span class="sd">            Weights of the recurrent layer&#39;s hidden state.</span>
<span class="sd">            Must be of shape ``(hidden_size, hidden_size)``.</span>
<span class="sd">        W_x: numpy.array</span>
<span class="sd">            Weights of the recurrent layer&#39;s input.</span>
<span class="sd">            Must be of shape ``(hidden_size, input_size)``.</span>
<span class="sd">        b: numpy.array or None</span>
<span class="sd">            Bias of the recurrent layer&#39;s output. If ``None``, bias is ignored.</span>
<span class="sd">            Otherwise it must be of shape ``(hidden_size, )``.</span>
<span class="sd">        hidden_size: int</span>
<span class="sd">            Number of hidden units. This is equal to the number of channels of output shape.</span>
<span class="sd">        input_size: int</span>
<span class="sd">            Number of the number of channels of input shape.</span>
<span class="sd">        activation: str</span>
<span class="sd">            Activation function name. Can be one of the following option:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            See add_activation for more detailed description.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names list of this layer, in the order of ``[x, h_input]``.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names list of this layer, in the order of ``[y, h_output]``.</span>
<span class="sd">        output_all: boolean</span>
<span class="sd">            Whether the recurrent layer should output at every time step.</span>

<span class="sd">            - If False, the output is the result after the final state update.</span>
<span class="sd">            - If True, the output is a sequence, containing outputs at all time steps.</span>

<span class="sd">        reverse_input: boolean</span>
<span class="sd">            Whether the recurrent layer should process the input sequence in the reverse order.</span>

<span class="sd">            - If False, the input sequence order is not reversed.</span>
<span class="sd">            - If True, the input sequence order is reversed.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation, add_gru, add_unilstm, add_bidirlstm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">simpleRecurrent</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reverseInput</span> <span class="o">=</span> <span class="n">reverse_input</span>

        <span class="c1"># set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputVectorSize</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputVectorSize</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBiasVector</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">sequenceOutput</span> <span class="o">=</span> <span class="n">output_all</span>

        <span class="n">activation_f</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activation</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_f</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>

        <span class="c1"># Write the weights</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">recursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_h</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">biasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_gru">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_gru">[docs]</a>
    <span class="k">def</span> <span class="nf">add_gru</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W_h</span><span class="p">,</span>
        <span class="n">W_x</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;TANH&quot;</span><span class="p">,</span>
        <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;SIGMOID_HARD&quot;</span><span class="p">,</span>
        <span class="n">output_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">reverse_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a Gated-Recurrent Unit (GRU) layer to the model.</span>
<span class="sd">        Refer to the ``GRULayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W_h: [numpy.array]</span>
<span class="sd">            List of recursion weight matrices. The ordering is ``[R_z, R_r, R_o]``,</span>
<span class="sd">            where ``R_z``, ``R_r`` and ``R_o`` are weight matrices at update gate,</span>
<span class="sd">            reset gate and output gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, hidden_size)``.</span>
<span class="sd">        W_x: [numpy.array]</span>
<span class="sd">            List of input weight matrices. The ordering is ``[W_z, W_r, W_o]``,</span>
<span class="sd">            where ``W_z``, ``W_r``, and ``W_o`` are weight matrices at update gate,</span>
<span class="sd">            reset gate and output gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, input_size)``.</span>
<span class="sd">        b: [numpy.array] or None</span>
<span class="sd">            List of biases of the GRU layer. The ordering is ``[b_z, b_r, b_o]``,</span>
<span class="sd">            where ``b_z``, ``b_r``, and ``b_o`` are biases at update gate,</span>
<span class="sd">            reset gate and output gate.</span>
<span class="sd">            If ``None``, biases are ignored. Otherwise the shapes of the biases are ``(hidden_size, )``.</span>
<span class="sd">        hidden_size: int</span>
<span class="sd">            Number of hidden units. This is equal to the number of channels of output shape.</span>
<span class="sd">        input_size: int</span>
<span class="sd">            Number of the number of channels of input shape.</span>
<span class="sd">        activation: str</span>
<span class="sd">            Activation function used at the output gate. Can be one of the following options:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            Defaults to ``&#39;TANH&#39;``.</span>
<span class="sd">            See add_activation for more detailed description.</span>
<span class="sd">        inner_activation: str</span>
<span class="sd">            Inner activation function used at update and reset gates.</span>
<span class="sd">            Can be one of the following options:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            Defaults to ``&#39;SIGMOID_HARD&#39;``.</span>
<span class="sd">            See add_activation for more detailed description.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names list of this layer, in the order of ``[x, h_input]``.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names list of this layer, in the order of ``[y, h_output]``.</span>
<span class="sd">        output_all: boolean</span>
<span class="sd">            Whether the recurrent layer should output at every time step.</span>

<span class="sd">            - If False, the output is the result after the final state update.</span>
<span class="sd">            - If True, the output is a sequence, containing outputs at all time steps.</span>

<span class="sd">        reverse_input: boolean</span>
<span class="sd">            Whether the recurrent layer should process the input sequence in the reverse order.</span>

<span class="sd">            - If False, the input sequence order is not reversed.</span>
<span class="sd">            - If True, the input sequence order is reversed.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation, add_simple_rnn, add_unilstm, add_bidirlstm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">gru</span>

        <span class="c1"># set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputVectorSize</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputVectorSize</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBiasVectors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">sequenceOutput</span> <span class="o">=</span> <span class="n">output_all</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reverseInput</span> <span class="o">=</span> <span class="n">reverse_input</span>

        <span class="n">activation_f</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_g</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_f</span><span class="p">,</span> <span class="n">inner_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_g</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>

        <span class="c1"># Write the weights</span>
        <span class="n">R_z</span><span class="p">,</span> <span class="n">R_r</span><span class="p">,</span> <span class="n">R_o</span> <span class="o">=</span> <span class="n">W_h</span>
        <span class="n">W_z</span><span class="p">,</span> <span class="n">W_r</span><span class="p">,</span> <span class="n">W_o</span> <span class="o">=</span> <span class="n">W_x</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">updateGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">resetGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_r</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">updateGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">resetGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_r</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">b_z</span><span class="p">,</span> <span class="n">b_r</span><span class="p">,</span> <span class="n">b_o</span> <span class="o">=</span> <span class="n">b</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">updateGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">resetGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_r</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_unilstm">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_unilstm">[docs]</a>
    <span class="k">def</span> <span class="nf">add_unilstm</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W_h</span><span class="p">,</span>
        <span class="n">W_x</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;SIGMOID&quot;</span><span class="p">,</span>
        <span class="n">cell_state_update_activation</span><span class="o">=</span><span class="s2">&quot;TANH&quot;</span><span class="p">,</span>
        <span class="n">output_activation</span><span class="o">=</span><span class="s2">&quot;TANH&quot;</span><span class="p">,</span>
        <span class="n">peep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">forget_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">coupled_input_forget_gate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">cell_clip_threshold</span><span class="o">=</span><span class="mf">50000.0</span><span class="p">,</span>
        <span class="n">reverse_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a Uni-directional LSTM layer to the model.</span>
<span class="sd">        Refer to the ``UniDirectionalLSTMLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W_h: [numpy.array]</span>
<span class="sd">            List of recursion weight matrices. The ordering is [R_i, R_f, R_o, R_z],</span>
<span class="sd">            where R_i, R_f, R_o, R_z are weight matrices at input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are (hidden_size, hidden_size).</span>
<span class="sd">        W_x: [numpy.array]</span>
<span class="sd">            List of input weight matrices. The ordering is [W_i, W_f, W_o, W_z],</span>
<span class="sd">            where W_i, W_f, W_o, W_z are weight matrices at input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are (hidden_size, input_size).</span>
<span class="sd">        b: [numpy.array] or None</span>
<span class="sd">            List of biases. The ordering is [b_i, b_f, b_o, b_z],</span>
<span class="sd">            where b_i, b_f, b_o, b_z are biases at input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            If ``None``, biases are ignored. Otherwise the shapes of the biases are (hidden_size, ).</span>
<span class="sd">        hidden_size: int</span>
<span class="sd">            Number of hidden units. This is equal to the number of channels of output shape.</span>
<span class="sd">        input_size: int</span>
<span class="sd">            Number of the number of channels of input shape.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names list of this layer, in the order of [x, h_input, c_input].</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names list of this layer, in the order of [y, h_output, c_output].</span>
<span class="sd">        inner_activation: str</span>
<span class="sd">            Inner activation function used at input and forget gate. Can be one of the following option:</span>
<span class="sd">            [&#39;RELU&#39;, &#39;TANH&#39;, &#39;SIGMOID&#39;, &#39;SCALED_TANH&#39;, &#39;SIGMOID_HARD&#39;, &#39;LINEAR&#39;].</span>
<span class="sd">        cell_state_update_activation: str</span>
<span class="sd">            Cell state update activation function used at the cell state update gate.</span>
<span class="sd">            [&#39;RELU&#39;, &#39;TANH&#39;, &#39;SIGMOID&#39;, &#39;SCALED_TANH&#39;, &#39;SIGMOID_HARD&#39;, &#39;LINEAR&#39;].</span>
<span class="sd">        output_activation: str</span>
<span class="sd">            Activation function used at the output gate. Can be one of the following option:</span>
<span class="sd">            [&#39;RELU&#39;, &#39;TANH&#39;, &#39;SIGMOID&#39;, &#39;SCALED_TANH&#39;, &#39;SIGMOID_HARD&#39;, &#39;LINEAR&#39;].</span>
<span class="sd">        peep: [numpy.array] or None</span>
<span class="sd">            List of peephole vectors. The ordering is [p_i, p_f, p_o],</span>
<span class="sd">            where p_i, p_f, and p_o are peephole vectors at input gate, forget gate, output gate.</span>
<span class="sd">            The shapes of the peephole vectors are (hidden_size,).</span>
<span class="sd">        output_all: boolean</span>
<span class="sd">            Whether the LSTM layer should output at every time step.</span>

<span class="sd">            - If False, the output is the result after the final state update.</span>
<span class="sd">            - If True, the output is a sequence, containing outputs at all time steps.</span>

<span class="sd">        forget_bias: boolean</span>
<span class="sd">            If True, a vector of 1s is added to forget gate bias.</span>
<span class="sd">        coupled_input_forget_gate: boolean</span>
<span class="sd">            If True, the input gate and forget gate is coupled. i.e. forget gate is not used.</span>
<span class="sd">        cell_clip_threshold: float</span>
<span class="sd">            The limit on the maximum and minimum values on the cell state.</span>
<span class="sd">            If not provided, it is defaulted to 50.0.</span>
<span class="sd">        reverse_input: boolean</span>
<span class="sd">            Whether the LSTM layer should process the input sequence in the reverse order.</span>

<span class="sd">            - If False, the input sequence order is not reversed.</span>
<span class="sd">            - If True, the input sequence order is reversed.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation, add_simple_rnn, add_gru, add_bidirlstm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">uniDirectionalLSTM</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">params</span>
        <span class="n">weight_params</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightParams</span>

        <span class="c1"># set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputVectorSize</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputVectorSize</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="n">params</span><span class="o">.</span><span class="n">sequenceOutput</span> <span class="o">=</span> <span class="n">output_all</span>
        <span class="n">params</span><span class="o">.</span><span class="n">forgetBias</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">hasBiasVectors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">peep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">hasPeepholeVectors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">params</span><span class="o">.</span><span class="n">coupledInputAndForgetGate</span> <span class="o">=</span> <span class="n">coupled_input_forget_gate</span>
        <span class="n">params</span><span class="o">.</span><span class="n">cellClipThreshold</span> <span class="o">=</span> <span class="n">cell_clip_threshold</span>
        <span class="n">params</span><span class="o">.</span><span class="n">forgetBias</span> <span class="o">=</span> <span class="n">forget_bias</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reverseInput</span> <span class="o">=</span> <span class="n">reverse_input</span>

        <span class="n">activation_f</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_g</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_h</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_f</span><span class="p">,</span> <span class="n">inner_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_g</span><span class="p">,</span> <span class="n">cell_state_update_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_h</span><span class="p">,</span> <span class="n">output_activation</span><span class="p">)</span>

        <span class="c1"># Write the weights</span>
        <span class="n">R_i</span><span class="p">,</span> <span class="n">R_f</span><span class="p">,</span> <span class="n">R_o</span><span class="p">,</span> <span class="n">R_z</span> <span class="o">=</span> <span class="n">W_h</span>
        <span class="n">W_i</span><span class="p">,</span> <span class="n">W_f</span><span class="p">,</span> <span class="n">W_o</span><span class="p">,</span> <span class="n">W_z</span> <span class="o">=</span> <span class="n">W_x</span>

        <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">b_i</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">b_o</span><span class="p">,</span> <span class="n">b_z</span> <span class="o">=</span> <span class="n">b</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">peep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_i</span><span class="p">,</span> <span class="n">p_f</span><span class="p">,</span> <span class="n">p_o</span> <span class="o">=</span> <span class="n">peep</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_bidirlstm">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_bidirlstm">[docs]</a>
    <span class="k">def</span> <span class="nf">add_bidirlstm</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">W_h</span><span class="p">,</span>
        <span class="n">W_x</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">W_h_back</span><span class="p">,</span>
        <span class="n">W_x_back</span><span class="p">,</span>
        <span class="n">b_back</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;SIGMOID&quot;</span><span class="p">,</span>
        <span class="n">cell_state_update_activation</span><span class="o">=</span><span class="s2">&quot;TANH&quot;</span><span class="p">,</span>
        <span class="n">output_activation</span><span class="o">=</span><span class="s2">&quot;TANH&quot;</span><span class="p">,</span>
        <span class="n">peep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">peep_back</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">forget_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">coupled_input_forget_gate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">cell_clip_threshold</span><span class="o">=</span><span class="mf">50000.0</span><span class="p">,</span>
    <span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a Bi-directional LSTM layer to the model.</span>
<span class="sd">        Refer to the ``BiDirectionalLSTMLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        W_h: [numpy.array]</span>
<span class="sd">            List of recursion weight matrices for the forward layer.</span>
<span class="sd">            The ordering is ``[R_i, R_f, R_o, R_z]``,</span>
<span class="sd">            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices at</span>
<span class="sd">            input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, hidden_size)``.</span>
<span class="sd">        W_x: [numpy.array]</span>
<span class="sd">            List of input weight matrices for the forward layer. The ordering</span>
<span class="sd">            is ``[W_i, W_f, W_o, W_z]``,</span>
<span class="sd">            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices at</span>
<span class="sd">            input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, input_size)``.</span>
<span class="sd">        b: [numpy.array]</span>
<span class="sd">            List of biases for the forward layer. The ordering is</span>
<span class="sd">            ``[b_i, b_f, b_o, b_z]``,</span>
<span class="sd">            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input</span>
<span class="sd">            gate, forget gate, output gate and cell gate.</span>
<span class="sd">            If ``None``, biases are ignored. Otherwise the shapes of the biases</span>
<span class="sd">            are ``(hidden_size, )``.</span>
<span class="sd">        W_h_back: [numpy.array]</span>
<span class="sd">            List of recursion weight matrices for the backward layer. The</span>
<span class="sd">            ordering is ``[R_i, R_f, R_o, R_z]``,</span>
<span class="sd">            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices</span>
<span class="sd">            at input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, hidden_size)``.</span>
<span class="sd">        W_x_back: [numpy.array]</span>
<span class="sd">            List of input weight matrices for the backward layer. The ordering</span>
<span class="sd">            is `[W_i, W_f, W_o, W_z]``,</span>
<span class="sd">            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices</span>
<span class="sd">            at input gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of these matrices are ``(hidden_size, input_size)``.</span>
<span class="sd">        b_back: [numpy.array]</span>
<span class="sd">            List of biases for the backward layer. The ordering is ``[b_i, b_f, b_o, b_z]``,</span>
<span class="sd">            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input</span>
<span class="sd">            gate, forget gate, output gate and cell gate.</span>
<span class="sd">            The shapes of the biases ``(hidden_size)``.</span>
<span class="sd">        hidden_size: int</span>
<span class="sd">            Number of hidden units. This is equal to the number of channels of output shape.</span>
<span class="sd">        input_size: int</span>
<span class="sd">            Number of the number of channels of input shape.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer, in the order of</span>
<span class="sd">            ``[x, h_input, c_input, h_reverse_input, c_reverse_input]``.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names of this layer, in the order of</span>
<span class="sd">            ``[y, h_output, c_output, h_reverse_output, c_reverse_output]``.</span>
<span class="sd">        inner_activation: str</span>
<span class="sd">            Inner activation function used at input and forget gate. Can be one</span>
<span class="sd">            of the following options:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            Defaults to ``&#39;SIGMOID&#39;``.</span>
<span class="sd">        cell_state_update_activation: str</span>
<span class="sd">            Cell state update activation function used at the cell state update gate.</span>
<span class="sd">            Can be one of the following options:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            Defaults to ``&#39;TANH&#39;``.</span>
<span class="sd">        output_activation: str</span>
<span class="sd">            Activation function used at the output gate. Can be one of the following options:</span>
<span class="sd">            [``&#39;RELU&#39;``, ``&#39;TANH&#39;``, ``&#39;SIGMOID&#39;``, ``&#39;SCALED_TANH&#39;``, ``&#39;SIGMOID_HARD&#39;``, ``&#39;LINEAR&#39;``].</span>
<span class="sd">            Defaults to ``&#39;TANH&#39;``.</span>
<span class="sd">        peep: [numpy.array] or None</span>
<span class="sd">            List of peephole vectors for the forward layer. The ordering</span>
<span class="sd">            is ``[p_i, p_f, p_o]``,</span>
<span class="sd">            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input</span>
<span class="sd">            gate, forget gate, and output gate.</span>
<span class="sd">            The shapes of the peephole vectors are ``(hidden_size,)``. Defaults to ``None``.</span>
<span class="sd">        peep_back: [numpy.array] or None</span>
<span class="sd">            List of peephole vectors for the backward layer. The ordering</span>
<span class="sd">            is ``[p_i, p_f, p_o]``,</span>
<span class="sd">            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input</span>
<span class="sd">            gate, forget gate, and output gate.</span>
<span class="sd">            The shapes of the peephole vectors are ``(hidden_size,)``. Defaults to ``None``.</span>
<span class="sd">        output_all: boolean</span>
<span class="sd">            Whether the LSTM layer should output at every time step. Defaults to ``False``.</span>

<span class="sd">            - If ``False``, the output is the result after the final state update.</span>
<span class="sd">            - If ``True``, the output is a sequence, containing outputs at all time steps.</span>

<span class="sd">        forget_bias: boolean</span>
<span class="sd">            If ``True``, a vector of 1s is added to forget gate bias. Defaults to ``False``.</span>
<span class="sd">        coupled_input_forget_gate: boolean</span>
<span class="sd">            If ``True``, the input gate and forget gate is coupled. That is, the</span>
<span class="sd">            forget gate is not used.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        cell_clip_threshold: float</span>
<span class="sd">            The limit on the maximum and minimum values on the cell state.</span>
<span class="sd">            Defaults to 50.0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation, add_simple_rnn, add_unilstm, add_bidirlstm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">biDirectionalLSTM</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">params</span>
        <span class="n">weight_params</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightParams</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">weight_params_back</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightParams</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>

        <span class="c1"># set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">inputVectorSize</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputVectorSize</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">hasBiasVectors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">params</span><span class="o">.</span><span class="n">sequenceOutput</span> <span class="o">=</span> <span class="n">output_all</span>
        <span class="n">params</span><span class="o">.</span><span class="n">forgetBias</span> <span class="o">=</span> <span class="n">forget_bias</span>
        <span class="k">if</span> <span class="n">peep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">hasPeepholeVectors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">params</span><span class="o">.</span><span class="n">coupledInputAndForgetGate</span> <span class="o">=</span> <span class="n">coupled_input_forget_gate</span>
        <span class="n">params</span><span class="o">.</span><span class="n">cellClipThreshold</span> <span class="o">=</span> <span class="n">cell_clip_threshold</span>

        <span class="c1"># set activations</span>
        <span class="n">activation_f</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsForwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_g</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsForwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_h</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsForwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_f</span><span class="p">,</span> <span class="n">inner_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_g</span><span class="p">,</span> <span class="n">cell_state_update_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_h</span><span class="p">,</span> <span class="n">output_activation</span><span class="p">)</span>

        <span class="n">activation_f_back</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsBackwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_g_back</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsBackwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">activation_h_back</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">activationsBackwardLSTM</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_f_back</span><span class="p">,</span> <span class="n">inner_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_g_back</span><span class="p">,</span> <span class="n">cell_state_update_activation</span><span class="p">)</span>
        <span class="n">_set_recurrent_activation</span><span class="p">(</span><span class="n">activation_h_back</span><span class="p">,</span> <span class="n">output_activation</span><span class="p">)</span>

        <span class="c1"># Write the forward lstm weights</span>
        <span class="n">R_i</span><span class="p">,</span> <span class="n">R_f</span><span class="p">,</span> <span class="n">R_o</span><span class="p">,</span> <span class="n">R_z</span> <span class="o">=</span> <span class="n">W_h</span>
        <span class="n">W_i</span><span class="p">,</span> <span class="n">W_f</span><span class="p">,</span> <span class="n">W_o</span><span class="p">,</span> <span class="n">W_z</span> <span class="o">=</span> <span class="n">W_x</span>

        <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">b_i</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">b_o</span><span class="p">,</span> <span class="n">b_z</span> <span class="o">=</span> <span class="n">b</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">blockInputBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">peep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_i</span><span class="p">,</span> <span class="n">p_f</span><span class="p">,</span> <span class="n">p_o</span> <span class="o">=</span> <span class="n">peep</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">inputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">forgetGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params</span><span class="o">.</span><span class="n">outputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># Write the backward lstm weights</span>
        <span class="n">R_i</span><span class="p">,</span> <span class="n">R_f</span><span class="p">,</span> <span class="n">R_o</span><span class="p">,</span> <span class="n">R_z</span> <span class="o">=</span> <span class="n">W_h_back</span>
        <span class="n">W_i</span><span class="p">,</span> <span class="n">W_f</span><span class="p">,</span> <span class="n">W_o</span><span class="p">,</span> <span class="n">W_z</span> <span class="o">=</span> <span class="n">W_x_back</span>

        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">inputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">forgetGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">outputGateWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">blockInputWeightMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">inputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">forgetGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">outputGateRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">weight_params_back</span><span class="o">.</span><span class="n">blockInputRecursionMatrix</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">R_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">b_back</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">b_i</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">b_o</span><span class="p">,</span> <span class="n">b_z</span> <span class="o">=</span> <span class="n">b_back</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">inputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">forgetGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">outputGateBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">blockInputBiasVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b_z</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">peep_back</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_i</span><span class="p">,</span> <span class="n">p_f</span><span class="p">,</span> <span class="n">p_o</span> <span class="o">=</span> <span class="n">peep_back</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">inputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">forgetGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">weight_params_back</span><span class="o">.</span><span class="n">outputGatePeepholeVector</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">p_o</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_flatten">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_flatten">[docs]</a>
    <span class="k">def</span> <span class="nf">add_flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a flatten layer. Only flattens the channel, height and width axis.</span>
<span class="sd">        Leaves the sequence axis as is.</span>
<span class="sd">        Refer to the ``FlattenLayerParams`` message in the</span>
<span class="sd">        specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        mode: int</span>

<span class="sd">            - If mode == 0, the flatten layer is in CHANNEL_FIRST mode.</span>
<span class="sd">            - If mode == 1, the flatten layer is in CHANNEL_LAST mode.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_permute, add_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">flatten</span>

        <span class="c1"># Set the parameters</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">FlattenLayerParams</span><span class="o">.</span><span class="n">FlattenOrder</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHANNEL_FIRST&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">FlattenLayerParams</span><span class="o">.</span><span class="n">FlattenOrder</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHANNEL_LAST&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unknown flatten mode </span><span class="si">%d</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_slice">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_slice">[docs]</a>
    <span class="k">def</span> <span class="nf">add_slice</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">start_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a slice layer. Equivalent to to numpy slice [start_index:end_index:stride],</span>
<span class="sd">        start_index is included, while end_index is exclusive.</span>
<span class="sd">        Refer to the ``SliceLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: str</span>
<span class="sd">            axis along which input is sliced.</span>
<span class="sd">            allowed values: &#39;channel&#39;, &#39;height&#39;, &#39;width&#39;</span>
<span class="sd">        start_index: int</span>
<span class="sd">            must be non-negative.</span>
<span class="sd">        end_index: int</span>
<span class="sd">            negative indexing is supported.</span>
<span class="sd">        stride: int</span>
<span class="sd">            must be positive.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_permute, add_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">slice</span>

        <span class="c1"># Set the parameters</span>
        <span class="k">if</span> <span class="n">start_index</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid start_index value </span><span class="si">%d</span><span class="s2">. Must be non-negative.&quot;</span> <span class="o">%</span> <span class="n">start_index</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid stride value </span><span class="si">%d</span><span class="s2">. Must be positive.&quot;</span> <span class="o">%</span> <span class="n">stride</span><span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">startIndex</span> <span class="o">=</span> <span class="n">start_index</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">endIndex</span> <span class="o">=</span> <span class="n">end_index</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

        <span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">axis</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;channel&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SliceLayerParams</span><span class="o">.</span><span class="n">SliceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHANNEL_AXIS&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;height&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SliceLayerParams</span><span class="o">.</span><span class="n">SliceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;HEIGHT_AXIS&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SliceLayerParams</span><span class="o">.</span><span class="n">SliceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;WIDTH_AXIS&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unsupported Slice axis </span><span class="si">%s</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_slice_by_size">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_slice_by_size">[docs]</a>
    <span class="k">def</span> <span class="nf">add_slice_by_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a slice layer. Equivalent to to numpy slice [start_index: start_index+size],</span>
<span class="sd">        Input is list of str which is [input_tensor, begin_id].</span>

<span class="sd">        Assume input_tensor has shape (2, 3, 4), and axis=1, size=2.</span>
<span class="sd">        This would produce input_tensor[:, begin_id:begin_id+2, :]</span>

<span class="sd">        Refer to the ``SliceBySizeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            axis along which input is sliced.</span>
<span class="sd">        size: int</span>
<span class="sd">            The size of which input will be taken</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_slice, add_slice_static, add_slice_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">sliceBySize</span>

        <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid size value </span><span class="si">%d</span><span class="s2">. Must be positive.&quot;</span> <span class="o">%</span> <span class="n">size</span><span class="p">)</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reorganize_data">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reorganize_data">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reorganize_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;SPACE_TO_DEPTH&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a data reorganization layer of type &quot;SPACE_TO_DEPTH&quot; or &quot;DEPTH_TO_SPACE&quot;.</span>
<span class="sd">        Refer to the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        mode: str</span>

<span class="sd">            - If mode == &#39;SPACE_TO_DEPTH&#39;: data is moved from the spatial to the channel dimension.</span>
<span class="sd">              Input is spatially divided into non-overlapping blocks of size block_size X block_size</span>
<span class="sd">              and data from each block is moved to the channel dimension.</span>
<span class="sd">              Output CHW dimensions are: [C * block_size * block_size, H/block_size, C/block_size].</span>

<span class="sd">            - If mode == &#39;DEPTH_TO_SPACE&#39;: data is moved from the channel to the spatial dimension.</span>
<span class="sd">              Reverse of the operation &#39;SPACE_TO_DEPTH&#39;.</span>
<span class="sd">              Output CHW dimensions are: [C/(block_size * block_size), H * block_size, C * block_size].</span>

<span class="sd">            - If mode == &#39;PIXEL_SHUFFLE&#39;:  data is moved from the channel to the spatial dimension.</span>
<span class="sd">              Reverse of the operation &#39;SPACE_TO_DEPTH&#39;.</span>
<span class="sd">              Output CHW dimensions are: [C/(block_size * block_size), H * block_size, C * block_size].</span>

<span class="sd">        block_size: int</span>
<span class="sd">            Must be greater than 1. Must divide H and W, when mode is &#39;SPACE_TO_DEPTH&#39;. (block_size * block_size)</span>
<span class="sd">            must divide C when mode is &#39;DEPTH_TO_SPACE&#39; or &#39;PIXEL_SHUFFLE&#39;.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_flatten, add_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reorganizeData</span>

        <span class="c1"># Set the parameters</span>
        <span class="k">if</span> <span class="n">block_size</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid block_size value </span><span class="si">%d</span><span class="s2">. Must be greater than 1.&quot;</span> <span class="o">%</span> <span class="n">block_size</span>
            <span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">blockSize</span> <span class="o">=</span> <span class="n">block_size</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SPACE_TO_DEPTH&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReorganizeDataLayerParams</span><span class="o">.</span><span class="n">ReorganizationType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;SPACE_TO_DEPTH&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;DEPTH_TO_SPACE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReorganizeDataLayerParams</span><span class="o">.</span><span class="n">ReorganizationType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;DEPTH_TO_SPACE&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;PIXEL_SHUFFLE&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReorganizeDataLayerParams</span><span class="o">.</span><span class="n">ReorganizationType</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;PIXEL_SHUFFLE&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unknown reorganization mode </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_batchnorm">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_batchnorm">[docs]</a>
    <span class="k">def</span> <span class="nf">add_batchnorm</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">,</span>
        <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">variance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">output_name</span><span class="o">=</span><span class="s2">&quot;out&quot;</span><span class="p">,</span>
        <span class="n">compute_mean_var</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">instance_normalization</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a batch normalization layer. Batch normalization operation is</span>
<span class="sd">        defined as:</span>

<span class="sd">        ``y = gamma * (x - mean) / sqrt(variance + epsilon) + beta``</span>

<span class="sd">        Refer to the ``BatchnormLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        channels: int</span>
<span class="sd">            Number of channels of the input blob.</span>
<span class="sd">        gamma: numpy.array</span>
<span class="sd">            Values of gamma. Must be numpy array of shape ``(channels, )``.</span>
<span class="sd">        beta: numpy.array</span>
<span class="sd">            Values of beta. Must be numpy array of shape ``(channels, )``.</span>
<span class="sd">        mean: numpy.array</span>
<span class="sd">            Means of the input blob on each channel. Must be numpy array of shape ``(channels, )``.</span>
<span class="sd">        variance:</span>
<span class="sd">            Variances of the input blob on each channel. Must be numpy array of shape ``(channels, )``.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        compute_mean_var: bool</span>
<span class="sd">            Set to ``True`` if mean and variance is to be computed from the input data.</span>
<span class="sd">        instance_normalization: bool</span>
<span class="sd">            Set compute_mean_var and this to ``True`` to perform</span>
<span class="sd">            instance normalization. That is, mean and variance are computed</span>
<span class="sd">            from the single input instance.</span>
<span class="sd">        epsilon: float</span>
<span class="sd">            Value of epsilon. Defaults to ``1e-5`` if not specified.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_convolution, add_pooling, add_inner_product</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">batchnorm</span>

        <span class="c1"># Set the parameters</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">gamma</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">computeMeanVar</span> <span class="o">=</span> <span class="n">compute_mean_var</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">instanceNormalization</span> <span class="o">=</span> <span class="n">instance_normalization</span>

        <span class="k">if</span> <span class="n">compute_mean_var</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">instance_normalization</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Batch-instance norm is currently not supported&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">compute_mean_var</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">variance</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_permute">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_permute">[docs]</a>
    <span class="k">def</span> <span class="nf">add_permute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a permute layer. Assumes that the input has dimensions in the order [Seq, C, H, W]</span>
<span class="sd">        Refer to the ``PermuteLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        dim: tuple</span>
<span class="sd">            The order in which to permute the input dimensions = [seq,C,H,W].</span>
<span class="sd">            Must have length 4 and a permutation of ``[0, 1, 2, 3]``.</span>

<span class="sd">            examples:</span>

<span class="sd">            Lets say input has shape: [seq, C, H, W].</span>

<span class="sd">            If ``dim`` is set to ``[0, 3, 1, 2]``,</span>
<span class="sd">            then the output has shape ``[W,C,H]``</span>
<span class="sd">            and has the same sequence length that of the input.</span>

<span class="sd">            If ``dim`` is set to ``[3, 1, 2, 0]``,</span>
<span class="sd">            and the input is a sequence of data</span>
<span class="sd">            with length ``Seq`` and shape ``[C, 1, 1]``,</span>
<span class="sd">            then the output is a unit sequence of data with shape ``[C, 1, Seq]``.</span>

<span class="sd">            If ``dim`` is set to ``[0, 3, 2, 1]``,</span>
<span class="sd">            the output is a reverse of the input: ``[C, H, W] -&gt; [W, H, C]``.</span>

<span class="sd">            If ``dim`` is not set, or is set to ``[0, 1, 2, 3]``,</span>
<span class="sd">            the output is the same as the input.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_flatten, add_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">permute</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Length of the &#39;dim&#39; parameter must be equal to 4&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reshape">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reshape">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">target_shape</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reshape layer.</span>
<span class="sd">        Refer to the ``ReshapeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        target_shape: tuple</span>
<span class="sd">            Shape of the output blob. The product of target_shape must be equal</span>
<span class="sd">            to the shape of the input blob.</span>
<span class="sd">            Can be either length 3 (C,H,W) or length 4 (Seq,C,H,W).</span>
<span class="sd">        mode: int</span>

<span class="sd">            - If mode == 0, the reshape layer is in CHANNEL_FIRST mode.</span>
<span class="sd">            - If mode == 1, the reshape layer is in CHANNEL_LAST mode.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_flatten, add_permute</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reshape</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">target_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReshapeLayerParams</span><span class="o">.</span><span class="n">ReshapeOrder</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHANNEL_FIRST&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReshapeLayerParams</span><span class="o">.</span><span class="n">ReshapeOrder</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHANNEL_LAST&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Length of the &#39;target-shape&#39; parameter must be equal to 3 or 4&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce layer. Applies the function specified by the parameter mode,</span>
<span class="sd">        along dimension(s) specified by the parameter axis.</span>
<span class="sd">        Refer to the ``ReduceLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        axis: str</span>
<span class="sd">            dimensions along which the reduction operation is applied.</span>
<span class="sd">            Allowed values: &#39;CHW&#39;, &#39;HW&#39;, &#39;C&#39;, &#39;H&#39;, &#39;W&#39;</span>

<span class="sd">        mode: str</span>
<span class="sd">            Reduction operation to be applied.</span>
<span class="sd">            Allowed values:</span>
<span class="sd">            &#39;sum&#39;, &#39;avg&#39;, &#39;prod&#39;, &#39;logsum&#39;, &#39;sumsquare&#39;, &#39;L1&#39;, &#39;L2&#39;, &#39;max&#39;, &#39;min&#39;, &#39;argmax&#39;.</span>
<span class="sd">            &#39;argmax&#39; is only supported with axis values &#39;C&#39;, &#39;H&#39; and &#39;W&#39;.</span>

<span class="sd">        epsilon: float</span>
<span class="sd">            number that is added to the input when &#39;logsum&#39; function is applied.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduce</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SUM&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;avg&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;AVG&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;prod&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;PROD&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;logsum&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;LOGSUM&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;sumsquare&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SUMSQUARE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;l1&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;L1&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;l2&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;L2&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;MAX&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;MIN&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;argmax&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceOperation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ARGMAX&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unknown reduction operation </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">axis</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;CHW&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;CHW&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;HW&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;HW&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;C&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;C&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;H&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;H&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="s2">&quot;W&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ReduceLayerParams</span><span class="o">.</span><span class="n">ReduceAxis</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;W&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unknown reduction axis </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_lrn">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_lrn">[docs]</a>
    <span class="k">def</span> <span class="nf">add_lrn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">local_size</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a LRN (local response normalization) layer. Supports &quot;across&quot; channels normalization.</span>
<span class="sd">        Refer to the ``LRNLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        alpha: float</span>
<span class="sd">            multiplicative constant in the denominator.</span>
<span class="sd">        beta: float</span>
<span class="sd">            exponent of the normalizing term in the denominator.</span>
<span class="sd">        k: float</span>
<span class="sd">            bias term in the denominator. Must be positive.</span>
<span class="sd">        local_size: int</span>
<span class="sd">            size of the neighborhood along the channel axis.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_l2_normalize, add_mvn</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">lrn</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">localSize</span> <span class="o">=</span> <span class="n">local_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_mvn">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_mvn">[docs]</a>
    <span class="k">def</span> <span class="nf">add_mvn</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">across_channels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">normalize_variance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an MVN (mean variance normalization) layer. Computes mean, variance and normalizes the input.</span>
<span class="sd">        Refer to the ``MeanVarianceNormalizeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        across_channels: boolean</span>
<span class="sd">            If False, each channel plane is normalized separately</span>
<span class="sd">            If True, mean/variance is computed across all C, H and W dimensions</span>

<span class="sd">        normalize_variance: boolean</span>
<span class="sd">            If False, only mean subtraction is performed.</span>

<span class="sd">        epsilon: float</span>
<span class="sd">            small bias to avoid division by zero.</span>


<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_l2_normalize, add_lrn</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">mvn</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">acrossChannels</span> <span class="o">=</span> <span class="n">across_channels</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">normalizeVariance</span> <span class="o">=</span> <span class="n">normalize_variance</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_l2_normalize">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_l2_normalize">[docs]</a>
    <span class="k">def</span> <span class="nf">add_l2_normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add L2 normalize layer. Normalizes the input by the L2 norm, i.e. divides by the</span>
<span class="sd">        the square root of the sum of squares of all elements of the input along C, H and W dimensions.</span>
<span class="sd">        Refer to the ``L2NormalizeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        epsilon: float</span>
<span class="sd">            small bias to avoid division by zero.</span>


<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_mvn, add_lrn</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">l2normalize</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_unary">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_unary">[docs]</a>
    <span class="k">def</span> <span class="nf">add_unary</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">shift</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a Unary layer. Applies the specified function (mode) to all the elements of the input.</span>
<span class="sd">        Prior to the application of the function the input can be scaled and shifted by using the &#39;scale&#39;,</span>
<span class="sd">        &#39;shift&#39; parameters.</span>
<span class="sd">        Refer to the ``UnaryFunctionLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        mode: str</span>
<span class="sd">            Unary function.</span>
<span class="sd">            Allowed values: &#39;sqrt&#39;, &#39;rsqrt&#39;, &#39;inverse&#39;, &#39;power&#39;, &#39;exp&#39;, &#39;log&#39;, &#39;abs&#39;, threshold&#39;.</span>

<span class="sd">        alpha: float</span>
<span class="sd">            constant used in with modes &#39;power&#39; and &#39;threshold&#39;.</span>

<span class="sd">        shift, scale: float</span>
<span class="sd">            input is modified by scale and shift prior to the application of the unary function.</span>

<span class="sd">        epsilon: float</span>
<span class="sd">            small bias to prevent division by zero.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">unary</span>
        <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use the default value of epsilon to be 1e-4, instead of 1e-6, if mode = &quot;rsqrt&quot; or &quot;inverse&quot;</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;inverse&quot;</span> <span class="ow">or</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;rsqrt&quot;</span><span class="p">:</span>
                <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-4</span>
            <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span><span class="p">:</span>
                <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-45</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-6</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SQRT&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;rsqrt&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;RSQRT&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;inverse&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;INVERSE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;power&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;POWER&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;EXP&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;LOG&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;abs&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ABS&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;threshold&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">UnaryFunctionLayerParams</span><span class="o">.</span><span class="n">Operation</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;THRESHOLD&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Unknown unary function </span><span class="si">%s</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_split">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_split">[docs]</a>
    <span class="k">def</span> <span class="nf">add_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_names</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a split layer that uniformly splits the input along the channel dimension</span>
<span class="sd">        to produce multiple outputs.</span>
<span class="sd">        Refer to the ``SplitLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            List of output blob names of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_elementwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">split</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">nOutputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_load_constant">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_load_constant">[docs]</a>
    <span class="k">def</span> <span class="nf">add_load_constant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">constant_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a load constant layer.</span>
<span class="sd">        Refer to the ``LoadConstantLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        constant_value: numpy.array</span>
<span class="sd">            value of the constant as a numpy array.</span>

<span class="sd">        shape: list of int or tuple of int</span>
<span class="sd">            List of ints representing the shape of the constant. Must be of length 3: [C,H,W]</span>


<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_elementwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">loadConstant</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">data</span>
        <span class="n">data</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">constant_value</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">floatValue</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dimensions of &#39;shape&#39; do not match the size of the provided constant&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_disable_rank5_shape_mapping</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;shape&#39; must be of length 3&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_custom">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_custom">[docs]</a>
    <span class="k">def</span> <span class="nf">add_custom</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">custom_proto_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a custom layer.</span>
<span class="sd">        Refer to the ``CustomLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names to this layer.</span>

<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names from this layer.</span>

<span class="sd">        custom_proto_spec: CustomLayerParams</span>
<span class="sd">            A protobuf CustomLayerParams message. This can also be left blank and filled in later.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># custom layers require a newer specification version</span>
        <span class="kn">from</span> <span class="nn">coremltools</span> <span class="kn">import</span> <span class="n">_MINIMUM_CUSTOM_LAYER_SPEC_VERSION</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span><span class="p">,</span> <span class="n">_MINIMUM_CUSTOM_LAYER_SPEC_VERSION</span>
            <span class="p">)</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>

        <span class="n">spec_layer</span><span class="o">.</span><span class="n">custom</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">custom_proto_spec</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">custom</span><span class="o">.</span><span class="n">CopyFrom</span><span class="p">(</span><span class="n">custom_proto_spec</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_resize_bilinear">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_resize_bilinear">[docs]</a>
    <span class="k">def</span> <span class="nf">add_resize_bilinear</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">target_height</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">target_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a resize bilinear layer to the model. A layer that resize the input to a given spatial size using bilinear interpolation.</span>
<span class="sd">        Refer to the ``ResizeBilinearLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        target_height: int</span>
<span class="sd">            Output height dimension.</span>
<span class="sd">        target_width: int</span>
<span class="sd">            Output width dimension.</span>
<span class="sd">        mode: str</span>
<span class="sd">            Following values are supported: &#39;STRICT_ALIGN_ENDPOINTS_MODE&#39;, &#39;ALIGN_ENDPOINTS_MODE&#39;, &#39;UPSAMPLE_MODE&#39;, &#39;ROI_ALIGN_MODE&#39;.</span>
<span class="sd">            This parameter determines the sampling grid used for bilinear interpolation.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_upsample</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">resizeBilinear</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_width</span><span class="p">)</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">:</span>

            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;STRICT_ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;STRICT_ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UPSAMPLE_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;UPSAMPLE_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ROI_ALIGN_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ROI_ALIGN_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported resize bilinear mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_crop_resize">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_crop_resize">[docs]</a>
    <span class="k">def</span> <span class="nf">add_crop_resize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">target_height</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">target_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;STRICT_ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">,</span>
        <span class="n">normalized_roi</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">box_indices_mode</span><span class="o">=</span><span class="s2">&quot;CORNERS_HEIGHT_FIRST&quot;</span><span class="p">,</span>
        <span class="n">spatial_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a crop resize layer to the model. A layer that extracts cropped spatial patches or RoIs (regions of interest)</span>
<span class="sd">        from the input and resizes them to a pre-specified size using bilinear interpolation.</span>
<span class="sd">        Note that RoI Align layer can be implemented with this layer followed by a pooling layer.</span>
<span class="sd">        Refer to the ``CropResizeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_names: list of str</span>
<span class="sd">            * Must be a list of two names: image feature map and crop indices/RoI input.</span>
<span class="sd">               * First input corresponds to a blob with shape ``[1, Batch, C, H_in, W_in]``.</span>
<span class="sd">                 This represents a batch of input image feature data with ``C`` channels.</span>
<span class="sd">               * The second input shape must be ``[N, 1, 4, 1, 1]`` or ``[N, 1, 5, 1, 1]``.</span>
<span class="sd">                 This represents the bounding box coordinates for ``N`` patches/RoIs.</span>
<span class="sd">            * ``N``: number of patches/RoIs to be extracted.</span>
<span class="sd">            * If RoI shape = ``[N, 1, 4, 1, 1]``, the channel axis corresponds</span>
<span class="sd">              to the four coordinates specifying the bounding box.</span>
<span class="sd">              All the N~ RoIs are extracted from all the batches of the input.</span>
<span class="sd">            * If RoI shape = ``[N, 1, 5, 1, 1]``, the first element of the</span>
<span class="sd">              channel axis specifies the input batch id from which to extract the RoI and</span>
<span class="sd">              must be in the interval ``[0, Batch - 1]``. That is, ``n`` -th RoI is</span>
<span class="sd">              extracted from the ``RoI[n,0,0,0]`` -th input batch id.</span>
<span class="sd">              The last four elements of the channel axis specify the</span>
<span class="sd">              bounding box coordinates.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        target_height: int</span>
<span class="sd">            Output height dimension.</span>

<span class="sd">        target_width: int</span>
<span class="sd">            Output width dimension.</span>

<span class="sd">        mode: str</span>
<span class="sd">            * The following values are supported:</span>
<span class="sd">              ``&#39;STRICT_ALIGN_ENDPOINTS_MODE&#39;``, ``&#39;ALIGN_ENDPOINTS_MODE&#39;``,</span>
<span class="sd">              ``&#39;UPSAMPLE_MODE&#39;``, ``&#39;ROI_ALIGN_MODE&#39;``.</span>
<span class="sd">            * This parameter determines the sampling grid used for bilinear interpolation.</span>

<span class="sd">        normalized_roi: bool</span>
<span class="sd">            * If true the bounding box coordinates must be in the interval ``[0, 1]``.</span>
<span class="sd">              They are scaled by ``(input_height - 1)``, ``(input_width - 1)``;</span>
<span class="sd">              that is, based on the input spatial dimensions.</span>
<span class="sd">            * If false the bounding box coordinates must be in the interval</span>
<span class="sd">              ``[0, input_height - 1]`` and ``[0, input_width - 1]``,</span>
<span class="sd">              respectively for height and width dimensions.</span>

<span class="sd">        box_indices_mode: str</span>
<span class="sd">            * The following values are supported:</span>
<span class="sd">              ``&#39;CORNERS_HEIGHT_FIRST&#39;``, ``&#39;CORNERS_WIDTH_FIRST&#39;``,</span>
<span class="sd">              ``&#39;CENTER_SIZE_HEIGHT_FIRST&#39;``, ``&#39;CENTER_SIZE_WIDTH_FIRST&#39;``.</span>
<span class="sd">            * Representation used to interpret the bounding box coordinates (RoI) input.</span>
<span class="sd">                * ``&#39;CORNERS_HEIGHT_FIRST&#39;``: ``[h_start, w_start, h_end, w_end]``</span>
<span class="sd">                * ``&#39;CORNERS_WIDTH_FIRST&#39;``: ``[w_start, h_start, w_end, h_end]``</span>
<span class="sd">                * ``&#39;CENTER_SIZE_HEIGHT_FIRST&#39;``: ``[h_center, w_center, box_height, box_width]``</span>
<span class="sd">                * ``&#39;CENTER_SIZE_WIDTH_FIRST&#39;``: ``[w_center, h_center, box_width, box_height]``</span>

<span class="sd">        spatial_scale: float</span>
<span class="sd">            Additional spatial scale that multiplies the bounding box coordinates.</span>
<span class="sd">            Generally used while implementing the RoI Align layer,</span>
<span class="sd">            which uses unnormalized RoI coordinates along with a spatial scale less than or equal to 1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_resize_bilinear, add_crop</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">cropResize</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_height</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetSize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_width</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">normalizedCoordinates</span> <span class="o">=</span> <span class="n">normalized_roi</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">spatialScale</span> <span class="o">=</span> <span class="n">spatial_scale</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="n">box_indices_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">box_indices_mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">box_indices_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">box_indices_mode</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;STRICT_ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;STRICT_ALIGN_ENDPOINTS_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UPSAMPLE_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;UPSAMPLE_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ROI_ALIGN_MODE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">samplingMethod</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">SamplingMode</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;ROI_ALIGN_MODE&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported crop resize mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">box_indices_mode</span> <span class="o">==</span> <span class="s2">&quot;CORNERS_HEIGHT_FIRST&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">boxIndicesMode</span><span class="o">.</span><span class="n">boxMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">BoxCoordinatesMode</span><span class="o">.</span><span class="n">Coordinates</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;CORNERS_HEIGHT_FIRST&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">box_indices_mode</span> <span class="o">==</span> <span class="s2">&quot;CORNERS_WIDTH_FIRST&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">boxIndicesMode</span><span class="o">.</span><span class="n">boxMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">BoxCoordinatesMode</span><span class="o">.</span><span class="n">Coordinates</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;CORNERS_WIDTH_FIRST&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">box_indices_mode</span> <span class="o">==</span> <span class="s2">&quot;CENTER_SIZE_HEIGHT_FIRST&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">boxIndicesMode</span><span class="o">.</span><span class="n">boxMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">BoxCoordinatesMode</span><span class="o">.</span><span class="n">Coordinates</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;CENTER_SIZE_HEIGHT_FIRST&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">box_indices_mode</span> <span class="o">==</span> <span class="s2">&quot;CENTER_SIZE_WIDTH_FIRST&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">boxIndicesMode</span><span class="o">.</span><span class="n">boxMode</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">BoxCoordinatesMode</span><span class="o">.</span><span class="n">Coordinates</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                    <span class="s2">&quot;CENTER_SIZE_WIDTH_FIRST&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported crop resize box indices mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">box_indices_mode</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.set_pre_processing_parameters">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.set_pre_processing_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">set_pre_processing_parameters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_input_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">is_bgr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">red_bias</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">green_bias</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">blue_bias</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">gray_bias</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">image_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">image_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a pre-processing parameters layer to the neural network object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image_input_names: list of str</span>
<span class="sd">            Name of input blobs that are images</span>

<span class="sd">        is_bgr: boolean or dict()</span>
<span class="sd">            Channel order for input blobs that are images. BGR if True else RGB.</span>
<span class="sd">            To specify a different value for each image input,</span>
<span class="sd">            provide a dictionary with input names as keys.</span>

<span class="sd">        red_bias: float or dict()</span>
<span class="sd">            Image re-centering parameter (red channel)</span>

<span class="sd">        blue_bias: float or dict()</span>
<span class="sd">            Image re-centering parameter (blue channel)</span>

<span class="sd">        green_bias: float or dict()</span>
<span class="sd">            Image re-centering parameter (green channel)</span>

<span class="sd">        gray_bias: float or dict()</span>
<span class="sd">            Image re-centering parameter (for grayscale images)</span>

<span class="sd">        image_scale: float or dict()</span>
<span class="sd">            Value by which to scale the images.</span>

<span class="sd">        image_format: str</span>
<span class="sd">            Image format, either &#39;NCHW&#39; / &#39;NHWC&#39;</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_input, set_output, set_class_labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_input_names</span><span class="p">:</span>
            <span class="k">return</span>  <span class="c1"># nothing to do here</span>

        <span class="n">image_format</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">image_format</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_format</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">image_format</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">image_format</span> <span class="o">!=</span> <span class="s2">&quot;NCHW&quot;</span> <span class="ow">and</span> <span class="n">image_format</span> <span class="o">!=</span> <span class="s2">&quot;NHWC&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Input image format must be either &#39;NCHW&#39; or &#39;NHWC&#39;. Provided </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">image_format</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">is_bgr</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">is_bgr</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">is_bgr</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">red_bias</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">red_bias</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">red_bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">blue_bias</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">blue_bias</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">blue_bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">green_bias</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">green_bias</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">green_bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gray_bias</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">gray_bias</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">gray_bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_scale</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">image_scale</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_input_names</span><span class="p">,</span> <span class="n">image_scale</span><span class="p">)</span>

        <span class="c1"># Raise error if any key in image preprocessing parameters</span>
        <span class="c1"># are not in image_input_names.</span>
        <span class="k">def</span> <span class="nf">check_valid_preprocessing_keys</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_name</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">target</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid key </span><span class="si">{}</span><span class="s2"> in </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">input_name</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">image_input_names</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">is_bgr</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;is_bgr&quot;</span><span class="p">)</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">red_bias</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;red_bias&quot;</span><span class="p">)</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">blue_bias</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;blue_bias&quot;</span><span class="p">)</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">green_bias</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;green_bias&quot;</span><span class="p">)</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">gray_bias</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;gray_bias&quot;</span><span class="p">)</span>
        <span class="n">check_valid_preprocessing_keys</span><span class="p">(</span><span class="n">image_scale</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="s2">&quot;image_scale&quot;</span><span class="p">)</span>

        <span class="n">spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span>

        <span class="c1"># Add image inputs</span>
        <span class="k">for</span> <span class="n">input_</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">image_input_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">WhichOneof</span><span class="p">(</span><span class="s2">&quot;Type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;multiArrayType&quot;</span><span class="p">:</span>
                    <span class="n">array_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">multiArrayType</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">array_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                        <span class="n">input_indices</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="k">if</span> <span class="n">image_format</span> <span class="o">==</span> <span class="s2">&quot;NCHW&quot;</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">array_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                        <span class="c1"># Adding dummy index for &#39;batch&#39; for compatibility</span>
                        <span class="n">input_indices</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">image_format</span> <span class="o">==</span> <span class="s2">&quot;NCHW&quot;</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;Invalid input shape. Input of rank </span><span class="si">{}</span><span class="s2">, but expecting input of either rank 3 or rank 4&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="nb">len</span><span class="p">(</span><span class="n">array_shape</span><span class="p">)</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

                    <span class="c1"># Extract image shape depending on input format</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="p">[</span><span class="n">array_shape</span><span class="p">[</span><span class="n">e</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">input_indices</span><span class="p">]</span>

                    <span class="k">if</span> <span class="n">image_format</span> <span class="o">==</span> <span class="s2">&quot;NHWC&quot;</span><span class="p">:</span>
                        <span class="c1"># If input format is &#39;NHWC&#39; for TF model, it will be</span>
                        <span class="c1"># &#39;NCHW&#39; for CoreML model. Therefore, add transpose to</span>
                        <span class="c1"># NHWC after the input and replace all use of input</span>
                        <span class="n">layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span>
                        <span class="n">complement_transpose</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">transpose_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
                        <span class="n">transpose_outputs</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">layer_</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                            <span class="k">if</span> <span class="p">(</span>
                                <span class="n">layer_</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;transpose&quot;</span><span class="p">)</span>
                                <span class="ow">and</span> <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span>
                            <span class="p">):</span>
                                <span class="n">transpose_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">transpose</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">transpose_order</span> <span class="o">==</span> <span class="p">[</span>
                                    <span class="mi">0</span><span class="p">,</span>
                                    <span class="mi">3</span><span class="p">,</span>
                                    <span class="mi">1</span><span class="p">,</span>
                                    <span class="mi">2</span><span class="p">,</span>
                                <span class="p">]</span> <span class="ow">or</span> <span class="n">transpose_order</span> <span class="o">==</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
                                    <span class="n">transpose_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                                    <span class="n">transpose_outputs</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">complement_transpose</span> <span class="o">=</span> <span class="kc">False</span>
                                    <span class="k">break</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
                                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                                        <span class="n">complement_transpose</span> <span class="o">=</span> <span class="kc">False</span>
                                        <span class="k">break</span>
                        <span class="k">if</span> <span class="n">complement_transpose</span><span class="p">:</span>
                            <span class="k">for</span> <span class="n">layer_</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">)):</span>
                                    <span class="k">if</span> <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">in</span> <span class="n">transpose_names</span><span class="p">:</span>
                                        <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span>
                            <span class="k">for</span> <span class="n">layer_</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                                <span class="k">if</span> <span class="n">layer_</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                                    <span class="k">del</span> <span class="n">layer_</span><span class="o">.</span><span class="n">output</span><span class="p">[:]</span>
                                    <span class="n">layer_</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">transpose_outputs</span><span class="p">)</span>
                                    <span class="k">break</span>
                            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">transpose_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">layer_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
                                    <span class="k">if</span> <span class="n">layer_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">transpose_names</span><span class="p">:</span>
                                        <span class="k">del</span> <span class="n">layers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                                        <span class="n">transpose_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">array_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                                <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                            <span class="n">input_transpose</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_to_nhwc&quot;</span>
                            <span class="n">transpose_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_transpose</span><span class="p">(</span>
                                <span class="n">name</span><span class="o">=</span><span class="n">input_transpose</span><span class="p">,</span>
                                <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span>
                                <span class="n">input_name</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                <span class="n">output_name</span><span class="o">=</span><span class="n">input_transpose</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="n">layers</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
                            <span class="k">for</span> <span class="n">layer_</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">)):</span>
                                    <span class="k">if</span> <span class="n">layer_</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">input_transpose</span><span class="p">:</span>
                                        <span class="k">continue</span>
                                    <span class="k">if</span> <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                                        <span class="n">layer_</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_transpose</span>

                    <span class="c1"># TODO: If input is not rank 3 or 4, then accordingly handle</span>
                    <span class="c1"># e.g. for rank-2 input, squeeze additional dimension in case of Gray scale image</span>
                    <span class="k">if</span> <span class="n">channels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">colorSpace</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">_proto</span><span class="o">.</span><span class="n">FeatureTypes_pb2</span><span class="o">.</span><span class="n">ImageFeatureType</span><span class="o">.</span><span class="n">ColorSpace</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;GRAYSCALE&quot;</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">elif</span> <span class="n">channels</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">is_bgr</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">is_bgr</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]:</span>
                                <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">colorSpace</span> <span class="o">=</span> <span class="p">(</span>
                                    <span class="n">_proto</span><span class="o">.</span><span class="n">FeatureTypes_pb2</span><span class="o">.</span><span class="n">ImageFeatureType</span><span class="o">.</span><span class="n">ColorSpace</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;BGR&quot;</span><span class="p">)</span>
                                <span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">colorSpace</span> <span class="o">=</span> <span class="p">(</span>
                                    <span class="n">_proto</span><span class="o">.</span><span class="n">FeatureTypes_pb2</span><span class="o">.</span><span class="n">ImageFeatureType</span><span class="o">.</span><span class="n">ColorSpace</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
                                <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">colorSpace</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="n">_proto</span><span class="o">.</span><span class="n">FeatureTypes_pb2</span><span class="o">.</span><span class="n">ImageFeatureType</span><span class="o">.</span><span class="n">ColorSpace</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;Channel Value </span><span class="si">%d</span><span class="s2"> not supported for image inputs&quot;</span> <span class="o">%</span> <span class="n">channels</span>
                        <span class="p">)</span>
                    <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
                    <span class="n">input_</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">imageType</span><span class="o">.</span><span class="n">height</span> <span class="o">=</span> <span class="n">height</span>

                <span class="n">preprocessing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
                <span class="n">preprocessing</span><span class="o">.</span><span class="n">featureName</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span>
                <span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">scaler</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">image_scale</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">channelScale</span> <span class="o">=</span> <span class="n">image_scale</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">channelScale</span> <span class="o">=</span> <span class="mf">1.0</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">red_bias</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">redBias</span> <span class="o">=</span> <span class="n">red_bias</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">blue_bias</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">blueBias</span> <span class="o">=</span> <span class="n">blue_bias</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">green_bias</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">greenBias</span> <span class="o">=</span> <span class="n">green_bias</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">gray_bias</span><span class="p">:</span>
                    <span class="n">scaler</span><span class="o">.</span><span class="n">grayBias</span> <span class="o">=</span> <span class="n">gray_bias</span><span class="p">[</span><span class="n">input_</span><span class="o">.</span><span class="n">name</span><span class="p">]</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_transpose">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_transpose">[docs]</a>
    <span class="k">def</span> <span class="nf">add_transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a N-D transpose layer with axes as a parameter.</span>
<span class="sd">        Refer to the ``TransposeLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        axes: list of int or tuple of int</span>
<span class="sd">            The list containing a permutation of &quot;[0,1,2,...,N-1]&quot; where N is the rank of input/output tensor.</span>

<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_permute, add_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank</span> <span class="o">+</span> <span class="n">axis</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">]</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">transpose</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_softmax_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_softmax_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_softmax_nd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a softmax_nd layer to the model that performs softmax operation along</span>
<span class="sd">        the given axis.</span>
<span class="sd">        Refer to the ``SoftmaxNDLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            Axis to perform the softmax operation on.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">softmaxND</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_concat_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_concat_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_concat_nd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">interleave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a concat_nd layer to the model that performs concatenation along the</span>
<span class="sd">        given axis.</span>
<span class="sd">        Refer to the ``ConcatNDLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            Axis to perform the concat operation on.</span>
<span class="sd">        interleave : bool</span>
<span class="sd">            (Only available in Core ML Specification &gt;= 5 (iOS &gt;= 14, macOS &gt;= 11.0)</span>
<span class="sd">            If true, concatenate by interleaving the inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">concatND</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="k">if</span> <span class="n">interleave</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">interleave</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span><span class="p">,</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_erf">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_erf">[docs]</a>
    <span class="k">def</span> <span class="nf">add_erf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an erf function (gaussian error function) layer to the model.</span>
<span class="sd">        Refer to the ``ErfLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">erf</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_gelu">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_gelu">[docs]</a>
    <span class="k">def</span> <span class="nf">add_gelu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;EXACT&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a GELU (gaussian error linear unit) activation layer, which is:</span>
<span class="sd">        ``0.5 * x * (1 + erf(x / sqrt(2)))``.</span>
<span class="sd">        Refer to the ``GeluLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mode: str, optional</span>
<span class="sd">            Gelu mode in [EXACT | TANH_APPROXIMATION | SIGMOID_APPROXIMATION], default EXACT.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">gelu</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;EXACT&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">GeluLayerParams</span><span class="o">.</span><span class="n">GeluMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;EXACT&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;TANH_APPROXIMATION&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">GeluLayerParams</span><span class="o">.</span><span class="n">GeluMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;TANH_APPROXIMATION&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SIGMOID_APPROXIMATION&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">GeluLayerParams</span><span class="o">.</span><span class="n">GeluMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span>
                <span class="s2">&quot;SIGMOID_APPROXIMATION&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported Gelu mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_sin">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_sin">[docs]</a>
    <span class="k">def</span> <span class="nf">add_sin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a sin layer to the model that computes element-wise sine for the</span>
<span class="sd">        input tensor.</span>
<span class="sd">        Refer to the ``SinLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_sinh, add_asin, add_asinh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">sin</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_cos">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_cos">[docs]</a>
    <span class="k">def</span> <span class="nf">add_cos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a cos layer to the model that computes element-wise cosine for the</span>
<span class="sd">        input tensor.</span>
<span class="sd">        Refer to the ``CosLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_cosh, add_acos, add_acosh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">cos</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_tan">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_tan">[docs]</a>
    <span class="k">def</span> <span class="nf">add_tan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a tan layer to the model that computes element-wise tangent for the</span>
<span class="sd">        input tensor.</span>
<span class="sd">        Refer to the ``TanLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_tanh, add_atan, add_atanh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">tan</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_asin">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_asin">[docs]</a>
    <span class="k">def</span> <span class="nf">add_asin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an asin layer to the model that computes element-wise arc-sine for</span>
<span class="sd">        the input tensor.</span>
<span class="sd">        Refer to the ``AsinLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_sin, add_sinh, add_asinh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">asin</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_acos">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_acos">[docs]</a>
    <span class="k">def</span> <span class="nf">add_acos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an acos layer to the model that computes element-wise arc-cosine</span>
<span class="sd">        for the input tensor.</span>
<span class="sd">        Refer to the ``AcosLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_cos, add_cosh, add_acosh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">acos</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_atan">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_atan">[docs]</a>
    <span class="k">def</span> <span class="nf">add_atan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an atan layer to the model that computes element-wise arc-tangent</span>
<span class="sd">        for the input tensor.</span>
<span class="sd">        Refer to the ``AtanLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_tan, add_tanh, add_atanh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">atan</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_sinh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_sinh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_sinh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a sinh layer to the model that computes element-wise hyperbolic sine for the input tensor.</span>
<span class="sd">        Refer to the ``SinhLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_sin, add_asin, add_asinh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">sinh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_cosh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_cosh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_cosh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a osh layer to the model that computes element-wise hyperbolic</span>
<span class="sd">        cosine for the input tensor.</span>
<span class="sd">        Refer to the ``CoshLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_cos, add_acos, add_acosh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">cosh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_tanh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_tanh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a tanh layer to the model that computes element-wise hyperbolic</span>
<span class="sd">        tangent for the input tensor.</span>
<span class="sd">        Refer to the ``TanhLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_tan, add_atan, add_atanh</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">tanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_asinh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_asinh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_asinh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an asinh layer to the model that computes element-wise inverse</span>
<span class="sd">        hyperbolic sine for the input tensor.</span>
<span class="sd">        Refer to the ``AsinhLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_sin, add_sinh, add_asin</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">asinh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_acosh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_acosh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_acosh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an acosh layer to the model that computes element-wise inverse</span>
<span class="sd">        hyperbolic cosine for the input tensor.</span>
<span class="sd">        Refer to the ``AcoshLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_cos, add_cosh, add_acos</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">acosh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_atanh">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_atanh">[docs]</a>
    <span class="k">def</span> <span class="nf">add_atanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an atanh layer to the model that computes element-wise inverse</span>
<span class="sd">        hyperbolic tangent for the input tensor.</span>
<span class="sd">        Refer to the ``AtanhLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_tan, add_tanh, add_atan</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">atanh</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_exp2">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_exp2">[docs]</a>
    <span class="k">def</span> <span class="nf">add_exp2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an exp2 layer to the model that performs element-wise experiential operation.</span>
<span class="sd">        Refer to the ``Exp2LayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">exp2</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_add_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_add_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_add_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an add_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        addition operation with broadcast support.</span>
<span class="sd">        Refer to the ``AddBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">addBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_multiply_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_multiply_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_multiply_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a multiply_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        multiplication operation with broadcast support.</span>
<span class="sd">        Refer to the ``MultiplyBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">multiplyBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_divide_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_divide_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_divide_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a divide_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        division operation with broadcast support.</span>
<span class="sd">        Refer to the ``DivideBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">divideBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_subtract_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_subtract_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_subtract_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a subtract_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        subtraction operation with broadcast support.</span>
<span class="sd">        Refer to the ``SubtractBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">subtractBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_max_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_max_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_max_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a max_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        maximum operation with broadcast support.</span>
<span class="sd">        Refer to the ``MaxBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">maxBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_min_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_min_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_min_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a min_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        minimum operation with broadcast support.</span>
<span class="sd">        Refer to the ``MinBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">minBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_floor_div_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_floor_div_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_floor_div_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a floor_div_broadcastable layer to the model that performs floor</span>
<span class="sd">        division operation with broadcast support.</span>
<span class="sd">        Refer to the ``FloorDivBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_divide_broadcastable</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">floorDivBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_mod_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_mod_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_mod_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a mod_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        modular operation with broadcast support.</span>
<span class="sd">        Refer to the ``ModBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">modBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_pow_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_pow_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_pow_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a pow_broadcastable layer to the model that performs element-wise</span>
<span class="sd">        power operation with broadcast support.</span>
<span class="sd">        Refer to the ``PowBroadcastableLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">powBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_stack">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_stack">[docs]</a>
    <span class="k">def</span> <span class="nf">add_stack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a stack layer to the model that performs stack operation on a list of</span>
<span class="sd">        tensors into one rank+1 tensor on the given axis.</span>
<span class="sd">        Refer to the ``StackLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            The axis to perform stack operation, default: 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">stack</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_ceil">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_ceil">[docs]</a>
    <span class="k">def</span> <span class="nf">add_ceil</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a ceil layer to the model that performs element-wise ceil operation</span>
<span class="sd">        on the input tensor that rounds the value to the smallest integer not</span>
<span class="sd">        less than x.</span>
<span class="sd">        Refer to the ``CeilLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_floor, add_clip</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">ceil</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_floor">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_floor">[docs]</a>
    <span class="k">def</span> <span class="nf">add_floor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a floor layer to the model that performs element-wise floor operation</span>
<span class="sd">        on the input tensor that rounds the value to the largest integer not</span>
<span class="sd">        greater than x.</span>
<span class="sd">        Refer to the ``FloorLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_ceil, add_clip</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">floor</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_round">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_round">[docs]</a>
    <span class="k">def</span> <span class="nf">add_round</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a round layer to the model that performs element-wise round operation</span>
<span class="sd">        on the input tensor that rounds the value to the nearest integer.</span>
<span class="sd">        Refer to the ``RoundLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">round</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_sign">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_sign">[docs]</a>
    <span class="k">def</span> <span class="nf">add_sign</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a sign layer to the model that performs element-wise sign operation</span>
<span class="sd">        (+1 for positive values, -1 for negative values, 0 for zeroes).</span>
<span class="sd">        Refer to the ``SignLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">sign</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_clip">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_clip">[docs]</a>
    <span class="k">def</span> <span class="nf">add_clip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a clip layer to the model that performs element-wise clip operation.</span>
<span class="sd">        Clip the values in the input tensor to the range [min_value, max_value].</span>
<span class="sd">        Refer to the ``ClipLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        min_value: float, optional</span>
<span class="sd">            Lower bound / minimum value for clip, default: 0.0.</span>
<span class="sd">        max_value: float, optional</span>
<span class="sd">            Upper bound / maximum value for clip, default: 1.0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_floor, add_ceil</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">spec_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">clip</span>

        <span class="n">spec_params</span><span class="o">.</span><span class="n">minVal</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">min_value</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">maxVal</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_split_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_split_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_split_nd</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">split_sizes</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a split layer to the model that splits the input tensor into multiple</span>
<span class="sd">        output tensors. Either uniformly split the input tensor into ``num_splits``</span>
<span class="sd">        tensors, or split into given size list ``split_sizes`` output tensors.</span>
<span class="sd">        Refer to the ``SplitNDLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            Axis to perform split on.</span>
<span class="sd">        num_splits: int, optional</span>
<span class="sd">            Number of splits, default: 2.</span>
<span class="sd">        split_sizes: list of int or tuple of int, optional</span>
<span class="sd">            List of size to split, default ``[]`` or ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">split_sizes</span><span class="p">:</span>
            <span class="n">split_sizes</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">splitND</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

        <span class="k">if</span> <span class="n">split_sizes</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">splitSizes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">)</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numSplits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numSplits</span> <span class="o">=</span> <span class="n">num_splits</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_names</span><span class="p">)</span> <span class="o">==</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numSplits</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_slice_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_slice_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_slice_static</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">begin_ids</span><span class="p">,</span>
        <span class="n">end_ids</span><span class="p">,</span>
        <span class="n">strides</span><span class="p">,</span>
        <span class="n">begin_masks</span><span class="p">,</span>
        <span class="n">end_masks</span><span class="p">,</span>
        <span class="n">squeeze_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a slice_static layer to the model that extracts a slice of size</span>
<span class="sd">        ``(end - begin) / stride`` from the given input tensor.</span>
<span class="sd">        Refer to the ``SliceStaticLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        begin_ids: list of int or tuple of int</span>
<span class="sd">            Begin offsets for slice layer.</span>
<span class="sd">        end_ids: list of int or tuple of int</span>
<span class="sd">            End offsets for slice layer.</span>
<span class="sd">        strides: list of int or tuple of int</span>
<span class="sd">            Strides for slice layer.</span>
<span class="sd">        begin_masks: list of bool</span>
<span class="sd">            Boolean masks for begin offsets.</span>
<span class="sd">        end_masks: list of bool</span>
<span class="sd">            Boolean masks for end offsets.</span>
<span class="sd">        squeeze_masks: list of bool</span>
<span class="sd">            Boolean masks for squeezing axis.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_slice_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">begin_ids</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_ids</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">begin_masks</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_masks</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span>
        <span class="k">assert</span> <span class="n">squeeze_masks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">squeeze_masks</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">sliceStatic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beginIds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">begin_ids</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">endIds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">end_ids</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strides</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beginMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">begin_masks</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">endMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">end_masks</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">squeeze_masks</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">squeeze_masks</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">spec_layer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">squeezeMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">squeeze_masks</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_slice_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_slice_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_slice_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">end_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">begin_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">end_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">squeeze_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a slice_dynamic layer to the model that extracts a slice of size</span>
<span class="sd">        ``(end - begin) / stride`` from the given input tensor.</span>
<span class="sd">        Refer to the ``SliceDynamicLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        end_ids: list of int or tuple of int, optional</span>
<span class="sd">            End offsets for slice layer, default: [1].</span>
<span class="sd">        strides: list of int or tuple of int, optional</span>
<span class="sd">            Strides for slice layer, default: [1].</span>
<span class="sd">        begin_masks: list of bool, optional</span>
<span class="sd">            Boolean masks for begin offsets, default: [false].</span>
<span class="sd">        end_masks: list of bool, optional</span>
<span class="sd">            Boolean masks for end offsets, default: [false].</span>
<span class="sd">        squeeze_masks: list of bool, optional</span>
<span class="sd">            Boolean masks for squeezing axis, default: [false].</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_slice_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">end_ids</span><span class="p">:</span>
            <span class="n">end_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">strides</span><span class="p">:</span>
            <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">begin_masks</span><span class="p">:</span>
            <span class="n">begin_masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">end_masks</span><span class="p">:</span>
            <span class="n">end_masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">squeeze_masks</span><span class="p">:</span>
            <span class="n">squeeze_masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">sliceDynamic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">endIds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">end_ids</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">strides</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beginMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">begin_masks</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">endMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">end_masks</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">squeeze_masks</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">spec_layer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">squeezeMasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">squeeze_masks</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_tile">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_tile">[docs]</a>
    <span class="k">def</span> <span class="nf">add_tile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="p">[]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a tile layer to the model that construct a tensor by repeating the</span>
<span class="sd">        input tensor multiple number of times.</span>
<span class="sd">        Refer to the ``TileLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str or list[str]</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">            If second input is provided, reps parameter is ignored.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        reps: list of int or tuple of int</span>
<span class="sd">            Number of times to replicate.</span>
<span class="sd">            If `input_name` provides two inputs, second input is used as</span>
<span class="sd">            reps and this parameter is ignored.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_stack, add_concat_nd</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_name</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">tile</span>
        <span class="c1"># If two inputs are provided,</span>
        <span class="c1"># ignore reps attribute.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">reps</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">reps</span><span class="p">])</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reps</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_range_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_range_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_range_static</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">input_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a range_static layer that returns a tensor that contains evenly spaced values.</span>
<span class="sd">        This layer has no input and three parameters.</span>
<span class="sd">        Refer to the ``RangeStaticLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        end: int, optional</span>
<span class="sd">            Range parameter: end, default: 1.</span>
<span class="sd">        start: int, optional</span>
<span class="sd">            Range parameter: start, default: 0.</span>
<span class="sd">        step: int, optional</span>
<span class="sd">            Range parameter: step size, default: 1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_range_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">rangeStatic</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">spec_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">rangeStatic</span>

        <span class="n">spec_params</span><span class="o">.</span><span class="n">endValue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">startValue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">stepSizeValue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_range_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_range_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_range_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a range_dynamic layer that returns a tensor that contains evenly spaced values.</span>
<span class="sd">        This layer has up to three inputs or no input and three parameters.</span>
<span class="sd">        Refer to the ``RangeDynamicLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names.</span>
<span class="sd">            If input size == 1: end is input, start and step are read from parameters</span>
<span class="sd">            If input size == 2: end, start are inputs, step is read from parameters</span>
<span class="sd">            If input size == 3: start, end, step are all inputs, none of the parameters are used.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        start: int, optional</span>
<span class="sd">            Range parameter: start. Ignored if start is provided as input, default: 0.</span>
<span class="sd">        step: int, optional</span>
<span class="sd">            Range parameter: step. Ignored if step is provided as input, default: 1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_range_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;RangeDynamic layer must have either 1, 2 or 3 inputs.&quot;</span><span class="p">)</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">rangeDynamic</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">spec_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">rangeDynamic</span>

        <span class="n">spec_params</span><span class="o">.</span><span class="n">startValue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">stepSizeValue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_branch">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_branch">[docs]</a>
    <span class="k">def</span> <span class="nf">add_branch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">if_branch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">else_branch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a branch layer to the model that provides the functionality of</span>
<span class="sd">        branching or an ``if-else`` block.</span>
<span class="sd">        Refer to the ``BranchLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        if_branch: NeuralNetwork</span>
<span class="sd">            Neural network to execute if the absolute value of the input tensor is greater than 1e-6.</span>
<span class="sd">        else_branch: NeuralNetwork, optional</span>
<span class="sd">            Neural network to execute if the absolute value of the input tensor is less than 1e-6.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_loop, add_loop_continue, add_loop_break</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[])</span>
        <span class="n">branch</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">branch</span>
        <span class="k">if</span> <span class="n">if_branch</span><span class="p">:</span>
            <span class="n">branch</span><span class="o">.</span><span class="n">ifBranch</span> <span class="o">=</span> <span class="n">if_branch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">branch</span><span class="o">.</span><span class="n">ifBranch</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">else_branch</span><span class="p">:</span>
            <span class="n">branch</span><span class="o">.</span><span class="n">elseBranch</span> <span class="o">=</span> <span class="n">else_branch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">branch</span><span class="o">.</span><span class="n">elseBranch</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_loop">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_loop">[docs]</a>
    <span class="k">def</span> <span class="nf">add_loop</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">body_network</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">condition</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">condition_network</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iterations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a loop layer to the model that provides the functionality of a ``for``</span>
<span class="sd">        loop, or a ``while`` loop.</span>
<span class="sd">        Refer to the ``LoopLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        body_network: NeuralNetwork</span>
<span class="sd">            Neural network to execute for the body of the loop.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        condition: str, optional</span>
<span class="sd">            Condition of the loop.</span>
<span class="sd">        condition_network: NeuralNetwork, optional</span>
<span class="sd">            Neural network to execute for the condition of the loop.</span>
<span class="sd">        max_iterations: int, optional</span>
<span class="sd">            Maximum number of iterations of the loop.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_loop_break, add_loop_continue, add_branch</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">input_names</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">input_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">input_name</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[])</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">loop</span>
        <span class="k">if</span> <span class="n">condition_network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">conditionNetwork</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">conditionNetwork</span> <span class="o">=</span> <span class="n">condition_network</span>

        <span class="k">if</span> <span class="n">condition</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">conditionVar</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">condition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_iterations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">maxLoopIterations</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">max_iterations</span> <span class="k">if</span> <span class="n">max_iterations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">body_network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">bodyNetwork</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">bodyNetwork</span> <span class="o">=</span> <span class="n">body_network</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_loop_break">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_loop_break">[docs]</a>
    <span class="k">def</span> <span class="nf">add_loop_break</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a loop_break layer to the model that terminates the loop that</span>
<span class="sd">        contains this layer. Must reside in the ``bodyNetwork`` of the loop layer.</span>
<span class="sd">        Refer to the ``LoopBreakLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_loop, add_loop_continue, add_branch</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">loopBreak</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_loop_continue">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_loop_continue">[docs]</a>
    <span class="k">def</span> <span class="nf">add_loop_continue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a loop_continue layer to the model that stops the current loop</span>
<span class="sd">        iteration and continue on the next iteration. Must reside in the</span>
<span class="sd">        ``bodyNetwork`` of the loop layer.</span>
<span class="sd">        Refer to the ``LoopContinueLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_loop, add_loop_break, add_branch</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn_spec</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">loopContinue</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_copy">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_copy">[docs]</a>
    <span class="k">def</span> <span class="nf">add_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a copy layer to the model that copies its input tensor to the output</span>
<span class="sd">        tensor. Input tensor and output tensor must have distinct names.</span>
<span class="sd">        Refer to the ``CopyLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">copy</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="c1"># If output name rank is different than earlier,</span>
        <span class="c1"># mark it as unknown</span>
        <span class="k">if</span> <span class="n">output_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span>
            <span class="n">output_name</span>
        <span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_greater_than">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_greater_than">[docs]</a>
    <span class="k">def</span> <span class="nf">add_greater_than</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">use_greater_than_equal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a greater_than layer to the model that performs the element-wise</span>
<span class="sd">        greater-than (&gt;) operation or greater-than-or-equal-to (&gt;=) operation.</span>
<span class="sd">        Broadcasting is supported.</span>
<span class="sd">        Refer to the ``GreaterThanLayerParams``, ``GreaterEqualLayerParams`` messages</span>
<span class="sd">        in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        use_greater_than_equal: bool, optional</span>
<span class="sd">            Whether or not to allow greater than or equal to, default: false.</span>
<span class="sd">        alpha: float, optional</span>
<span class="sd">            y = x1 != alpha, if only one input is provided, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_equal, add_not_equal, add_less_than</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">use_greater_than_equal</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">greaterEqual</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">greaterEqual</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">greaterThan</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">greaterThan</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_less_than">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_less_than">[docs]</a>
    <span class="k">def</span> <span class="nf">add_less_than</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">use_less_than_equal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a less_than layer to the model that performs the element-wise</span>
<span class="sd">        less-than (&lt;) operation or less-than-or-equal-to (&lt;=) operation.</span>
<span class="sd">        Broadcasting is supported.</span>
<span class="sd">        Refer to the ``LessThanL_ayerParams``, ``LessEqualLayerParams`` messages in</span>
<span class="sd">        specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        use_less_than_equal: bool, optional</span>
<span class="sd">            Whether or not to allow less than or equal to, default: false.</span>
<span class="sd">        alpha: float, optional</span>
<span class="sd">            y = x1 != alpha, if only one input is provided, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_equal, add_not_equal, add_greater_than</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">use_less_than_equal</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">lessEqual</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">lessEqual</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">lessThan</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec_layer</span><span class="o">.</span><span class="n">lessThan</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_equal">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_equal">[docs]</a>
    <span class="k">def</span> <span class="nf">add_equal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an equal layer to the model that performs the element-wise equal</span>
<span class="sd">        (=) operation. Broadcasting is supported.</span>
<span class="sd">        Refer to the ``EqualLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        alpha: float, optional</span>
<span class="sd">            y = x1 != alpha, if only one input is provided, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_not_equal, add_greater_than, add_less_than</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">equal</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">equal</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_not_equal">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_not_equal">[docs]</a>
    <span class="k">def</span> <span class="nf">add_not_equal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a not_equal layer to the model that performs the element-wise not</span>
<span class="sd">        equal (!=) operation. Broadcasting is supported.</span>
<span class="sd">        Refer to the ``NotEqualLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        alpha: float, optional</span>
<span class="sd">            y = x1 != alpha, if only one input is provided, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_equal, add_greater_than, add_less_than</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>
        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">notEqual</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">notEqual</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_logical">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_logical">[docs]</a>
    <span class="k">def</span> <span class="nf">add_logical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a logical layer to the model that performs element-wise logical</span>
<span class="sd">        and/or/xor/not operation. Broadcasting is supported.</span>
<span class="sd">        Refer to the ``LogicalOrLayerParams``, ``LogicalNotLayerParams``,</span>
<span class="sd">        ``LogicalNotLayerParams``, and ``LogicalAndLayerParam`` messages in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mode: str</span>
<span class="sd">            Logical operation mode in [AND | OR | XOR | NOT].</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_names</span><span class="p">]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;AND&quot;</span><span class="p">,</span> <span class="s2">&quot;OR&quot;</span><span class="p">,</span> <span class="s2">&quot;XOR&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Logical operation &quot;</span><span class="si">%s</span><span class="s1">&quot; requires 2 inputs&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;NOT&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Logical operation &quot;</span><span class="si">%s</span><span class="s1">&quot; requires 1 input&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;AND&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">logicalAnd</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;OR&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">logicalOr</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;XOR&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">logicalXor</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;NOT&quot;</span><span class="p">:</span>
            <span class="n">spec_layer</span><span class="o">.</span><span class="n">logicalNot</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Logical operation &quot;</span><span class="si">%s</span><span class="s1">&quot; is not supported&#39;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_sliding_windows">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_sliding_windows">[docs]</a>
    <span class="k">def</span> <span class="nf">add_sliding_windows</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a sliding_windows layer to the model that returns a tensor containing</span>
<span class="sd">        all windows of size ``window_size`` * separated by ``step`` along the dimension ``axis``.</span>
<span class="sd">        Refer to the ``SlidingWindowsLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The of input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            Axis to perform the operation.</span>
<span class="sd">        window_size: int</span>
<span class="sd">            Number of elements in the sliding window.</span>
<span class="sd">        step: int, optional</span>
<span class="sd">            The stride of the input elements in the sliding window, default: 1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_slice, add_slice_static, add_slice_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">slidingWindows</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">windowSize</span> <span class="o">=</span> <span class="n">window_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reverse">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reverse">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">reverse_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reverse layer to the model that reverses specific dimensions of</span>
<span class="sd">        the input tensor.</span>
<span class="sd">        Refer to the ``ReverseLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        reverse_dim: list of int or tuple of int</span>
<span class="sd">            Reverse along the dimension, default [1].</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reverse_sequence</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">reverse_dim</span><span class="p">:</span>
            <span class="n">reverse_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reverse</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reverseDim</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">reverse_dim</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reverse_sequence">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reverse_sequence">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reverse_sequence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">batch_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">seq_axis</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reverse sequence layer to the model that reverses variable length slices.</span>
<span class="sd">        Refer to the ``ReverseSeqLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        batch_axis: int, optional</span>
<span class="sd">            Slices input along the dimension batch_axis, default 0.</span>
<span class="sd">        seq_axis: int, optional</span>
<span class="sd">            Reverse along the dimension seq_axis, default: -1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reverse</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">reverseSeq</span><span class="o">.</span><span class="n">batchAxis</span> <span class="o">=</span> <span class="n">batch_axis</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">reverseSeq</span><span class="o">.</span><span class="n">sequenceAxis</span> <span class="o">=</span> <span class="n">seq_axis</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_gather">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_gather">[docs]</a>
    <span class="k">def</span> <span class="nf">add_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a gather layer to the model that gathers elements or slices from</span>
<span class="sd">        data and store to a tensor whose shape is defined by indices from the</span>
<span class="sd">        input.</span>
<span class="sd">        Refer to the ``GatherLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            The axis the operation perform on, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_gather_nd, add_gather_along_axis, add_scatter, add_scatter_nd, add_scatter_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">gather</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_scatter">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_scatter">[docs]</a>
    <span class="k">def</span> <span class="nf">add_scatter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;UPDATE&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a scatter layer to the model that scatters data into a new tensor</span>
<span class="sd">        according to indices from the input.</span>
<span class="sd">        Refer to the ``ScatterLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            The axis the operation perform on, default: 0.</span>
<span class="sd">        mode: str, optional</span>
<span class="sd">            Scatter accumulation mode in [UPDATE | ADD | SUB | MUL | DIV | MAX | MIN], default: UPDATE.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_scatter_nd, add_scatter_along_axis, add_gather, add_gather_nd, add_gather_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">scatter</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UPDATE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_UPDATE&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ADD&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_ADD&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SUB&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_SUB&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MUL&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MUL&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;DIV&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_DIV&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MAX&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MIN&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MIN&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported Scatter mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_gather_along_axis">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_gather_along_axis">[docs]</a>
    <span class="k">def</span> <span class="nf">add_gather_along_axis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a gather_along_axis layer to the model that gathers elements or slices</span>
<span class="sd">        from data and store to a tensor whose shape is defined by indices from the</span>
<span class="sd">        input along the given axis into the output tensor.</span>
<span class="sd">        Refer to the ``GatherAlongAxisLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            The axis the operation perform on, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_gather, add_gather_nd, add_scatter, add_scatter_nd, add_scatter_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">gatherAlongAxis</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_scatter_along_axis">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_scatter_along_axis">[docs]</a>
    <span class="k">def</span> <span class="nf">add_scatter_along_axis</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;UPDATE&quot;</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a scatter_along_axis layer to the model that scatters data into a new</span>
<span class="sd">        tensor according to indices from the input along the given axis into the</span>
<span class="sd">        output tensor.</span>
<span class="sd">        Refer to the ``ScatterAlongAxisLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            The axis to perform on, default: 0.</span>
<span class="sd">        mode: str, optional</span>
<span class="sd">            Scatter accumulation mode in [UPDATE | ADD | SUB | MUL | DIV | MAX | MIN], default: UPDATE</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_scatter, add_scatter_nd, add_gather, add_gather_nd, add_gather_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">scatterAlongAxis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UPDATE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_UPDATE&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ADD&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_ADD&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SUB&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_SUB&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MUL&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MUL&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;DIV&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_DIV&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MAX&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MIN&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MIN&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported scatter_along_axis mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_gather_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_gather_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_gather_nd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a gather layer to the model that gathers elements or slices from</span>
<span class="sd">        data and store to a tensor whose shape is defined by indices from the</span>
<span class="sd">        input. This is the reverse operation of the scatter operation.</span>
<span class="sd">        Refer to the ``GatherNDLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_gather, add_gather_along_axis, add_scatter, add_scatter_nd, add_scatter_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">gatherND</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="c1"># NOTE: ideally, following is formula for computing output rank</span>
        <span class="c1"># self.rank_dict[output_name] = self._get_rank(input_names[1]) - 1 + self._get_rank(input_names[0])</span>
        <span class="c1">#                               + shape_dict[input_names[1]][-1]</span>
        <span class="c1"># But, shape of indices (input_names[1]) is unknown and hence marking as -1</span>
        <span class="c1"># Converter should update rank if indices are known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_scatter_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_scatter_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_scatter_nd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;UPDATE&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a scatter layer to the model that scatters data into a new tensor</span>
<span class="sd">        according to indices from input. This is the reverse operation of the</span>
<span class="sd">        gather operation.</span>
<span class="sd">        Refer to the ``ScatterNDLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mode: str, optional</span>
<span class="sd">            Scatter accumulation mode in [UPDATE | ADD | SUB | MUL | DIV | MAX | MIN], default: UPDATE</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_scatter, add_scatter_along_axis, add_gather, add_gather_nd, add_gather_along_axis</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">scatterND</span>

        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;UPDATE&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_UPDATE&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ADD&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_ADD&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;SUB&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_SUB&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MUL&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MUL&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;DIV&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_DIV&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MAX&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;MIN&quot;</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">_proto</span><span class="o">.</span><span class="n">NeuralNetwork_pb2</span><span class="o">.</span><span class="n">ScatterMode</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s2">&quot;SCATTER_MIN&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported scatter mode </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_topk">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_topk">[docs]</a>
    <span class="k">def</span> <span class="nf">add_topk</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_bottom_k</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a topk layer to the model that returns top or bottom k values and</span>
<span class="sd">        the corresponding indices of the input tensor along a given axis.</span>
<span class="sd">        Refer to the ``TopKLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer. It must be of length 1 or 2.</span>
<span class="sd">            The optional second input corresponds to value of K.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names of this layer. First and second correspond to</span>
<span class="sd">            values and indices, respectively.</span>
<span class="sd">        k: int, optional</span>
<span class="sd">            number of values/indices to be computed along the axis.</span>
<span class="sd">            Need not be given of there are two inputs, default: 0.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            axis along which the topk values/indices are computed.</span>
<span class="sd">            negative indexing is supported, default: 0</span>
<span class="sd">        use_bottom_k: bool, optional</span>
<span class="sd">            if true, bottom k values are computed instead, default: false.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">topK</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">useBottomK</span> <span class="o">=</span> <span class="n">use_bottom_k</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_argmax">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_argmax">[docs]</a>
    <span class="k">def</span> <span class="nf">add_argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an argmax layer to the model that returns the indices of the maximum</span>
<span class="sd">        value along a specified axis in the input tensor.</span>
<span class="sd">        Refer to the ``ArgMaxLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            axis along which the argmax is computed. Negative indexing is supported.</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            if true, output rank is same as input rank, default: true.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_argmin</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">argMax</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">removeDim</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">keepdims</span>

        <span class="n">input_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_rank</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_rank</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_argmin">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_argmin">[docs]</a>
    <span class="k">def</span> <span class="nf">add_argmin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an argmin layer to the model that returns the indices of the minimum</span>
<span class="sd">        value along a specified axis in the input tensor.</span>
<span class="sd">        Refer to the ``ArgMinLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int</span>
<span class="sd">            axis along which the argmin is computed. Negative indexing is supported.</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            if true, output rank is same as input rank, default: true.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_argmax</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">argMin</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">removeDim</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">keepdims</span>

        <span class="n">input_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_rank</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_rank</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_constant_pad">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_constant_pad">[docs]</a>
    <span class="k">def</span> <span class="nf">add_constant_pad</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">pad_to_given_output_size_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">pad_amounts</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a constant pad layer.</span>
<span class="sd">        Refer to the ``ConstantPaddingLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob name(s) of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        value: float</span>
<span class="sd">            value to be used for padding.</span>
<span class="sd">        pad_to_given_output_size_mode: bool</span>
<span class="sd">            if true, pad_amounts are interpreted as output shapes (see example in NeuralNetwork.proto)</span>
<span class="sd">        pad_amounts: [int], optional</span>
<span class="sd">            must be non negative. Amount to pad in each dimension. Length of the list must be twice the input/output rank.</span>
<span class="sd">            Not required if second input is present.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_padding</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">constantPad</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">padToGivenOutputSizeMode</span> <span class="o">=</span> <span class="n">pad_to_given_output_size_mode</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_amounts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">padAmounts</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">pad_amounts</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_amounts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Constant_pad layer: pad_amounts must be provided when there is a single input&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_nms">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_nms">[docs]</a>
    <span class="k">def</span> <span class="nf">add_nms</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">iou_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">score_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">max_boxes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">per_class_suppression</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a non maximum suppression layer.</span>
<span class="sd">        Refer to the ``NonMaximumSuppressionLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer. Must be at least 2, and maximum 5.</span>
<span class="sd">        output_names: list of str</span>
<span class="sd">            The output blob names of this layer. Must be of length 4 exactly.</span>
<span class="sd">        iou_threshold: float</span>
<span class="sd">            intersection over union threshold for suppression. Ignored if 3rd input is present.</span>
<span class="sd">        score_threshold: float</span>
<span class="sd">            threshold for selecting boxes to be used for NMS algorithm. Ignored if 4th input is present.</span>
<span class="sd">        max_boxes: int</span>
<span class="sd">            maximum number of boxes to output. Ignored if 5th input is present.</span>
<span class="sd">        per_class_suppression: bool</span>
<span class="sd">            If true, boxes are organized into classes and suppression is applied to each class group separately</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_constant_pad</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">NonMaximumSuppression</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">iouThreshold</span> <span class="o">=</span> <span class="n">iou_threshold</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">scoreThreshold</span> <span class="o">=</span> <span class="n">score_threshold</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">maxBoxes</span> <span class="o">=</span> <span class="n">max_boxes</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">perClassSuppression</span> <span class="o">=</span> <span class="n">per_class_suppression</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_names</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_names</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_embedding_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_embedding_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_embedding_nd</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">,</span>
        <span class="n">embedding_size</span><span class="p">,</span>
        <span class="n">W</span><span class="p">,</span>
        <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">is_quantized_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">quant_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_lut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an embedding layer to the model that performs a matrix lookup and</span>
<span class="sd">        optionally adds a bias.</span>
<span class="sd">        Refer to the ``EmbeddingNDLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        vocab_size: int</span>
<span class="sd">            Size of the vocabulary (1 + maximum integer index of the words).</span>
<span class="sd">        embedding_size: int</span>
<span class="sd">            Size of the embedded vector.</span>
<span class="sd">        W: float32 numpy.array or bytes()</span>
<span class="sd">            Weight matrix of shape (embedding_size, vocab_size).</span>
<span class="sd">            If W is of type bytes(), i.e. quantized to 1-8 bits, other quantization</span>
<span class="sd">            related arguments must be provided as well (see below).</span>
<span class="sd">        b: numpy.array , optional</span>
<span class="sd">            Bias vector of shape (embedding_size, ).</span>
<span class="sd">        Quantization arguments expected, when W is of type bytes():</span>
<span class="sd">        is_quantized_weight: bool</span>
<span class="sd">            Set it to true when W is of type bytes(), representing quantized weights</span>
<span class="sd">        quantization_type: str</span>
<span class="sd">            When weights are quantized (i.e. W is of type bytes()), this should be either &quot;linear&quot; or &quot;lut&quot;.</span>
<span class="sd">        nbits: int</span>
<span class="sd">            Should be between 1 and 8 (inclusive). Number of bits per weight value.</span>
<span class="sd">        quant_scale: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            scale vector to be used with linear quantization. Must be of length either 1 or embedding_size.</span>
<span class="sd">        quant_bias: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            bias vector to be used with linear quantization. Must be of length either 1 or embedding_size.</span>
<span class="sd">        quant_lut: numpy.array(dtype=numpy.float32)</span>
<span class="sd">            the LUT (look up table) to be used with LUT quantization. Must be of length 2^nbits.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_inner_product, add_embedding</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="c1"># Fill in the parameters</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">embeddingND</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">vocabSize</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">embeddingSize</span> <span class="o">=</span> <span class="n">embedding_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_quantized_weight</span><span class="p">:</span>
            <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_verify_quantization_arguments</span><span class="p">(</span>
                <span class="n">weight</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">output_channels</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">_fill_quantized_weights</span><span class="p">(</span>
                <span class="n">weights_message</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_batched_mat_mul">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_batched_mat_mul">[docs]</a>
    <span class="k">def</span> <span class="nf">add_batched_mat_mul</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_matrix_rows</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">weight_matrix_columns</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">int_8_dynamic_quantize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">is_quantized_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">quant_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">quant_lut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a N-D Batched Matrix Multiplication layer with NumPy-like broadcasting.</span>
<span class="sd">        Refer to the ``BatchedMatMulLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>

<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>

<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        transpose_a: bool, optional</span>
<span class="sd">            Whether or not to transpose A, default: false.</span>

<span class="sd">        transpose_b: bool, optional</span>
<span class="sd">            Whether or not to transpose B, default: false.</span>

<span class="sd">        weight_matrix_rows: int, optional</span>
<span class="sd">            Must be equal to the last dimension of the input, default: 0.</span>

<span class="sd">        weight_matrix_columns: int, optional</span>
<span class="sd">            Must be equal to the last dimension of the output, default: 0.</span>

<span class="sd">        W: float32 numpy.array or bytes(), optional</span>
<span class="sd">            Weight matrix of shape ``(weight_matrix_rows, weight_matrix_columns)``.</span>
<span class="sd">            If ``W`` is of type ``bytes()`` (quantized to 1-8 bits), other</span>
<span class="sd">            quantization-related arguments must be provided as well (see below).</span>

<span class="sd">        bias: float32 numpy.array, optional</span>
<span class="sd">            Bias vector of shape (weight_matrix_columns,).</span>

<span class="sd">        Quantization</span>
<span class="sd">                Quantization arguments, used when ``W`` is of type ``bytes()``:</span>

<span class="sd">                                is_quantized_weight: bool, optional</span>
<span class="sd">                                        Set it to true when ``W`` is of type ``bytes()``, representing</span>
<span class="sd">                                        quantized weights, default: false.</span>

<span class="sd">                                quantization_type: str, optional</span>
<span class="sd">                                        When weights are quantized (that is, ``W`` is of type ``bytes()``),</span>
<span class="sd">                                        this should be either ``&quot;linear&quot;`` or ``&quot;lut&quot;``, default: ``&quot;linear&quot;``.</span>

<span class="sd">                                nbits: int, optional</span>
<span class="sd">                                        Should be between 1 and 8 (inclusive). Number of bits per weight value, default: 8.</span>

<span class="sd">                                quant_scale: numpy.array(dtype=numpy.float32), optional</span>
<span class="sd">                                        Scale vector to be used with linear quantization.</span>
<span class="sd">                                        Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.</span>

<span class="sd">                                quant_bias: numpy.array(dtype=numpy.float32), optional</span>
<span class="sd">                                        Bias vector to be used with linear quantization.</span>
<span class="sd">                                        Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.</span>

<span class="sd">                                quant_lut: numpy.array(dtype=numpy.float32), optional</span>
<span class="sd">                                        The LUT (look up table) to be used with LUT quantization.</span>
<span class="sd">                                        Must be of length 2^n bits, default: ``None``.</span>

<span class="sd">                                int_8_dynamic_quantize: bool</span>
<span class="sd">                                        Whether to quantize and dequantize before and after</span>
<span class="sd">                                        batched matmul, respectively.</span>
<span class="sd">                                        Expects byte weights, representing int8 values, if True.</span>
<span class="sd">                                        See NeuralNetwork.proto for other validation conditions.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_inner_product</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>

        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">batchedMatmul</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">transposeA</span> <span class="o">=</span> <span class="n">transpose_a</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">transposeB</span> <span class="o">=</span> <span class="n">transpose_b</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">int8DynamicQuantize</span> <span class="o">=</span> <span class="n">int_8_dynamic_quantize</span>

        <span class="k">if</span> <span class="p">((</span><span class="n">W</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;batched_mat_mul: Weight and/or bias are ignored when there are two inputs&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">W</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;batched_mat_mul: Weight parameter must be provided when there is one input&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">for</span> <span class="n">input_</span> <span class="ow">in</span> <span class="n">input_names</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">output_name</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightMatrixFirstDimension</span> <span class="o">=</span> <span class="n">weight_matrix_rows</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weightMatrixSecondDimension</span> <span class="o">=</span> <span class="n">weight_matrix_columns</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">hasBias</span> <span class="o">=</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

            <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">weights</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_quantized_weight</span><span class="p">:</span>
                <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_verify_quantization_arguments</span><span class="p">(</span>
                    <span class="n">weight</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
                    <span class="n">output_channels</span><span class="o">=</span><span class="n">weight_matrix_columns</span><span class="p">,</span>
                    <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                    <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                    <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                    <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                    <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
                    <span class="n">int_8_dynamic_quantize</span><span class="o">=</span><span class="n">int_8_dynamic_quantize</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">nbits</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
                    <span class="n">num_weights</span> <span class="o">=</span> <span class="n">weight_matrix_rows</span> <span class="o">*</span> <span class="n">weight_matrix_columns</span>
                    <span class="n">byte_arr</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
                    <span class="n">W</span> <span class="o">=</span> <span class="n">_unpack_to_bytes</span><span class="p">(</span><span class="n">byte_arr</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">nbits</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">int_8_dynamic_quantize</span><span class="p">:</span>
                    <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

                <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="n">weight_matrix_rows</span><span class="p">,</span> <span class="n">weight_matrix_columns</span><span class="p">))</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

                <span class="n">W_bytes</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">nbits</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                    <span class="n">W_bytes</span> <span class="o">+=</span> <span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W_bytes</span> <span class="o">+=</span> <span class="n">_convert_array_to_nbit_quantized_bytes</span><span class="p">(</span>
                        <span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">nbits</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>

                <span class="n">_fill_quantized_weights</span><span class="p">(</span>
                    <span class="n">weights_message</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                    <span class="n">W</span><span class="o">=</span><span class="n">W_bytes</span><span class="p">,</span>
                    <span class="n">use_int_8</span><span class="o">=</span><span class="n">int_8_dynamic_quantize</span><span class="p">,</span>
                    <span class="n">quantization_type</span><span class="o">=</span><span class="n">quantization_type</span><span class="p">,</span>
                    <span class="n">nbits</span><span class="o">=</span><span class="n">nbits</span><span class="p">,</span>
                    <span class="n">quant_scale</span><span class="o">=</span><span class="n">quant_scale</span><span class="p">,</span>
                    <span class="n">quant_bias</span><span class="o">=</span><span class="n">quant_bias</span><span class="p">,</span>
                    <span class="n">quant_lut</span><span class="o">=</span><span class="n">quant_lut</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">bias_param</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">bias</span>
                <span class="n">bias_param</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_get_shape">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_get_shape">[docs]</a>
    <span class="k">def</span> <span class="nf">add_get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a get_shape layer to the model.</span>
<span class="sd">        Refer to the ``GetShapeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reshape, add_reshape_like, add_reshape_static, add_reshape_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">getShape</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_load_constant_nd">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_load_constant_nd">[docs]</a>
    <span class="k">def</span> <span class="nf">add_load_constant_nd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">constant_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a load_constant layer that loads data as a parameter and provides it</span>
<span class="sd">        as an output.</span>
<span class="sd">        Refer to the ``LoadConstantNDLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        constant_value: numpy.array()</span>
<span class="sd">            value of the constant as a numpy array.</span>
<span class="sd">        shape: list of int or tuple of int</span>
<span class="sd">            List of ints representing the shape of the constant.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_elementwise</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">loadConstantND</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">data</span>
        <span class="n">data</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">constant_value</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># Rank information</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">floatValue</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dimensions of &#39;shape&#39; do not match the size of the provided constant&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_fill_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_fill_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_fill_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a fill_like layer to the model outputs a tensor filled with a</span>
<span class="sd">        scalar value.</span>
<span class="sd">        Refer to the ``FillLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        value: float, optional</span>
<span class="sd">            A scalar value for the fill operation, default 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_fill_static, add_fill_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">fillLike</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_fill_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_fill_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_fill_static</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a fill_static layer to the model that outputs a tensor filled</span>
<span class="sd">        with a scalar value given shape as parameter.</span>
<span class="sd">        Refer to the ``FillStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            The target shape of the output tensor.</span>
<span class="sd">        value: float, optional</span>
<span class="sd">            A scalar value for the fill operation, default 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_fill_like, add_fill_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">fillStatic</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_fill_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_fill_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_fill_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a fill_dynamic layer to the model that outputs a tensor filled</span>
<span class="sd">        with a scalar value.</span>
<span class="sd">        Refer to the ``FillDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        value: float, optional</span>
<span class="sd">            A scalar value for the fill operation, default: 0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_fill_like, add_fill_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">fillDynamic</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_broadcast_to_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_broadcast_to_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_broadcast_to_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a broadcast_to_like layer to the model that broadcasts a tensor</span>
<span class="sd">        to a compatible shape.</span>
<span class="sd">        Refer to the ``BroadcastToLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_broadcast_to_static, add_broadcast_to_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">broadcastToLike</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;BroadcastToLikeLayer must have two inputs&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_broadcast_to_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_broadcast_to_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_broadcast_to_static</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a broadcast_to_static layer to the model that broadcasts a tensor</span>
<span class="sd">        to a compatible shape.</span>
<span class="sd">        Refer to the ``BroadcastToStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            The target shape of the output tensor.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_broadcast_to_like, add_broadcast_to_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">broadcastToStatic</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_broadcast_to_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_broadcast_to_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_broadcast_to_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a broadcast_to_dynamic layer to the model that broadcasts a tensor</span>
<span class="sd">        to a compatible shape.</span>
<span class="sd">        Refer to the ``BroadcastToDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_broadcast_to_like, add_broadcast_to_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">broadcastToDynamic</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="c1"># Setting rank to -1 is a hint that Rank was not computed</span>
        <span class="c1"># converter can modify if it&#39;s a constant and known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_expand_dims">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_expand_dims">[docs]</a>
    <span class="k">def</span> <span class="nf">add_expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an expand dims layer to the model that increases the rank of the</span>
<span class="sd">        input tensor by adding unit dimensions.</span>
<span class="sd">        Refer to the ``ExpandDimsLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int</span>
<span class="sd">            Dimensions the operation perform on.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_squeeze</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">expandDims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_squeeze">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_squeeze">[docs]</a>
    <span class="k">def</span> <span class="nf">add_squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">squeeze_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a squeeze layer to the model that decrease the rank of the input</span>
<span class="sd">        tensor by removing unit dimensions.</span>
<span class="sd">        Refer to the ``SqueezeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            Dimensions to perform the operation, default: ``None`` (squeeze_all).</span>
<span class="sd">        squeeze_all: bool, optional</span>
<span class="sd">            If true, all dimensions that are 1 are squeezed, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_expand_dims</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">squeeze</span>
        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">squeezeAll</span> <span class="o">=</span> <span class="n">squeeze_all</span>

        <span class="k">if</span> <span class="n">squeeze_all</span> <span class="ow">or</span> <span class="n">axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># All the dimensions that are 1 will be squeezed</span>
            <span class="c1"># converter should update rank if shape is known</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span> <span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_flatten_to_2d">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_flatten_to_2d">[docs]</a>
    <span class="k">def</span> <span class="nf">add_flatten_to_2d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a flatten_to_2d layer to the model that flattens the input tensor</span>
<span class="sd">        into a 2-dimensional matrix.</span>
<span class="sd">        Refer to the ``FlattenTo2DLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The of input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            Axis to perform the operation, default: 1.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_flatten</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">flattenTo2D</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reshape_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reshape_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reshape_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reshape_like layer to the model that reshapes a tensor.</span>
<span class="sd">        Refer to the ``ReshapeLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reshape, add_reshape_static, add_reshape_dynamic, add_rank_preserving_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">reshapeLike</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reshape_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reshape_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reshape_static</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reshape_static layer to the model that reshapes a tensor.</span>
<span class="sd">        Refer to the ``ReshapeStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            Target shape of the output tensor.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reshape, add_reshape_like, add_reshape_dynamic, add_rank_preserving_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reshapeStatic</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reshape_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reshape_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reshape_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reshape_dynamic layer to the model that reshapes a tensor.</span>
<span class="sd">        Refer to the ``ReshapeDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reshape, add_reshape_like, add_reshape_static, add_rank_preserving_reshape</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">reshapeDynamic</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="c1"># Setting rank to -1 is a hint that Rank was not computed</span>
        <span class="c1"># converter can modify if it&#39;s a constant and known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_rank_preserving_reshape">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_rank_preserving_reshape">[docs]</a>
    <span class="k">def</span> <span class="nf">add_rank_preserving_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a rank_preserving_reshape layer to the model that reshapes the input</span>
<span class="sd">        tensor without altering the rank of the tensor.</span>
<span class="sd">        Refer to the ``RankPreservingReshapeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            Determines the shape of the output blob.</span>
<span class="sd">            0: copy the dimension of the input to output</span>
<span class="sd">            -1: calculate dimensions from the rest of the shape</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reshape, add_reshape_like, add_reshape_static, add_reshape_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">output_name</span><span class="p">],</span>
            <span class="n">input_ranks</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)],</span>
            <span class="n">input_shapes</span><span class="o">=</span><span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_shape</span><span class="p">]],</span>
            <span class="n">output_ranks</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)],</span>
            <span class="n">output_shapes</span><span class="o">=</span><span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_shape</span><span class="p">]],</span>
        <span class="p">)</span>

        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">rankPreservingReshape</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">targetShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_normal_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_normal_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_normal_like</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_normal_like layer to the model that fills the output</span>
<span class="sd">        tensor with random values from normal distribution.</span>
<span class="sd">        Refer to the ``RandomNormalLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mean: float, optional</span>
<span class="sd">            The mean of the normal distribution, default: 0.0.</span>
<span class="sd">        stddev: float, optional</span>
<span class="sd">            The standard deviation of the normal distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution, default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_normal_static, add_random_normal_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomNormalLike</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stdDev</span> <span class="o">=</span> <span class="n">stddev</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_normal_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_normal_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_normal_static</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_normal_static layer to the model that fills the output</span>
<span class="sd">        tensor with random values from normal distribution.</span>
<span class="sd">        Refer to the ``RandomNormaStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            Target shape of the output tensor.</span>
<span class="sd">        mean: float, optional</span>
<span class="sd">            The mean of the normal distribution, default: 0.0.</span>
<span class="sd">        stddev: float, optional</span>
<span class="sd">            The standard deviation of the normal distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. Default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_normal_like, add_random_normal_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomNormalStatic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stdDev</span> <span class="o">=</span> <span class="n">stddev</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_normal_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_normal_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_normal_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_normal_dynamic layer to the model that fills the output</span>
<span class="sd">        tensor with random values from normal distribution.</span>
<span class="sd">        Refer to the ``RandomNormalDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        mean: float, optional</span>
<span class="sd">            The mean of the normal distribution, default: 0.0.</span>
<span class="sd">        stddev: float, optional</span>
<span class="sd">            The standard deviation of the normal distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. Default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_normal_like, add_random_normal_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomNormalDynamic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">stdDev</span> <span class="o">=</span> <span class="n">stddev</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="c1"># Setting rank to -1 is a hint that Rank was not computed</span>
        <span class="c1"># converter can modify if it&#39;s a constant and known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_uniform_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_uniform_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_uniform_like</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">minval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_uniform_like layer to the model that fills the output</span>
<span class="sd">        tensors with random values from uniform distribution.</span>
<span class="sd">        Refer to the ``RandomUniformLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        minval: float, optional</span>
<span class="sd">            Lower bound / minimum value of the uniform distribution, default: 0.0.</span>
<span class="sd">        maxval: float, optional</span>
<span class="sd">            Upper bound / maximum value of the uniform distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_uniform_static, add_random_uniform_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomUniformLike</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">minVal</span> <span class="o">=</span> <span class="n">minval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">maxVal</span> <span class="o">=</span> <span class="n">maxval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_uniform_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_uniform_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_uniform_static</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">minval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_uniform_static layer to the model that fills the output</span>
<span class="sd">        tensors with random values from uniform distribution.</span>
<span class="sd">        Refer to the ``RandomUniformStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            Target shape of the output tensor.</span>
<span class="sd">        minval: float, optional</span>
<span class="sd">            Lower bound / minimum value of the uniform distribution, default: 0.0.</span>
<span class="sd">        maxval: float, optional</span>
<span class="sd">            Upper bound / maximum value of the uniform distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_uniform_like, add_random_uniform_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomUniformStatic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">minVal</span> <span class="o">=</span> <span class="n">minval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">maxVal</span> <span class="o">=</span> <span class="n">maxval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_uniform_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_uniform_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_uniform_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">minval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_uniform_dynamic layer to the model that fills the output</span>
<span class="sd">        tensors with random values from uniform distribution.</span>
<span class="sd">        Refer to the ``RandomUniformDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        minval: float, optional</span>
<span class="sd">            Lower bound / minimum value of the uniform distribution, default: 0.0.</span>
<span class="sd">        maxval: float, optional</span>
<span class="sd">            Upper bound / maximum value of the uniform distribution, default: 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_uniform_like, add_random_uniform_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomUniformDynamic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">minVal</span> <span class="o">=</span> <span class="n">minval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">maxVal</span> <span class="o">=</span> <span class="n">maxval</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="c1"># Setting rank to -1 is a hint that Rank was not computed</span>
        <span class="c1"># converter can modify if it&#39;s a constant and known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_bernoulli_like">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_bernoulli_like">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_bernoulli_like</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_bernoulli_like layer to the model that fills the output</span>
<span class="sd">        tensor with random values from Bernoulli distribution.</span>
<span class="sd">        Refer to the ``RandomBernoulliLikeLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        prob: float, optional</span>
<span class="sd">            Probabilities for Bernoulli distribution, default: 0.5.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_bernoulli_static, add_random_bernoulli_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomBernoulliLike</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_bernoulli_static">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_bernoulli_static">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_bernoulli_static</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_bernoulli_static layer to the model that fills the output</span>
<span class="sd">        tensor with random values from Bernoulli distribution.</span>
<span class="sd">        Refer to the ``RandomBernoulliStaticLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        output_shape: list of int or tuple of int</span>
<span class="sd">            Target shape of the output tensor.</span>
<span class="sd">        prob: float, optional</span>
<span class="sd">            Probabilities for Bernoulli distribution, default: 0.5.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_bernoulli_like, add_random_bernoulli_dynamic</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomBernoulliStatic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">outputShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_random_bernoulli_dynamic">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_random_bernoulli_dynamic">[docs]</a>
    <span class="k">def</span> <span class="nf">add_random_bernoulli_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a random_bernoulli_dynamic layer to the model that fills the output</span>
<span class="sd">        tensor with random values from Bernoulli distribution.</span>
<span class="sd">        Refer to the ``RandomBernoulliDynamicLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        prob: float, optional</span>
<span class="sd">            Probabilities for Bernoulli distribution, default: 0.5.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_random_bernoulli_like, add_random_bernoulli_static</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">randomBernoulliDynamic</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="c1"># Setting rank to -1 is a hint that Rank was not computed</span>
        <span class="c1"># converter can modify if it&#39;s a constant and known</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_categorical_distribution">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_categorical_distribution">[docs]</a>
    <span class="k">def</span> <span class="nf">add_categorical_distribution</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="p">,</span>
        <span class="n">is_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a categorical_distribution layer to the model that fills the output</span>
<span class="sd">        tensor with random values from categorical distribution.</span>
<span class="sd">        Refer to the ``CategoricalDistributionLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        num_samples: int</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">        is_logits: bool, optional</span>
<span class="sd">            If true, the input is log probabilities. If false, the input is</span>
<span class="sd">            probabilities, default: True</span>
<span class="sd">        eps: float, optional</span>
<span class="sd">            Epsilon parameter for categorical distribution, default 1e-10.</span>
<span class="sd">        temperature: float, optional</span>
<span class="sd">            Temperature parameter for categorical distribution, default 1.0.</span>
<span class="sd">        seed: int, optional</span>
<span class="sd">            Used to create a random seed for the distribution. default -1 (random).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">categoricalDistribution</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numSamples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">isLogits</span> <span class="o">=</span> <span class="n">is_logits</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_sum">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_sum">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_sum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_sum layer to the model that reduces the input tensor</span>
<span class="sd">        using ``sum(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceSumLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range ``[-rank(input), rank(input))``, default: ``None`` (``reduce_all``).</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_min, add_reduce_prod,</span>
<span class="sd">        add_reduce_max, add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp,</span>
<span class="sd">        add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceSum</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_prod">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_prod">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_prod</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_prod layer to the model that reduces the input tensor</span>
<span class="sd">        using ``prod(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceProdLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes. If axes list is empty, it will</span>
<span class="sd">            be set to true, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min,</span>
<span class="sd">        add_reduce_max, add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp,</span>
<span class="sd">        add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceProd</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_mean">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_mean">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_mean layer to the model that reduces the input tensor</span>
<span class="sd">        using ``mean(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceMeanLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_prod</span>
<span class="sd">        add_reduce_max, add_reduce_logsum, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceMean</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_max">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_max">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_max</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_max layer to the model that reduces the input tensor</span>
<span class="sd">        using ``max(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceMaxLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_prod</span>
<span class="sd">        add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceMax</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_min">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_min">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_min</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_min layer to the model that reduces the input tensor</span>
<span class="sd">        using ``min(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceMinLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_max, add_reduce_prod</span>
<span class="sd">        add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceMin</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_l2">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_l2">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_l2</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_l2 layer to the model that reduces the input tensor</span>
<span class="sd">        using ``l2_normalization(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceL2LayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_sum, add_reduce_min, add_reduce_max, add_reduce_prod</span>
<span class="sd">        add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceL2</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_l1">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_l1">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_l1</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_l1 layer to the model that reduces the input tensor</span>
<span class="sd">        using ``l1_normalization(elements across given dimensions)``.</span>
<span class="sd">        Refer to the ``ReduceL1LayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_max, add_reduce_prod</span>
<span class="sd">        add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceL1</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_sumsquare">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_sumsquare">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_sumsquare</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_sumsquare layer to the model that reduces the input tensor</span>
<span class="sd">        using ``sum(square(elements across given dimensions))``.</span>
<span class="sd">        Refer to the ``ReduceSumSquareLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_prod</span>
<span class="sd">        add_reduce_max, add_reduce_mean, add_reduce_logsum, add_reduce_logsumexp</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceSumSquare</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_logsum">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_logsum">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_logsum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_logsum layer to the model that reduces the input tensor</span>
<span class="sd">        using log(sum(elements across given dimensions)).</span>
<span class="sd">        Refer to the ``ReduceLogSumLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_prod</span>
<span class="sd">        add_reduce_max, add_reduce_mean, add_reduce_logsumexp, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceLogSum</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_reduce_logsumexp">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_reduce_logsumexp">[docs]</a>
    <span class="k">def</span> <span class="nf">add_reduce_logsumexp</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_all</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a reduce_logsumexp layer to the model that computes ``log(sum(exp(tensor)))``</span>
<span class="sd">        and reduces along the given axis.</span>
<span class="sd">        Refer to the ``ReduceLogSumExpLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axes: list of int or tuple of int, optional</span>
<span class="sd">            List of dimensions for the reduce operations.</span>
<span class="sd">            Each should be in range [-rank(input), rank(input)), default: ``None`` (reduce_all)</span>
<span class="sd">        keepdims: bool, optional</span>
<span class="sd">            Whether or not to retain the reduced dimensions with length 1, default: true.</span>
<span class="sd">        reduce_all: bool, optional</span>
<span class="sd">            Whether or not to reduce on all axes, default: false.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_reduce_l1, add_reduce_l2, add_reduce_sum, add_reduce_min, add_reduce_prod</span>
<span class="sd">        add_reduce_max, add_reduce_mean, add_reduce_logsum, add_reduce_sumsquare</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">reduceLogSumExp</span>

        <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduce_all</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">keepDims</span> <span class="o">=</span> <span class="n">keepdims</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reduceAll</span> <span class="o">=</span> <span class="n">reduce_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_rank_for_reduce_op</span><span class="p">(</span>
            <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">,</span> <span class="n">reduce_all</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_where_nonzero">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_where_nonzero">[docs]</a>
    <span class="k">def</span> <span class="nf">add_where_nonzero</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a where_nonzero layer to the model that returns a tensor containing</span>
<span class="sd">        the indices of all non-zero elements of input tensor.</span>
<span class="sd">        Refer to the ``WhereNonZeroLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_where_broadcastable</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">whereNonZero</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank_dict</span><span class="p">[</span><span class="n">output_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_matrix_band_part">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_matrix_band_part">[docs]</a>
    <span class="k">def</span> <span class="nf">add_matrix_band_part</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">num_lower</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_upper</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a matrix_band_part layer to the model that copies a tensor setting</span>
<span class="sd">        everything outside a central band in each inner-most matrix to zero.</span>
<span class="sd">        Refer to the ``MatrixBandPartLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The of input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        num_lower: int, optional</span>
<span class="sd">            Number of lower sub-diagonals to keep.</span>
<span class="sd">            Default: -1 (keep entire lower triangle).</span>
<span class="sd">        num_upper: int, optional</span>
<span class="sd">            Number of upper sub-diagonals to keep.</span>
<span class="sd">            Default: -1 (keep entire upper triangle).</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_lower_triangular, add_lower_triangular</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">matrixBandPart</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numLower</span> <span class="o">=</span> <span class="n">num_lower</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">numUpper</span> <span class="o">=</span> <span class="n">num_upper</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_lower_triangular">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_lower_triangular">[docs]</a>
    <span class="k">def</span> <span class="nf">add_lower_triangular</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a lower_triangular layer to the model that copies a tensor setting</span>
<span class="sd">        everything outside lower triangular to zero.</span>
<span class="sd">        Refer to the ``LowerTriangularLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The of input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        k: int, optional</span>
<span class="sd">            Diagonal below which to zero elements, default: 0 (main diagonal),</span>
<span class="sd">            k &lt; 0 is lower it and k &gt; 0 is upper.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_upper_triangular, add_matrix_band_part</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">lowerTriangular</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_upper_triangular">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_upper_triangular">[docs]</a>
    <span class="k">def</span> <span class="nf">add_upper_triangular</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a upper_triangular layer to the model that copies a tensor setting</span>
<span class="sd">        everything outside upper triangular to zero.</span>
<span class="sd">        Refer to the ``UpperTriangularLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The of input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        k: int, optional</span>
<span class="sd">            Diagonal above which to zero elements, default: 0 (main diagonal),</span>
<span class="sd">            k &lt; 0 is lower it and k &gt; 0 is upper.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_lower_triangular, add_matrix_band_part</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">upperTriangular</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_where_broadcastable">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_where_broadcastable">[docs]</a>
    <span class="k">def</span> <span class="nf">add_where_broadcastable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a where_broadcastable layer to the model that returns the elements</span>
<span class="sd">        either from tensor x or tensor y, depending on the value in the</span>
<span class="sd">        condition tensor.</span>
<span class="sd">        Refer to the ``WhereBroadcastableLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_where_nonzero</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">whereBroadcastable</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_input_rank</span><span class="p">(</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_layer_normalization">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_layer_normalization">[docs]</a>
    <span class="k">def</span> <span class="nf">add_layer_normalization</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a layer normalization layer to the model that applies layer</span>
<span class="sd">        normalization over the input tensor.</span>
<span class="sd">        Refer to the ``LayerNormalizationLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        normalized_shape: list of int or tuple of int</span>
<span class="sd">            Input shape from an expected input of size.</span>
<span class="sd">        gamma: WeightParams</span>
<span class="sd">            Weight parameters.</span>
<span class="sd">        beta: WeightParams</span>
<span class="sd">            Bias parameters.</span>
<span class="sd">        eps: float, optional</span>
<span class="sd">            Constant value added to the denominator, default: 1e-5.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">gamma</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape of parameter gamma should match normalized_shape&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">beta</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape of parameter beta should match normalized_shape&quot;</span><span class="p">)</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">layerNormalization</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">normalizedShape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">gamma</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">gamma</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">bias</span> <span class="o">=</span> <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">beta</span>
        <span class="n">bias</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_one_hot">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_one_hot">[docs]</a>
    <span class="k">def</span> <span class="nf">add_one_hot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">output_name</span><span class="p">,</span>
        <span class="n">one_hot_vector_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">on_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">off_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a one hot layer to the model that computes the one hot representation of the input tensor.</span>
<span class="sd">        Refer to the ``OneHotLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        one_hot_vector_size:  int &gt; 0</span>
<span class="sd">            size of the one hot vector.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            refers to the axis in the output tensor, default: -1.</span>
<span class="sd">        on_value: float, optional</span>
<span class="sd">            Constant value on locations represented by first input, default: 1.0.</span>
<span class="sd">        off_value: float, optional</span>
<span class="sd">            Constant value at all other locations, default: 0.0.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">oneHot</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="k">if</span> <span class="n">one_hot_vector_size</span><span class="p">:</span>
            <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">oneHotVectorSize</span> <span class="o">=</span> <span class="n">one_hot_vector_size</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">onValue</span> <span class="o">=</span> <span class="n">on_value</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">offValue</span> <span class="o">=</span> <span class="n">off_value</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_cumsum">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_cumsum">[docs]</a>
    <span class="k">def</span> <span class="nf">add_cumsum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a cum sum layer to the model computes the cumulative sum values of the input along a given axis.</span>
<span class="sd">        Refer to the ``CumSumLayerParams`` message in the specification</span>
<span class="sd">        (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_names: list of str</span>
<span class="sd">            The input blob names of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">            Axis to perform the operation, default: -1.</span>
<span class="sd">        reverse: bool, optional</span>
<span class="sd">            if true, cumsum is performed in the opposite direction, default: False.</span>
<span class="sd">        exclusive: bool, optional</span>
<span class="sd">            whether to perform exclusive or inclusive cumulative summation, default: False.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">input_names</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">cumSum</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">reverse</span> <span class="o">=</span> <span class="n">reverse</span>
        <span class="n">spec_layer_params</span><span class="o">.</span><span class="n">excludeFinalSum</span> <span class="o">=</span> <span class="n">exclusive</span>
        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_clamped_relu">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_clamped_relu">[docs]</a>
    <span class="k">def</span> <span class="nf">add_clamped_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">6.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a clamped relu layer to the model.</span>
<span class="sd">        Clamped relu formula is f(x) = min((x &gt;= 0 ? x : alpha * x), beta)</span>
<span class="sd">        Refer to the ``ClampedReluLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        alpha: float, optional</span>
<span class="sd">             slope of the output when input is negative, default: 0.0.</span>
<span class="sd">        beta: float, optional</span>
<span class="sd">            Upper bound on the output value, default: 6.0.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_clip</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">clampedReLU</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">spec_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">clampedReLU</span>

        <span class="n">spec_params</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>


<div class="viewcode-block" id="NeuralNetworkBuilder.add_argsort">
<a class="viewcode-back" href="../../../../source/coremltools.models.neural_network.html#coremltools.models.neural_network.builder.NeuralNetworkBuilder.add_argsort">[docs]</a>
    <span class="k">def</span> <span class="nf">add_argsort</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an argsort layer to the model.</span>
<span class="sd">        Refer to the ``ArgsortLayerParams`` message in the specification (NeuralNetwork.proto) for more details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            The name of this layer.</span>
<span class="sd">        input_name: str</span>
<span class="sd">            The input blob name of this layer.</span>
<span class="sd">        output_name: str</span>
<span class="sd">            The output blob name of this layer.</span>
<span class="sd">        axis: int, optional</span>
<span class="sd">             axis along which to compute the sorting indices</span>
<span class="sd">        descending: bool, optional</span>
<span class="sd">            order of sorting</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_topk</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">&lt;</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">specificationVersion</span> <span class="o">=</span> <span class="n">_SPECIFICATION_VERSION_IOS_14</span>

        <span class="n">spec_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_generic_layer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="p">[</span><span class="n">output_name</span><span class="p">])</span>
        <span class="n">spec_layer</span><span class="o">.</span><span class="n">argSort</span><span class="o">.</span><span class="n">MergeFromString</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">spec_params</span> <span class="o">=</span> <span class="n">spec_layer</span><span class="o">.</span><span class="n">argSort</span>

        <span class="n">spec_params</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="n">spec_params</span><span class="o">.</span><span class="n">descending</span> <span class="o">=</span> <span class="n">descending</span>

        <span class="k">return</span> <span class="n">spec_layer</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>