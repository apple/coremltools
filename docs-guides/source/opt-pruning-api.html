
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>API Overview &#8212; Guide to Core ML Tools</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/imgstyle.css?v=27a1495e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c1ce5b23"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/opt-pruning-api';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Combining Compression Types" href="opt-joint-compression.html" />
    <link rel="prev" title="Pruning Algorithms" href="opt-pruning-algos.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Guide to Core ML Tools</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">coremltools API Reference</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="new-features.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-to-contribute.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-learning-models.html">Converting Deep Learning Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="target-conversion-formats.html">Source and Conversion Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="load-and-convert-model.html">Load and Convert Model Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-ml-program.html">Convert Models to ML Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-to-neural-network.html">Convert Models to Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="comparing-ml-programs-and-neural-networks.html">Comparing ML Programs and Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution.html">Typed Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="typed-execution-example.html">Typed Execution Workflow Example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-image-classifier.html">Converting a TensorFlow 1 Image Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="convert-pytorch.html">Converting from PyTorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="convert-pytorch-workflow.html">PyTorch Conversion Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-tracing.html">Model Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-exporting.html">Model Exporting</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-torchvision-model-from-pytorch.html">Converting a torchvision Model from PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-pytorch-segmentation-model.html">Converting a PyTorch Segmentation Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-openelm.html">Converting an Open Efficient Language Model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="conversion-options.html">Conversion Options</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="new-conversion-options.html">New Conversion Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="model-input-and-output-types.html">Model Input and Output Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-inputs.html">Image Input and Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-models.html">Stateful Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="flexible-inputs.html">Flexible Input Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="composite-operators.html">Composite Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom-operators.html">Custom Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph-passes-intro.html">Graph Passes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="opt-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-whats-new.html">What’s New</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-overview-examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-resnet.html">Optimizing ResNet50 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-opt1_3.html">Optimizing OPT Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-stable-diffusion.html">Optimizing StableDiffusion Model</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="opt-workflow.html">Optimization Workflow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-palettization.html">Palettization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-overview.html">Palettization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-algos.html">Palettization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-palettization-api.html">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="opt-quantization.html">Linear Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-overview.html">Quantization Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-algos.html">Quantization Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-quantization-api.html">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="opt-pruning.html">Pruning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-perf.html">Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="opt-pruning-algos.html">Pruning Algorithms</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">API Overview</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="opt-joint-compression.html">Combining Compression Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="opt-conversion.html">Conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="xgboost-conversion.html">XGBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multifunction-models.html">Multifunction Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-prediction.html">Model Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="updatable-model-examples.html">Updatable Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="updatable-neural-network-classifier-on-mnist-dataset.html">Neural Network Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-tiny-drawing-classifier-pipeline-model.html">Pipeline Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="updatable-nearest-neighbor-classifier.html">Nearest Neighbor Classifier</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/apple/coremltools" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/source/opt-pruning-api.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>API Overview</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-apis-for-core-ml-model">Pruning APIs for Core ML model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-free-pruning">Data free Pruning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-apis-for-torch-model">Pruning APIs for Torch model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calibration-data-based-pruning-sparsegpt">Calibration data based Pruning (SparseGPT)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Data-free Pruning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-time-pruning">Training time Pruning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-torch-models-to-core-ml">Converting Torch models to Core ML</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="api-overview">
<h1>API Overview<a class="headerlink" href="#api-overview" title="Link to this heading">#</a></h1>
<section id="pruning-apis-for-core-ml-model">
<h2>Pruning APIs for Core ML model<a class="headerlink" href="#pruning-apis-for-core-ml-model" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.coreml.config.html#coremltools.optimize.coreml.OpMagnitudePrunerConfig"><code class="docutils literal notranslate"><span class="pre">OpMagnitudePrunerConfig</span></code></a>: Prune the weights with a constant sparsity percentile.</p></li>
<li><p><a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.coreml.config.html#coremltools.optimize.coreml.OpThresholdPrunerConfig"><code class="docutils literal notranslate"><span class="pre">OpThresholdPrunerConfig</span></code></a>: Set all weight values below a certain value.</p></li>
</ul>
<section id="data-free-pruning">
<h3>Data free Pruning<a class="headerlink" href="#data-free-pruning" title="Link to this heading">#</a></h3>
<p>Here is a simple example showing the usage of <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.coreml.config.html#coremltools.optimize.coreml.OpThresholdPrunerConfig"><code class="docutils literal notranslate"><span class="pre">OpThresholdPrunerConfig</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">coremltools.optimize.coreml</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OpThresholdPrunerConfig</span><span class="p">,</span>
    <span class="n">OptimizationConfig</span><span class="p">,</span>
    <span class="n">prune_weights</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">OptimizationConfig</span><span class="p">(</span><span class="n">global_config</span><span class="o">=</span><span class="n">OpThresholdPrunerConfig</span><span class="p">(</span>
  <span class="n">threshold</span><span class="o">=</span><span class="mf">0.03</span>
<span class="p">))</span>
<span class="n">model_compressed</span> <span class="o">=</span> <span class="n">prune_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>All weight values below a certain value, as specified by <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, are set to zero.</p></li>
</ul>
<p>Another way to perform data-free pruning would be using the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.coreml.config.html#coremltools.optimize.coreml.OpMagnitudePrunerConfig"><code class="docutils literal notranslate"><span class="pre">OpMagnitudePrunerConfig</span></code></a>. Below, we see how to configure it with different config parameters based on the op type and op name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">coremltools.optimize.coreml</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OpMagnitudePrunerConfig</span><span class="p">,</span>
    <span class="n">OptimizationConfig</span><span class="p">,</span>
    <span class="n">prune_weights</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">global_config</span> <span class="o">=</span> <span class="n">OpMagnitudePrunerConfig</span><span class="p">(</span>
    <span class="n">target_sparsity</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">weight_threshold</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">linear_config</span> <span class="o">=</span> <span class="n">OpMagnitudePrunerConfig</span><span class="p">(</span><span class="n">target_sparsity</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">OptimizationConfig</span><span class="p">(</span>
  <span class="n">global_config</span><span class="o">=</span><span class="n">op_config</span><span class="p">,</span>
  <span class="n">op_type_configs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;linear&quot;</span><span class="p">:</span> <span class="n">linear_config</span><span class="p">},</span>
  <span class="n">op_name_configs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;fc&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
<span class="p">)</span>
<span class="n">model_compressed</span> <span class="o">=</span> <span class="n">prune_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_sparsity</span></code>: Lowest magnitude values up to <code class="docutils literal notranslate"><span class="pre">target_sparsity</span></code> are set to zero.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_threshold</span></code>: Weight tensors only of size (# of elements) greater than <code class="docutils literal notranslate"><span class="pre">weight_threshold</span></code> are pruned.</p></li>
<li><p>Structured sparsity such as block-structured or <code class="docutils literal notranslate"><span class="pre">n:m</span></code> structured can be applied using <code class="docutils literal notranslate"><span class="pre">block_size</span></code> and <code class="docutils literal notranslate"><span class="pre">n_m_ratio</span></code> respectively.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type_configs</span></code> and <code class="docutils literal notranslate"><span class="pre">op_name_configs</span></code>: Configure the modules at a more fine-grained level. Here we configure all <code class="docutils literal notranslate"><span class="pre">linear</span></code> layers with 75% sparsity, skip pruning the <code class="docutils literal notranslate"><span class="pre">fc</span></code> layer, and the remaining layers are pruned to 50% sparsity.</p></li>
<li><p><a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.coreml.post_training_quantization.html#coremltools.optimize.coreml.get_weights_metadata"><code class="docutils literal notranslate"><span class="pre">get_weights_metadata()</span></code></a>: Utility that provides detailed information about all the weights in the Core ML model, which can be used to find the names of the ops to customize.</p></li>
</ul>
</section>
</section>
<section id="pruning-apis-for-torch-model">
<h2>Pruning APIs for Torch model<a class="headerlink" href="#pruning-apis-for-torch-model" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SparseGPT</span></code> using <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.torch.pruning.html#sparsegpt"><code class="docutils literal notranslate"><span class="pre">LayerwiseCompressor</span></code></a>: A post-training calibration data-based compression algorithm based on the paper <a class="reference external" href="https://arxiv.org/pdf/2301.00774.pdf">SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MagnitudePruner</span></code>:  A weight norm guided pruning algorithm based on the paper <a class="reference external" href="https://arxiv.org/pdf/1710.01878.pdf">To prune or not to prune</a></p></li>
</ul>
<section id="calibration-data-based-pruning-sparsegpt">
<h3>Calibration data based Pruning (SparseGPT)<a class="headerlink" href="#calibration-data-based-pruning-sparsegpt" title="Link to this heading">#</a></h3>
<p>The following example shows how to compress a model using <code class="docutils literal notranslate"><span class="pre">SparseGPT</span></code> and <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.torch.pruning.html#sparsegpt"><code class="docutils literal notranslate"><span class="pre">LayerwiseCompressor</span></code></a>. Here we provide the pruning config using a <code class="docutils literal notranslate"><span class="pre">yaml</span></code> file. Across all APIs, the configs can be provided either in code via a dictionary structure or via <code class="docutils literal notranslate"><span class="pre">yaml</span></code> files.</p>
<p><code class="docutils literal notranslate"><span class="pre">sparse_gpt_config.yaml</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">algorithm</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;sparsegpt&quot;</span>
<span class="nt">layers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&#39;model.layer\d+&#39;</span>
<span class="nt">global_config</span><span class="p">:</span>
<span class="w">  </span><span class="nt">target_sparsity</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="nt">calibration_nsamples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">125</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">coremltools.optimize.torch</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LayerwiseCompressor</span><span class="p">,</span>
    <span class="n">LayerwiseCompressorConfig</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">LayerwiseCompressorConfig</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="s2">&quot;sparse_gpt_config.yaml&quot;</span><span class="p">)</span>

<span class="n">compressor</span> <span class="o">=</span> <span class="n">LayerwiseCompressor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">compressor</span><span class="o">.</span><span class="n">compress</span><span class="p">(</span><span class="n">dataloader</span><span class="o">=</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is set to <code class="docutils literal notranslate"><span class="pre">&quot;sparsegpt&quot;</span></code> in the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.torch.pruning.html#sparsegpt"><code class="docutils literal notranslate"><span class="pre">LayerwiseCompressor</span></code></a> algorithm.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_sparsity</span></code>: Refers to the amount of sparsity to apply for each layer’s weight tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">layers</span></code>: Layers to be pruned. This is a list of either fully-qualified layer (module) name(s) or a regex for the layer name(s).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">quantization_granularity</span></code> and <code class="docutils literal notranslate"><span class="pre">quantization_scheme</span></code> can be configured to quantize the non-zero weights for further compression.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n:m</span></code> structured sparsity can be set through the <code class="docutils literal notranslate"><span class="pre">n_m_ratio</span></code> option.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">compress</span></code> method takes in a dataloader for the calibration dataset as well as the device for performing computation. The dataloader is an iterable of the inputs that need to be fed into the model.</p></li>
</ul>
</section>
<section id="id1">
<h3>Data-free Pruning<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>As mentioned in the previous <a class="reference internal" href="opt-pruning-algos.html"><span class="doc std std-doc">Pruning Algorithms</span></a> section, the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.torch.pruning.html#magnitude-pruning"><code class="docutils literal notranslate"><span class="pre">MagnitudePruner</span></code></a> can be used to perform a data-free pruning to experiment with different pruning structures. In the example below, <code class="docutils literal notranslate"><span class="pre">n:m</span></code> structured (with a ratio <code class="docutils literal notranslate"><span class="pre">6:8</span></code>) pruning is applied to the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">coremltools.optimize.torch</span> <span class="kn">import</span> <span class="p">(</span>
  <span class="n">MagnitudePrunerConfig</span><span class="p">,</span>
  <span class="n">MagniutdePruner</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">MagniutdePrunerConfig</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
  <span class="s2">&quot;global_config&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;n_m_ratio&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
  <span class="p">}</span>
<span class="p">})</span>
<span class="n">pruner</span> <span class="o">=</span> <span class="n">MagniutdePruner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

<span class="n">pruner</span><span class="o">.</span><span class="n">prepare</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pruner</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
</pre></div>
</div>
<p>Here the <code class="docutils literal notranslate"><span class="pre">ConstantSparsityScheduler</span></code> is being used by default to prune the model in a data-free manner.</p>
</section>
<section id="training-time-pruning">
<h3>Training time Pruning<a class="headerlink" href="#training-time-pruning" title="Link to this heading">#</a></h3>
<p>The <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.optimize.torch.pruning.html#magnitude-pruning"><code class="docutils literal notranslate"><span class="pre">MagnitudePruner</span></code></a> can be used to introduce sparsity while fine-tuning the model to adapt to the loss of accuracy due to the sparsification of the model. In the example below, 75% sparsity is applied to all convolution layers of the model in a gradual incremental manner.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">coremltools.optimize.torch</span> <span class="kn">import</span> <span class="p">(</span>
  <span class="n">MagnitudePrunerConfig</span><span class="p">,</span>
  <span class="n">MagniutdePruner</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">MagnitudePrunerConfig</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">&quot;module_type_configs&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;Conv2d&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;update_steps&quot;</span><span class="p">:</span> <span class="s2">&quot;range(0, 100, 5)&quot;</span><span class="p">},</span>
        <span class="s2">&quot;target_sparsity&quot;</span><span class="p">:</span> <span class="mf">0.75</span><span class="p">,</span>
        <span class="s2">&quot;granularity&quot;</span><span class="p">:</span> <span class="s2">&quot;per_scalar&quot;</span><span class="p">,</span>
      <span class="p">},</span>
    <span class="p">}</span>
<span class="p">})</span>

<span class="n">pruner</span> <span class="o">=</span> <span class="n">MagnitudePruner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pruner</span><span class="o">.</span><span class="n">prepare</span><span class="p">()</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
    <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">pruner</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="n">pruner</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_sparsity</span></code>: Refers to the amount of sparsity that the model will finally have.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">granularity</span></code>: One of <code class="docutils literal notranslate"><span class="pre">per_scalar</span></code>, <code class="docutils literal notranslate"><span class="pre">per_kernel</span></code> or <code class="docutils literal notranslate"><span class="pre">per_channel</span></code> allows for different ways of structuring the sparsity in the weight tensor.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> (above uses the <code class="docutils literal notranslate"><span class="pre">PolynomialDecayScheduler</span></code>) incrementally adds sparsity through the course of training to make sure the weights can adapt to the introduction of sparsity. The <code class="docutils literal notranslate"><span class="pre">update_steps</span></code> parameter refers to the training steps upon which the sparsity has to be introduced. In this example, the sparsity is applied every five steps starting from zero all the way up to 100.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MagnitudePruner.prepare</span></code> helps to insert the pruning layers and hooks on to the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MagnitudePruner.step</span></code> incremenetally adds sparsity based on the sparsity schedule described by the <code class="docutils literal notranslate"><span class="pre">scheduler</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MagnitudePruner.finalize</span></code> commits all the changes on the model by replacing the pruned weights with zeros.</p></li>
</ul>
</section>
<section id="converting-torch-models-to-core-ml">
<h3>Converting Torch models to Core ML<a class="headerlink" href="#converting-torch-models-to-core-ml" title="Link to this heading">#</a></h3>
<p>If the Torch model already contains weights that have been zeroed out but are still in a dense representation, the <code class="docutils literal notranslate"><span class="pre">ct.optimize.coreml</span></code> APIs mentioned above can be used to generate a sparse representation Core ML model. If the Torch model was pruned using the <code class="docutils literal notranslate"><span class="pre">ct.optimize.torch</span></code> APIs mentioned above, then simply calling <code class="docutils literal notranslate"><span class="pre">ct.convert</span></code> should be sufficient to generate the sparse Core ML model.</p>
<p>For more details, refer to <a class="reference internal" href="convert-pytorch-workflow.html"><span class="doc std std-doc">PyTorch Conversion Workflow</span></a>.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="opt-pruning-algos.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Pruning Algorithms</p>
      </div>
    </a>
    <a class="right-next"
       href="opt-joint-compression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Combining Compression Types</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-apis-for-core-ml-model">Pruning APIs for Core ML model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-free-pruning">Data free Pruning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruning-apis-for-torch-model">Pruning APIs for Torch model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calibration-data-based-pruning-sparsegpt">Calibration data based Pruning (SparseGPT)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Data-free Pruning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-time-pruning">Training time Pruning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-torch-models-to-core-ml">Converting Torch models to Core ML</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Apple
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, Apple Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>