

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>NeuralNetwork &mdash; Core ML Format Reference  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Other Classifiers" href="Classifiers.html" />
    <link rel="prev" title="MILspec.Program" href="MIL.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Core ML Format Reference
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Model.html">Core ML Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="DataStructuresTypes.html">Data Structures, Types and Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="FeatureEngineering.html">Feature Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="Identity.html">Identity</a></li>
<li class="toctree-l1"><a class="reference internal" href="MIL.html">MILspec.Program</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">NeuralNetwork</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preprocessing">Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkimagescaler">NeuralNetworkImageScaler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkmeanimage">NeuralNetworkMeanImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkpreprocessing">NeuralNetworkPreprocessing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#activation-functions">Activation Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#activationrelu">ActivationReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationleakyrelu">ActivationLeakyReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationtanh">ActivationTanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationscaledtanh">ActivationScaledTanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationsigmoid">ActivationSigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationlinear">ActivationLinear</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationsigmoidhard">ActivationSigmoidHard</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationprelu">ActivationPReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationelu">ActivationELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationthresholdedrelu">ActivationThresholdedReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationsoftsign">ActivationSoftsign</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationsoftplus">ActivationSoftplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationparametricsoftplus">ActivationParametricSoftplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationparams">ActivationParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensor">Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworklayer">NeuralNetworkLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#branchlayerparams">BranchLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#looplayerparams">LoopLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loopbreaklayerparams">LoopBreakLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loopcontinuelayerparams">LoopContinueLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#copylayerparams">CopyLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#greaterthanlayerparams">GreaterThanLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#greaterequallayerparams">GreaterEqualLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lessthanlayerparams">LessThanLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lessequallayerparams">LessEqualLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#equallayerparams">EqualLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notequallayerparams">NotEqualLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logicalandlayerparams">LogicalAndLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logicalorlayerparams">LogicalOrLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logicalxorlayerparams">LogicalXorLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logicalnotlayerparams">LogicalNotLayerParams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#borderamounts">BorderAmounts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#borderamounts-edgesizes">BorderAmounts.EdgeSizes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#validpadding">ValidPadding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#samepadding">SamePadding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#samplingmode">SamplingMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#boxcoordinatesmode">BoxCoordinatesMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#weightparams">WeightParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantizationparams">QuantizationParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linearquantizationparams">LinearQuantizationParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lookuptablequantizationparams">LookUpTableQuantizationParams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#layers">Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#convolutionlayerparams">ConvolutionLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolution3dlayerparams">Convolution3DLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#innerproductlayerparams">InnerProductLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#embeddinglayerparams">EmbeddingLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#embeddingndlayerparams">EmbeddingNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batchnormlayerparams">BatchnormLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolinglayerparams">PoolingLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolinglayerparams-validcompletepadding">PoolingLayerParams.ValidCompletePadding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pooling3dlayerparams">Pooling3DLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#globalpooling3dlayerparams">GlobalPooling3DLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayerparams">PaddingLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayerparams-paddingconstant">PaddingLayerParams.PaddingConstant</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayerparams-paddingreflection">PaddingLayerParams.PaddingReflection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayerparams-paddingreplication">PaddingLayerParams.PaddingReplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concatlayerparams">ConcatLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrnlayerparams">LRNLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#softmaxlayerparams">SoftmaxLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#splitlayerparams">SplitLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#addlayerparams">AddLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiplylayerparams">MultiplyLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unaryfunctionlayerparams">UnaryFunctionLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#upsamplelayerparams">UpsampleLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resizebilinearlayerparams">ResizeBilinearLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropresizelayerparams">CropResizeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#biaslayerparams">BiasLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalelayerparams">ScaleLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loadconstantlayerparams">LoadConstantLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#l2normalizelayerparams">L2NormalizeLayerParams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-reorganization-layers">Data Reorganization Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#flattenlayerparams">FlattenLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshapelayerparams">ReshapeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#permutelayerparams">PermuteLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reorganizedatalayerparams">ReorganizeDataLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slicelayerparams">SliceLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducelayerparams">ReduceLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#croplayerparams">CropLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#averagelayerparams">AverageLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxlayerparams">MaxLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#minlayerparams">MinLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dotproductlayerparams">DotProductLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#meanvariancenormalizelayerparams">MeanVarianceNormalizeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequencerepeatlayerparams">SequenceRepeatLayerParams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#recurrent-layers">Recurrent Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#simplerecurrentlayerparams">SimpleRecurrentLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#grulayerparams">GRULayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lstmparams">LSTMParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lstmweightparams">LSTMWeightParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unidirectionallstmlayerparams">UniDirectionalLSTMLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bidirectionallstmlayerparams">BiDirectionalLSTMLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#customlayerparams">CustomLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#customlayerparams-customlayerparamvalue">CustomLayerParams.CustomLayerParamValue</a></li>
<li class="toctree-l3"><a class="reference internal" href="#customlayerparams-parametersentry">CustomLayerParams.ParametersEntry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transposelayerparams">TransposeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batchedmatmullayerparams">BatchedMatMulLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concatndlayerparams">ConcatNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#softmaxndlayerparams">SoftmaxNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reverselayerparams">ReverseLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reverseseqlayerparams">ReverseSeqLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loadconstantndlayerparams">LoadConstantNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filllikelayerparams">FillLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fillstaticlayerparams">FillStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filldynamiclayerparams">FillDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#wherebroadcastablelayerparams">WhereBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sinlayerparams">SinLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#coslayerparams">CosLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tanlayerparams">TanLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asinlayerparams">AsinLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#acoslayerparams">AcosLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#atanlayerparams">AtanLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sinhlayerparams">SinhLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#coshlayerparams">CoshLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tanhlayerparams">TanhLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asinhlayerparams">AsinhLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#acoshlayerparams">AcoshLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#atanhlayerparams">AtanhLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#powbroadcastablelayerparams">PowBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exp2layerparams">Exp2LayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#wherenonzerolayerparams">WhereNonZeroLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#matrixbandpartlayerparams">MatrixBandPartLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#uppertriangularlayerparams">UpperTriangularLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lowertriangularlayerparams">LowerTriangularLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#broadcasttolikelayerparams">BroadcastToLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#broadcasttostaticlayerparams">BroadcastToStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#broadcasttodynamiclayerparams">BroadcastToDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#addbroadcastablelayerparams">AddBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxbroadcastablelayerparams">MaxBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#minbroadcastablelayerparams">MinBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modbroadcastablelayerparams">ModBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#floordivbroadcastablelayerparams">FloorDivBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#subtractbroadcastablelayerparams">SubtractBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiplybroadcastablelayerparams">MultiplyBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dividebroadcastablelayerparams">DivideBroadcastableLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gatherlayerparams">GatherLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scatterlayerparams">ScatterLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gatherndlayerparams">GatherNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scatterndlayerparams">ScatterNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gatheralongaxislayerparams">GatherAlongAxisLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scatteralongaxislayerparams">ScatterAlongAxisLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stacklayerparams">StackLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rankpreservingreshapelayerparams">RankPreservingReshapeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#constantpaddinglayerparams">ConstantPaddingLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomnormallikelayerparams">RandomNormalLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomnormalstaticlayerparams">RandomNormalStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomnormaldynamiclayerparams">RandomNormalDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomuniformlikelayerparams">RandomUniformLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomuniformstaticlayerparams">RandomUniformStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomuniformdynamiclayerparams">RandomUniformDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randombernoullilikelayerparams">RandomBernoulliLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randombernoullistaticlayerparams">RandomBernoulliStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randombernoullidynamiclayerparams">RandomBernoulliDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#categoricaldistributionlayerparams">CategoricalDistributionLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducel1layerparams">ReduceL1LayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducel2layerparams">ReduceL2LayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducemaxlayerparams">ReduceMaxLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reduceminlayerparams">ReduceMinLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducesumlayerparams">ReduceSumLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reduceprodlayerparams">ReduceProdLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducemeanlayerparams">ReduceMeanLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducelogsumlayerparams">ReduceLogSumLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducesumsquarelayerparams">ReduceSumSquareLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducelogsumexplayerparams">ReduceLogSumExpLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#expanddimslayerparams">ExpandDimsLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#flattento2dlayerparams">FlattenTo2DLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshapestaticlayerparams">ReshapeStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshapelikelayerparams">ReshapeLikeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshapedynamiclayerparams">ReshapeDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#squeezelayerparams">SqueezeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#topklayerparams">TopKLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#argmaxlayerparams">ArgMaxLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#argminlayerparams">ArgMinLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#splitndlayerparams">SplitNDLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ceillayerparams">CeilLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#roundlayerparams">RoundLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#floorlayerparams">FloorLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#signlayerparams">SignLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cliplayerparams">ClipLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slicestaticlayerparams">SliceStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slicedynamiclayerparams">SliceDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tilelayerparams">TileLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getshapelayerparams">GetShapeLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#erflayerparams">ErfLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gelulayerparams">GeluLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rangestaticlayerparams">RangeStaticLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rangedynamiclayerparams">RangeDynamicLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slidingwindowslayerparams">SlidingWindowsLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layernormalizationlayerparams">LayerNormalizationLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nonmaximumsuppressionlayerparams">NonMaximumSuppressionLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#clampedrelulayerparams">ClampedReLULayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#argsortlayerparams">ArgSortLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slicebysizelayerparams">SliceBySizeLayerParams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#neural-network-specializations">Neural Network Specializations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkclassifier">NeuralNetworkClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="#onehotlayerparams">OneHotLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cumsumlayerparams">CumSumLayerParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkregressor">NeuralNetworkRegressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#on-device-training-messages">On-device Training Messages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#networkupdateparameters">NetworkUpdateParameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#losslayer">LossLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#categoricalcrossentropylosslayer">CategoricalCrossEntropyLossLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#meansquarederrorlosslayer">MeanSquaredErrorLossLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#optimizer">Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sgdoptimizer">SGDOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adamoptimizer">AdamOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolution3dlayerparams-paddingtype">Convolution3DLayerParams.PaddingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#flattenlayerparams-flattenorder">FlattenLayerParams.FlattenOrder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gelulayerparams-gelumode">GeluLayerParams.GeluMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#globalpooling3dlayerparams-globalpoolingtype3d">GlobalPooling3DLayerParams.GlobalPoolingType3D</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkimageshapemapping">NeuralNetworkImageShapeMapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="#neuralnetworkmultiarrayshapemapping">NeuralNetworkMultiArrayShapeMapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pooling3dlayerparams-pooling3dpaddingtype">Pooling3DLayerParams.Pooling3DPaddingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pooling3dlayerparams-poolingtype3d">Pooling3DLayerParams.PoolingType3D</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolinglayerparams-poolingtype">PoolingLayerParams.PoolingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducelayerparams-reduceaxis">ReduceLayerParams.ReduceAxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducelayerparams-reduceoperation">ReduceLayerParams.ReduceOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reorganizedatalayerparams-reorganizationtype">ReorganizeDataLayerParams.ReorganizationType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshapelayerparams-reshapeorder">ReshapeLayerParams.ReshapeOrder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#samepadding-samepaddingmode">SamePadding.SamePaddingMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#samplingmode-method">SamplingMode.Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#boxcoordinatesmode-coordinates">BoxCoordinatesMode.Coordinates</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scattermode">ScatterMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slicelayerparams-sliceaxis">SliceLayerParams.SliceAxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unaryfunctionlayerparams-operation">UnaryFunctionLayerParams.Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#upsamplelayerparams-interpolationmode">UpsampleLayerParams.InterpolationMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#upsamplelayerparams-linearupsamplemode">UpsampleLayerParams.LinearUpsampleMode</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Classifiers.html">Other Classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="OtherModels.html">Other Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Regressors.html">Other Regressors</a></li>
<li class="toctree-l1"><a class="reference internal" href="SVM.html">Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="TreeEnsemble.html">TreeEnsemble</a></li>
</ul>
<p class="caption"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://coremltools.readme.io/docs">Guides and examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/index.html">Core ML Tools (coremltools) API</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools/tree/main/mlmodel">GitHub</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Core ML Format Reference</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>NeuralNetwork</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Format/NeuralNetwork.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="neuralnetwork">
<h1>NeuralNetwork<a class="headerlink" href="#neuralnetwork" title="Permalink to this headline">¶</a></h1>
<p>A neural network is defined through a collection of layers
and represents a directed acyclic graph (DAG).
Each layer has a name, a layer type,
a list of input names, a list of output names,
and a collection of parameters specific to the layer type.</p>
<p>The graph structure and connectivity of the neural network
is inferred from the input and output names.
A neural network starts with the layer
whose input name is equal to the value specified in
<code class="docutils literal notranslate"><span class="pre">Model.description.input.name</span></code>,
and ends with the layer
whose output name is equal to the value specified in
<code class="docutils literal notranslate"><span class="pre">Model.description.output.name</span></code>.</p>
<p>Layers must have unique input and output names,
and a layer may not have input or output names that
refer to layers that are not yet defined.</p>
<p>For Core ML specification version &lt;=3,
all inputs are mapped to static rank 5 tensors, with axis notations
[Sequence, Batch, Channel, Height, Width].</p>
<p>From specification version 4 onwards (iOS &gt;= 13, macOS &gt;= 10.15), more options
are available (see enums <code class="docutils literal notranslate"><span class="pre">NeuralNetworkMultiArrayShapeMapping</span></code>,
<code class="docutils literal notranslate"><span class="pre">NeuralNetworkImageShapeMapping</span></code>) to map inputs to generic N-Dimensional
(or N rank) tensors, where N &gt;= 1.</p>
<p>Each layer type may have specific constraints on the ranks of its inputs and
outputs.</p>
<p>Some of the layers (such as softmax, reduce, etc.) have parameters that have
been described in terms of notational axis “Channel”, “Height”, “Width” or
“Sequence”. They can be re-interpreted easily in
the general ND setting by using the following rule:</p>
<ul class="simple">
<li><p>“width” is same as axis = -1 (i.e. the last axis from the end)</p></li>
<li><p>“height” is same as axis = -2 (i.e. the second last axis from the end)</p></li>
<li><p>“channel” is same as axis = -3 (i.e. the third last axis from the end)</p></li>
<li><p>“sequence” is same as axis = -5 (i.e. the fifth last axis from the end)</p></li>
</ul>
<p>Several layers are available in 3 different variations, with the names ending
in identifiers <code class="docutils literal notranslate"><span class="pre">like</span></code>, <code class="docutils literal notranslate"><span class="pre">static</span></code> and <code class="docutils literal notranslate"><span class="pre">dynamic</span></code>, such as <code class="docutils literal notranslate"><span class="pre">FillLike</span></code>,
<code class="docutils literal notranslate"><span class="pre">FillStatic</span></code> and <code class="docutils literal notranslate"><span class="pre">FillDynamic</span></code>. The <code class="docutils literal notranslate"><span class="pre">static</span></code> variation generally will have
a property corresponding to the shape of the output.</p>
<p>For example, if the output of the <code class="docutils literal notranslate"><span class="pre">FillStatic</span></code> layer is desired to be of
shape (10, 4), the property <code class="docutils literal notranslate"><span class="pre">targetShape</span></code> will have to be set to [10, 4].</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">dynamic</span></code> case, the shape is an input, hence it can be changed at
runtime. For example, for a <code class="docutils literal notranslate"><span class="pre">FillDynamic</span></code> layer, the input would have to be an
array containing the values 10 and 4, if the desired output is of shape (10, 4).
Whereas in the <code class="docutils literal notranslate"><span class="pre">like</span></code> case, the additional input’s shape is used as the output
shape, ignoring its values. For instance, for a <code class="docutils literal notranslate"><span class="pre">FillLike</span></code> layer, for an input
with shape (10, 4), the output generated will also be of shape (10, 4), values
of the input will be ignored.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetwork</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="n">NeuralNetworkLayer</span> <span class="na">layers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="n">NeuralNetworkPreprocessing</span> <span class="na">preprocessing</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs</span>
    <span class="n">NeuralNetworkMultiArrayShapeMapping</span> <span class="na">arrayInputShapeMapping</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for image inputs</span>
    <span class="n">NeuralNetworkImageShapeMapping</span> <span class="na">imageInputShapeMapping</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>


    <span class="n">NetworkUpdateParameters</span> <span class="na">updateParams</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
<div class="section" id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¶</a></h2>
<div class="section" id="neuralnetworkimagescaler">
<h3>NeuralNetworkImageScaler<a class="headerlink" href="#neuralnetworkimagescaler" title="Permalink to this headline">¶</a></h3>
<p>A neural network preprocessor that
performs a scalar multiplication of an image
followed by addition of scalar biases to the channels.</p>
<dl class="simple">
<dt>Input: X</dt><dd><p>An image in BGR or RGB format with shape <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>
or in grayscale format with shape <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
<dt>Output: Y</dt><dd><p>An image with format and shape corresponding to the input.</p>
</dd>
</dl>
<p>If the input image is in BGR format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">blueBias</span>
<span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">greenBias</span>
<span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">redBias</span>
</pre></div>
</div>
<p>If the input image is in RGB format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">redBias</span>
<span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">greenBias</span>
<span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">blueBias</span>
</pre></div>
</div>
<p>If the input image is in grayscale format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">channelScale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">grayBias</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkImageScaler</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">channelScale</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">blueBias</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">greenBias</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">redBias</span> <span class="o">=</span> <span class="mi">22</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">grayBias</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworkmeanimage">
<h3>NeuralNetworkMeanImage<a class="headerlink" href="#neuralnetworkmeanimage" title="Permalink to this headline">¶</a></h3>
<p>A neural network preprocessor that
subtracts the provided mean image from the input image.
The mean image is subtracted from the input named
<code class="docutils literal notranslate"><span class="pre">NeuralNetworkPreprocessing.featureName</span></code>.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkMeanImage</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">float</span> <span class="na">meanImage</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworkpreprocessing">
<h3>NeuralNetworkPreprocessing<a class="headerlink" href="#neuralnetworkpreprocessing" title="Permalink to this headline">¶</a></h3>
<p>Preprocessing parameters for image inputs.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkPreprocessing</span> <span class="p">{</span>

    <span class="kt">string</span> <span class="na">featureName</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">oneof</span> <span class="n">preprocessor</span> <span class="p">{</span>
        <span class="n">NeuralNetworkImageScaler</span> <span class="na">scaler</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="n">NeuralNetworkMeanImage</span> <span class="na">meanImage</span> <span class="o">=</span> <span class="mi">11</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="activation-functions">
<h2>Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="activationrelu">
<h3>ActivationReLU<a class="headerlink" href="#activationrelu" title="Permalink to this headline">¶</a></h3>
<p>A rectified linear unit (ReLU) activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \text{max}(0, x)\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationReLU</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationleakyrelu">
<h3>ActivationLeakyReLU<a class="headerlink" href="#activationleakyrelu" title="Permalink to this headline">¶</a></h3>
<p>A leaky rectified linear unit (ReLU) activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(x) = \begin{cases}
        x      &amp; \text{if } x \geq 0 \\
        \alpha x &amp; \text{if } x &lt; 0
       \end{cases}\end{split}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationLeakyReLU</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">//negative slope value for leakyReLU</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationtanh">
<h3>ActivationTanh<a class="headerlink" href="#activationtanh" title="Permalink to this headline">¶</a></h3>
<p>A hyperbolic tangent activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \dfrac{1 - e^{-2x}}{1 + e^{-2x}}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationTanh</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationscaledtanh">
<h3>ActivationScaledTanh<a class="headerlink" href="#activationscaledtanh" title="Permalink to this headline">¶</a></h3>
<p>A scaled hyperbolic tangent activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \alpha \tanh(\beta x)\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationScaledTanh</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationsigmoid">
<h3>ActivationSigmoid<a class="headerlink" href="#activationsigmoid" title="Permalink to this headline">¶</a></h3>
<p>A sigmoid activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \dfrac{1}{1 + e^{-x}}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationSigmoid</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationlinear">
<h3>ActivationLinear<a class="headerlink" href="#activationlinear" title="Permalink to this headline">¶</a></h3>
<p>A linear activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \alpha x + \beta\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationLinear</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationsigmoidhard">
<h3>ActivationSigmoidHard<a class="headerlink" href="#activationsigmoidhard" title="Permalink to this headline">¶</a></h3>
<p>A hard sigmoid activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \text{min}(\text{max}(\alpha x + \beta, 0), 1)\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationSigmoidHard</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationprelu">
<h3>ActivationPReLU<a class="headerlink" href="#activationprelu" title="Permalink to this headline">¶</a></h3>
<p>A parameterized rectified linear unit (PReLU) activation function.
Input must be at least rank 3. Axis = -3 is denoted by “C”, or channels.
“alpha” parameter can be a vector of length C.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(x_i) = \begin{cases}
             x_i          &amp; \text{if } x_i \geq 0 \\
             \alpha_i x_i &amp; \text{if } x_i &lt; 0
         \end{cases} \;,\;i=1,...,C\end{split}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationPReLU</span> <span class="p">{</span>

    <span class="c1">// parameter of length C or 1.</span>
    <span class="c1">// If length is 1, same value is used for all channels</span>
    <span class="n">WeightParams</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationelu">
<h3>ActivationELU<a class="headerlink" href="#activationelu" title="Permalink to this headline">¶</a></h3>
<p>An exponential linear unit (ELU) activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(x) = \begin{cases}
        x              &amp; \text{if } x \geq 0 \\
        \alpha (e^x - 1) &amp; \text{if } x &lt; 0
       \end{cases}\end{split}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationELU</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationthresholdedrelu">
<h3>ActivationThresholdedReLU<a class="headerlink" href="#activationthresholdedrelu" title="Permalink to this headline">¶</a></h3>
<p>A thresholded rectified linear unit (ReLU) activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(x) = \begin{cases}
        x &amp; \text{if } x \geq \alpha \\
        0 &amp; \text{if } x &lt; \alpha
       \end{cases}\end{split}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationThresholdedReLU</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationsoftsign">
<h3>ActivationSoftsign<a class="headerlink" href="#activationsoftsign" title="Permalink to this headline">¶</a></h3>
<p>A softsign activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \dfrac{x}{1 + |x|}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationSoftsign</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationsoftplus">
<h3>ActivationSoftplus<a class="headerlink" href="#activationsoftplus" title="Permalink to this headline">¶</a></h3>
<p>A softplus activation function.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x) = \text{log}(1 + e^x)\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationSoftplus</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationparametricsoftplus">
<h3>ActivationParametricSoftplus<a class="headerlink" href="#activationparametricsoftplus" title="Permalink to this headline">¶</a></h3>
<p>A parametric softplus activation function.
Input must be at least rank 3. axis = -3 is denoted by “C”, or channels.
“alpha”/”beta” parameter can be a vector of length C.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[f(x_i) = \alpha_i \text{log}(1 + e^{\beta_i x_i}) \;,\;i=1,...,C\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationParametricSoftplus</span> <span class="p">{</span>

    <span class="c1">// If length is 1, same value is used for all channels</span>
    <span class="n">WeightParams</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">//parameter of length C or 1</span>
    <span class="n">WeightParams</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="c1">//parameter of length C or 1</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="activationparams">
<h3>ActivationParams<a class="headerlink" href="#activationparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ActivationParams</span> <span class="p">{</span>

    <span class="k">oneof</span> <span class="n">NonlinearityType</span> <span class="p">{</span>
        <span class="n">ActivationLinear</span> <span class="na">linear</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

        <span class="n">ActivationReLU</span> <span class="na">ReLU</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="n">ActivationLeakyReLU</span> <span class="na">leakyReLU</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>
        <span class="n">ActivationThresholdedReLU</span> <span class="na">thresholdedReLU</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
        <span class="n">ActivationPReLU</span> <span class="na">PReLU</span> <span class="o">=</span> <span class="mi">25</span><span class="p">;</span>

        <span class="n">ActivationTanh</span> <span class="na">tanh</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
        <span class="n">ActivationScaledTanh</span> <span class="na">scaledTanh</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>

        <span class="n">ActivationSigmoid</span> <span class="na">sigmoid</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>
        <span class="n">ActivationSigmoidHard</span> <span class="na">sigmoidHard</span> <span class="o">=</span> <span class="mi">41</span><span class="p">;</span>

        <span class="n">ActivationELU</span> <span class="na">ELU</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>

        <span class="n">ActivationSoftsign</span> <span class="na">softsign</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>
        <span class="n">ActivationSoftplus</span> <span class="na">softplus</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span>
        <span class="n">ActivationParametricSoftplus</span> <span class="na">parametricSoftplus</span> <span class="o">=</span> <span class="mi">71</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="tensor">
<h3>Tensor<a class="headerlink" href="#tensor" title="Permalink to this headline">¶</a></h3>
<p>Representation of the intermediate tensors</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">Tensor</span> <span class="p">{</span>

    <span class="c1">// Number of dimensions in the tensor shape</span>
    <span class="kt">uint32</span> <span class="na">rank</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="c1">// actual value of the tensor shape.</span>
    <span class="c1">// must be of length &quot;rank&quot;. Can contain -1s for unknown dimensions.</span>
    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">dimValue</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworklayer">
<h3>NeuralNetworkLayer<a class="headerlink" href="#neuralnetworklayer" title="Permalink to this headline">¶</a></h3>
<p>A single neural network layer.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkLayer</span> <span class="p">{</span>

    <span class="kt">string</span> <span class="na">name</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">//descriptive name of the layer</span>
    <span class="k">repeated</span> <span class="kt">string</span> <span class="na">input</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">string</span> <span class="na">output</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="n">Tensor</span> <span class="na">inputTensor</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// must be the same length as the &quot;input&quot; field</span>
    <span class="k">repeated</span> <span class="n">Tensor</span> <span class="na">outputTensor</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="c1">// must be the same length as the &quot;output&quot; field</span>

    <span class="c1">// Must be set to true to mark the layer as updatable.</span>
    <span class="c1">// If true, the weightParams in the layer&#39;s properties must also be set to updatable</span>
    <span class="c1">// If false, the value of the isUpdatable parameter within the layer&#39;s weights are ignored</span>
    <span class="kt">bool</span> <span class="na">isUpdatable</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="k">oneof</span> <span class="n">layer</span> <span class="p">{</span>

        <span class="c1">// Start at 100 here</span>
        <span class="n">ConvolutionLayerParams</span> <span class="na">convolution</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

        <span class="n">PoolingLayerParams</span> <span class="na">pooling</span> <span class="o">=</span> <span class="mi">120</span><span class="p">;</span>

        <span class="n">ActivationParams</span> <span class="na">activation</span> <span class="o">=</span> <span class="mi">130</span><span class="p">;</span>

        <span class="n">InnerProductLayerParams</span> <span class="na">innerProduct</span> <span class="o">=</span> <span class="mi">140</span><span class="p">;</span>
        <span class="n">EmbeddingLayerParams</span> <span class="na">embedding</span> <span class="o">=</span> <span class="mi">150</span><span class="p">;</span>

        <span class="c1">// Normalization-related Layers</span>
        <span class="n">BatchnormLayerParams</span> <span class="na">batchnorm</span> <span class="o">=</span> <span class="mi">160</span><span class="p">;</span>
        <span class="n">MeanVarianceNormalizeLayerParams</span> <span class="na">mvn</span> <span class="o">=</span> <span class="mi">165</span><span class="p">;</span>
        <span class="n">L2NormalizeLayerParams</span> <span class="na">l2normalize</span> <span class="o">=</span> <span class="mi">170</span><span class="p">;</span>
        <span class="n">SoftmaxLayerParams</span> <span class="na">softmax</span> <span class="o">=</span> <span class="mi">175</span><span class="p">;</span>
        <span class="n">LRNLayerParams</span> <span class="na">lrn</span> <span class="o">=</span> <span class="mi">180</span><span class="p">;</span>

        <span class="n">CropLayerParams</span> <span class="na">crop</span> <span class="o">=</span> <span class="mi">190</span><span class="p">;</span>
        <span class="n">PaddingLayerParams</span> <span class="na">padding</span> <span class="o">=</span> <span class="mi">200</span><span class="p">;</span>
        <span class="n">UpsampleLayerParams</span> <span class="na">upsample</span> <span class="o">=</span> <span class="mi">210</span><span class="p">;</span>

        <span class="n">ResizeBilinearLayerParams</span> <span class="na">resizeBilinear</span> <span class="o">=</span> <span class="mi">211</span><span class="p">;</span>
        <span class="n">CropResizeLayerParams</span> <span class="na">cropResize</span> <span class="o">=</span> <span class="mi">212</span><span class="p">;</span>

        <span class="n">UnaryFunctionLayerParams</span> <span class="na">unary</span> <span class="o">=</span> <span class="mi">220</span><span class="p">;</span>

        <span class="c1">// Element-wise Operations</span>
        <span class="n">AddLayerParams</span> <span class="na">add</span> <span class="o">=</span> <span class="mi">230</span><span class="p">;</span>
        <span class="n">MultiplyLayerParams</span> <span class="na">multiply</span> <span class="o">=</span> <span class="mi">231</span><span class="p">;</span>

        <span class="n">AverageLayerParams</span> <span class="na">average</span> <span class="o">=</span> <span class="mi">240</span><span class="p">;</span>
        <span class="n">ScaleLayerParams</span> <span class="na">scale</span> <span class="o">=</span> <span class="mi">245</span><span class="p">;</span>

        <span class="n">BiasLayerParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">250</span><span class="p">;</span>
        <span class="n">MaxLayerParams</span> <span class="k">max</span> <span class="o">=</span> <span class="mi">260</span><span class="p">;</span>
        <span class="n">MinLayerParams</span> <span class="na">min</span> <span class="o">=</span> <span class="mi">261</span><span class="p">;</span>

        <span class="n">DotProductLayerParams</span> <span class="na">dot</span> <span class="o">=</span> <span class="mi">270</span><span class="p">;</span>
        <span class="n">ReduceLayerParams</span> <span class="na">reduce</span> <span class="o">=</span> <span class="mi">280</span><span class="p">;</span>
        <span class="n">LoadConstantLayerParams</span> <span class="na">loadConstant</span> <span class="o">=</span> <span class="mi">290</span><span class="p">;</span>

        <span class="c1">// Data Reorganization</span>
        <span class="n">ReshapeLayerParams</span> <span class="na">reshape</span> <span class="o">=</span> <span class="mi">300</span><span class="p">;</span>
        <span class="n">FlattenLayerParams</span> <span class="na">flatten</span> <span class="o">=</span> <span class="mi">301</span><span class="p">;</span>
        <span class="n">PermuteLayerParams</span> <span class="na">permute</span> <span class="o">=</span> <span class="mi">310</span><span class="p">;</span>
        <span class="n">ConcatLayerParams</span> <span class="na">concat</span> <span class="o">=</span> <span class="mi">320</span><span class="p">;</span>
        <span class="n">SplitLayerParams</span> <span class="na">split</span> <span class="o">=</span> <span class="mi">330</span><span class="p">;</span>
        <span class="n">SequenceRepeatLayerParams</span> <span class="na">sequenceRepeat</span> <span class="o">=</span> <span class="mi">340</span><span class="p">;</span>

        <span class="n">ReorganizeDataLayerParams</span> <span class="na">reorganizeData</span> <span class="o">=</span> <span class="mi">345</span><span class="p">;</span>
        <span class="n">SliceLayerParams</span> <span class="na">slice</span> <span class="o">=</span> <span class="mi">350</span><span class="p">;</span>

        <span class="c1">// Recurrent Layers</span>
        <span class="n">SimpleRecurrentLayerParams</span> <span class="na">simpleRecurrent</span> <span class="o">=</span> <span class="mi">400</span><span class="p">;</span>
        <span class="n">GRULayerParams</span> <span class="na">gru</span> <span class="o">=</span> <span class="mi">410</span><span class="p">;</span>
        <span class="n">UniDirectionalLSTMLayerParams</span> <span class="na">uniDirectionalLSTM</span> <span class="o">=</span> <span class="mi">420</span><span class="p">;</span>
        <span class="n">BiDirectionalLSTMLayerParams</span> <span class="na">biDirectionalLSTM</span> <span class="o">=</span> <span class="mi">430</span><span class="p">;</span>

        <span class="c1">// Custom (user-implemented) Layer</span>
        <span class="n">CustomLayerParams</span> <span class="na">custom</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span>

        <span class="c1">// Following layers are available only after Core ML Specification</span>
        <span class="c1">// version &gt;= 4 (iOS &gt;= 13, macOS &gt;= 10.15)</span>

        <span class="c1">// Control Flow related Layers</span>
        <span class="n">CopyLayerParams</span> <span class="na">copy</span> <span class="o">=</span> <span class="mi">600</span><span class="p">;</span>
        <span class="n">BranchLayerParams</span> <span class="na">branch</span> <span class="o">=</span> <span class="mi">605</span><span class="p">;</span>

        <span class="n">LoopLayerParams</span> <span class="na">loop</span> <span class="o">=</span> <span class="mi">615</span><span class="p">;</span>
        <span class="n">LoopBreakLayerParams</span> <span class="na">loopBreak</span> <span class="o">=</span> <span class="mi">620</span><span class="p">;</span>
        <span class="n">LoopContinueLayerParams</span> <span class="na">loopContinue</span> <span class="o">=</span> <span class="mi">625</span><span class="p">;</span>

        <span class="n">RangeStaticLayerParams</span> <span class="na">rangeStatic</span> <span class="o">=</span> <span class="mi">635</span><span class="p">;</span>
        <span class="n">RangeDynamicLayerParams</span> <span class="na">rangeDynamic</span> <span class="o">=</span> <span class="mi">640</span><span class="p">;</span>

        <span class="c1">// Element-wise Unary Layers</span>
        <span class="n">ClipLayerParams</span> <span class="na">clip</span> <span class="o">=</span> <span class="mi">660</span><span class="p">;</span>
        <span class="n">CeilLayerParams</span> <span class="na">ceil</span> <span class="o">=</span> <span class="mi">665</span><span class="p">;</span>
        <span class="n">FloorLayerParams</span> <span class="na">floor</span> <span class="o">=</span> <span class="mi">670</span><span class="p">;</span>

        <span class="n">SignLayerParams</span> <span class="na">sign</span> <span class="o">=</span> <span class="mi">680</span><span class="p">;</span>
        <span class="n">RoundLayerParams</span> <span class="na">round</span> <span class="o">=</span> <span class="mi">685</span><span class="p">;</span>

        <span class="n">Exp2LayerParams</span> <span class="na">exp2</span> <span class="o">=</span> <span class="mi">700</span><span class="p">;</span>

        <span class="n">SinLayerParams</span> <span class="na">sin</span> <span class="o">=</span> <span class="mi">710</span><span class="p">;</span>
        <span class="n">CosLayerParams</span> <span class="na">cos</span> <span class="o">=</span> <span class="mi">715</span><span class="p">;</span>
        <span class="n">TanLayerParams</span> <span class="na">tan</span> <span class="o">=</span> <span class="mi">720</span><span class="p">;</span>

        <span class="n">AsinLayerParams</span> <span class="na">asin</span> <span class="o">=</span> <span class="mi">730</span><span class="p">;</span>
        <span class="n">AcosLayerParams</span> <span class="na">acos</span> <span class="o">=</span> <span class="mi">735</span><span class="p">;</span>
        <span class="n">AtanLayerParams</span> <span class="na">atan</span> <span class="o">=</span> <span class="mi">740</span><span class="p">;</span>

        <span class="n">SinhLayerParams</span> <span class="na">sinh</span> <span class="o">=</span> <span class="mi">750</span><span class="p">;</span>
        <span class="n">CoshLayerParams</span> <span class="na">cosh</span> <span class="o">=</span> <span class="mi">755</span><span class="p">;</span>
        <span class="n">TanhLayerParams</span> <span class="na">tanh</span> <span class="o">=</span> <span class="mi">760</span><span class="p">;</span>

        <span class="n">AsinhLayerParams</span> <span class="na">asinh</span> <span class="o">=</span> <span class="mi">770</span><span class="p">;</span>
        <span class="n">AcoshLayerParams</span> <span class="na">acosh</span> <span class="o">=</span> <span class="mi">775</span><span class="p">;</span>
        <span class="n">AtanhLayerParams</span> <span class="na">atanh</span> <span class="o">=</span> <span class="mi">780</span><span class="p">;</span>

        <span class="n">ErfLayerParams</span> <span class="na">erf</span> <span class="o">=</span> <span class="mi">790</span><span class="p">;</span>
        <span class="n">GeluLayerParams</span> <span class="na">gelu</span> <span class="o">=</span> <span class="mi">795</span><span class="p">;</span>

        <span class="c1">// Element-wise Binary with Broadcasting Support</span>
        <span class="n">EqualLayerParams</span> <span class="na">equal</span> <span class="o">=</span> <span class="mi">815</span><span class="p">;</span>
        <span class="n">NotEqualLayerParams</span> <span class="na">notEqual</span> <span class="o">=</span> <span class="mi">820</span><span class="p">;</span>
        <span class="n">LessThanLayerParams</span> <span class="na">lessThan</span> <span class="o">=</span> <span class="mi">825</span><span class="p">;</span>
        <span class="n">LessEqualLayerParams</span> <span class="na">lessEqual</span> <span class="o">=</span> <span class="mi">827</span><span class="p">;</span>
        <span class="n">GreaterThanLayerParams</span> <span class="na">greaterThan</span> <span class="o">=</span> <span class="mi">830</span><span class="p">;</span>
        <span class="n">GreaterEqualLayerParams</span> <span class="na">greaterEqual</span> <span class="o">=</span> <span class="mi">832</span><span class="p">;</span>

        <span class="n">LogicalOrLayerParams</span> <span class="na">logicalOr</span> <span class="o">=</span> <span class="mi">840</span><span class="p">;</span>
        <span class="n">LogicalXorLayerParams</span> <span class="na">logicalXor</span> <span class="o">=</span> <span class="mi">845</span><span class="p">;</span>
        <span class="n">LogicalNotLayerParams</span> <span class="na">logicalNot</span> <span class="o">=</span> <span class="mi">850</span><span class="p">;</span>
        <span class="n">LogicalAndLayerParams</span> <span class="na">logicalAnd</span> <span class="o">=</span> <span class="mi">855</span><span class="p">;</span>

        <span class="n">ModBroadcastableLayerParams</span> <span class="na">modBroadcastable</span> <span class="o">=</span> <span class="mi">865</span><span class="p">;</span>
        <span class="n">MinBroadcastableLayerParams</span> <span class="na">minBroadcastable</span> <span class="o">=</span> <span class="mi">870</span><span class="p">;</span>
        <span class="n">MaxBroadcastableLayerParams</span> <span class="na">maxBroadcastable</span> <span class="o">=</span> <span class="mi">875</span><span class="p">;</span>
        <span class="n">AddBroadcastableLayerParams</span> <span class="na">addBroadcastable</span> <span class="o">=</span> <span class="mi">880</span><span class="p">;</span>
        <span class="n">PowBroadcastableLayerParams</span> <span class="na">powBroadcastable</span> <span class="o">=</span> <span class="mi">885</span><span class="p">;</span>
        <span class="n">DivideBroadcastableLayerParams</span> <span class="na">divideBroadcastable</span> <span class="o">=</span> <span class="mi">890</span><span class="p">;</span>
        <span class="n">FloorDivBroadcastableLayerParams</span> <span class="na">floorDivBroadcastable</span> <span class="o">=</span> <span class="mi">895</span><span class="p">;</span>
        <span class="n">MultiplyBroadcastableLayerParams</span> <span class="na">multiplyBroadcastable</span> <span class="o">=</span> <span class="mi">900</span><span class="p">;</span>
        <span class="n">SubtractBroadcastableLayerParams</span> <span class="na">subtractBroadcastable</span> <span class="o">=</span> <span class="mi">905</span><span class="p">;</span>

        <span class="c1">// Tensor Manipulations</span>
        <span class="n">TileLayerParams</span> <span class="na">tile</span> <span class="o">=</span> <span class="mi">920</span><span class="p">;</span>
        <span class="n">StackLayerParams</span> <span class="na">stack</span> <span class="o">=</span> <span class="mi">925</span><span class="p">;</span>
        <span class="n">GatherLayerParams</span> <span class="na">gather</span> <span class="o">=</span> <span class="mi">930</span><span class="p">;</span>
        <span class="n">ScatterLayerParams</span> <span class="na">scatter</span> <span class="o">=</span> <span class="mi">935</span><span class="p">;</span>
        <span class="n">GatherNDLayerParams</span> <span class="na">gatherND</span> <span class="o">=</span> <span class="mi">940</span><span class="p">;</span>
        <span class="n">ScatterNDLayerParams</span> <span class="na">scatterND</span> <span class="o">=</span> <span class="mi">945</span><span class="p">;</span>
        <span class="n">SoftmaxNDLayerParams</span> <span class="na">softmaxND</span> <span class="o">=</span> <span class="mi">950</span><span class="p">;</span>
        <span class="n">GatherAlongAxisLayerParams</span> <span class="na">gatherAlongAxis</span> <span class="o">=</span> <span class="mi">952</span><span class="p">;</span>
        <span class="n">ScatterAlongAxisLayerParams</span> <span class="na">scatterAlongAxis</span> <span class="o">=</span> <span class="mi">954</span><span class="p">;</span>

        <span class="n">ReverseLayerParams</span> <span class="na">reverse</span> <span class="o">=</span> <span class="mi">960</span><span class="p">;</span>
        <span class="n">ReverseSeqLayerParams</span> <span class="na">reverseSeq</span> <span class="o">=</span> <span class="mi">965</span><span class="p">;</span>

        <span class="n">SplitNDLayerParams</span> <span class="na">splitND</span> <span class="o">=</span> <span class="mi">975</span><span class="p">;</span>
        <span class="n">ConcatNDLayerParams</span> <span class="na">concatND</span> <span class="o">=</span> <span class="mi">980</span><span class="p">;</span>
        <span class="n">TransposeLayerParams</span> <span class="na">transpose</span> <span class="o">=</span> <span class="mi">985</span><span class="p">;</span>

        <span class="n">SliceStaticLayerParams</span> <span class="na">sliceStatic</span> <span class="o">=</span> <span class="mi">995</span><span class="p">;</span>
        <span class="n">SliceDynamicLayerParams</span> <span class="na">sliceDynamic</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
        <span class="n">SlidingWindowsLayerParams</span> <span class="na">slidingWindows</span> <span class="o">=</span> <span class="mi">1005</span><span class="p">;</span>

        <span class="n">TopKLayerParams</span> <span class="na">topK</span> <span class="o">=</span> <span class="mi">1015</span><span class="p">;</span>
        <span class="n">ArgMinLayerParams</span> <span class="na">argMin</span> <span class="o">=</span> <span class="mi">1020</span><span class="p">;</span>
        <span class="n">ArgMaxLayerParams</span> <span class="na">argMax</span> <span class="o">=</span> <span class="mi">1025</span><span class="p">;</span>

        <span class="n">EmbeddingNDLayerParams</span> <span class="na">embeddingND</span> <span class="o">=</span> <span class="mi">1040</span><span class="p">;</span>
        <span class="n">BatchedMatMulLayerParams</span> <span class="na">batchedMatmul</span> <span class="o">=</span> <span class="mi">1045</span><span class="p">;</span>

        <span class="c1">// Tensor Allocation / Reshape-related Operations</span>
        <span class="n">GetShapeLayerParams</span> <span class="na">getShape</span> <span class="o">=</span> <span class="mi">1065</span><span class="p">;</span>
        <span class="n">LoadConstantNDLayerParams</span> <span class="na">loadConstantND</span> <span class="o">=</span> <span class="mi">1070</span><span class="p">;</span>

        <span class="n">FillLikeLayerParams</span> <span class="na">fillLike</span> <span class="o">=</span> <span class="mi">1080</span><span class="p">;</span>
        <span class="n">FillStaticLayerParams</span> <span class="na">fillStatic</span> <span class="o">=</span> <span class="mi">1085</span><span class="p">;</span>
        <span class="n">FillDynamicLayerParams</span> <span class="na">fillDynamic</span> <span class="o">=</span> <span class="mi">1090</span><span class="p">;</span>

        <span class="n">BroadcastToLikeLayerParams</span> <span class="na">broadcastToLike</span> <span class="o">=</span> <span class="mi">1100</span><span class="p">;</span>
        <span class="n">BroadcastToStaticLayerParams</span> <span class="na">broadcastToStatic</span> <span class="o">=</span> <span class="mi">1105</span><span class="p">;</span>
        <span class="n">BroadcastToDynamicLayerParams</span> <span class="na">broadcastToDynamic</span> <span class="o">=</span> <span class="mi">1110</span><span class="p">;</span>

        <span class="n">SqueezeLayerParams</span> <span class="na">squeeze</span> <span class="o">=</span> <span class="mi">1120</span><span class="p">;</span>
        <span class="n">ExpandDimsLayerParams</span> <span class="na">expandDims</span> <span class="o">=</span> <span class="mi">1125</span><span class="p">;</span>
        <span class="n">FlattenTo2DLayerParams</span> <span class="na">flattenTo2D</span> <span class="o">=</span> <span class="mi">1130</span><span class="p">;</span>
        <span class="n">ReshapeLikeLayerParams</span> <span class="na">reshapeLike</span> <span class="o">=</span> <span class="mi">1135</span><span class="p">;</span>
        <span class="n">ReshapeStaticLayerParams</span> <span class="na">reshapeStatic</span> <span class="o">=</span> <span class="mi">1140</span><span class="p">;</span>
        <span class="n">ReshapeDynamicLayerParams</span> <span class="na">reshapeDynamic</span> <span class="o">=</span> <span class="mi">1145</span><span class="p">;</span>
        <span class="n">RankPreservingReshapeLayerParams</span> <span class="na">rankPreservingReshape</span> <span class="o">=</span> <span class="mi">1150</span><span class="p">;</span>

        <span class="n">ConstantPaddingLayerParams</span> <span class="na">constantPad</span> <span class="o">=</span> <span class="mi">1155</span><span class="p">;</span>

        <span class="c1">// Random Distributions</span>
        <span class="n">RandomNormalLikeLayerParams</span> <span class="na">randomNormalLike</span> <span class="o">=</span> <span class="mi">1170</span><span class="p">;</span>
        <span class="n">RandomNormalStaticLayerParams</span> <span class="na">randomNormalStatic</span> <span class="o">=</span> <span class="mi">1175</span><span class="p">;</span>
        <span class="n">RandomNormalDynamicLayerParams</span> <span class="na">randomNormalDynamic</span> <span class="o">=</span> <span class="mi">1180</span><span class="p">;</span>

        <span class="n">RandomUniformLikeLayerParams</span> <span class="na">randomUniformLike</span> <span class="o">=</span> <span class="mi">1190</span><span class="p">;</span>
        <span class="n">RandomUniformStaticLayerParams</span> <span class="na">randomUniformStatic</span> <span class="o">=</span> <span class="mi">1195</span><span class="p">;</span>
        <span class="n">RandomUniformDynamicLayerParams</span> <span class="na">randomUniformDynamic</span> <span class="o">=</span> <span class="mi">1200</span><span class="p">;</span>

        <span class="n">RandomBernoulliLikeLayerParams</span> <span class="na">randomBernoulliLike</span> <span class="o">=</span> <span class="mi">1210</span><span class="p">;</span>
        <span class="n">RandomBernoulliStaticLayerParams</span> <span class="na">randomBernoulliStatic</span> <span class="o">=</span> <span class="mi">1215</span><span class="p">;</span>
        <span class="n">RandomBernoulliDynamicLayerParams</span> <span class="na">randomBernoulliDynamic</span> <span class="o">=</span> <span class="mi">1220</span><span class="p">;</span>

        <span class="n">CategoricalDistributionLayerParams</span> <span class="na">categoricalDistribution</span> <span class="o">=</span> <span class="mi">1230</span><span class="p">;</span>

        <span class="c1">// Reduction-related Layers:</span>
        <span class="n">ReduceL1LayerParams</span> <span class="na">reduceL1</span> <span class="o">=</span> <span class="mi">1250</span><span class="p">;</span>
        <span class="n">ReduceL2LayerParams</span> <span class="na">reduceL2</span> <span class="o">=</span> <span class="mi">1255</span><span class="p">;</span>
        <span class="n">ReduceMaxLayerParams</span> <span class="na">reduceMax</span> <span class="o">=</span> <span class="mi">1260</span><span class="p">;</span>
        <span class="n">ReduceMinLayerParams</span> <span class="na">reduceMin</span> <span class="o">=</span> <span class="mi">1265</span><span class="p">;</span>
        <span class="n">ReduceSumLayerParams</span> <span class="na">reduceSum</span> <span class="o">=</span> <span class="mi">1270</span><span class="p">;</span>
        <span class="n">ReduceProdLayerParams</span> <span class="na">reduceProd</span> <span class="o">=</span> <span class="mi">1275</span><span class="p">;</span>
        <span class="n">ReduceMeanLayerParams</span> <span class="na">reduceMean</span> <span class="o">=</span> <span class="mi">1280</span><span class="p">;</span>
        <span class="n">ReduceLogSumLayerParams</span> <span class="na">reduceLogSum</span> <span class="o">=</span> <span class="mi">1285</span><span class="p">;</span>
        <span class="n">ReduceSumSquareLayerParams</span> <span class="na">reduceSumSquare</span> <span class="o">=</span> <span class="mi">1290</span><span class="p">;</span>
        <span class="n">ReduceLogSumExpLayerParams</span> <span class="na">reduceLogSumExp</span> <span class="o">=</span> <span class="mi">1295</span><span class="p">;</span>

        <span class="c1">// Masking / Selection Layers</span>
        <span class="n">WhereNonZeroLayerParams</span> <span class="na">whereNonZero</span> <span class="o">=</span> <span class="mi">1313</span><span class="p">;</span>
        <span class="n">MatrixBandPartLayerParams</span> <span class="na">matrixBandPart</span> <span class="o">=</span> <span class="mi">1315</span><span class="p">;</span>
        <span class="n">LowerTriangularLayerParams</span> <span class="na">lowerTriangular</span> <span class="o">=</span> <span class="mi">1320</span><span class="p">;</span>
        <span class="n">UpperTriangularLayerParams</span> <span class="na">upperTriangular</span> <span class="o">=</span> <span class="mi">1325</span><span class="p">;</span>
        <span class="n">WhereBroadcastableLayerParams</span> <span class="na">whereBroadcastable</span> <span class="o">=</span> <span class="mi">1330</span><span class="p">;</span>

        <span class="c1">// Normalization Layers</span>
        <span class="n">LayerNormalizationLayerParams</span> <span class="na">layerNormalization</span> <span class="o">=</span> <span class="mi">1350</span><span class="p">;</span>

        <span class="n">NonMaximumSuppressionLayerParams</span> <span class="na">NonMaximumSuppression</span> <span class="o">=</span> <span class="mi">1400</span><span class="p">;</span>

        <span class="c1">// Following layers are available only after Core ML Specification</span>
        <span class="c1">// version &gt;= 5 (iOS &gt;= 14, macOS &gt;= 10.16)</span>
        <span class="n">OneHotLayerParams</span> <span class="na">oneHot</span> <span class="o">=</span> <span class="mi">1450</span><span class="p">;</span>
        <span class="n">CumSumLayerParams</span> <span class="na">cumSum</span> <span class="o">=</span> <span class="mi">1455</span><span class="p">;</span>
        <span class="n">ClampedReLULayerParams</span> <span class="na">clampedReLU</span> <span class="o">=</span> <span class="mi">1460</span><span class="p">;</span>
        <span class="n">ArgSortLayerParams</span> <span class="na">argSort</span> <span class="o">=</span> <span class="mi">1461</span><span class="p">;</span>
        <span class="n">Pooling3DLayerParams</span> <span class="na">pooling3d</span> <span class="o">=</span> <span class="mi">1465</span><span class="p">;</span>
        <span class="n">GlobalPooling3DLayerParams</span> <span class="na">globalPooling3d</span> <span class="o">=</span> <span class="mi">1466</span><span class="p">;</span>
        <span class="n">SliceBySizeLayerParams</span> <span class="na">sliceBySize</span> <span class="o">=</span> <span class="mi">1470</span><span class="p">;</span>
        <span class="n">Convolution3DLayerParams</span> <span class="na">convolution3d</span> <span class="o">=</span> <span class="mi">1471</span><span class="p">;</span>

    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="branchlayerparams">
<h3>BranchLayerParams<a class="headerlink" href="#branchlayerparams" title="Permalink to this headline">¶</a></h3>
<p>Branching Layer</p>
<p>A layer that provides the functionality of branching or an If-Else block.</p>
<p>Must have 1 input. There are no outputs as the execution is transferred to either the
if or the else branch based on the value of the input.</p>
<p>Input is the condition predicate. Must be a scalar (length 1 tensor).</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BranchLayerParams</span> <span class="p">{</span>

    <span class="n">NeuralNetwork</span> <span class="na">ifBranch</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">NeuralNetwork</span> <span class="na">elseBranch</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="looplayerparams">
<h3>LoopLayerParams<a class="headerlink" href="#looplayerparams" title="Permalink to this headline">¶</a></h3>
<p>Loop Layer</p>
<p>A layer that provides the functionality of a “for” loop or a “while” loop.</p>
<p>There are either no inputs or 1 input. When an input is present, it corresponds
to the maximum loop count, in that case the value of the “maxLoopIterations”
field is ignored. Input must be a scalar. (For description below,
maxLoopIterations is assumed to be the value of the input, when its present)</p>
<p>No outputs are produced. Blobs produced by the condition or the body network are
visible in the scope of the overall network.</p>
<p>“conditionNetwork” must produce a tensor with the name specified in the
“conditionVar” field.</p>
<p>There are 3 possible cases for determining the termination condition:</p>
<p>Case 1:</p>
<p>If there is no “conditionNetwork”, in this case the layer corresponds to a pure
for loop, which is run “maxLoopIterations” number of times.</p>
<p>Equivalent pseudo-code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">loopIterator</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">maxLoopIterations</span>
         <span class="n">bodyNetwork</span><span class="p">()</span>
</pre></div>
</div>
<p>Case 2:</p>
<p>“conditionNetwork” is present, and “maxLoopIterations” is 0 and there is no input,
in this case the layer corresponds to a while loop. Equivalent pseudo-code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conditionVar</span> <span class="o">=</span> <span class="n">conditionNetwork</span><span class="p">()</span>
<span class="k">while</span> <span class="n">conditionVar</span><span class="p">:</span>
         <span class="n">bodyNetwork</span><span class="p">()</span>
         <span class="n">conditionVar</span> <span class="o">=</span> <span class="n">conditionNetwork</span><span class="p">()</span>
</pre></div>
</div>
<p>Case 3:</p>
<p>“conditionNetwork” is provided, and “maxLoopIterations” is positive or there is
an input, in this case the layer corresponds to a while loop with a joint
condition. Equivalent pseudo-code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loopIterator</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">conditionVar</span> <span class="o">=</span> <span class="n">conditionNetwork</span><span class="p">()</span>
<span class="k">while</span> <span class="p">(</span><span class="n">conditionVar</span> <span class="ow">and</span> <span class="n">loopIterator</span> <span class="o">&lt;</span> <span class="n">maxLoopIterations</span><span class="p">):</span>
         <span class="n">bodyNetwork</span><span class="p">()</span>
         <span class="n">loopIterator</span> <span class="o">=</span> <span class="n">loopIterator</span> <span class="o">+</span> <span class="mi">1</span>
         <span class="n">conditionVar</span> <span class="o">=</span> <span class="n">conditionNetwork</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LoopLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">maxLoopIterations</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">string</span> <span class="na">conditionVar</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">NeuralNetwork</span> <span class="na">conditionNetwork</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">NeuralNetwork</span> <span class="na">bodyNetwork</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loopbreaklayerparams">
<h3>LoopBreakLayerParams<a class="headerlink" href="#loopbreaklayerparams" title="Permalink to this headline">¶</a></h3>
<p>Loop break Layer</p>
<p>Terminate the loop that has this layer.
If present, it should always reside in the “bodyNetwork” of the loop layer</p>
<p>No inputs/outputs</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LoopBreakLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loopcontinuelayerparams">
<h3>LoopContinueLayerParams<a class="headerlink" href="#loopcontinuelayerparams" title="Permalink to this headline">¶</a></h3>
<p>Loop Continue Layer</p>
<p>Stop the current loop iteration and continue on the next iteration.
If present, it should always reside in the “bodyNetwork” of the loop layer</p>
<p>No inputs/outputs</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LoopContinueLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="copylayerparams">
<h3>CopyLayerParams<a class="headerlink" href="#copylayerparams" title="Permalink to this headline">¶</a></h3>
<p>Copy Layer</p>
<p>A layer that copies its input tensor to the output tensor.
Must have 1 input and 1 output, with distinct names.
This is the only layer that is allowed to re-generate an output that is already present in the neural network prior to this layer,
in which case it will overwrite the output tensor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CopyLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="greaterthanlayerparams">
<h3>GreaterThanLayerParams<a class="headerlink" href="#greaterthanlayerparams" title="Permalink to this headline">¶</a></h3>
<p>GreaterThan Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise greater than operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&gt;</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&gt;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GreaterThanLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="greaterequallayerparams">
<h3>GreaterEqualLayerParams<a class="headerlink" href="#greaterequallayerparams" title="Permalink to this headline">¶</a></h3>
<p>GreaterEqual Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise greater equal operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&gt;=</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&gt;=</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GreaterEqualLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lessthanlayerparams">
<h3>LessThanLayerParams<a class="headerlink" href="#lessthanlayerparams" title="Permalink to this headline">¶</a></h3>
<p>LessThan Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise less than operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&lt;</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LessThanLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lessequallayerparams">
<h3>LessEqualLayerParams<a class="headerlink" href="#lessequallayerparams" title="Permalink to this headline">¶</a></h3>
<p>LessEqual Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise less equal operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&lt;=</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">&lt;=</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LessEqualLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="equallayerparams">
<h3>EqualLayerParams<a class="headerlink" href="#equallayerparams" title="Permalink to this headline">¶</a></h3>
<p>Equal Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise equal operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">==</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">==</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">EqualLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="notequallayerparams">
<h3>NotEqualLayerParams<a class="headerlink" href="#notequallayerparams" title="Permalink to this headline">¶</a></h3>
<p>NotEqual Layer</p>
<p>Either 1 or 2 inputs.
Produces 1 output.
Perform elementwise not equal operation.</p>
<p>Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">!=</span> <span class="n">x2</span>
    <span class="ow">or</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">!=</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">if</span> <span class="n">only</span> <span class="n">one</span> <span class="nb">input</span> <span class="ow">is</span> <span class="n">provided</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NotEqualLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="logicalandlayerparams">
<h3>LogicalAndLayerParams<a class="headerlink" href="#logicalandlayerparams" title="Permalink to this headline">¶</a></h3>
<p>LogicalAnd Layer</p>
<p>Must have 2 inputs, produces 1 output.
Perform elementwise logical AND operation.</p>
<p>Input is considered False if equal to 0.0f otherwise True.
Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AND</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LogicalAndLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="logicalorlayerparams">
<h3>LogicalOrLayerParams<a class="headerlink" href="#logicalorlayerparams" title="Permalink to this headline">¶</a></h3>
<p>LogicalOr Layer</p>
<p>Must have 2 inputs, produces 1 output.
Perform elementwise logical OR operation.</p>
<p>Input is considered False if equal to 0.0f otherwise True.
Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">OR</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LogicalOrLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="logicalxorlayerparams">
<h3>LogicalXorLayerParams<a class="headerlink" href="#logicalxorlayerparams" title="Permalink to this headline">¶</a></h3>
<p>LogicalXor Layer</p>
<p>Must have 2 inputs, produces 1 output.
Perform elementwise logical XOR operation.</p>
<p>Input is considered False if equal to 0.0f otherwise True.
Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">XOR</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
<p>Broadcasting is supported.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LogicalXorLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="logicalnotlayerparams">
<h3>LogicalNotLayerParams<a class="headerlink" href="#logicalnotlayerparams" title="Permalink to this headline">¶</a></h3>
<p>LogicalNot Layer</p>
<p>Must have 1 input, produces 1 output.
Perform elementwise logical NOT operation.</p>
<p>Input is considered False if equal to 0.0f otherwise True.
Output is 1.0f if the condition is true otherwise 0.0f.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">NOT</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LogicalNotLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="borderamounts">
<h2>BorderAmounts<a class="headerlink" href="#borderamounts" title="Permalink to this headline">¶</a></h2>
<div class="section" id="borderamounts-edgesizes">
<h3>BorderAmounts.EdgeSizes<a class="headerlink" href="#borderamounts-edgesizes" title="Permalink to this headline">¶</a></h3>
<p>Specifies the amount of spatial border to be either padded or cropped.</p>
<p>For padding:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">+</span> <span class="n">H_in</span> <span class="o">+</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span> <span class="o">+</span> <span class="n">W_in</span> <span class="o">+</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>

<span class="n">topPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">startEdgeSize</span>
<span class="n">bottomPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">endEdgeSize</span>
<span class="n">leftPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">startEdgeSize</span>
<span class="n">rightPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">endEdgeSize</span>
</pre></div>
</div>
<p>For cropping:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span><span class="p">)</span> <span class="o">+</span> <span class="n">H_in</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span><span class="p">)</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span><span class="p">)</span> <span class="o">+</span> <span class="n">W_in</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span><span class="p">)</span>

<span class="n">topCropAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">startEdgeSize</span>
<span class="n">bottomCropAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">endEdgeSize</span>
<span class="n">leftCropAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">startEdgeSize</span>
<span class="n">rightCropAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">endEdgeSize</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BorderAmounts</span> <span class="p">{</span>

    <span class="kd">message</span> <span class="nc">EdgeSizes</span> <span class="p">{</span>
        <span class="kt">uint64</span> <span class="na">startEdgeSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

        <span class="kt">uint64</span> <span class="na">endEdgeSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">repeated</span> <span class="n">EdgeSizes</span> <span class="na">borderAmounts</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">EdgeSizes</span> <span class="p">{</span>
    <span class="kt">uint64</span> <span class="na">startEdgeSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">uint64</span> <span class="na">endEdgeSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="validpadding">
<h3>ValidPadding<a class="headerlink" href="#validpadding" title="Permalink to this headline">¶</a></h3>
<p>Specifies the type of padding to be used with Convolution/Deconvolution and Pooling layers.
After padding, input spatial shape: <code class="docutils literal notranslate"><span class="pre">[H_in,</span> <span class="pre">W_in]</span></code>, gets modified to the
output spatial shape <code class="docutils literal notranslate"><span class="pre">[H_out,</span> <span class="pre">W_out]</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">bottomPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
<span class="n">leftPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">rightPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
</pre></div>
</div>
<p>With Convolution or Pooling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">int_division_round_down</span><span class="p">((</span><span class="n">H_in</span> <span class="o">+</span> <span class="n">topPaddingAmount</span> <span class="o">+</span> <span class="n">bottomPaddingAmount</span> <span class="o">-</span> <span class="n">KernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
<p>which is same as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">int_division_round_up</span><span class="p">((</span><span class="n">H_in</span> <span class="o">+</span> <span class="n">topPaddingAmount</span> <span class="o">+</span> <span class="n">bottomPaddingAmount</span> <span class="o">-</span> <span class="n">KernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>With Deconvolution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">H_in</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">kernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">topPaddingAmount</span> <span class="o">+</span> <span class="n">bottomPaddingAmount</span><span class="p">)</span>
</pre></div>
</div>
<p>The equivalent expressions hold true for <code class="docutils literal notranslate"><span class="pre">W_out</span></code> as well.</p>
<p>By default, the values of <code class="docutils literal notranslate"><span class="pre">paddingAmounts</span></code> are set to <code class="docutils literal notranslate"><span class="pre">0</span></code>,
which results in a “true” valid padding.
If non-zero values are provided for <code class="docutils literal notranslate"><span class="pre">paddingAmounts</span></code>,
“valid” convolution/pooling is performed within the spatially expanded input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ValidPadding</span> <span class="p">{</span>

    <span class="n">BorderAmounts</span> <span class="na">paddingAmounts</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="samepadding">
<h3>SamePadding<a class="headerlink" href="#samepadding" title="Permalink to this headline">¶</a></h3>
<p>Specifies the type of padding to be used with Convolution/Deconvolution and pooling layers.
After padding, input spatial shape: <code class="docutils literal notranslate"><span class="pre">[H_in,</span> <span class="pre">W_in]</span></code>, gets modified to the
output spatial shape <code class="docutils literal notranslate"><span class="pre">[H_out,</span> <span class="pre">W_out]</span></code>.
With Convolution or pooling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">int_division_round_up</span><span class="p">(</span><span class="n">H_in</span><span class="p">,</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">int_division_round_up</span><span class="p">(</span><span class="n">W_in</span><span class="p">,</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>This is achieved by using the following padding amounts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">totalPaddingHeight</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,(</span><span class="n">H_out</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">KernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">Hin</span><span class="p">)</span>
<span class="n">totalPaddingWidth</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,(</span><span class="n">W_out</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">KernelSize</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Win</span><span class="p">)</span>
</pre></div>
</div>
<p>There are two modes of asymmetry:
<code class="docutils literal notranslate"><span class="pre">BOTTOM_RIGHT_HEAVY</span></code>, and <code class="docutils literal notranslate"><span class="pre">TOP_LEFT_HEAVY</span></code>.</p>
<p>If the mode is <code class="docutils literal notranslate"><span class="pre">BOTTOM_RIGHT_HEAVY</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topPaddingAmount</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">totalPaddingHeight</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">bottomPaddingAmount</span> <span class="o">=</span> <span class="n">totalPaddingHeight</span> <span class="o">-</span> <span class="n">topPaddingAmount</span>
<span class="n">leftPaddingAmount</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">totalPaddingWidth</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">rightPaddingAmount</span> <span class="o">=</span> <span class="n">totalPaddingWidth</span> <span class="o">-</span> <span class="n">leftPaddingAmount</span>
</pre></div>
</div>
<p>If the mode is <code class="docutils literal notranslate"><span class="pre">TOP_LEFT_HEAVY</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bottomPaddingAmount</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">totalPaddingHeight</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">topPaddingAmount</span> <span class="o">=</span> <span class="n">totalPaddingHeight</span> <span class="o">-</span> <span class="n">bottomPaddingAmount</span>
<span class="n">rightPaddingAmount</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">totalPaddingWidth</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">leftPaddingAmount</span> <span class="o">=</span> <span class="n">totalPaddingWidth</span> <span class="o">-</span> <span class="n">rightPaddingAmount</span>
</pre></div>
</div>
<p>With Deconvolution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">H_in</span> <span class="o">*</span> <span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">W_in</span> <span class="o">*</span> <span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SamePadding</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">SamePaddingMode</span> <span class="p">{</span>

        <span class="na">BOTTOM_RIGHT_HEAVY</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">TOP_LEFT_HEAVY</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">SamePaddingMode</span> <span class="na">asymmetryMode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="samplingmode">
<h3>SamplingMode<a class="headerlink" href="#samplingmode" title="Permalink to this headline">¶</a></h3>
<p>Specifies how grid points are sampled from an interval.
Without the loss of generality, assume the interval to be [0, X-1] from which N points are to be sampled.
Here X may correspond to an input image’s height or width.
All the methods can be expressed in terms of numpy’s linspace function, along with the constraint that grid points have to lie in the interval [0, X-1].
Note: numpy.linspace(start = start, end = end, num = N, endpoint = True) corresponds to sampling
N points uniformly from the interval [start, end], endpoints included.
The methods vary in how the <code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> values are computed.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SamplingMode</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">Method</span> <span class="p">{</span>

        <span class="na">STRICT_ALIGN_ENDPOINTS_MODE</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

        <span class="na">ALIGN_ENDPOINTS_MODE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

        <span class="na">UPSAMPLE_MODE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

        <span class="na">ROI_ALIGN_MODE</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="n">Method</span> <span class="na">samplingMethod</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="boxcoordinatesmode">
<h3>BoxCoordinatesMode<a class="headerlink" href="#boxcoordinatesmode" title="Permalink to this headline">¶</a></h3>
<p>Specifies the convention used to specify four bounding box coordinates for an image of size (Height, Width).
The (0,0) coordinate corresponds to the top-left corner of the image.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BoxCoordinatesMode</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">Coordinates</span> <span class="p">{</span>

        <span class="na">CORNERS_HEIGHT_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

        <span class="na">CORNERS_WIDTH_FIRST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

        <span class="na">CENTER_SIZE_HEIGHT_FIRST</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

        <span class="na">CENTER_SIZE_WIDTH_FIRST</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="n">Coordinates</span> <span class="na">boxMode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="weightparams">
<h3>WeightParams<a class="headerlink" href="#weightparams" title="Permalink to this headline">¶</a></h3>
<p>Weights for layer parameters.
Weights are stored as repeated floating point numbers
using row-major ordering
and can represent 1-, 2-, 3-, or 4-dimensional data.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">WeightParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">float</span> <span class="na">floatValue</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">bytes</span> <span class="na">float16Value</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bytes</span> <span class="na">rawValue</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>

    <span class="kt">bytes</span> <span class="na">int8RawValue</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>

    <span class="n">QuantizationParams</span> <span class="na">quantization</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">isUpdatable</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="quantizationparams">
<h3>QuantizationParams<a class="headerlink" href="#quantizationparams" title="Permalink to this headline">¶</a></h3>
<p>Quantization parameters.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">QuantizationParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">numberOfBits</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">oneof</span> <span class="n">QuantizationType</span> <span class="p">{</span>
        <span class="n">LinearQuantizationParams</span> <span class="na">linearQuantization</span> <span class="o">=</span> <span class="mi">101</span><span class="p">;</span>
        <span class="n">LookUpTableQuantizationParams</span> <span class="na">lookupTableQuantization</span> <span class="o">=</span> <span class="mi">102</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="linearquantizationparams">
<h3>LinearQuantizationParams<a class="headerlink" href="#linearquantizationparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LinearQuantizationParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">float</span> <span class="na">scale</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">float</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lookuptablequantizationparams">
<h3>LookUpTableQuantizationParams<a class="headerlink" href="#lookuptablequantizationparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span>message LookUpTableQuantizationParams {

    (2^numberOfBits) Elements.
    repeated float floatValue = 1;

}
</pre></div>
</div>
</div>
</div>
<div class="section" id="layers">
<h2>Layers<a class="headerlink" href="#layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="convolutionlayerparams">
<h3>ConvolutionLayerParams<a class="headerlink" href="#convolutionlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs spatial convolution or deconvolution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ConvolutionLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 or 2 inputs and produces 1 output.</p>
<dl>
<dt>Input</dt><dd><dl>
<dt>First Input:</dt><dd><blockquote>
<div><p>A blob with rank greater than or equal to 4.
Rank 4 blob represents [Batch, channels, height, width].
For ranks greater than 4, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</div></blockquote>
<p>From Core ML specification version 4 onwards (iOS &gt;= 13, macOS &gt;= 10.15).
convolution layer can have 2 inputs, in which case the second input is
the blob representing the weights. This is allowed when “isDeconvolution”
= False. The weight blob should have shape
<code class="docutils literal notranslate"><span class="pre">[outputChannels,</span> <span class="pre">kernelChannels,</span> <span class="pre">kernelHeight,</span> <span class="pre">kernelWidth]</span></code>,
where kernelChannels == inputChannels / nGroups.</p>
</dd>
</dl>
</dd>
<dt>Output</dt><dd><p>Rank is same as the input. For example: for rank 4 input, output shape is
[B, C_out, H_out, W_out].</p>
</dd>
</dl>
<p>If <code class="docutils literal notranslate"><span class="pre">dilationFactor</span></code> is not 1, effective kernel size is
modified as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">KernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;--</span> <span class="p">(</span><span class="n">kernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dilationFactor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">KernelSize</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;--</span> <span class="p">(</span><span class="n">kernelSize</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dilationFactor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Type of padding can be <code class="docutils literal notranslate"><span class="pre">valid</span></code> or <code class="docutils literal notranslate"><span class="pre">same</span></code>. Output spatial dimensions depend on the
the type of padding. For details, refer to the descriptions of the messages “ValidPadding”
and “SamePadding”. Padded values are all zeros.</p>
<p>For Deconvolution, <code class="docutils literal notranslate"><span class="pre">ConvolutionPaddingType</span></code> (<code class="docutils literal notranslate"><span class="pre">valid</span></code> or <code class="docutils literal notranslate"><span class="pre">same</span></code>) is ignored when <code class="docutils literal notranslate"><span class="pre">outputShape</span></code> is set.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ConvolutionLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">outputChannels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">uint64</span> <span class="na">kernelChannels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">uint64</span> <span class="na">nGroups</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">kernelSize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">stride</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">dilationFactor</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>

    <span class="k">oneof</span> <span class="n">ConvolutionPaddingType</span> <span class="p">{</span>
        <span class="n">ValidPadding</span> <span class="na">valid</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
        <span class="n">SamePadding</span> <span class="na">same</span> <span class="o">=</span> <span class="mi">51</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kt">bool</span> <span class="na">isDeconvolution</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">90</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">91</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">outputShape</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="convolution3dlayerparams">
<h3>Convolution3DLayerParams<a class="headerlink" href="#convolution3dlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs a 3-dimensional convolution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">Convolution3DLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob of rank 5.
The input blob’s shape should be <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">channels,</span> <span class="pre">depth,</span> <span class="pre">height,</span> <span class="pre">width]</span></code>.</p>
</dd>
<dt>Fields</dt><dd><p>The bias field, if set, should have shape of <code class="docutils literal notranslate"><span class="pre">[channelsOut]</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>A blob of rank 5.
The output blob’s shape is <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">channelsOut,</span> <span class="pre">depthOut,</span> <span class="pre">heightOut,</span> <span class="pre">widthOut]</span></code>.</p>
</dd>
</dl>
<p>Type of padding can be <code class="docutils literal notranslate"><span class="pre">custom</span></code>, <code class="docutils literal notranslate"><span class="pre">valid</span></code>, or <code class="docutils literal notranslate"><span class="pre">same</span></code>. Padded values are all zeros.
Output spatial dimensions depend on the the type of padding. For details, refer to the
descriptions of the <code class="docutils literal notranslate"><span class="pre">PaddingType</span></code> field of this <code class="docutils literal notranslate"><span class="pre">Convolution3DLayerParams</span></code> message.</p>
<dl class="simple">
<dt>Example</dt><dd><p>For example, given an input of size <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">3,</span> <span class="pre">3,</span> <span class="pre">8,</span> <span class="pre">8]</span></code>, a stride of 2 in each dimension,
a kernel of 3 in each dimension, 2 output channels, and <code class="docutils literal notranslate"><span class="pre">same</span></code> padding, this layer will
compute the total padding applied in the depth, height, and width dimensions to be 2, 1, and 1,
respectively. The depth padding is even and will be applied equally to both sides of the depth
dimension. Since the height and width padding values are odd, they’ll be applied to the
bottom/right of the height/width dimensions. Thus, the padding applied to the input will be
<code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">1]</span></code> (front, back, top, bottom, left, right). Finally, the output produced
will have size <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">2,</span> <span class="pre">4,</span> <span class="pre">4]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">Convolution3DLayerParams</span> <span class="p">{</span>

    <span class="kt">int32</span> <span class="na">outputChannels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">inputChannels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">nGroups</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">kernelDepth</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">kernelHeight</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">kernelWidth</span> <span class="o">=</span> <span class="mi">22</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">strideDepth</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">strideHeight</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">strideWidth</span> <span class="o">=</span> <span class="mi">33</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">dilationDepth</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">dilationHeight</span> <span class="o">=</span> <span class="mi">41</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">dilationWidth</span> <span class="o">=</span> <span class="mi">42</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">61</span><span class="p">;</span>


    <span class="kd">enum</span> <span class="n">PaddingType</span> <span class="p">{</span>
        <span class="na">CUSTOM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">VALID</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">SAME</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">PaddingType</span> <span class="na">paddingType</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingFront</span> <span class="o">=</span> <span class="mi">80</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingBack</span> <span class="o">=</span> <span class="mi">81</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingTop</span> <span class="o">=</span> <span class="mi">82</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingBottom</span> <span class="o">=</span> <span class="mi">83</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingLeft</span> <span class="o">=</span> <span class="mi">84</span><span class="p">;</span>

    <span class="kt">int32</span> <span class="na">customPaddingRight</span> <span class="o">=</span> <span class="mi">85</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="innerproductlayerparams">
<h3>InnerProductLayerParams<a class="headerlink" href="#innerproductlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs a matrix-vector or matrix-matrix product.
This is equivalent to a fully-connected, or dense layer.
The weight parameters correspond to a matrix of dimensions (inputChannels, outputChannels) i.e. (C_in, C_out)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">InnerProductLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>Input can have rank 1 to rank 5. This is how it is reshaped in to the matrix (for rank &gt; 1):
rank 1 (x1) : in this case, the layer corresponds to a matrix-vector product. x1 must be equal to C_in
rank 2 (x1, x2): x2 must be equal to C_in
rank 3 (x1, x2, x3) –&gt; (x1 * x2, x3). x3 must be equal to C_in
rank 4 (x1, x2, x3, x4) —&gt; (x1, x2 * x3 * x4). x2 * x3 * x4 must be equal to C_in
rank 5 (x1, x2, x3, x4, x5) —&gt; (x1 * x2, x3 * x4 * x5). x3 * x4 * x5 must be equal to C_in</p>
</dd>
<dt>Output</dt><dd><p>Output rank is same as the input rank
rank 1: (C_out)
rank 2: (x1, C_out)
rank 3: (x1, x2, C_out)
rank 4: (x1, C_out, 1, 1)
rank 5: (x1, x2, C_out, 1, 1)</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">InnerProductLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputChannels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputChannels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">int8DynamicQuantize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="embeddinglayerparams">
<h3>EmbeddingLayerParams<a class="headerlink" href="#embeddinglayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs a matrix lookup and optionally adds a bias.
The weights matrix is stored with dimensions [outputChannels, inputDim].</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl>
<dt>Input</dt><dd><p>Input values must be in the range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">inputDim</span> <span class="pre">-</span> <span class="pre">1]</span></code>.</p>
<p>Input must have rank equal to 4 or 5, such that the last 3 dimensions are all 1.
rank 4: shape (x1, 1, 1, 1). x1 is effectively the batch/sequence length.
rank 5: shape (x1, x2 , 1, 1, 1). x1 * x2 is effectively the combined batch/sequence length.</p>
</dd>
<dt>Output</dt><dd><p>Output rank is same as the input rank. Please see input description above.
rank 4: shape (x1, outputChannels, 1, 1)
rank 5: shape (x1, x2, outputChannels, 1, 1)</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">EmbeddingLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputDim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputChannels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="embeddingndlayerparams">
<h3>EmbeddingNDLayerParams<a class="headerlink" href="#embeddingndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs a matrix lookup and optionally adds a bias.
The weights matrix is stored with dimensions [embeddingSize, vocabSize].</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">EmbeddingNDLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>Input values must be in the range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">vocabSize</span> <span class="pre">-</span> <span class="pre">1]</span></code>.
Input must have rank at least 2. The last dimension must always be 1.
rank 2: shape (x1, 1). x1 is the batch/sequence length.
rank 3: shape (x1, x2, 1). x1 * x2 is effectively the combined batch/sequence length.
rank 4: shape (x1, x2, x3, 1). x1 * x2 * x2 is effectively the combined batch/sequence length.
rank 5: shape (x1, x2 , x3, x4, 1). x1 * x2 * x3 * x4 is effectively the combined batch/sequence length.</p>
</dd>
<dt>Output</dt><dd><p>Output rank is same as the input rank. Please see input description above.
rank 2: shape (x1, embeddingSize)
rank 3: shape (x1, x2, embeddingSize)
rank 4: shape (x1, x2, x3, embeddingSize)
rank 5: shape (x1, x2, x3, x4, embeddingSize)</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">EmbeddingNDLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">vocabSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">embeddingSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="batchnormlayerparams">
<h3>BatchnormLayerParams<a class="headerlink" href="#batchnormlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs batch normalization,
which is performed along axis = -3,
and repeated along the other axes, if present.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">BatchnormLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<p>This operation is described by the following formula:</p>
<div class="math notranslate nohighlight">
\[y_i = \gamma_i \dfrac{ (x_i - \mu_i)}{\sqrt{\sigma_i^2 + \epsilon}} + \beta_i \;,\;i=1,....,C\]</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 3.
Example: Rank 4 blob represents [Batch, channels, height, width]
For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BatchnormLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">channels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">computeMeanVar</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">instanceNormalization</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">epsilon</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">gamma</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">mean</span> <span class="o">=</span> <span class="mi">17</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">variance</span> <span class="o">=</span> <span class="mi">18</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="poolinglayerparams">
<h3>PoolingLayerParams<a class="headerlink" href="#poolinglayerparams" title="Permalink to this headline">¶</a></h3>
<p>A spatial pooling layer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">PoolingLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 4.
Rank 4 blob represents [Batch, channels, height, width]
For ranks greater than 4, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Rank is same as the input. For example: for rank 4 input, output shape is
[B, C, H_out, W_out].</p>
</dd>
</dl>
<p>Padding options are similar to <code class="docutils literal notranslate"><span class="pre">ConvolutionLayerParams</span></code>
with the additional option of <code class="docutils literal notranslate"><span class="pre">ValidCompletePadding</span></code> (<code class="docutils literal notranslate"><span class="pre">includeLastPixel</span></code>),
which ensures that the last application of the kernel
always includes the last pixel of the input image, if there is padding.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">H_in</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">paddingAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">kernelSize</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">Stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">1</span>
<span class="k">if</span> <span class="p">(</span><span class="n">paddingAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">paddingAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
     <span class="k">if</span> <span class="p">((</span><span class="n">H_out</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Stride</span> <span class="o">&gt;=</span> <span class="n">H_in</span> <span class="o">+</span> <span class="n">paddingAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="p">{</span>
         <span class="n">H_out</span> <span class="o">=</span> <span class="n">H_out</span> <span class="o">-</span> <span class="mi">1</span>
     <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The equivalent expressions hold true for <code class="docutils literal notranslate"><span class="pre">W_out</span></code> as well.
Only symmetric padding is supported with this option.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PoolingLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">PoolingType</span> <span class="p">{</span>

        <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">L2</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">PoolingType</span> <span class="na">type</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">kernelSize</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">stride</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="kd">message</span> <span class="nc">ValidCompletePadding</span> <span class="p">{</span>

        <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">paddingAmounts</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="k">oneof</span> <span class="n">PoolingPaddingType</span> <span class="p">{</span>
        <span class="n">ValidPadding</span> <span class="na">valid</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
        <span class="n">SamePadding</span> <span class="na">same</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>
        <span class="n">ValidCompletePadding</span> <span class="na">includeLastPixel</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kt">bool</span> <span class="na">avgPoolExcludePadding</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">globalPooling</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="poolinglayerparams-validcompletepadding">
<h3>PoolingLayerParams.ValidCompletePadding<a class="headerlink" href="#poolinglayerparams-validcompletepadding" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ValidCompletePadding</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">paddingAmounts</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="pooling3dlayerparams">
<h3>Pooling3DLayerParams<a class="headerlink" href="#pooling3dlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">Pooling3DLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">PoolingType3D</span> <span class="p">{</span>
        <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Whether to use Max or Average</span>
    <span class="n">PoolingType3D</span> <span class="na">type</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="c1">// Depth of the pooling region.</span>
    <span class="kt">int32</span> <span class="na">kernelDepth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="c1">// Height of the pooling region.</span>
    <span class="kt">int32</span> <span class="na">kernelHeight</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="c1">// Width of the pooling region.</span>
    <span class="kt">int32</span> <span class="na">kernelWidth</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="c1">// Stride along the depth direction</span>
    <span class="kt">int32</span> <span class="na">strideDepth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

    <span class="c1">// Stride along the height direction</span>
    <span class="kt">int32</span> <span class="na">strideHeight</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

    <span class="c1">// Stride along the width direction</span>
    <span class="kt">int32</span> <span class="na">strideWidth</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">Pooling3DPaddingType</span> <span class="p">{</span>
        <span class="na">CUSTOM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">VALID</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">SAME</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Pooling3DPaddingType</span> <span class="na">paddingType</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="c1">// Padding before the input in the depth direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingFront</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>

    <span class="c1">// Padding after the input in the depth direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingBack</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span>

    <span class="c1">// Padding before the input in the height direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingTop</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="c1">// Padding after the input in the height direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingBottom</span> <span class="o">=</span> <span class="mi">11</span><span class="p">;</span>

    <span class="c1">// Padding before the input in the width direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingLeft</span> <span class="o">=</span> <span class="mi">12</span><span class="p">;</span>

    <span class="c1">// Padding after the input in the width direction.</span>
    <span class="kt">int32</span> <span class="na">customPaddingRight</span> <span class="o">=</span> <span class="mi">13</span><span class="p">;</span>

    <span class="c1">// If true, exclude zeros from padding in Average pooling.  Meaningless in Max Pooling.</span>
    <span class="kt">bool</span> <span class="na">countExcludePadding</span> <span class="o">=</span> <span class="mi">14</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="globalpooling3dlayerparams">
<h3>GlobalPooling3DLayerParams<a class="headerlink" href="#globalpooling3dlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GlobalPooling3DLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">GlobalPoolingType3D</span> <span class="p">{</span>
        <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Whether to use Max or Average</span>
    <span class="n">GlobalPoolingType3D</span> <span class="na">type</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="paddinglayerparams">
<h3>PaddingLayerParams<a class="headerlink" href="#paddinglayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs padding along spatial dimensions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">PaddingLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 2.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[H_in,</span> <span class="pre">W_in]</span></code>.
For ranks greater than 2, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.
That is, padding is applied on last two dimensions.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[H_out,</span> <span class="pre">W_out]</span></code>.</p>
</dd>
</dl>
<p>Output dimensions are calculated as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H_out</span> <span class="o">=</span> <span class="n">H_in</span> <span class="o">+</span> <span class="n">topPaddingAmount</span> <span class="o">+</span> <span class="n">bottomPaddingAmount</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">W_in</span> <span class="o">+</span> <span class="n">leftPaddingAmount</span> <span class="o">+</span> <span class="n">rightPaddingAmount</span>

<span class="n">topPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">bottomPaddingAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
<span class="n">leftPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">rightPaddingAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
</pre></div>
</div>
<p>There are three types of padding:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingConstant</span></code>, which fills a constant value at the border.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingReflection</span></code>, which reflects the values at the border.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingReplication</span></code>, which replicates the values at the border.</p></li>
</ul>
<p>Given the following input:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>  <span class="p">:</span>  <span class="mi">1</span>   <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">5</span>   <span class="mi">6</span>   <span class="mi">7</span>   <span class="mi">8</span>
              <span class="mi">9</span>   <span class="mi">10</span>  <span class="mi">11</span>  <span class="mi">12</span>
</pre></div>
</div>
<p>Here is the output of applying the padding
<code class="docutils literal notranslate"><span class="pre">(top=2,</span> <span class="pre">left=2,</span> <span class="pre">bottom=0,</span> <span class="pre">right=0)</span></code>
with each of the supported types:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingConstant</span></code> (<code class="docutils literal notranslate"><span class="pre">value</span> <span class="pre">=</span> <span class="pre">0</span></code>):
.. code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="p">:</span>  <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>  <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>
              <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>  <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>
              <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">1</span>  <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">5</span>  <span class="mi">6</span>   <span class="mi">7</span>   <span class="mi">8</span>
              <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">9</span>  <span class="mi">10</span>  <span class="mi">11</span>  <span class="mi">12</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingReflection</span></code>:
.. code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="p">:</span>  <span class="mi">11</span>  <span class="mi">10</span>  <span class="mi">9</span>  <span class="mi">10</span>  <span class="mi">11</span>  <span class="mi">12</span>
              <span class="mi">7</span>   <span class="mi">6</span>   <span class="mi">5</span>  <span class="mi">6</span>   <span class="mi">7</span>   <span class="mi">8</span>
              <span class="mi">3</span>   <span class="mi">2</span>   <span class="mi">1</span>  <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">7</span>   <span class="mi">6</span>   <span class="mi">5</span>  <span class="mi">6</span>   <span class="mi">7</span>   <span class="mi">8</span>
              <span class="mi">11</span>  <span class="mi">10</span>  <span class="mi">9</span>  <span class="mi">10</span>  <span class="mi">11</span>  <span class="mi">12</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">PaddingReplication</span></code>:
.. code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="p">:</span>  <span class="mi">1</span>   <span class="mi">1</span>   <span class="mi">1</span>  <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">1</span>   <span class="mi">1</span>   <span class="mi">1</span>  <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">1</span>   <span class="mi">1</span>   <span class="mi">1</span>  <span class="mi">2</span>   <span class="mi">3</span>   <span class="mi">4</span>
              <span class="mi">5</span>   <span class="mi">5</span>   <span class="mi">5</span>  <span class="mi">6</span>   <span class="mi">7</span>   <span class="mi">8</span>
              <span class="mi">9</span>   <span class="mi">9</span>   <span class="mi">9</span>  <span class="mi">10</span>  <span class="mi">11</span>  <span class="mi">12</span>
</pre></div>
</div>
</li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PaddingLayerParams</span> <span class="p">{</span>

    <span class="kd">message</span> <span class="nc">PaddingConstant</span> <span class="p">{</span>
        <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">message</span> <span class="nc">PaddingReflection</span> <span class="p">{</span>
    <span class="p">}</span>

    <span class="kd">message</span> <span class="nc">PaddingReplication</span> <span class="p">{</span>
    <span class="p">}</span>

    <span class="k">oneof</span> <span class="n">PaddingType</span> <span class="p">{</span>
        <span class="n">PaddingConstant</span> <span class="na">constant</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">PaddingReflection</span> <span class="na">reflection</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
        <span class="n">PaddingReplication</span> <span class="na">replication</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">BorderAmounts</span> <span class="na">paddingAmounts</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="paddinglayerparams-paddingconstant">
<h3>PaddingLayerParams.PaddingConstant<a class="headerlink" href="#paddinglayerparams-paddingconstant" title="Permalink to this headline">¶</a></h3>
<p>Fill a constant value in the padded region.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PaddingConstant</span> <span class="p">{</span>
    <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="paddinglayerparams-paddingreflection">
<h3>PaddingLayerParams.PaddingReflection<a class="headerlink" href="#paddinglayerparams-paddingreflection" title="Permalink to this headline">¶</a></h3>
<p>Reflect the values at the border for padding.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PaddingReflection</span> <span class="p">{</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="paddinglayerparams-paddingreplication">
<h3>PaddingLayerParams.PaddingReplication<a class="headerlink" href="#paddinglayerparams-paddingreplication" title="Permalink to this headline">¶</a></h3>
<p>Replicate the values at the border for padding.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PaddingReplication</span> <span class="p">{</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="concatlayerparams">
<h3>ConcatLayerParams<a class="headerlink" href="#concatlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that concatenates along the axis = -3 or -5.
For general concatenation along any axis, see ConcatNDLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ConcatLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">....</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires more than 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>All input blobs must have same rank.
If “sequenceConcat” = False, rank must be greater than equal to 3. In this case concatenation is along axis = -3
If “sequenceConcat” = True, rank must be greater than equal to 5. In this case concatenation is along axis = -5</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ConcatLayerParams</span> <span class="p">{</span>

    <span class="kt">bool</span> <span class="na">sequenceConcat</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lrnlayerparams">
<h3>LRNLayerParams<a class="headerlink" href="#lrnlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs local response normalization (LRN).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">LRNLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 3.
Example: Rank 4 blob represents [Batch, channels, height, width]
For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<p>This layer is described by the following formula:</p>
<div class="math notranslate nohighlight">
\[x_i \leftarrow  \dfrac{x_i}{\left ( k + \dfrac{\alpha}{\text{localSize} \sum_j x_j^2 \right )^\beta}\]</div>
<p>where the summation is done over a <code class="docutils literal notranslate"><span class="pre">(localSize,</span> <span class="pre">1,</span> <span class="pre">1)</span></code> neighborhood —
that is, over a window “across” channels in 1x1 spatial neighborhoods.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LRNLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">localSize</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">k</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="softmaxlayerparams">
<h3>SoftmaxLayerParams<a class="headerlink" href="#softmaxlayerparams" title="Permalink to this headline">¶</a></h3>
<p>Softmax Normalization Layer</p>
<p>A layer that performs softmax normalization.
Normalization is applied along axis = -3 or N-3 (where N is the rank of the input)
For softmax layer that can operate on any axis, see SoftmaxNDLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SoftmaxLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>Must be a blob with rank &gt;= 3.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<p>This layer is described by the following formula:</p>
<div class="math notranslate nohighlight">
\[x_i \leftarrow \dfrac{e^{x_i}}{\sum_i{e^{x_i}}}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SoftmaxLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="splitlayerparams">
<h3>SplitLayerParams<a class="headerlink" href="#splitlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that uniformly splits across axis = -3 to produce a specified number of outputs.
For general split operation along any axis, see SplitNDLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span><span class="o">...</span><span class="n">yN</span><span class="p">)</span> <span class="o">=</span> <span class="n">SplitLayer</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">where</span> <span class="n">N</span> <span class="o">=</span> <span class="n">nOutputs</span>
</pre></div>
</div>
<p>Requires 1 input and produces multiple outputs.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
<dt>Output</dt><dd><p><code class="docutils literal notranslate"><span class="pre">nOutputs</span></code> blobs each with same rank as the input.
For example: For input that is of shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>, output shapes
will be <code class="docutils literal notranslate"><span class="pre">[C/nOutputs,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SplitLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">nOutputs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="addlayerparams">
<h3>AddLayerParams<a class="headerlink" href="#addlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs elementwise addition.
This layer has limited broadcasting support. For general broadcasting see
AddBroadcastableLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AddLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 or more than 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>In general, there are no rank constraints.
However, only certain set of shapes are broadcastable. For example:
[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]</p>
</dd>
<dt>Output</dt><dd><p>A blob with shape equal to the input blob.</p>
</dd>
</dl>
<p>If only one input is provided, scalar addition is performed:</p>
<div class="math notranslate nohighlight">
\[y = x + \alpha\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AddLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="multiplylayerparams">
<h3>MultiplyLayerParams<a class="headerlink" href="#multiplylayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs elementwise multiplication.
This layer has limited broadcasting support. For general broadcasting see MultiplyBroadcastableLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">MultiplyLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 or more than 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>In general, there are no rank constraints.
However, only certain set of shapes are broadcastable. For example:
[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]</p>
</dd>
<dt>Output</dt><dd><p>A blob with shape equal to the first input blob.</p>
</dd>
</dl>
<p>If only one input is provided, scalar multiplication is performed:</p>
<div class="math notranslate nohighlight">
\[y = \alpha x\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MultiplyLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="unaryfunctionlayerparams">
<h3>UnaryFunctionLayerParams<a class="headerlink" href="#unaryfunctionlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that applies a unary function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">UnaryFunctionLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with no rank constraints.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<p>The input is first modified by shifting and scaling:</p>
<div class="math notranslate nohighlight">
\[x \leftarrow \text{scale} \cdot x + \text{shift}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">UnaryFunctionLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">Operation</span> <span class="p">{</span>
        <span class="na">SQRT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">RSQRT</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">INVERSE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
        <span class="na">POWER</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
        <span class="na">EXP</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
        <span class="na">LOG</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
        <span class="na">ABS</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
        <span class="na">THRESHOLD</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Operation</span> <span class="na">type</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">epsilon</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">shift</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">scale</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="upsamplelayerparams">
<h3>UpsampleLayerParams<a class="headerlink" href="#upsamplelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that scales up spatial dimensions.
It supports two modes: nearest neighbour (default) and bilinear.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">UpsampleLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">scalingFactor[0]</span> <span class="pre">*</span> <span class="pre">H,</span> <span class="pre">scalingFactor[1]</span> <span class="pre">*</span> <span class="pre">W]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">UpsampleLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">scalingFactor</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">float</span> <span class="na">fractionalScalingFactor</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">InterpolationMode</span> <span class="p">{</span>

        <span class="na">NN</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">BILINEAR</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="n">InterpolationMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">LinearUpsampleMode</span> <span class="p">{</span>

        <span class="na">DEFAULT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">ALIGN_CORNERS_TRUE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">ALIGN_CORNERS_FALSE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="n">LinearUpsampleMode</span> <span class="na">linearUpsampleMode</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="resizebilinearlayerparams">
<h3>ResizeBilinearLayerParams<a class="headerlink" href="#resizebilinearlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that resizes the input to a pre-specified spatial size using bilinear interpolation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ResizeBilinearLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_in,</span> <span class="pre">W_in]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ResizeBilinearLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">targetSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="n">SamplingMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="cropresizelayerparams">
<h3>CropResizeLayerParams<a class="headerlink" href="#cropresizelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that extracts cropped spatial patches or RoIs (regions of interest) from
the input and resizes them to a pre-specified size using bilinear interpolation.</p>
<p>Note that RoI Align layer can be implemented with this layer followed by a pooling layer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">CropResizeLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 2 inputs and produces 1 output.</p>
<dl>
<dt>Input</dt><dd><p>There are two inputs.
First input represents an image feature map.
Second input represents the bounding box coordinates for N patches or RoIs
(region of interest).</p>
<p>First input is rank 5: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">Batch,</span> <span class="pre">C,</span> <span class="pre">H_in,</span> <span class="pre">W_in]</span></code>.</p>
<p>Second input is rank 5. Its shape can be either <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>
or <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">5,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p>
<p>N: number of patches/RoIs to be extracted</p>
<dl class="simple">
<dt>If RoI shape = <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">1]</span></code></dt><dd><p>The axis=-3 corresponds to the four coordinates specifying the bounding box.
All the N RoIs are extracted from all the batches of the input.</p>
</dd>
<dt>If RoI shape = <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">5,</span> <span class="pre">1,</span> <span class="pre">1]</span></code></dt><dd><p>The first element of the <code class="docutils literal notranslate"><span class="pre">axis=-3</span></code> specifies the input batch
id from which to extract the RoI and
must be in the interval <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">Batch</span> <span class="pre">-</span> <span class="pre">1]</span></code>.
That is, the <code class="docutils literal notranslate"><span class="pre">n</span></code> th RoI is extracted from the
<code class="docutils literal notranslate"><span class="pre">RoI[n,0,0,0,0]</span></code> th input batch id.
The last four elements of the <code class="docutils literal notranslate"><span class="pre">axis=-3</span></code>
specify the bounding box coordinates.</p>
</dd>
</dl>
</dd>
<dt>Output</dt><dd><dl class="simple">
<dt>A blob with rank 5.</dt><dd><ul class="simple">
<li><p>Shape is <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">Batch,</span> <span class="pre">C,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> if input RoI shape is
<code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p></li>
<li><p>Shape is <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">C,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> if input RoI shape is
<code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">1,</span> <span class="pre">5,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CropResizeLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">targetSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">normalizedCoordinates</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="n">SamplingMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="n">BoxCoordinatesMode</span> <span class="na">boxIndicesMode</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">spatialScale</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="biaslayerparams">
<h3>BiasLayerParams<a class="headerlink" href="#biaslayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs elementwise addition of a bias,
which is broadcasted to match the input shape.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BiasLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="scalelayerparams">
<h3>ScaleLayerParams<a class="headerlink" href="#scalelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs elmentwise multiplication by a scale factor
and optionally adds a bias;
both the scale and bias are broadcasted to match the input shape.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ScaleLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ScaleLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">shapeScale</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">scale</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">shapeBias</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loadconstantlayerparams">
<h3>LoadConstantLayerParams<a class="headerlink" href="#loadconstantlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that loads data as a parameter and provides it as an output.
The output is rank 5. For general rank, see LoadConstantNDLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">LoadConstantLayer</span><span class="p">()</span>
</pre></div>
</div>
<p>Requires no input and produces 1 output.</p>
<dl class="simple">
<dt>Output:</dt><dd><p>A blob with rank 5 and shape <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code></p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LoadConstantLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">data</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="l2normalizelayerparams">
<h3>L2NormalizeLayerParams<a class="headerlink" href="#l2normalizelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs L2 normalization, i.e. divides by the
the square root of the sum of squares of all elements of input.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">L2NormalizeLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 3.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<p>This layer is described by the following formula:</p>
<div class="math notranslate nohighlight">
\[x_i \leftarrow \dfrac{x_i}{\sqrt{\sum{x_i^2} + \epsilon}}\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">L2NormalizeLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">epsilon</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-reorganization-layers">
<h2>Data Reorganization Layers<a class="headerlink" href="#data-reorganization-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="flattenlayerparams">
<h3>FlattenLayerParams<a class="headerlink" href="#flattenlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that flattens the input. Requires 1 input and produces 1 output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">FlattenLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 3.
For example: Rank 4 blob represents <code class="docutils literal notranslate"><span class="pre">[Batch,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input, such that last two dimensions are both 1.
For example: For rank 4 input, output shape is <code class="docutils literal notranslate"><span class="pre">[Batch,</span> <span class="pre">C</span> <span class="pre">*</span> <span class="pre">H</span> <span class="pre">*</span> <span class="pre">W,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p>
</dd>
</dl>
<p>There are two X orders: <code class="docutils literal notranslate"><span class="pre">CHANNEL_FIRST</span></code> and <code class="docutils literal notranslate"><span class="pre">CHANNEL_LAST</span></code>.
<code class="docutils literal notranslate"><span class="pre">CHANNEL_FIRST</span></code> does not require data to be rearranged,
because row major ordering is used by internal storage.
<code class="docutils literal notranslate"><span class="pre">CHANNEL_LAST</span></code> requires data to be rearranged.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FlattenLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">FlattenOrder</span> <span class="p">{</span>

        <span class="na">CHANNEL_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">CHANNEL_LAST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">FlattenOrder</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reshapelayerparams">
<h3>ReshapeLayerParams<a class="headerlink" href="#reshapelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that recasts the input into a new shape.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ReshapeLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank 5.
For example: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code> or <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">1,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>A blob with rank 5.
For example: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> or <code class="docutils literal notranslate"><span class="pre">[Seq_out,</span> <span class="pre">1,</span> <span class="pre">C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>.</p>
</dd>
</dl>
<p>There are two reshape orders: <code class="docutils literal notranslate"><span class="pre">CHANNEL_FIRST</span></code> and <code class="docutils literal notranslate"><span class="pre">CHANNEL_LAST</span></code>.
<code class="docutils literal notranslate"><span class="pre">CHANNEL_FIRST</span></code> is equivalent to
flattening the input to <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">1,</span> <span class="pre">C</span> <span class="pre">*</span> <span class="pre">H</span> <span class="pre">*</span> <span class="pre">W,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> in channel first order
and then reshaping it to the target shape;
no data rearrangement is required.
<code class="docutils literal notranslate"><span class="pre">CHANNEL_LAST</span></code> is equivalent to
flattening the input to <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">1,</span> <span class="pre">H</span> <span class="pre">*</span> <span class="pre">W</span> <span class="pre">*</span> <span class="pre">C,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> in channel last order,
reshaping it to <code class="docutils literal notranslate"><span class="pre">[Seq_out,</span> <span class="pre">1,</span> <span class="pre">H_out,</span> <span class="pre">W_out,</span> <span class="pre">C_out]</span></code> (it is now in “H_out-major”” order),
and then permuting it to <code class="docutils literal notranslate"><span class="pre">[C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>;
both the flattening and permuting requires the data to be rearranged.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReshapeLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">targetShape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">ReshapeOrder</span> <span class="p">{</span>

        <span class="na">CHANNEL_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">CHANNEL_LAST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">ReshapeOrder</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="permutelayerparams">
<h3>PermuteLayerParams<a class="headerlink" href="#permutelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that rearranges the dimensions and data of an input.
For generic transpose/permute operation see TransposeLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">PermuteLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>Must be a rank 5 blob.
For example: shape <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>Rank 5 blob. Transposed version of the input, such that dimensions at axis=1
or axis=-4 is unchanged.</p>
</dd>
</dl>
<p>Examples:</p>
<blockquote>
<div><p>Assume input shape is <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>:</p>
</div></blockquote>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is set to <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">3,</span> <span class="pre">1,</span> <span class="pre">2]</span></code>,
then the output has shape <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">W,</span> <span class="pre">C,</span> <span class="pre">H]</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is set to <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">0]</span></code>,
then the output has shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">Seq]</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is set to <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">3,</span> <span class="pre">2,</span> <span class="pre">1]</span></code>,
then the output has shape <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">W,</span> <span class="pre">H,</span> <span class="pre">C]</span></code></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is not set, or is set to <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3]</span></code>,
the output is the same as the input.</p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PermuteLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reorganizedatalayerparams">
<h3>ReorganizeDataLayerParams<a class="headerlink" href="#reorganizedatalayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reorganizes data in the input in specific ways.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ReorganizeDataLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 3.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
For example: blob with shape <code class="docutils literal notranslate"><span class="pre">[C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>.</p>
</dd>
<dt>mode == SPACE_TO_DEPTH</dt><dd><p><code class="docutils literal notranslate"><span class="pre">[C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> : <code class="docutils literal notranslate"><span class="pre">[C</span> <span class="pre">*</span> <span class="pre">blockSize</span> <span class="pre">*</span> <span class="pre">blockSize,</span> <span class="pre">H/blockSize,</span> <span class="pre">W/blockSize]</span></code>.
blockSize must divide H and W.
Data is moved from the spatial dimensions to the channel dimension. Input is spatially divided into
non-overlapping blocks of size blockSize X blockSize and data from each block is moved into the
channel dimension.</p>
</dd>
<dt>mode == DEPTH_TO_SPACE</dt><dd><p><code class="docutils literal notranslate"><span class="pre">[C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> : <code class="docutils literal notranslate"><span class="pre">[C/(blockSize</span> <span class="pre">*</span> <span class="pre">blockSize),</span> <span class="pre">H</span> <span class="pre">*</span> <span class="pre">blockSize,</span> <span class="pre">W</span> <span class="pre">*</span> <span class="pre">blockSize]</span></code>.
Square of blockSize must divide C.
Reverse of SPACE_TO_DEPTH. Data is moved from the channel dimension to the spatial dimensions.</p>
</dd>
<dt>mode == PIXEL_SHUFFLE</dt><dd><p><code class="docutils literal notranslate"><span class="pre">[C_out,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code> : <code class="docutils literal notranslate"><span class="pre">[C/(blockSize</span> <span class="pre">*</span> <span class="pre">blockSize),</span> <span class="pre">H</span> <span class="pre">*</span> <span class="pre">blockSize,</span> <span class="pre">W</span> <span class="pre">*</span>&#160; <span class="pre">blockSize]</span></code>.
Square of blockSize must divide C.
Similar to DEPTH_TO_SPACE, but using the pixel-shuffle semantics for channel order in the output space.
In both modes, elements along the channel dimension are collapsed into
blocks in the spatial dimensions. The difference is in the arrangement of
the input-channels’ data in the output space. See below example for more
detail.
(Only available in Core ML Specification &gt;= 5 (iOS &gt;= 14, macOS &gt;= 11.0)</p>
</dd>
</dl>
<p>Examples:</p>
<p>Assume input is the following [C = 8, H = 1, W = 2] tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">7</span> <span class="mi">8</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">9</span> <span class="mi">10</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">11</span> <span class="mi">12</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">13</span> <span class="mi">14</span><span class="p">]]</span> <span class="p">[[</span><span class="mi">15</span> <span class="mi">16</span><span class="p">]]]</span>
</pre></div>
</div>
<p>If block_size == 2 and mode == DEPTH_TO_SPACE, output will be the following
[C = 2, H = 2, W = 4] tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span> <span class="mi">1</span>  <span class="mi">5</span>  <span class="mi">2</span>  <span class="mi">6</span><span class="p">]</span>
  <span class="p">[</span> <span class="mi">9</span> <span class="mi">13</span> <span class="mi">10</span> <span class="mi">14</span><span class="p">]]</span>

 <span class="p">[[</span> <span class="mi">3</span>  <span class="mi">7</span>  <span class="mi">4</span>  <span class="mi">8</span><span class="p">]</span>
  <span class="p">[</span><span class="mi">11</span> <span class="mi">15</span> <span class="mi">12</span> <span class="mi">16</span><span class="p">]]]</span>
</pre></div>
</div>
<p>For mode == SPACE_TO_DEPTH, the behavior is the same as mode ==
DEPTH_TO_SPACE, but with the input and output swapped.</p>
<p>If block_size == 2 and mode == PIXEL_SHUFFLE, output will be the following
[C = 2, H = 2, W = 4] tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span> <span class="mi">1</span>  <span class="mi">3</span>  <span class="mi">2</span>  <span class="mi">4</span><span class="p">]</span>
  <span class="p">[</span> <span class="mi">5</span>  <span class="mi">7</span>  <span class="mi">6</span>  <span class="mi">8</span><span class="p">]]</span>

 <span class="p">[[</span> <span class="mi">9</span> <span class="mi">11</span> <span class="mi">10</span> <span class="mi">12</span><span class="p">]</span>
  <span class="p">[</span><span class="mi">13</span> <span class="mi">15</span> <span class="mi">14</span> <span class="mi">16</span><span class="p">]]]</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReorganizeDataLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">ReorganizationType</span> <span class="p">{</span>

        <span class="na">SPACE_TO_DEPTH</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">DEPTH_TO_SPACE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">PIXEL_SHUFFLE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">ReorganizationType</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">blockSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slicelayerparams">
<h3>SliceLayerParams<a class="headerlink" href="#slicelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that slices the input data along axis = -1 or -2 or -3.
For general slice along any axis, please see SliceStaticLayer/SliceDynamicLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SliceLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob that can, in general, have any rank. However, depending on the value of “axis” ,
there may be additional rank constraints.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same rank as the input.</p>
</dd>
</dl>
<p>Sliced section is taken from the interval <code class="docutils literal notranslate"><span class="pre">[startIndex,</span> <span class="pre">endIndex)</span></code>, i.e.
startIndex is inclusive while endIndex is exclusive.
stride must be positive and represents the step size for slicing.
Negative indexing is supported for startIndex and endIndex.
-1 denotes N-1, -2 denotes N-2 and so on, where N is the length of the dimension to be sliced.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SliceLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">startIndex</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int64</span> <span class="na">endIndex</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">stride</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">SliceAxis</span> <span class="p">{</span>

        <span class="na">CHANNEL_AXIS</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">HEIGHT_AXIS</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">WIDTH_AXIS</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="c1">// The following mapping is used for interpreting this parameter:</span>
    <span class="c1">// CHANNEL_AXIS =&gt; axis = -3, input must have rank at least 3.</span>
    <span class="c1">// HEIGHT_AXIS =&gt; axis = -2, input must have rank at least 2.</span>
    <span class="c1">// WIDTH_AXIS =&gt; axis = -1</span>
    <span class="n">SliceAxis</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducelayerparams">
<h3>ReduceLayerParams<a class="headerlink" href="#reducelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reduces the input using a specified operation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ReduceLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl>
<dt>Input</dt><dd><dl class="simple">
<dt>A blob that can, in general, have any rank. However, depending on the value of “axis” ,</dt><dd><p>there may be additional rank constraints.</p>
</dd>
</dl>
</dd>
<dt>Output</dt><dd><p>A blob with the same rank as the input, which has 1s on the dimensions specified in the parameter “axis”</p>
<p>Values supported for axis are [-1], [-2], [-3], [-2,-1], [-3,-2,-1]
and the equivalent positive values (depending on the rank of the input)
For mode == ‘ArgMax’, axis must be [-1] or [-2] or [-3].</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">ReduceOperation</span> <span class="p">{</span>

        <span class="na">SUM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">AVG</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">PROD</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
        <span class="na">LOGSUM</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
        <span class="na">SUMSQUARE</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
        <span class="na">L1</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
        <span class="na">L2</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
        <span class="na">MAX</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>
        <span class="na">MIN</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
        <span class="na">ARGMAX</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span>

    <span class="p">}</span>
    <span class="n">ReduceOperation</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">epsilon</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kd">enum</span> <span class="n">ReduceAxis</span> <span class="p">{</span>

        <span class="na">CHW</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">HW</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">C</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
        <span class="na">H</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
        <span class="na">W</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="c1">// The following mapping is used for interpreting this parameter:</span>
    <span class="c1">// CHW = axis [-3, -2, -1], input must have rank at least 3.</span>
    <span class="c1">// HW = axis [-2, -1], input must have rank at least 2.</span>
    <span class="c1">// C = axis [-3]</span>
    <span class="c1">// H = axis [-2]</span>
    <span class="c1">// W = axis [-1]</span>
    <span class="n">ReduceAxis</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="croplayerparams">
<h3>CropLayerParams<a class="headerlink" href="#croplayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that crops the spatial dimensions of an input.
If two inputs are provided, the shape of the second input is used as the
reference shape.</p>
<div class="math notranslate nohighlight">
\[y = CropLayer(x1) or y = CropLayer(x1,x2)\]</div>
<p>Requires 1 or 2 inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><ul class="simple">
<li><p>1 or 2 tensors, each with rank at least 3, both inputs must have equal rank.</p></li>
<li><p>For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p></li>
</ul>
</dd>
<dt>Examples</dt><dd><ul class="simple">
<li><p>1 input case: A blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_in,</span> <span class="pre">W_in]</span></code>.</p></li>
<li><p>2 input case: 1st blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_in,</span> <span class="pre">W_in]</span></code>, 2nd blob with
shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>.</p></li>
</ul>
</dd>
<dt>Output</dt><dd><ul class="simple">
<li><p>Same rank as the inputs.</p></li>
<li><p>For example: A blob with shape <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">H_out,</span> <span class="pre">W_out]</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>If one input is used, output is computed as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[:,</span> <span class="n">topCropAmount</span><span class="p">:</span><span class="n">H_in</span> <span class="o">-</span> <span class="n">bottomCropAmount</span><span class="p">,</span> <span class="n">leftCropAmount</span><span class="p">:</span><span class="n">W_in</span> <span class="o">-</span> <span class="n">rightCropAmount</span><span class="p">]</span>

<span class="n">topCropAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">bottomCropAmount</span> <span class="o">==</span> <span class="n">Height</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>
<span class="n">leftCropAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">startEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startEdgeSize</span>
<span class="n">rightCropAmount</span> <span class="o">==</span> <span class="n">Width</span> <span class="n">endEdgeSize</span> <span class="o">==</span> <span class="n">borderAmounts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">endEdgeSize</span>

<span class="n">H_out</span> <span class="o">=</span> <span class="n">H_in</span> <span class="o">-</span> <span class="n">topCropAmount</span> <span class="o">-</span> <span class="n">bottomCropAmount</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">W_in</span> <span class="o">-</span> <span class="n">leftCropAmount</span> <span class="o">-</span> <span class="n">rightCropAmount</span>
</pre></div>
</div>
<p>If two inputs are used, output is computed as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[:,</span> <span class="n">offset</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">offset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">H_out</span><span class="p">,</span> <span class="n">offset</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">offset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">W_out</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CropLayerParams</span> <span class="p">{</span>

    <span class="n">BorderAmounts</span> <span class="na">cropAmounts</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">offset</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="averagelayerparams">
<h3>AverageLayerParams<a class="headerlink" href="#averagelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the elementwise average of the inputs.
This layer has limited broadcasting support. For general broadcasting see AddBroadcastableLayer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AverageLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires multiple inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>In general, there are no rank constraints.
However, only certain set of shapes are broadcastable. For example:
[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as each input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AverageLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="maxlayerparams">
<h3>MaxLayerParams<a class="headerlink" href="#maxlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the elementwise maximum over the inputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">MaxLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires multiple inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>In general, there are no rank constraints.
However, only certain set of shapes are broadcastable. For example:
[B, C, 1, 1], [B, C, H, W]</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as each input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MaxLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="minlayerparams">
<h3>MinLayerParams<a class="headerlink" href="#minlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the elementwise minimum over the inputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">MinLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires multiple inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>In general, there are no rank constraints.
However, only certain set of shapes are broadcastable. For example:
[B, C, 1, 1], [B, C, H, W]</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as each input.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MinLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="dotproductlayerparams">
<h3>DotProductLayerParams<a class="headerlink" href="#dotproductlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the dot product of two vectors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">DotProductLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 2 inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>Two blobs with rank at least 3, such that the last two dimensions must be 1.
For example: Blobs with shape <code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">C,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.
For ranks greater than 3, the leading dimensions, starting from 0 to -4
(inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
For example: For rank 4 inputs, output shape: <code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">DotProductLayerParams</span> <span class="p">{</span>

    <span class="kt">bool</span> <span class="na">cosineSimilarity</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="meanvariancenormalizelayerparams">
<h3>MeanVarianceNormalizeLayerParams<a class="headerlink" href="#meanvariancenormalizelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs mean variance normalization, along axis = -3.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">MeanVarianceNormalizeLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank greater than equal to 3.
Example: Rank 4 blob represents [Batch, channels, height, width]
For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.</p>
</dd>
<dt>Output</dt><dd><p>A blob with the same shape as the input.</p>
</dd>
</dl>
<p>If <code class="docutils literal notranslate"><span class="pre">acrossChannels</span> <span class="pre">==</span> <span class="pre">true</span></code>
normalization is performed on flattened input, i.e. the input is reshaped to (Batch,C), where “Batch” contains
all dimensions from 0 to -4 (inclusive), and C contains dimensions -1, -2, -3.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">acrossChannels</span> <span class="pre">==</span> <span class="pre">false</span></code>
normalization is performed within a channel,
across spatial dimensions (i.e. last two dimensions).</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MeanVarianceNormalizeLayerParams</span> <span class="p">{</span>

    <span class="kt">bool</span> <span class="na">acrossChannels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">normalizeVariance</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">epsilon</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sequencerepeatlayerparams">
<h3>SequenceRepeatLayerParams<a class="headerlink" href="#sequencerepeatlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that repeats a sequence or the dimension sitting at axis = -5</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SequenceRepeatLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A blob with rank at least 5.
e.g: shape <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code></p>
</dd>
<dt>Output</dt><dd><p>A blob with the same rank as the input.
For example: for input shape <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>, output shape
is <code class="docutils literal notranslate"><span class="pre">[nRepetitions</span> <span class="pre">*</span> <span class="pre">Seq,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SequenceRepeatLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">nRepetitions</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="recurrent-layers">
<h2>Recurrent Layers<a class="headerlink" href="#recurrent-layers" title="Permalink to this headline">¶</a></h2>
<dl class="simple">
<dt>The following activations are supported with recurrent layers:</dt><dd><ul class="simple">
<li><p>Linear</p></li>
<li><p>Sigmoid</p></li>
<li><p>Tanh</p></li>
<li><p>ReLU</p></li>
<li><p>Scaled Hyperbolic Tangent: alpha * tanh(beta * x), currently only
supported for alpha = 1.7159, beta = 2/3</p></li>
<li><p>Hard Sigmoid: min(max(alpha * x + beta, 0), 1), currently only supported
for alpha = 0.2, beta = 0.5</p></li>
</ul>
</dd>
</dl>
<div class="section" id="simplerecurrentlayerparams">
<h3>SimpleRecurrentLayerParams<a class="headerlink" href="#simplerecurrentlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A simple recurrent layer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_t</span> <span class="o">=</span> <span class="n">SimpleRecurrentLayer</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob of rank 5, with shape <cite>[Seq, Batch, inputVectorSize, 1, 1]`</cite>.
This represents a sequence of vectors of size <code class="docutils literal notranslate"><span class="pre">inputVectorSize</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
Represents a vector of size <code class="docutils literal notranslate"><span class="pre">outputVectorSize</span></code>. It is either the final output or a sequence of outputs at all time steps.</p>
</dd>
</dl>
<ul class="simple">
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">false</span></code></p></li>
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">true</span></code></p></li>
</ul>
<p>This layer is described by the following equation:</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{y_t} = f(\mathrm{clip}(W \boldsymbol{x_t} + \
                                   R \boldsymbol{y_{t-1}} + b))\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">W</span></code> is a 2-dimensional weight matrix
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">inputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">R</span></code> is a 2-dimensional recursion matrix
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">outputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">b</span></code> is a 1-dimensional bias vector (<code class="docutils literal notranslate"><span class="pre">[outputVectorSize]</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">f()</span></code> is an activation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip()</span></code> is a function that constrains values between <code class="docutils literal notranslate"><span class="pre">[-50.0,</span> <span class="pre">50.0]</span></code></p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SimpleRecurrentLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputVectorSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputVectorSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="n">ActivationParams</span> <span class="na">activation</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

        <span class="n">If</span> <span class="kc">false</span> <span class="n">output</span> <span class="n">is</span> <span class="n">just</span> <span class="n">the</span> <span class="n">result</span> <span class="n">after</span> <span class="n">final</span> <span class="n">state</span> <span class="n">update.</span>
        <span class="n">If</span> <span class="kc">true</span><span class="p">,</span> <span class="n">output</span> <span class="n">is</span> <span class="n">a</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">containing</span> <span class="n">outputs</span> <span class="n">at</span> <span class="n">all</span> <span class="n">time</span> <span class="n">steps.</span>
    <span class="kt">bool</span> <span class="na">sequenceOutput</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBiasVector</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weightMatrix</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">recursionMatrix</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">biasVector</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">reverseInput</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="c1">// If true, then the node processes the input sequence from right to left</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="grulayerparams">
<h3>GRULayerParams<a class="headerlink" href="#grulayerparams" title="Permalink to this headline">¶</a></h3>
<p>Gated-Recurrent Unit (GRU) Layer</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_t</span> <span class="o">=</span> <span class="n">GRULayer</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob of rank 5, with shape <cite>[Seq, Batch, inputVectorSize, 1, 1]`</cite>.
This represents a sequence of vectors of size <code class="docutils literal notranslate"><span class="pre">inputVectorSize</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
Represents a vector of size <code class="docutils literal notranslate"><span class="pre">outputVectorSize</span></code>. It is either the final output or a sequence of outputs at all time steps.</p>
</dd>
</dl>
<ul class="simple">
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">false</span></code></p></li>
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">true</span></code></p></li>
</ul>
<p>This layer is described by the following equations:</p>
<dl>
<dt>Update Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{z_t} = \
    f(\mathrm{clip}(W_z \boldsymbol{x_t} + \
                    R_z \boldsymbol{y_{t-1}} + b_z)\]</div>
</dd>
<dt>Reset Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{r_t} = \
    f(\mathrm{clip}(W_r \boldsymbol{x_t} + \
                    R_r \boldsymbol{y_{t-1}} + b_r))\]</div>
</dd>
<dt>Cell Memory State</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{c_t} = \
    \boldsymbol{y_{t-1}} \odot \boldsymbol{r_t}\]</div>
</dd>
<dt>Output Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{o_t} = \
    g(\mathrm{clip}(W_o \boldsymbol{x_t} + \
                    R_o \boldsymbol{c_t} + b_o))\]</div>
</dd>
<dt>Output</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{y_t} = \
    (1 - \boldsymbol{z_t}) \odot \boldsymbol{o_t} + \
     \boldsymbol{z_t} \odot \boldsymbol{y_{t-1}}\]</div>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">W_z</span></code>, <code class="docutils literal notranslate"><span class="pre">W_r</span></code>, <code class="docutils literal notranslate"><span class="pre">W_o</span></code> are 2-dimensional input weight matrices
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">inputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">R_z</span></code>, <code class="docutils literal notranslate"><span class="pre">R_r</span></code>, <code class="docutils literal notranslate"><span class="pre">R_o</span></code> are 2-dimensional recursion matrices
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">outputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">b_z</span></code>, <code class="docutils literal notranslate"><span class="pre">b_r</span></code>, <code class="docutils literal notranslate"><span class="pre">b_o</span></code> are 1-dimensional bias vectors
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize]</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">f()</span></code>, <code class="docutils literal notranslate"><span class="pre">g()</span></code> are activations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip()</span></code> is a function that constrains values between <code class="docutils literal notranslate"><span class="pre">[-50.0,</span> <span class="pre">50.0]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">⊙</span></code> denotes the elementwise product of matrices</p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GRULayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputVectorSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputVectorSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="n">ActivationParams</span> <span class="na">activations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">sequenceOutput</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBiasVectors</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">updateGateWeightMatrix</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">resetGateWeightMatrix</span> <span class="o">=</span> <span class="mi">31</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateWeightMatrix</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">updateGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">resetGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">51</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">52</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">updateGateBiasVector</span> <span class="o">=</span> <span class="mi">70</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">resetGateBiasVector</span> <span class="o">=</span> <span class="mi">71</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateBiasVector</span> <span class="o">=</span> <span class="mi">72</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">reverseInput</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lstmparams">
<h3>LSTMParams<a class="headerlink" href="#lstmparams" title="Permalink to this headline">¶</a></h3>
<p>Long short-term memory (LSTM) parameters.</p>
<p>This is described by the following equations:</p>
<dl>
<dt>Input Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{i_t} = \
    f(\mathrm{clip}(W_i \boldsymbol{x_t} + \
                    R_i \boldsymbol{y_{t-1}} + \
                    p_i \odot c_{t-1} + b_i))\]</div>
</dd>
<dt>Forget Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{f_t} = \
    f(\mathrm{clip}(W_f \boldsymbol{x_t} + \
                    R_f \boldsymbol{y_{t-1}} + \
                    p_f \odot c_{t-1} + b_f))\]</div>
</dd>
<dt>Block Input</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{z_t} = \
    g(\mathrm{clip}(W_z \boldsymbol{x_t} + \
                    R_z \boldsymbol{y_{t-1}} + b_z))\]</div>
</dd>
<dt>Cell Memory State</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{c_t} = \
    \boldsymbol{c_{t-1}} \odot \boldsymbol{f_t} + \
    \boldsymbol{i_t} \odot \boldsymbol{z_t}\]</div>
</dd>
<dt>Output Gate</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{o_t} = \
    f(\mathrm{clip}(W_o \boldsymbol{x_t} + \
                    R_o \boldsymbol{y_{t-1}} + \
                    p_o \odot c_t + b_o))\]</div>
</dd>
<dt>Output</dt><dd><div class="math notranslate nohighlight">
\[\boldsymbol{y_t} = \
    h(\boldsymbol{c_t}) \odot \boldsymbol{o_t}\]</div>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">W_i</span></code>, <code class="docutils literal notranslate"><span class="pre">W_f</span></code>, <code class="docutils literal notranslate"><span class="pre">W_z</span></code>, <code class="docutils literal notranslate"><span class="pre">W_o</span></code> are 2-dimensional input weight matrices
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">inputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">R_i</span></code>, <code class="docutils literal notranslate"><span class="pre">R_f</span></code>, <code class="docutils literal notranslate"><span class="pre">R_z</span></code>, <code class="docutils literal notranslate"><span class="pre">R_o</span></code> are 2-dimensional recursion matrices
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize,</span> <span class="pre">outputVectorSize]</span></code>, row-major)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">b_i</span></code>, <code class="docutils literal notranslate"><span class="pre">b_f</span></code>, <code class="docutils literal notranslate"><span class="pre">b_z</span></code>, <code class="docutils literal notranslate"><span class="pre">b_o</span></code> are 1-dimensional bias vectors
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize]</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p_</span></code>, <code class="docutils literal notranslate"><span class="pre">p_f</span></code>, <code class="docutils literal notranslate"><span class="pre">p_o</span></code> are 1-dimensional peephole vectors
(<code class="docutils literal notranslate"><span class="pre">[outputVectorSize]</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">f()</span></code>, <code class="docutils literal notranslate"><span class="pre">g()</span></code>, <code class="docutils literal notranslate"><span class="pre">h()</span></code> are activations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip()</span></code> is a function that constrains values between <code class="docutils literal notranslate"><span class="pre">[-50.0,</span> <span class="pre">50.0]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">⊙</span></code> denotes the elementwise product of matrices</p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LSTMParams</span> <span class="p">{</span>

    <span class="kt">bool</span> <span class="na">sequenceOutput</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBiasVectors</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">forgetBias</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasPeepholeVectors</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">coupledInputAndForgetGate</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">cellClipThreshold</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lstmweightparams">
<h3>LSTMWeightParams<a class="headerlink" href="#lstmweightparams" title="Permalink to this headline">¶</a></h3>
<p>Weights for long short-term memory (LSTM) layers</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LSTMWeightParams</span> <span class="p">{</span>

    <span class="n">WeightParams</span> <span class="na">inputGateWeightMatrix</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">forgetGateWeightMatrix</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">blockInputWeightMatrix</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateWeightMatrix</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">inputGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">forgetGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">21</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">blockInputRecursionMatrix</span> <span class="o">=</span> <span class="mi">22</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateRecursionMatrix</span> <span class="o">=</span> <span class="mi">23</span><span class="p">;</span>

    <span class="c1">//biases:</span>
    <span class="n">WeightParams</span> <span class="na">inputGateBiasVector</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">forgetGateBiasVector</span> <span class="o">=</span> <span class="mi">41</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">blockInputBiasVector</span> <span class="o">=</span> <span class="mi">42</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGateBiasVector</span> <span class="o">=</span> <span class="mi">43</span><span class="p">;</span>

    <span class="c1">//peepholes:</span>
    <span class="n">WeightParams</span> <span class="na">inputGatePeepholeVector</span> <span class="o">=</span> <span class="mi">60</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">forgetGatePeepholeVector</span> <span class="o">=</span> <span class="mi">61</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">outputGatePeepholeVector</span> <span class="o">=</span> <span class="mi">62</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="unidirectionallstmlayerparams">
<h3>UniDirectionalLSTMLayerParams<a class="headerlink" href="#unidirectionallstmlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A unidirectional long short-term memory (LSTM) layer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="n">c_t</span><span class="p">)</span> <span class="o">=</span> <span class="n">UniDirectionalLSTMLayer</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">c_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob of rank 5, with shape <cite>[Seq, Batch, inputVectorSize, 1, 1]`</cite>.
This represents a sequence of vectors of size <code class="docutils literal notranslate"><span class="pre">inputVectorSize</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
Represents a vector of size <code class="docutils literal notranslate"><span class="pre">outputVectorSize</span></code>. It is either the final output or a sequence of outputs at all time steps.</p>
</dd>
</dl>
<ul class="simple">
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">false</span></code></p></li>
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">Batch,</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">true</span></code></p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">UniDirectionalLSTMLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputVectorSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputVectorSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="n">ActivationParams</span> <span class="na">activations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="n">LSTMParams</span> <span class="na">params</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="n">LSTMWeightParams</span> <span class="na">weightParams</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">reverseInput</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="bidirectionallstmlayerparams">
<h3>BiDirectionalLSTMLayerParams<a class="headerlink" href="#bidirectionallstmlayerparams" title="Permalink to this headline">¶</a></h3>
<p>Bidirectional long short-term memory (LSTM) layer</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="n">c_t</span><span class="p">,</span> <span class="n">y_t_reverse</span><span class="p">,</span> <span class="n">c_t_reverse</span><span class="p">)</span> <span class="o">=</span> <span class="n">BiDirectionalLSTMLayer</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">y_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">c_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">y_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span><span class="n">_reverse</span><span class="p">,</span> <span class="n">c_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span><span class="n">_reverse</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A blob of rank 5, with shape <cite>[Seq, Batch, inputVectorSize, 1, 1]`</cite>.
This represents a sequence of vectors of size <code class="docutils literal notranslate"><span class="pre">inputVectorSize</span></code>.</p>
</dd>
<dt>Output</dt><dd><p>Same rank as the input.
Represents a vector of size <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">outputVectorSize</span></code>. It is either the final output or a sequence of outputs at all time steps.</p>
</dd>
</dl>
<ul class="simple">
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">Batch,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">false</span></code></p></li>
<li><p>Output Shape: <code class="docutils literal notranslate"><span class="pre">[Seq,</span> <span class="pre">Batch,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">outputVectorSize,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> , if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">==</span> <span class="pre">true</span></code></p></li>
</ul>
<p>The first LSTM operates on the input sequence in the forward direction.
The second LSTM operates on the input sequence in the reverse direction.</p>
<p>Example: given the input sequence <code class="docutils literal notranslate"><span class="pre">[x_1,</span> <span class="pre">x_2,</span> <span class="pre">x_3]</span></code>,
where <code class="docutils literal notranslate"><span class="pre">x_i</span></code> are vectors at time index <code class="docutils literal notranslate"><span class="pre">i</span></code>:</p>
<p>The forward LSTM output is <code class="docutils literal notranslate"><span class="pre">[yf_1,</span> <span class="pre">yf_2,</span> <span class="pre">yf_3]</span></code>,</p>
<p>where <code class="docutils literal notranslate"><span class="pre">yf_i</span></code> are vectors of size <code class="docutils literal notranslate"><span class="pre">outputVectorSize</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">yf_1</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_1</span></code>}</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yf_2</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_1</span></code>, <code class="docutils literal notranslate"><span class="pre">x_2</span></code>}</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yf_3</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_1</span></code>, <code class="docutils literal notranslate"><span class="pre">x_2</span></code>, <code class="docutils literal notranslate"><span class="pre">x_3</span></code>}</p></li>
</ul>
<p>The backward LSTM output: <code class="docutils literal notranslate"><span class="pre">[yb_1,</span> <span class="pre">yb_2,</span> <span class="pre">yb_3]</span></code>,</p>
<p>where <code class="docutils literal notranslate"><span class="pre">yb_i</span></code> are vectors of size <code class="docutils literal notranslate"><span class="pre">outputVectorSize</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">yb_1</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_3</span></code>}</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yb_2</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_3</span></code>, <code class="docutils literal notranslate"><span class="pre">x_2</span></code>}</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yb_3</span></code> is the output at the end of sequence {<code class="docutils literal notranslate"><span class="pre">x_3</span></code>, <code class="docutils literal notranslate"><span class="pre">x_2</span></code>, <code class="docutils literal notranslate"><span class="pre">x_1</span></code>}</p></li>
</ul>
<p>Output of the bi-dir layer:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">=</span> <span class="pre">True</span></code> : { <code class="docutils literal notranslate"><span class="pre">[yf_1,</span> <span class="pre">yb_3]</span></code>,  <code class="docutils literal notranslate"><span class="pre">[yf_2,</span> <span class="pre">yb_2]</span></code>,  <code class="docutils literal notranslate"><span class="pre">[yf_3,</span> <span class="pre">yb_1]</span></code> }</p></li>
<li><p>if <code class="docutils literal notranslate"><span class="pre">sequenceOutput</span> <span class="pre">=</span> <span class="pre">False</span></code> : { <code class="docutils literal notranslate"><span class="pre">[yf_3,</span> <span class="pre">yb_3]</span></code> }</p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BiDirectionalLSTMLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">inputVectorSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">outputVectorSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="n">ActivationParams</span> <span class="na">activationsForwardLSTM</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="n">ActivationParams</span> <span class="na">activationsBackwardLSTM</span> <span class="o">=</span> <span class="mi">11</span><span class="p">;</span>

    <span class="n">LSTMParams</span> <span class="na">params</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="n">LSTMWeightParams</span> <span class="na">weightParams</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="customlayerparams">
<h3>CustomLayerParams<a class="headerlink" href="#customlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CustomLayerParams</span> <span class="p">{</span>

    <span class="kd">message</span> <span class="nc">CustomLayerParamValue</span> <span class="p">{</span>
        <span class="k">oneof</span> <span class="n">value</span> <span class="p">{</span>
            <span class="kt">double</span> <span class="na">doubleValue</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
            <span class="kt">string</span> <span class="na">stringValue</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
            <span class="kt">int32</span> <span class="na">intValue</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
            <span class="kt">int64</span> <span class="na">longValue</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>
            <span class="kt">bool</span> <span class="na">boolValue</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="kt">string</span> <span class="na">className</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="c1">// The name of the class (conforming to MLCustomLayer) corresponding to this layer</span>
    <span class="k">repeated</span> <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span> <span class="c1">// Any weights -- these are serialized in binary format and memmapped at runtime</span>
    <span class="n">map</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">,</span> <span class="n">CustomLayerParamValue</span><span class="p">&gt;</span> <span class="na">parameters</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span> <span class="c1">// these may be handled as strings, so this should not be large</span>
    <span class="kt">string</span> <span class="na">description</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span> <span class="c1">// An (optional) description of the layer provided by the model creator. This information is displayed when viewing the model, but does not affect the model&#39;s execution on device.</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="customlayerparams-customlayerparamvalue">
<h3>CustomLayerParams.CustomLayerParamValue<a class="headerlink" href="#customlayerparams-customlayerparamvalue" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CustomLayerParamValue</span> <span class="p">{</span>
    <span class="k">oneof</span> <span class="n">value</span> <span class="p">{</span>
        <span class="kt">double</span> <span class="na">doubleValue</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="kt">string</span> <span class="na">stringValue</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
        <span class="kt">int32</span> <span class="na">intValue</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
        <span class="kt">int64</span> <span class="na">longValue</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>
        <span class="kt">bool</span> <span class="na">boolValue</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="customlayerparams-parametersentry">
<h3>CustomLayerParams.ParametersEntry<a class="headerlink" href="#customlayerparams-parametersentry" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CustomLayerParamValue</span> <span class="p">{</span>
    <span class="k">oneof</span> <span class="n">value</span> <span class="p">{</span>
        <span class="kt">double</span> <span class="na">doubleValue</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="kt">string</span> <span class="na">stringValue</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
        <span class="kt">int32</span> <span class="na">intValue</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
        <span class="kt">int64</span> <span class="na">longValue</span> <span class="o">=</span> <span class="mi">40</span><span class="p">;</span>
        <span class="kt">bool</span> <span class="na">boolValue</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="transposelayerparams">
<h3>TransposeLayerParams<a class="headerlink" href="#transposelayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">TransposeLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">//</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="batchedmatmullayerparams">
<h3>BatchedMatMulLayerParams<a class="headerlink" href="#batchedmatmullayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the matrix multiplication of two tensors with numpy-like broadcasting
where the matrices reside in the last two indices of the tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">BatchedMatMul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 or 2 inputs and produces 1 output.</p>
<p>The first tensor, “a”, must be provided as an input. The second tensor can either be an input or provided as a weight matrix parameter.</p>
<dl class="simple">
<dt>Input</dt><dd><ul class="simple">
<li><p>a: First N-Dimensional tensor</p></li>
<li><p>b: Second N-Dimensional tensor (either a rank-N input or a matrix, i.e. N=2, provided as a layer parameter)</p></li>
</ul>
</dd>
<dt>Output</dt><dd><p>A tensor containing the matrix product of two tensors.
When there are two inputs: rank is max(2, rank(a), rank(b))
When there is one input: rank is same as that of the input.</p>
</dd>
</dl>
<p>This operation behaves as following:</p>
<blockquote>
<div><dl class="simple">
<dt>When there are two inputs:</dt><dd><ul class="simple">
<li><p>If N &gt;= 2 for both tensors, it is treated as a batch of matrices residing in the last two indices.
All the indices, except for the last two, are broadcasted using conventional rules.</p></li>
<li><p>If the first tensor is 1-D, it is converted to a 2-D tensor by prepending a 1 to its shape. Eg. (D) -&gt; (1,D)</p></li>
<li><p>If the second tensor is 1-D, it is converted to a 2-D tensor by appending a 1 to its shape. Eg. (D) -&gt; (D,1)</p></li>
</ul>
</dd>
<dt>When there is one input:</dt><dd><ul class="simple">
<li><p>The weight matrix corresponds to a matrix, of shape (X1, X2). Values of X1, X2 must be provided as layer parameters.</p></li>
<li><dl class="simple">
<dt>The input, “a”, is reshaped into a matrix by combining all the leading dimensions, except the last, into a batch dimension. eg:</dt><dd><ul>
<li><p>if “a” is rank 1 (X1,) –&gt;  (1, X1). Output shape will be (X2,)</p></li>
<li><p>if “a” is rank 2 (B1, X1) –&gt; no need to reshape. Output shape will be (B1, X2)</p></li>
<li><p>if “a” is rank 3 (B1, B2, X1) –&gt; (B1 * B2, X1). Output shape will be (B1, B2, X2)</p></li>
<li><p>etc</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</div></blockquote>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BatchedMatMulLayerParams</span> <span class="p">{</span>

    <span class="kt">bool</span> <span class="na">transposeA</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">transposeB</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>


    <span class="kt">uint64</span> <span class="na">weightMatrixFirstDimension</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">weightMatrixSecondDimension</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">hasBias</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>

    <span class="n">WeightParams</span> <span class="na">weights</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">bias</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">int8DynamicQuantize</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="concatndlayerparams">
<h3>ConcatNDLayerParams<a class="headerlink" href="#concatndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that concatenates a list of tensors along a specified axis.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">ConcatNDLayer</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="o">....</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires at least 2 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>A Sequence of N-dimensional tensors. The rank of the input tensors must match and all dimensions except ‘axis’ must be equal.</p>
</dd>
<dt>Output</dt><dd><p>A N-Dimensional tensor with the same rank .</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ConcatNDLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="softmaxndlayerparams">
<h3>SoftmaxNDLayerParams<a class="headerlink" href="#softmaxndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs softmax normalization along a specified axis.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SoftmaxNDLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<p>Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SoftmaxNDLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reverselayerparams">
<h3>ReverseLayerParams<a class="headerlink" href="#reverselayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reverses specific dimensions of the input tensor.
It is similar in functionality to the numpy.flip method.</p>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReverseLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">reverseDim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reverseseqlayerparams">
<h3>ReverseSeqLayerParams<a class="headerlink" href="#reverseseqlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reverses variable length slices.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>2 inputs, in order are denoted by “data”, “seq_lengths”.
“seq_lenghts” must be a rank 1 tensor, i.e. seq_lengths.shape = (B,)
which contains the lengths of the amount of sequence to be reversed, for each element of the batch.
Dimension “batchAxis” in “data” must be equal to B, i.e,
data.shape[batchAxis] = B.</p>
<p>According to the batch axis, input “data” is first divided into a batch of B inputs,
each of which is flipped along the dimension “sequenceAxis”, by the amount specified in
“seq_lengths”, the second input.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">)]:</span>
<span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">seq_lengths</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)]:</span>
<span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">batchAxis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sequenceAxis</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">output</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">)]:</span>
<span class="p">[</span><span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">]</span>


<span class="n">data</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)]:</span>
<span class="p">[</span><span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">[</span><span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">4</span> <span class="mi">5</span><span class="p">]</span> <span class="p">(</span><span class="nb">slice</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">[</span><span class="mi">6</span> <span class="mi">7</span><span class="p">]</span>
<span class="p">[</span><span class="mi">8</span> <span class="mi">9</span><span class="p">]</span>
<span class="p">[</span><span class="mi">10</span> <span class="mi">11</span><span class="p">]</span> <span class="p">(</span><span class="nb">slice</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">seq_lengths</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)]:</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">batchAxis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sequenceAxis</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">output</span> <span class="p">[</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)]:</span>
<span class="p">[</span><span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">[</span><span class="mi">4</span> <span class="mi">5</span><span class="p">]</span> <span class="p">(</span><span class="nb">slice</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">[</span><span class="mi">10</span> <span class="mi">11</span><span class="p">]</span>
<span class="p">[</span><span class="mi">8</span> <span class="mi">9</span><span class="p">]</span>
<span class="p">[</span><span class="mi">6</span> <span class="mi">7</span><span class="p">]</span> <span class="p">(</span><span class="nb">slice</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReverseSeqLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">batchAxis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// batch axis has to be strictly less than seq_axis</span>
    <span class="kt">int64</span> <span class="na">sequenceAxis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loadconstantndlayerparams">
<h3>LoadConstantNDLayerParams<a class="headerlink" href="#loadconstantndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that loads data as a parameter and provides it as an output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">LoadConstantNDLayer</span><span class="p">()</span>
</pre></div>
</div>
<p>Requires no input and produces 1 output.</p>
<p>Output: A tensor with shape as provided in the parameter “shape”</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LoadConstantNDLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">data</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="filllikelayerparams">
<h3>FillLikeLayerParams<a class="headerlink" href="#filllikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that generates an output tensor with a constant value.
Input is only used to determine the shape of the output.
This layer is used to allocate a tensor with a dynamic shape (that of the input) and constant value.</p>
<p>Requires 1 input and produces 1 output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">FillLikeLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A N-Dimensional tensor, whose values are ignored. Only the shape is used to
infer the shape of the output.</p>
</dd>
<dt>Output</dt><dd><p>A N-Dimensional tensor with the same shape as the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FillLikeLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="fillstaticlayerparams">
<h3>FillStaticLayerParams<a class="headerlink" href="#fillstaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that generates an output tensor with a constant value.
This layer is used to allocate a tensor with a static shape and constant value.</p>
<p>Requires no input and produces 1 output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">FillStaticLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Output</dt><dd><p>A N-Dimensional tensor of shape “targetShape”.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FillStaticLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">targetShape</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="filldynamiclayerparams">
<h3>FillDynamicLayerParams<a class="headerlink" href="#filldynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that generates an output tensor with a constant value.
This layer is used to allocate a tensor with a dynamic shape (as specified by the input) and constant value.</p>
<p>Requires 1 input and produces 1 output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">FillDynamicLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Input</dt><dd><p>A rank 1 tensor specifying the shape of the output</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the shape specified by the values in the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FillDynamicLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="wherebroadcastablelayerparams">
<h3>WhereBroadcastableLayerParams<a class="headerlink" href="#wherebroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns the elements either from tensor x or tensor y,
depending on the value in the condition tensor.
It is similar in functionality to the numpy.where method with 3 inputs.</p>
<p>Requires 3 inputs and produces 1 output.
Inputs, in order, are the condition tensor, x and y.</p>
<dl class="simple">
<dt>for each vector index (i,…,j):</dt><dd><dl class="simple">
<dt>output[i,…,j] = x[i,…,j] if condition[i,…,j] = True</dt><dd><p>y[i,…,j] if condition[i,…,j] = False</p>
</dd>
</dl>
</dd>
</dl>
<p>All the 3 inputs are first broadcasted to a common shape.
(the shapes must be broadcastable)</p>
<p>output.rank = max(input[0].rank, input[1].rank, input[2].rank)</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">WhereBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sinlayerparams">
<h3>SinLayerParams<a class="headerlink" href="#sinlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric sine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SinLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SinLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="coslayerparams">
<h3>CosLayerParams<a class="headerlink" href="#coslayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric cosine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">CosLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CosLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="tanlayerparams">
<h3>TanLayerParams<a class="headerlink" href="#tanlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric tangent function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">TanLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">TanLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="asinlayerparams">
<h3>AsinLayerParams<a class="headerlink" href="#asinlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric arcsine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AsinLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AsinLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="acoslayerparams">
<h3>AcosLayerParams<a class="headerlink" href="#acoslayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric arccosine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AcosLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AcosLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="atanlayerparams">
<h3>AtanLayerParams<a class="headerlink" href="#atanlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric arctangent function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AtanLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AtanLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sinhlayerparams">
<h3>SinhLayerParams<a class="headerlink" href="#sinhlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic sine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SinhLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SinhLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="coshlayerparams">
<h3>CoshLayerParams<a class="headerlink" href="#coshlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic cosine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">CoshLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CoshLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="tanhlayerparams">
<h3>TanhLayerParams<a class="headerlink" href="#tanhlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic tangent function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">TanhLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">TanhLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="asinhlayerparams">
<h3>AsinhLayerParams<a class="headerlink" href="#asinhlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic arcsine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AsinhLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AsinhLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="acoshlayerparams">
<h3>AcoshLayerParams<a class="headerlink" href="#acoshlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic arccosine function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AcoshLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AcoshLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="atanhlayerparams">
<h3>AtanhLayerParams<a class="headerlink" href="#atanhlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes elementwise trigonometric hyperbolic arctangent function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">AtanhLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AtanhLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="powbroadcastablelayerparams">
<h3>PowBroadcastableLayerParams<a class="headerlink" href="#powbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that raises each element in first tensor to the power of
corresponding element in the second tensor.
Supports conventional numpy-like broadcasting.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">PowBroadcastableLayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 2 inputs and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><ul class="simple">
<li><p>First N-Dimensional tensor</p></li>
<li><p>Second N-Dimensional tensor</p></li>
</ul>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the broadcast shape.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">PowBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="exp2layerparams">
<h3>Exp2LayerParams<a class="headerlink" href="#exp2layerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the exponential of all elements in the input tensor, with the base 2.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">Exp2Layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">Exp2LayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="wherenonzerolayerparams">
<h3>WhereNonZeroLayerParams<a class="headerlink" href="#wherenonzerolayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor containing the indices of all non-zero
elements of input tensor.
It is similar in functionality to the numpy.where method with 1 input.</p>
<p>Requires 1 input and produces 1 output.
Output is of rank 2, of shape (N,R),
where N is the number of non-zero elements in the input and R is the rank of the input.</p>
<p>Output contains indices represented in the multi-index form</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="p">{</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,)}:</span>
<span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">output</span> <span class="p">{</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)}:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">[</span><span class="mi">3</span><span class="p">]</span>


<span class="nb">input</span> <span class="p">{</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)}:</span>
<span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">[</span><span class="mi">0</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">[</span><span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">output</span> <span class="p">{</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">)}:</span>
<span class="p">[</span><span class="mf">0.</span> <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.</span> <span class="mf">1.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.</span> <span class="mf">2.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.</span> <span class="mf">2.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.</span> <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.</span> <span class="mf">1.</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">WhereNonZeroLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="matrixbandpartlayerparams">
<h3>MatrixBandPartLayerParams<a class="headerlink" href="#matrixbandpartlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that copies a tensor setting everything outside a central band in
each inner-most matrix to zero. Requires 1 input and produces 1 output.</p>
<p>Parameters for matrix_band_part layer:</p>
<p>Output shape is same as the input shape.
Rank of the input must be at least 2.
For rank higher than 2, the last 2 dimensions are treated as the matrix,
while the rest are treated as batch.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MatrixBandPartLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">numLower</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int64</span> <span class="na">numUpper</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="uppertriangularlayerparams">
<h3>UpperTriangularLayerParams<a class="headerlink" href="#uppertriangularlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that copies a tensor setting everything outside upper triangular to zero.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output shape is same as the input shape.
Rank of the input must be at least 2.
For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">UpperTriangularLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// Diagonal below which to zero elements. k = 0 (the default) is the main diagonal, k &lt; 0 is below it and k &gt; 0 is above</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="lowertriangularlayerparams">
<h3>LowerTriangularLayerParams<a class="headerlink" href="#lowertriangularlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that copies a tensor setting everything outside lower triangular to zero.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output shape is same as the input shape.
Rank of the input must be at least 2.
For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LowerTriangularLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// Diagonal above which to zero elements. k = 0 (the default) is the main diagonal, k &lt; 0 is below it and k &gt; 0 is above</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="broadcasttolikelayerparams">
<h3>BroadcastToLikeLayerParams<a class="headerlink" href="#broadcasttolikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that broadcasts a tensor to a new shape.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>First input is broadcast to produce the output, while the second input is only
used to determine the shape of the output. Values of second input are not used.</p>
<p>Output is a tensor with the same shape as the second input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BroadcastToLikeLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="broadcasttostaticlayerparams">
<h3>BroadcastToStaticLayerParams<a class="headerlink" href="#broadcasttostaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that broadcasts a tensor to a new shape.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output tensor is the broadcasted version of the input and has shape as specified in the
parameter “targetShape”.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BroadcastToStaticLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">targetShape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="broadcasttodynamiclayerparams">
<h3>BroadcastToDynamicLayerParams<a class="headerlink" href="#broadcasttodynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that broadcasts a tensor to a new shape.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>First input is the one that is broadcasted to produce the output.
Second input is a rank 1 tensor specifying the shape of the output.
Output tensor has shape as specified by the values in the 2nd input tensor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">BroadcastToDynamicLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="addbroadcastablelayerparams">
<h3>AddBroadcastableLayerParams<a class="headerlink" href="#addbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise addition operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AddBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="maxbroadcastablelayerparams">
<h3>MaxBroadcastableLayerParams<a class="headerlink" href="#maxbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise maximum operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MaxBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="minbroadcastablelayerparams">
<h3>MinBroadcastableLayerParams<a class="headerlink" href="#minbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise minimum operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MinBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="modbroadcastablelayerparams">
<h3>ModBroadcastableLayerParams<a class="headerlink" href="#modbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise modular operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ModBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="floordivbroadcastablelayerparams">
<h3>FloorDivBroadcastableLayerParams<a class="headerlink" href="#floordivbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise floor division operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FloorDivBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="subtractbroadcastablelayerparams">
<h3>SubtractBroadcastableLayerParams<a class="headerlink" href="#subtractbroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise subtract operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SubtractBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="multiplybroadcastablelayerparams">
<h3>MultiplyBroadcastableLayerParams<a class="headerlink" href="#multiplybroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise multiply operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MultiplyBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="dividebroadcastablelayerparams">
<h3>DivideBroadcastableLayerParams<a class="headerlink" href="#dividebroadcastablelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise division operation with broadcast support.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">DivideBroadcastableLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="gatherlayerparams">
<h3>GatherLayerParams<a class="headerlink" href="#gatherlayerparams" title="Permalink to this headline">¶</a></h3>
<p>Gather layer that gathers elements from the first input, along a specified axis,
at indices specified in the second input.</p>
<p>It is similar in functionality to the <code class="docutils literal notranslate"><span class="pre">numpy.take</span></code> method.</p>
<p>Requires two inputs and produces one output.</p>
<p>Given two inputs, <code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">indices</span></code>, gather the slices of <code class="docutils literal notranslate"><span class="pre">data</span></code>
and store into output.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
   <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>  <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">D</span> <span class="n">case</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">:</span>
<span class="k">for</span> <span class="n">each</span> <span class="n">vector</span> <span class="n">index</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
   <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">j</span><span class="p">,:,</span><span class="o">..</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">j</span><span class="p">],:,</span><span class="o">..</span><span class="p">,:]</span>

<span class="n">output</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">indices</span><span class="o">.</span><span class="n">rank</span>
</pre></div>
</div>
<p>Negative indices and negative axis are supported.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">indices</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">data</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">indices</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span> <span class="o">=</span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GatherLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="scatterlayerparams">
<h3>ScatterLayerParams<a class="headerlink" href="#scatterlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ScatterLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">ScatterMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="gatherndlayerparams">
<h3>GatherNDLayerParams<a class="headerlink" href="#gatherndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that gathers elements from the first input, <code class="docutils literal notranslate"><span class="pre">'params'</span></code>, at the
multi-indices specified by the second input, <code class="docutils literal notranslate"><span class="pre">'indices'</span></code>.</p>
<p>Requires two inputs and produces one output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;params&#39;</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;indices&#39;</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">'indices'</span></code> is a rank K+1 tensor of shape <code class="docutils literal notranslate"><span class="pre">[I_0,</span> <span class="pre">I_1,</span> <span class="pre">..,</span> <span class="pre">I_(K-1),</span> <span class="pre">I_K]</span></code>
which is viewed as a collection of indices of <code class="docutils literal notranslate"><span class="pre">(I_0</span> <span class="pre">*</span> <span class="pre">I_1</span> <span class="pre">*</span> <span class="pre">...</span> <span class="pre">*</span> <span class="pre">I_(K-1))</span></code>
points in the I_K dimensional space. For instance, the multi-index of the first
point is <code class="docutils literal notranslate"><span class="pre">indices[0,0,...,0,:]</span></code>.</p>
<p>The following shows how the output is constructed:</p>
<div class="math notranslate nohighlight">
\[for i = 0,1,...,(I_0-1)
  ...
        for j = 0,1,....,(I_(K-1)-1)
                 output[i,....,j,:,:,..,:] = params[indices[i,...,j,:], :,:,..,:]\]</div>
<p>Hence, output shape is <code class="docutils literal notranslate"><span class="pre">[I_0,</span> <span class="pre">I_1,...,I(K-1)]</span> <span class="pre">+</span> <span class="pre">params.shape[I_K:]</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span> <span class="o">+</span> <span class="p">()</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>

<span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GatherNDLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="scatterndlayerparams">
<h3>ScatterNDLayerParams<a class="headerlink" href="#scatterndlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ScatterNDLayerParams</span> <span class="p">{</span>

    <span class="n">ScatterMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="gatheralongaxislayerparams">
<h3>GatherAlongAxisLayerParams<a class="headerlink" href="#gatheralongaxislayerparams" title="Permalink to this headline">¶</a></h3>
<p>Gather layer that gathers elements from the first input, along a specified axis,
at indices specified in the second input.
It is similar in functionality to the numpy.take_along_axis method.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>Given two inputs, ‘data’ and ‘indices’, gather the slices of ‘data’
and store into output.</p>
<p>Both inputs and output have the same rank.
Output shape is same as the shape of ‘indices’
Shapes of ‘indices’ and ‘data’ match, except at the ‘axis’ dimension.</p>
<p>This operation performs the following operation for axis=0:</p>
<p>Negative indices and negative axis are supported.</p>
<p>For example:</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GatherAlongAxisLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="scatteralongaxislayerparams">
<h3>ScatterAlongAxisLayerParams<a class="headerlink" href="#scatteralongaxislayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that scatters data into a new tensor according to indices from
the input along the given axis into the output tensor.
This is the inverse operation of GatherAlongAxis.
It is similar in functionality to the numpy.put_along_axis method.</p>
<p>Requires three inputs and produces one output. Three inputs, in order are
denoted as <code class="docutils literal notranslate"><span class="pre">&quot;container&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;indices&quot;</span></code>, and <code class="docutils literal notranslate"><span class="pre">&quot;updates&quot;</span></code>.</p>
<p>All inputs and output have the same rank.
Output shape is same as the shape of <code class="docutils literal notranslate"><span class="pre">'container'</span></code>.
Shapes of ‘indices’ and ‘updates’ match, which is same as the shape of
<code class="docutils literal notranslate"><span class="pre">'container'</span></code> except at the <code class="docutils literal notranslate"><span class="pre">'axis'</span></code> dimension.</p>
<p>Negative indices and negative axis are supported.</p>
<p>This operation performs the following operation for <code class="docutils literal notranslate"><span class="pre">axis=0</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">container</span>
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[for each vector index (i,j,....,k)
   output[index[i,j,....,k],j,....,k] = updates[i,j,....,k]\]</div>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">container</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">indices</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">updates</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ScatterAlongAxisLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">ScatterMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="stacklayerparams">
<h3>StackLayerParams<a class="headerlink" href="#stacklayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that stacks the input tensors along the given axis.
It is similar in functionality to the numpy.stack method.</p>
<p>Requires at least 2 inputs and produces 1 output.
All inputs must have the same shape.
Rank of the output is 1 greater than the rank of the inputs.</p>
<p>Negative indexing is supported for the “axis” parameter.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">number</span> <span class="n">of</span> <span class="n">inputs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">number</span> <span class="n">of</span> <span class="n">inputs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">StackLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="rankpreservingreshapelayerparams">
<h3>RankPreservingReshapeLayerParams<a class="headerlink" href="#rankpreservingreshapelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reshapes a tensor that does not alter the rank of the input.
Order of the data is left unchanged.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">targetShape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">40</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">targetShape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">targetShape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RankPreservingReshapeLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">targetShape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="constantpaddinglayerparams">
<h3>ConstantPaddingLayerParams<a class="headerlink" href="#constantpaddinglayerparams" title="Permalink to this headline">¶</a></h3>
<p>Constant padding layer.
Pad the input array with a constant value, either along a single given axis or along a set of axes.</p>
<p>Requires 1 or 2 inputs and produces 1 output.
The amount of padding can be either set as a parameter (“padAmounts”) or provided as a second input.</p>
<p>Output rank is same as the rank of the first input.</p>
<p>when “padToGivenOutputSizeMode” is False:</p>
<p>output_shape[i] = input_shape[i] + padAmounts[2*i] + padAmounts[2*i+1], i=0,…,rank-1</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">padAmounts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">14</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">padAmounts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">&quot;padToGivenOutputSizeMode&quot;</span></code> is True:</p>
<div class="math notranslate nohighlight">
\[output_shape[i] = max(input_shape[i], max(padAmounts[2*i] + padAmounts[2*i+1])), i=0,...,rank-1\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">padAmounts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span><span class="mi">14</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">padAmounts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">14</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ConstantPaddingLayerParams</span> <span class="p">{</span>
    <span class="kt">float</span> <span class="na">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">padAmounts</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">padToGivenOutputSizeMode</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomnormallikelayerparams">
<h3>RandomNormalLikeLayerParams<a class="headerlink" href="#randomnormallikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the normal distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the normal distribution.
mean: mean of the normal distribution.
stdDev: standard deviation of the normal distribution.</p>
</dd>
<dt>Input</dt><dd><p>An N-Dimensional tensor, whose values are ignored. Only the shape is used to
infer the shape of the output.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the same shape as the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomNormalLikeLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">mean</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">stdDev</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomnormalstaticlayerparams">
<h3>RandomNormalStaticLayerParams<a class="headerlink" href="#randomnormalstaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the normal distribution.</p>
<p>Requires no input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the normal distribution.
mean: mean of the normal distribution.
stdDev: standard deviation of the normal distribution.
outputShape: shape of the output tensor.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor of shape “outputShape”.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomNormalStaticLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">mean</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">stdDev</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">outputShape</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomnormaldynamiclayerparams">
<h3>RandomNormalDynamicLayerParams<a class="headerlink" href="#randomnormaldynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the normal distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>seed: seed used for the normal distribution.
mean: mean of the normal distribution.
stdDev: standard deviation of the normal distribution.</p>
</dd>
<dt>Input</dt><dd><p>A rank 1 tensor specifying the shape of the output</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the shape specified by the values in the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomNormalDynamicLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">mean</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">stdDev</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomuniformlikelayerparams">
<h3>RandomUniformLikeLayerParams<a class="headerlink" href="#randomuniformlikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the uniform distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the uniform distribution.
minVal: lower bound on the range of random values for the uniform distribution.
maxVal: upper bound on the range of random values for the uniform distribution.</p>
</dd>
<dt>Input</dt><dd><p>An N-Dimensional tensor, whose values are ignored. Only the shape is used to
infer the shape of the output.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the same shape as the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomUniformLikeLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">minVal</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">maxVal</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomuniformstaticlayerparams">
<h3>RandomUniformStaticLayerParams<a class="headerlink" href="#randomuniformstaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the uniform distribution.</p>
<p>Requires no input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the uniform distribution.
minVal: lower bound on the range of random values for the uniform distribution.
maxVal: upper bound on the range of random values for the uniform distribution.
outputShape: shape of the output tensor.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor of shape “outputShape”.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomUniformStaticLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">minVal</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">maxVal</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">outputShape</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randomuniformdynamiclayerparams">
<h3>RandomUniformDynamicLayerParams<a class="headerlink" href="#randomuniformdynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the uniform distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>seed: seed used for the uniform distribution.
minVal: lower bound on the range of random values for the uniform distribution.
maxVal: upper bound on the range of random values for the uniform distribution.</p>
</dd>
<dt>Input</dt><dd><p>A rank 1 tensor specifying the shape of the output</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the shape specified by the values in the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomUniformDynamicLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">minVal</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">maxVal</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randombernoullilikelayerparams">
<h3>RandomBernoulliLikeLayerParams<a class="headerlink" href="#randombernoullilikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the Bernoulli distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the Bernoulli distribution.
prob: probability of a 1 event.</p>
</dd>
<dt>Input</dt><dd><p>An N-Dimensional tensor, whose values are ignored. Only the shape is used to
infer the shape of the output.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the same shape as the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomBernoulliLikeLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">prob</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randombernoullistaticlayerparams">
<h3>RandomBernoulliStaticLayerParams<a class="headerlink" href="#randombernoullistaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the Bernoulli distribution.</p>
<p>Requires no input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>seed: seed used for the Bernoulli distribution.
prob: probability of a 1 event.
outputShape: shape of the output tensor.</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor of shape “outputShape”.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomBernoulliStaticLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">prob</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">outputShape</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="randombernoullidynamiclayerparams">
<h3>RandomBernoulliDynamicLayerParams<a class="headerlink" href="#randombernoullidynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor filled with values from the Bernoulli distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>seed: seed used for the Bernoulli distribution.
prob: probability of a 1 event.</p>
</dd>
<dt>Input</dt><dd><p>A rank 1 tensor specifying the shape of the output</p>
</dd>
<dt>Output</dt><dd><p>An N-Dimensional tensor with the shape specified by the values in the input tensor.</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RandomBernoulliDynamicLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">prob</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="categoricaldistributionlayerparams">
<h3>CategoricalDistributionLayerParams<a class="headerlink" href="#categoricaldistributionlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor of the specified shape filled with values from the categorical distribution.</p>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameter:</dt><dd><p>seed: seed used for the categorical distribution.
numSamples: number of samples to draw.
isLogits: true if the inputs are logits, false if the inputs are probabilities.
eps: default value is 1e-10.
temperature: default value is 1.0.</p>
</dd>
</dl>
<p>Input tensor shape = [D_1, D_2, … , D_(R-1), D_R] (Rank = R)
Then the shape of the output is [D_1, D_2, … , D_(R-1), numSamples] (Rank = R)</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CategoricalDistributionLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int64</span> <span class="na">numSamples</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">isLogits</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">eps</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">temperature</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducel1layerparams">
<h3>ReduceL1LayerParams<a class="headerlink" href="#reducel1layerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with L1 normalization operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceL1LayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducel2layerparams">
<h3>ReduceL2LayerParams<a class="headerlink" href="#reducel2layerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with L2 normalization operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceL2LayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducemaxlayerparams">
<h3>ReduceMaxLayerParams<a class="headerlink" href="#reducemaxlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with max operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceMaxLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reduceminlayerparams">
<h3>ReduceMinLayerParams<a class="headerlink" href="#reduceminlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with min operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceMinLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducesumlayerparams">
<h3>ReduceSumLayerParams<a class="headerlink" href="#reducesumlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with sum operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceSumLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reduceprodlayerparams">
<h3>ReduceProdLayerParams<a class="headerlink" href="#reduceprodlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with prod operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceProdLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducemeanlayerparams">
<h3>ReduceMeanLayerParams<a class="headerlink" href="#reducemeanlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with mean operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceMeanLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducelogsumlayerparams">
<h3>ReduceLogSumLayerParams<a class="headerlink" href="#reducelogsumlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with logSum operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceLogSumLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducesumsquarelayerparams">
<h3>ReduceSumSquareLayerParams<a class="headerlink" href="#reducesumsquarelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with logSumExp operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceSumSquareLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducelogsumexplayerparams">
<h3>ReduceLogSumExpLayerParams<a class="headerlink" href="#reducelogsumexplayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs reduction with logSumExp operation.</p>
<p>Negative indexing is supported.
Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><p>axes: dimensions along which to perform reduction
keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
reduceAll: ignore the “axes” parameter, perform reduction along all axes</p>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReduceLogSumExpLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">keepDims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">reduceAll</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="expanddimslayerparams">
<h3>ExpandDimsLayerParams<a class="headerlink" href="#expanddimslayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that increases the rank of the input tensor by adding unit dimensions.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ExpandDimsLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="flattento2dlayerparams">
<h3>FlattenTo2DLayerParams<a class="headerlink" href="#flattento2dlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that flattens the input tensor into a 2-dimensional matrix.</p>
<p>Requires 1 input and produces 1 output.
Output tensor is always rank 2.</p>
<p>First dimension of output is the product of all the dimensions in input[:axis] (“axis” is exclusive)
Second dimension of output is the product of all the dimensions in input[axis:] (“axis” is inclusive)</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="o">-</span><span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="o">-</span><span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="mi">0</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="o">-</span><span class="mi">2</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axis</span><span class="p">:</span>  <span class="o">-</span><span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FlattenTo2DLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reshapestaticlayerparams">
<h3>ReshapeStaticLayerParams<a class="headerlink" href="#reshapestaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reshapes a tensor.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output tensor is the reshaped version of the input and has shape as specified in the
parameter “targetShape”.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReshapeStaticLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">targetShape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reshapelikelayerparams">
<h3>ReshapeLikeLayerParams<a class="headerlink" href="#reshapelikelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reshapes a tensor.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>First input is reshaped to produce the output, while the second input is only
used to determine the shape of the output. Values of the second input are not used.</p>
<p>Output is a tensor with the same shape as the second input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReshapeLikeLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reshapedynamiclayerparams">
<h3>ReshapeDynamicLayerParams<a class="headerlink" href="#reshapedynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that reshapes a tensor.</p>
<p>Requires 2 inputs and produces 1 output.</p>
<p>First input is the one that is reshaped to produce the output.
Second input is a rank 1 tensor specifying the shape of the output.
Output tensor has shape as specified by the values in the 2nd input tensor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ReshapeDynamicLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="squeezelayerparams">
<h3>SqueezeLayerParams<a class="headerlink" href="#squeezelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that decreases the rank of the input tensor by removing unit dimensions.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output rank is one less than input rank, if input rank is more than 1.
If input rank is 1, output rank is also 1.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SqueezeLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">axes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">squeezeAll</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="c1">// if true squeeze all dimensions that are 1.</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="topklayerparams">
<h3>TopKLayerParams<a class="headerlink" href="#topklayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns top K (or bottom K) values and the corresponding indices
of the input along a given axis.</p>
<p>Requires 1 or 2 inputs and produces 2 outputs.</p>
<p>The second input is the value of the K, and is optional.
If there is only one input, value of K that is specified in the layer parameter is used.</p>
<p>Both outputs have the same rank as the first input.
Second input must correspond to a scalar tensor.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">first</span> <span class="nb">input</span><span class="s1">&#39;s shape = (45, 34, 10, 5)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">,</span> <span class="k">for</span> <span class="n">both</span> <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">TopKLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">K</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">useBottomK</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="argmaxlayerparams">
<h3>ArgMaxLayerParams<a class="headerlink" href="#argmaxlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns the indices of the maximum value along a specified axis in a tensor.</p>
<p>Requires 1 input and produces 1 output. Negative indexing is supported.</p>
<p>Output has the same rank as the input if “removeDim” is False (default).
Output has rank one less than the input if “removeDim” is True and input rank is more than 1.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">False</span> <span class="p">(</span><span class="n">default</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">False</span> <span class="ow">or</span> <span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ArgMaxLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">removeDim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="argminlayerparams">
<h3>ArgMinLayerParams<a class="headerlink" href="#argminlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns the indices of the minimum value along a specified axis in a tensor.</p>
<p>Requires 1 input and produces 1 output. Negative indexing is supported.</p>
<p>Output has the same rank as the input if “removeDim” is False (default).
Output has rank one less than the input if “removeDim” is True and input rank is more than 1.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">False</span> <span class="p">(</span><span class="n">default</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="k">if</span> <span class="n">removeDim</span> <span class="o">=</span> <span class="kc">False</span> <span class="ow">or</span> <span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ArgMinLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">removeDim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="splitndlayerparams">
<h3>SplitNDLayerParams<a class="headerlink" href="#splitndlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer layer that splits the input tensor into multiple output tensors,
along the specified axis.</p>
<p>The layer either uniformly splits the input tensor into <code class="docutils literal notranslate"><span class="pre">num_splits</span></code> tensors, or
splits according to the given split sizes in <code class="docutils literal notranslate"><span class="pre">split_sizes</span></code>.
Supports unequal splits and negative indexing.</p>
<p>Requires 1 input and produces at least 2 outputs.
Rank of all the outputs is same as that of the input.</p>
<p>If parameter “splitSizes” is provided, value of the parameter “numSplits” is ignored, since in that case
“numSplits” is automatically inferred to be the length of “splitSizes”.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="n">split_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SplitNDLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">numSplits</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">splitSizes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="ceillayerparams">
<h3>CeilLayerParams<a class="headerlink" href="#ceillayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise ceil operation on the input tensor that
rounds the value to the smallest integer not less than x.</p>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CeilLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="roundlayerparams">
<h3>RoundLayerParams<a class="headerlink" href="#roundlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise round operation on the input tensor
that rounds the value to the nearest integer.</p>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RoundLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="floorlayerparams">
<h3>FloorLayerParams<a class="headerlink" href="#floorlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise floor operation on the input tensor
that rounds the value to the largest integer not greater than x.</p>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">FloorLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="signlayerparams">
<h3>SignLayerParams<a class="headerlink" href="#signlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise sign operation (+1 for positive values,
-1 for negative values, 0 for zeros).</p>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SignLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="cliplayerparams">
<h3>ClipLayerParams<a class="headerlink" href="#cliplayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise clip operation. Clip the values in the
input tensor to the threshold values [min_value, max_value].</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Parameter minVal: the minimum threshold.
Parameter maxVal: the maximum threshold.</p>
<p>output =  min(max(input, minVal), maxVal)</p>
<p>Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ClipLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">minVal</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">maxVal</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slicestaticlayerparams">
<h3>SliceStaticLayerParams<a class="headerlink" href="#slicestaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that extracts a slice of size <code class="docutils literal notranslate"><span class="pre">(end</span> <span class="pre">-</span> <span class="pre">begin)</span> <span class="pre">/</span> <span class="pre">stride</span></code>
from the given input tensor.
Support negative indexing and negative strides.</p>
<p>Requires 1 input and produces 1 output.
Output rank is same as the input rank.</p>
<p>Value of beginIds, beginMasks, endIds, endMasks, strides are required parameters.
Lengths of all the parameters must equal the rank of the input.</p>
<p>i-th element of “beginIds” is ignored and assumed to be 0 if the i-th element of
“beginMasks” is True</p>
<p>i-th element of “endIds” is ignored and assumed to be -1 if the i-th element of
“endMasks” is True</p>
<p>For example: If i-th element of “squeezeMasks” is set to True, only beginIds[i] would be sliced
out, and all other masks and inputs are ignored.</p>
<p>(Without squeezeMasks):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">beginIds</span><span class="p">:</span>  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">beginMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="n">endIds</span><span class="p">:</span>  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">endMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="n">strides</span><span class="p">:</span>  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">SqueezeMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">This</span> <span class="ow">is</span> <span class="n">equivalent</span> <span class="n">to</span> <span class="nb">input</span><span class="p">[:</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>(With squeezeMasks):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">beginIds</span><span class="p">:</span>  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">beginMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="n">endIds</span><span class="p">:</span>  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">endMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="n">strides</span><span class="p">:</span>  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">SqueezeMasks</span><span class="p">:</span>  <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span><span class="p">:</span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">This</span> <span class="ow">is</span> <span class="n">equivalent</span> <span class="n">to</span> <span class="nb">input</span><span class="p">[:</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SliceStaticLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">beginIds</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">beginMasks</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">endIds</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">endMasks</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">strides</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">squeezeMasks</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>


<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slicedynamiclayerparams">
<h3>SliceDynamicLayerParams<a class="headerlink" href="#slicedynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that extracts a slice of size <code class="docutils literal notranslate"><span class="pre">(end</span> <span class="pre">-</span> <span class="pre">begin)</span> <span class="pre">/</span> <span class="pre">stride</span></code>
from the given input tensor.
Support negative indexing and negative strides.
See “SliceStaticLayerParams” for the description and an example of the functionality of the layer.</p>
<p>Requires 2 to 7 inputs and produces 1 output.
Rank of the output is same as the rank of the first input unless squeezeMask is set.</p>
<p>Value of beginIds, beginMasks, endIds, endMasks, strides can be passed in either
as dynamic inputs or as static parameters.
Lengths of all the parameters or inputs from 2-6 must equal the rank of the first input.</p>
<p>The 2nd input represents the “beginIds”.
The 3rd input, if present, corresponds to “endIds”. In this case the value of the “endIds” parameter is ignored.
The 4th input, if present, corresponds to “strides”. In this case the value of the “strides” parameter is ignored.
The 5th input, if present, corresponds to “beginMasks”. In this case the value of the “beginMasks” parameter is ignored.
The 6th input, if present, corresponds to “endMasks”. In this case the value of the “endMasks” parameter is ignored.
The 7th input, if present, corresponds to “squeezeMasks”. In this case the value of the “squeezeMasks” parameter is ignored.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SliceDynamicLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">beginMasks</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">endIds</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">endMasks</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">strides</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="kt">bool</span> <span class="na">squeezeMasks</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="tilelayerparams">
<h3>TileLayerParams<a class="headerlink" href="#tilelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that constructs a tensor by repeating the input tensor multiple
number of times.</p>
<p>Requires 1 or 2 inputs and produces 1 output.
Output rank is same as the input rank.</p>
<p>If two inputs are provided, second input is used as “reps”
and “reps” parameter is ignored.</p>
<p>If only one input is provided,
length of the “reps” parameter must be at least 1 and
not greater than the rank of the input.
If it is less than the input rank, it is made equal to the input rank by prepending 1’s to it.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">reps</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">reps</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">reps</span> <span class="n">after</span> <span class="n">prepending</span> <span class="n">ones</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">second</span> <span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span> <span class="o">-&gt;</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">reps</span> <span class="o">=</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="p">[</span><span class="n">Ignored</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">TileLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">uint64</span> <span class="na">reps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="getshapelayerparams">
<h3>GetShapeLayerParams<a class="headerlink" href="#getshapelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns the shape of an input tensor.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Input: a tensor.
Output: a vector of length R, where R is the rank of the input tensor
Output is always a rank 1 tensor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GetShapeLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="erflayerparams">
<h3>ErfLayerParams<a class="headerlink" href="#erflayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that computes the Gauss error function,
which is defined as:</p>
<div class="math notranslate nohighlight">
\[f(x) = \dfrac{1}{\sqrt{\pi}}\int_{-x}^{x}{e^{-t^2}dt}\]</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ErfLayerParams</span> <span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="gelulayerparams">
<h3>GeluLayerParams<a class="headerlink" href="#gelulayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that evaluates the Gaussian Error Linear Unit (GELU) activation.
Following equations are used to compute the activation based on the value of the “mode” parameter:</p>
<p><code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">==</span> <span class="pre">'EXACT'</span></code>:</p>
<div class="math notranslate nohighlight">
\[f(x) = 0.5x\left ( 1+\rm{erf}\left ( \frac{x}{\sqrt{2}} \right ) \right )\]</div>
<p><code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">==</span> <span class="pre">'TANH_APPROXIMATION'</span></code>:</p>
<div class="math notranslate nohighlight">
\[f(x) = 0.5x\left ( 1+\rm{tanh}\left ( \sqrt{2/\pi}\left ( x + 0.044715x^3 \right ) \right ) \right )\]</div>
<p><code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">==</span> <span class="pre">'SIGMOID_APPROXIMATION'</span></code>:</p>
<div class="math notranslate nohighlight">
\[f(x) = x*\rm{sigmoid}(1.702x)\]</div>
<p>Requires 1 input and produces 1 output.
Output shape is same as the input.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">GeluLayerParams</span> <span class="p">{</span>

    <span class="kd">enum</span> <span class="n">GeluMode</span> <span class="p">{</span>

        <span class="na">EXACT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="na">TANH_APPROXIMATION</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="na">SIGMOID_APPROXIMATION</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="p">}</span>

    <span class="n">GeluMode</span> <span class="na">mode</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="rangestaticlayerparams">
<h3>RangeStaticLayerParams<a class="headerlink" href="#rangestaticlayerparams" title="Permalink to this headline">¶</a></h3>
<p>RangeStatic layer that returns a tensor that contains evenly spaced values.
It is similar in functionality to the numpy.arange method.</p>
<p>Requires no input and produces 1 output.
Output is a rank 1 tensor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RangeStaticLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">endValue</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">startValue</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">stepSizeValue</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="rangedynamiclayerparams">
<h3>RangeDynamicLayerParams<a class="headerlink" href="#rangedynamiclayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor that contains evenly spaced values.
Its functionality is similar to the numpy.arange method.</p>
<p>Requires at least 1 input, up to a maximum of 3 inputs.
Produces 1 output, which is a rank 1 tensor.</p>
<p>Each input must be a scalar, or rank 1 and shape (1,).</p>
<p>The first input represents the “endValue”.
The second input, if present, corresponds to “startValue”. In this case the value of the “startValue” parameter is ignored.
The third input, if present, corresponds to “stepSizeValue”. In this case the value of the “stepSizeValue” parameter is ignored.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">RangeDynamicLayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">startValue</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">stepSizeValue</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slidingwindowslayerparams">
<h3>SlidingWindowsLayerParams<a class="headerlink" href="#slidingwindowslayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns a tensor containing all windows of size <code class="docutils literal notranslate"><span class="pre">windowSize</span></code>
separated by <code class="docutils literal notranslate"><span class="pre">step</span></code> along the dimension <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">SlidingWindows</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Requires 1 input and produces 1 output.</p>
<dl class="simple">
<dt>Input</dt><dd><p>An N-Dimensional tensor.</p>
</dd>
<dt>Output</dt><dd><p>An (N+1)-Dimensional tensor.</p>
</dd>
<dt>This operation behaves as follows:</dt><dd><ul class="simple">
<li><p>if axis = 0 &amp; input is rank 1 (L,).
Output shape will be <code class="docutils literal notranslate"><span class="pre">(M,</span> <span class="pre">W)</span></code>.</p></li>
<li><p>if axis = 1 &amp; input is rank 3 (B1, L, C1).
Output shape will be <code class="docutils literal notranslate"><span class="pre">(B1,</span> <span class="pre">M,</span> <span class="pre">W,</span> <span class="pre">C1)</span></code>.</p></li>
<li><p>if axis = 2 &amp; input is rank 5
<code class="docutils literal notranslate"><span class="pre">(B1,</span> <span class="pre">B2,</span> <span class="pre">L,</span> <span class="pre">C1,</span> <span class="pre">C2)</span> <span class="pre">--&gt;</span> <span class="pre">(B1</span> <span class="pre">*</span> <span class="pre">B2,</span> <span class="pre">L,</span> <span class="pre">C1</span> <span class="pre">*</span> <span class="pre">C2)</span> <span class="pre">--&gt;</span> <span class="pre">(B1</span> <span class="pre">*</span> <span class="pre">B2,</span> <span class="pre">M,</span> <span class="pre">W,</span> <span class="pre">C1</span> <span class="pre">*</span> <span class="pre">C2)</span></code>.
Output shape will be <code class="docutils literal notranslate"><span class="pre">(B1,</span> <span class="pre">B2,</span> <span class="pre">M,</span> <span class="pre">W,</span> <span class="pre">C1,</span> <span class="pre">C2)</span></code>.</p></li>
<li><p>And so on.</p></li>
<li><dl class="simple">
<dt>Where:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">L</span></code>, <code class="docutils literal notranslate"><span class="pre">C</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code> refer to input length, feature dimension length,
and batch size respectively.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">W</span></code> is the window size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">M</span></code> is the number of windows/slices calculated as <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">=</span> <span class="pre">(L</span> <span class="pre">-</span> <span class="pre">W)</span> <span class="pre">/</span> <span class="pre">step</span> <span class="pre">+</span> <span class="pre">1</span></code>.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SlidingWindowsLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">windowSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">uint64</span> <span class="na">step</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="layernormalizationlayerparams">
<h3>LayerNormalizationLayerParams<a class="headerlink" href="#layernormalizationlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that applies layer normalization over the input tensor.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>output = gamma * (input - computed_mean) / (sqrt(computed_variance + eps)) + beta</p>
<dl class="simple">
<dt>Parameters</dt><dd><p>normalizedShape: subset of the input shape, along with layer norm is performed, rest of the input shape is treated as the batch dimension. The mean and variance are computed for the input, over the last few dimensions as specified by the normalizedShape parameter.
gamma: must have shape = “normalizedShape”
beta: must have shape = “normalizedShape”
eps: small constant to avoid division by 0</p>
</dd>
</dl>
<p>Output shape is same as the input.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">normalized</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">normalized</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,)</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LayerNormalizationLayerParams</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="kt">int64</span> <span class="na">normalizedShape</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">eps</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">gamma</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">WeightParams</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="nonmaximumsuppressionlayerparams">
<h3>NonMaximumSuppressionLayerParams<a class="headerlink" href="#nonmaximumsuppressionlayerparams" title="Permalink to this headline">¶</a></h3>
<p>Non maximum suppression (NMS) layer.</p>
<p>Applies the non maximum suppression algorithm to input bounding box coordinates.</p>
<p>The effect of this layer is similar to the functionality of the “NonMaximumSuppression”
model type (for details please see NonMaximumSuppression.proto) with a couple of
differences:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>This is a layer in a neural network model, whereas that is a
different model type.</p></li>
<li><p>This layer supports a batch of bounding boxes.</p></li>
</ol>
</div></blockquote>
<p>The NMS layer requires at least 2 inputs, and up to a maximum of 5 inputs. It
produces 4 outputs.</p>
<p>Following is the description of inputs and outputs:</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">1,</span> <span class="pre">shape</span> <span class="pre">(B,N,4)</span></code>: coordinates of N boxes, for a batch size B.</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">2,</span> <span class="pre">shape</span> <span class="pre">(B,N,C)</span></code>: class scores for each box. C can be 1 when there is
only 1 score per box, i.e., no class specific score.</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">3,</span> <span class="pre">optional,</span> <span class="pre">shape</span> <span class="pre">(1,)</span></code>: IoU threshold. When present, it overwrites the
value provided in layer parameter <code class="docutils literal notranslate"><span class="pre">&quot;iouThreshold&quot;</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">4,</span> <span class="pre">optional,</span> <span class="pre">shape</span> <span class="pre">(1,)</span></code>: Score threshold. When present, it overwrites the
value provided in layer parameter <code class="docutils literal notranslate"><span class="pre">&quot;scoreThreshold&quot;</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">5,</span> <span class="pre">optional,</span> <span class="pre">shape</span> <span class="pre">(1,)</span></code>: Maximum number of boxes. When present, it
overwrites the value provided in layer parameter <code class="docutils literal notranslate"><span class="pre">&quot;maxBoxes&quot;</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">1,</span> <span class="pre">shape</span> <span class="pre">(B,maxBoxes,4)</span></code>: box coordinates, corresponding to the surviving
boxes.</p>
<p><code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">2,</span> <span class="pre">shape</span> <span class="pre">(B,maxBoxes,C)</span></code>: box scores, corresponding to the surviving boxes.</p>
<p><code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">3,</span> <span class="pre">shape</span> <span class="pre">(B,maxBoxes)</span></code>: indices of the surviving boxes. Hence it will have
values in the range <code class="docutils literal notranslate"><span class="pre">[0,N-1]</span></code>, except for padding.</p>
<p><code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">4,</span> <span class="pre">shape</span> <span class="pre">(B,)</span></code>: number of boxes selected after the NMS algorithm, for each
batch.</p>
<p>When surviving boxes are less than <code class="docutils literal notranslate"><span class="pre">&quot;maxBoxes&quot;</span></code>, the first 3 outputs are padded.
For the first two outputs, the padding is done using values 0, whereas for the
third output the padding value used is -1, since the output values represent indices.</p>
<p>If no box survives, that is, all the scores are below the <code class="docutils literal notranslate"><span class="pre">&quot;scoreThreshold&quot;</span></code>,
then for that batch, number of boxes (value of the fourth output) will be 1.
The first 3 outputs will correspond to the box with the highest score.
This is to avoid generating an “empty” output.</p>
<p>The four values that describe the box dimensions are (in order):</p>
<blockquote>
<div><ul class="simple">
<li><p>x (center location of the box along the horizontal axis)</p></li>
<li><p>y (center location of the box along the vertical axis)</p></li>
<li><p>width (size of box along the horizontal axis)</p></li>
<li><p>height (size of box on along the vertical axis)</p></li>
</ul>
</div></blockquote>
<p>In each batch, the N scores for N boxes, used for suppression, are generated by
taking the max of the matrix (N,C) along the columns.</p>
<p>If “perClassSuppression” flag is false, suppression happens across all classes.
If “perClassSuppression” flag is true, each box is assigned to the class with
the highest score and then the suppression happens separately for boxes within
the same class.</p>
<p>Note that the 4th output can be used to dynamically slice the first 3 outputs,
in case the padded outputs are not required.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NonMaximumSuppressionLayerParams</span> <span class="p">{</span>
    <span class="kt">float</span> <span class="na">iouThreshold</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">float</span> <span class="na">scoreThreshold</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">uint64</span> <span class="na">maxBoxes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">perClassSuppression</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="clampedrelulayerparams">
<h3>ClampedReLULayerParams<a class="headerlink" href="#clampedrelulayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that performs element-wise clamped ReLU operation.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>This function has the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(x) = \begin{cases}
          \text{min}(\text{beta},x) \;\; \text{if} \;\; x \geq 0\\
          \text{min}(\text{beta} ,\text{alpha}\cdot x) \;\; \text{if} \;\; x&lt;0
       \end{cases}\end{split}\]</div>
<p>Output shape is same as the input.</p>
<p>Available (iOS &gt;= 14, macOS &gt;= 11.0, watchOS &gt;= 7)</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ClampedReLULayerParams</span> <span class="p">{</span>

    <span class="kt">float</span> <span class="na">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">beta</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="argsortlayerparams">
<h3>ArgSortLayerParams<a class="headerlink" href="#argsortlayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that returns the indices that would sort the input tensor, along a specified axis.</p>
<p>Requires 1 input and produces 1 output.</p>
<p>Output has the same rank and shape as the input.</p>
<p>Value of “axis” must be positive and less than the rank of the input.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">input</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.1</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">,</span> <span class="mf">32.9</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">77.0</span><span class="p">]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)</span>
<span class="n">output</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">descending</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">output</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">descending</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">input</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">descending</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">output</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">descending</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">ArgSortLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="na">descending</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slicebysizelayerparams">
<h3>SliceBySizeLayerParams<a class="headerlink" href="#slicebysizelayerparams" title="Permalink to this headline">¶</a></h3>
<p>A layer that does slice operation by providing size to be extracted
from the given input tensor.</p>
<p>Requires 2 inputs and produces 1 output.
Rank of the output is same as the rank of the first input.</p>
<p>The 1st input represents the tensor to be sliced.
The 2nd input represents the beginning index to be sliced from.</p>
<p>Example:
Input 1: x (x.shape = (2, 3, 4))
Input 2: begin
size: 2
axis: 1</p>
<p>Output: x[:, begin:begin+2, :]</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SliceBySizeLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="neural-network-specializations">
<h2>Neural Network Specializations<a class="headerlink" href="#neural-network-specializations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="neuralnetworkclassifier">
<h3>NeuralNetworkClassifier<a class="headerlink" href="#neuralnetworkclassifier" title="Permalink to this headline">¶</a></h3>
<p>A neural network specialized as a classifier.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkClassifier</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="n">NeuralNetworkLayer</span> <span class="na">layers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="n">NeuralNetworkPreprocessing</span> <span class="na">preprocessing</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs</span>
    <span class="n">NeuralNetworkMultiArrayShapeMapping</span> <span class="na">arrayInputShapeMapping</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for image inputs</span>
    <span class="n">NeuralNetworkImageShapeMapping</span> <span class="na">imageInputShapeMapping</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

    <span class="n">NetworkUpdateParameters</span> <span class="na">updateParams</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="c1">// The set of labels for every possible class.</span>
    <span class="k">oneof</span> <span class="n">ClassLabels</span> <span class="p">{</span>
        <span class="n">StringVector</span> <span class="na">stringClassLabels</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
        <span class="n">Int64Vector</span> <span class="na">int64ClassLabels</span> <span class="o">=</span> <span class="mi">101</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// The name of the output blob containing the probability of each class.</span>
    <span class="c1">// In other words, the score vector. Must be a 1-D tensor with the same</span>
    <span class="c1">// number and order of elements as ClassLabels.</span>
    <span class="kt">string</span> <span class="na">labelProbabilityLayerName</span> <span class="o">=</span> <span class="mi">200</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="onehotlayerparams">
<h3>OneHotLayerParams<a class="headerlink" href="#onehotlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">OneHotLayerParams</span> <span class="p">{</span>

    <span class="kt">uint64</span> <span class="na">oneHotVectorSize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">onValue</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="kt">float</span> <span class="na">offValue</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="cumsumlayerparams">
<h3>CumSumLayerParams<a class="headerlink" href="#cumsumlayerparams" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CumSumLayerParams</span> <span class="p">{</span>

    <span class="kt">int64</span> <span class="na">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">excludeFinalSum</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="kt">bool</span> <span class="na">reverse</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworkregressor">
<h3>NeuralNetworkRegressor<a class="headerlink" href="#neuralnetworkregressor" title="Permalink to this headline">¶</a></h3>
<p>A neural network specialized as a regressor.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NeuralNetworkRegressor</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="n">NeuralNetworkLayer</span> <span class="na">layers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">repeated</span> <span class="n">NeuralNetworkPreprocessing</span> <span class="na">preprocessing</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs</span>
    <span class="n">NeuralNetworkMultiArrayShapeMapping</span> <span class="na">arrayInputShapeMapping</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

    <span class="c1">// use this enum value to determine the input tensor shapes to the neural network, for image inputs</span>
    <span class="n">NeuralNetworkImageShapeMapping</span> <span class="na">imageInputShapeMapping</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

    <span class="n">NetworkUpdateParameters</span> <span class="na">updateParams</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="on-device-training-messages">
<h2>On-device Training Messages<a class="headerlink" href="#on-device-training-messages" title="Permalink to this headline">¶</a></h2>
<div class="section" id="networkupdateparameters">
<h3>NetworkUpdateParameters<a class="headerlink" href="#networkupdateparameters" title="Permalink to this headline">¶</a></h3>
<p>Details on how the network will be updated</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">NetworkUpdateParameters</span> <span class="p">{</span>

    <span class="k">repeated</span> <span class="n">LossLayer</span> <span class="na">lossLayers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">Optimizer</span> <span class="na">optimizer</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">Int64Parameter</span> <span class="na">epochs</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="n">BoolParameter</span> <span class="na">shuffle</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

    <span class="n">Int64Parameter</span> <span class="na">seed</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="losslayer">
<h3>LossLayer<a class="headerlink" href="#losslayer" title="Permalink to this headline">¶</a></h3>
<p>Loss layer - categorical cross entropy and mean squared error are the only supported loss functions currently</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">LossLayer</span> <span class="p">{</span>

    <span class="kt">string</span> <span class="na">name</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">oneof</span> <span class="n">LossLayerType</span> <span class="p">{</span>

        <span class="n">CategoricalCrossEntropyLossLayer</span> <span class="na">categoricalCrossEntropyLossLayer</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="n">MeanSquaredErrorLossLayer</span> <span class="na">meanSquaredErrorLossLayer</span> <span class="o">=</span> <span class="mi">11</span><span class="p">;</span>

    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="categoricalcrossentropylosslayer">
<h3>CategoricalCrossEntropyLossLayer<a class="headerlink" href="#categoricalcrossentropylosslayer" title="Permalink to this headline">¶</a></h3>
<p>Categorical cross entropy loss layer is used for single label categorization
(only one category is applicable for each data point).</p>
<p>The input is a vector of length N representing the distribution over <code class="docutils literal notranslate"><span class="pre">N</span></code>
categories.  It must be the output of a softmax.</p>
<p>The target is a single value representing the true category or class label.
If the target is the predictedFeatureName of a neural network classifier it will
be inverse mapped to the corresponding categorical index for you.</p>
<div class="math notranslate nohighlight">
\[Loss_{CCE}(input, target) = -\sum_{i=1}^{N} (target == i) log( input[i] ) = - log (input[target])\]</div>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">CategoricalCrossEntropyLossLayer</span> <span class="p">{</span>

    <span class="kt">string</span> <span class="na">input</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">string</span> <span class="na">target</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="meansquarederrorlosslayer">
<h3>MeanSquaredErrorLossLayer<a class="headerlink" href="#meansquarederrorlosslayer" title="Permalink to this headline">¶</a></h3>
<p>Mean squared error loss layer,
specifying input and target</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">MeanSquaredErrorLossLayer</span> <span class="p">{</span>

    <span class="kt">string</span> <span class="na">input</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">string</span> <span class="na">target</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="optimizer">
<h3>Optimizer<a class="headerlink" href="#optimizer" title="Permalink to this headline">¶</a></h3>
<p>Optimizer - stochastic gradient descent and adam are the only supported optimizers currently</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">Optimizer</span> <span class="p">{</span>

    <span class="k">oneof</span> <span class="n">OptimizerType</span> <span class="p">{</span>

        <span class="n">SGDOptimizer</span> <span class="na">sgdOptimizer</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="n">AdamOptimizer</span> <span class="na">adamOptimizer</span> <span class="o">=</span> <span class="mi">11</span><span class="p">;</span>

    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sgdoptimizer">
<h3>SGDOptimizer<a class="headerlink" href="#sgdoptimizer" title="Permalink to this headline">¶</a></h3>
<p>Stochastic gradient descent optimizer,
specifying configurable learning rate, mini batch size, and momentum</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">SGDOptimizer</span> <span class="p">{</span>

    <span class="n">DoubleParameter</span> <span class="na">learningRate</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">Int64Parameter</span> <span class="na">miniBatchSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">DoubleParameter</span> <span class="na">momentum</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="adamoptimizer">
<h3>AdamOptimizer<a class="headerlink" href="#adamoptimizer" title="Permalink to this headline">¶</a></h3>
<p>Adam optimizer,
specifying configurable learning rate, mini batch size, betas, and eps</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">message</span> <span class="nc">AdamOptimizer</span> <span class="p">{</span>

    <span class="n">DoubleParameter</span> <span class="na">learningRate</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">Int64Parameter</span> <span class="na">miniBatchSize</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">DoubleParameter</span> <span class="na">beta1</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">DoubleParameter</span> <span class="na">beta2</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="n">DoubleParameter</span> <span class="na">eps</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="convolution3dlayerparams-paddingtype">
<h3>Convolution3DLayerParams.PaddingType<a class="headerlink" href="#convolution3dlayerparams-paddingtype" title="Permalink to this headline">¶</a></h3>
<p>The type of padding.
All padding types pad the input shape with zeros.
CUSTOM padding will add the custom padding values specified below to their respective
dimensions, e.g., <cite>customPaddingFront</cite> number of zeros will be added to one side of the
input’s depth dimension and <cite>customPaddingBack</cite> number of zeros will be added to the other
side of the input’s depth dimension.
VALID padding adds no padding to any dimension. In this case, the last convolution along
each dimension will be dropped if the input dimension and the kernel size, stride, and
dilation do not match.
SAME padding adds enough padding to each dimension such that the output of the convolution
has size <code class="docutils literal notranslate"><span class="pre">Ceiling(inputShape</span> <span class="pre">/</span> <span class="pre">stride)</span></code>. Padding is added evenly to both sides of each
dimension unless the total padding to add is odd, in which case it is added to the
back/bottom/right side of the respective dimension. For example, if the total padding needed
in the depth dimension is 3, 1 zero will be added to the front side of the depth dimension
and 2 zeros will be added to the back side.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">PaddingType</span> <span class="p">{</span>
    <span class="na">CUSTOM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">VALID</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">SAME</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="flattenlayerparams-flattenorder">
<h3>FlattenLayerParams.FlattenOrder<a class="headerlink" href="#flattenlayerparams-flattenorder" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">FlattenOrder</span> <span class="p">{</span>

    <span class="na">CHANNEL_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">CHANNEL_LAST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="gelulayerparams-gelumode">
<h3>GeluLayerParams.GeluMode<a class="headerlink" href="#gelulayerparams-gelumode" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">GeluMode</span> <span class="p">{</span>

    <span class="na">EXACT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">TANH_APPROXIMATION</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">SIGMOID_APPROXIMATION</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="globalpooling3dlayerparams-globalpoolingtype3d">
<h3>GlobalPooling3DLayerParams.GlobalPoolingType3D<a class="headerlink" href="#globalpooling3dlayerparams-globalpoolingtype3d" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">GlobalPoolingType3D</span> <span class="p">{</span>
    <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworkimageshapemapping">
<h3>NeuralNetworkImageShapeMapping<a class="headerlink" href="#neuralnetworkimageshapemapping" title="Permalink to this headline">¶</a></h3>
<p>Describes how the shape of the input tensors is constructed from image inputs.</p>
<p>In this case, image input is mapped to a rank 5 tensor.</p>
<ul class="simple">
<li><p>For Color images, input tensor is shaped as [1,1,3,H,W].</p></li>
<li><p>For Gray images, input tensor is shaped as [1,1,1,H,W].</p></li>
</ul>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">NeuralNetworkImageShapeMapping</span> <span class="p">{</span>

    <span class="na">RANK5_IMAGE_MAPPING</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>


<span class="p">}</span>
</pre></div>
</div>
<p>For Color images, input tensor is shaped as [1,3,H,W].
For Gray images, input tensor is shaped as [1,1,H,W].
Supported only for Specification version &gt;= 4 (iOS &gt;= 13, macOS &gt;= 10.15).</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">NeuralNetworkImageShapeMapping</span> <span class="p">{</span>

    <span class="na">RANK4_IMAGE_MAPPING</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="neuralnetworkmultiarrayshapemapping">
<h3>NeuralNetworkMultiArrayShapeMapping<a class="headerlink" href="#neuralnetworkmultiarrayshapemapping" title="Permalink to this headline">¶</a></h3>
<p>Describes how the MultiArray shape for the inputs,
provided in Features Types proto via model description,
is mapped to construct tensors that are fed into the Neural Network layers.</p>
<p>Default legacy value. Only supported for Core ML Specification version &lt;= 3.</p>
<p>The default legacy shape mapping resolves all input shapes to a rank 5 equivalent
with axis notation of [Seq, Batch, Channel, Height, Width].</p>
<p>When this enum value is selected,
the repeated shape field in the message “ArrayFeatureType” in feature types
proto, must be either length 1 or length 3.</p>
<p>The following rule is used to map the values in the shape field to the actual
tensor shape:</p>
<ul class="simple">
<li><p>rank 1 shape is mapped to shape [1,1,C,1,1]</p></li>
<li><p>rank 3 shape is mapped to shape [1,1,C,H,W]</p></li>
</ul>
<p>At runtime, the first two dimensions (Seq or Batch) can be presented as well,
with non-1 values.</p>
<p>It is invalid to use this enum value if any of the layers added
Specification version 4 (iOS &gt;= 13, macOS &gt;= 10.15) onwards are used in the
network. Validator will raise an error in that case.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">NeuralNetworkMultiArrayShapeMapping</span> <span class="p">{</span>

    <span class="na">RANK5_ARRAY_MAPPING</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
<p>The exact shape and rank (i.e. number of dimensions in the shape) of the input,
as specified in the message “ArrayFeatureType”, is passed through to the layers.
Supported only for Specification version &gt;= 4 (iOS &gt;= 13, macOS &gt;= 10.15).</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">NeuralNetworkMultiArrayShapeMapping</span> <span class="p">{</span>

    <span class="na">EXACT_ARRAY_MAPPING</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="pooling3dlayerparams-pooling3dpaddingtype">
<h3>Pooling3DLayerParams.Pooling3DPaddingType<a class="headerlink" href="#pooling3dlayerparams-pooling3dpaddingtype" title="Permalink to this headline">¶</a></h3>
<p>The type of padding.
All padding types pad the input shape with zeros.
CUSTOM padding will add the custom padding values specified below to their respective
dimensions, e.g., <cite>customPaddingFront</cite> number of zeros will be added to one side of the
input’s depth dimension and <cite>customPaddingBack</cite> number of zeros will be added to the other
side of the input’s depth dimension.
VALID padding adds no padding to any dimension. In this case, the last pool along
each dimension will be dropped if the input dimension and the kernel size, and stride do not match.
SAME padding adds enough padding to each dimension such that the output
has the same spatial dimensions as the input. Padding is added evenly to both
sides of each dimension unless the total padding to add is odd, in which case the extra padding
is added to the back/bottom/right side of the respective dimension.  For example, if the the
total horizontal padding is 3, then there will be 1 padding on the left, and 2 padding on the right.</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">Pooling3DPaddingType</span> <span class="p">{</span>
    <span class="na">CUSTOM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">VALID</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">SAME</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="pooling3dlayerparams-poolingtype3d">
<h3>Pooling3DLayerParams.PoolingType3D<a class="headerlink" href="#pooling3dlayerparams-poolingtype3d" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">PoolingType3D</span> <span class="p">{</span>
    <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="poolinglayerparams-poolingtype">
<h3>PoolingLayerParams.PoolingType<a class="headerlink" href="#poolinglayerparams-poolingtype" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">PoolingType</span> <span class="p">{</span>

    <span class="na">MAX</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">AVERAGE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">L2</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducelayerparams-reduceaxis">
<h3>ReduceLayerParams.ReduceAxis<a class="headerlink" href="#reducelayerparams-reduceaxis" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">ReduceAxis</span> <span class="p">{</span>

    <span class="na">CHW</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">HW</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">C</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="na">H</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="na">W</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reducelayerparams-reduceoperation">
<h3>ReduceLayerParams.ReduceOperation<a class="headerlink" href="#reducelayerparams-reduceoperation" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">ReduceOperation</span> <span class="p">{</span>

    <span class="na">SUM</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">AVG</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">PROD</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="na">LOGSUM</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="na">SUMSQUARE</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="na">L1</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="na">L2</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
    <span class="na">MAX</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>
    <span class="na">MIN</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
    <span class="na">ARGMAX</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reorganizedatalayerparams-reorganizationtype">
<h3>ReorganizeDataLayerParams.ReorganizationType<a class="headerlink" href="#reorganizedatalayerparams-reorganizationtype" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">ReorganizationType</span> <span class="p">{</span>

    <span class="na">SPACE_TO_DEPTH</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">DEPTH_TO_SPACE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">PIXEL_SHUFFLE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="reshapelayerparams-reshapeorder">
<h3>ReshapeLayerParams.ReshapeOrder<a class="headerlink" href="#reshapelayerparams-reshapeorder" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">ReshapeOrder</span> <span class="p">{</span>

    <span class="na">CHANNEL_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">CHANNEL_LAST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="samepadding-samepaddingmode">
<h3>SamePadding.SamePaddingMode<a class="headerlink" href="#samepadding-samepaddingmode" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">SamePaddingMode</span> <span class="p">{</span>

    <span class="na">BOTTOM_RIGHT_HEAVY</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">TOP_LEFT_HEAVY</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="samplingmode-method">
<h3>SamplingMode.Method<a class="headerlink" href="#samplingmode-method" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">Method</span> <span class="p">{</span>

    <span class="na">STRICT_ALIGN_ENDPOINTS_MODE</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="na">ALIGN_ENDPOINTS_MODE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="na">UPSAMPLE_MODE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="na">ROI_ALIGN_MODE</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="boxcoordinatesmode-coordinates">
<h3>BoxCoordinatesMode.Coordinates<a class="headerlink" href="#boxcoordinatesmode-coordinates" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">Coordinates</span> <span class="p">{</span>

    <span class="na">CORNERS_HEIGHT_FIRST</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="na">CORNERS_WIDTH_FIRST</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="na">CENTER_SIZE_HEIGHT_FIRST</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

    <span class="na">CENTER_SIZE_WIDTH_FIRST</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="scattermode">
<h3>ScatterMode<a class="headerlink" href="#scattermode" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">ScatterMode</span> <span class="p">{</span>

    <span class="na">SCATTER_UPDATE</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">SCATTER_ADD</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">SCATTER_SUB</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="na">SCATTER_MUL</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="na">SCATTER_DIV</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="na">SCATTER_MAX</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="na">SCATTER_MIN</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="slicelayerparams-sliceaxis">
<h3>SliceLayerParams.SliceAxis<a class="headerlink" href="#slicelayerparams-sliceaxis" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">SliceAxis</span> <span class="p">{</span>

    <span class="na">CHANNEL_AXIS</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">HEIGHT_AXIS</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">WIDTH_AXIS</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="unaryfunctionlayerparams-operation">
<h3>UnaryFunctionLayerParams.Operation<a class="headerlink" href="#unaryfunctionlayerparams-operation" title="Permalink to this headline">¶</a></h3>
<p>A unary operator.</p>
<p>The following functions are supported:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">SQRT</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = \sqrt{x}\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">RSQRT</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = \dfrac{1}{\sqrt{x + \epsilon}}\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">INVERSE</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = \dfrac{1}{x + \epsilon}\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">POWER</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = x^\alpha\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">EXP</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = e^x\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">LOG</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = \log x\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">ABS</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = |x|\]</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">THRESHOLD</span></code></dt><dd><div class="math notranslate nohighlight">
\[f(x) = \text{max}(\alpha, x)\]</div>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">Operation</span> <span class="p">{</span>
    <span class="na">SQRT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">RSQRT</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">INVERSE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="na">POWER</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="na">EXP</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="na">LOG</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="na">ABS</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
    <span class="na">THRESHOLD</span> <span class="o">=</span> <span class="mi">7</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="upsamplelayerparams-interpolationmode">
<h3>UpsampleLayerParams.InterpolationMode<a class="headerlink" href="#upsamplelayerparams-interpolationmode" title="Permalink to this headline">¶</a></h3>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">InterpolationMode</span> <span class="p">{</span>

    <span class="na">NN</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">BILINEAR</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="upsamplelayerparams-linearupsamplemode">
<h3>UpsampleLayerParams.LinearUpsampleMode<a class="headerlink" href="#upsamplelayerparams-linearupsamplemode" title="Permalink to this headline">¶</a></h3>
<p>LinearUpsampleMode specifies the behavior for linear upsampling. Only valid when
Interpolation Mode is BILINEAR.</p>
<p>If input grid is [0, Xin-1] (corresponding to an input size of Xin), and if the
output size is Xout, then the grid points are sampled in the following manner:</p>
<dl>
<dt>DEFAULT</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>spacing = (Xin-Xin/Xout) / (Xout-1)
grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
</pre></div>
</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">ALIGN_CORNERS_TRUE</span></code></dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>spacing = (Xin-1) / (Xout-1)
grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
</pre></div>
</div>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">ALIGN_CORNERS_FALSE</span></code></dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>spacing = Xin / Xout
grid_point[i] = min(Xin-1, max(0, i * spacing + 0.5 * spacing - 0.5)), for i = 0,1,2,….,Xout-1
</pre></div>
</div>
</dd>
</dl>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="kd">enum</span> <span class="n">LinearUpsampleMode</span> <span class="p">{</span>

    <span class="na">DEFAULT</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="na">ALIGN_CORNERS_TRUE</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="na">ALIGN_CORNERS_FALSE</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Classifiers.html" class="btn btn-neutral float-right" title="Other Classifiers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="MIL.html" class="btn btn-neutral float-left" title="MILspec.Program" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Apple Inc.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>