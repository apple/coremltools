<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Converting a TensorFlow 1 Image Classifier &mdash; Core ML Tools Guide  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/imgstyle.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Converting a TensorFlow 1 DeepSpeech Model" href="convert-a-tensorflow-1-deepspeech-model.html" />
    <link rel="prev" title="TensorFlow 1 Workflow" href="tensorflow-1-workflow.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Core ML Tools Guide
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../overview/overview-coremltools.html">What Is Core ML Tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview/new-features.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview/faqs.html">Core ML Tools FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview/coremltools-examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview/migration.html">Migration Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview/contributing.html">Contributing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Essentials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../essentials/installing-coremltools.html">Installing Core ML Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../essentials/introductory-quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../essentials/unified-conversion-api.html">Core ML Tools API Overview</a></li>
<li class="toctree-l1"><a class="reference external" href="https://apple.github.io/coremltools/mlmodel/index.html">Core ML Model Format</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apple/coremltools">API GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Unified Conversion</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../convert-learning-models/convert-learning-models.html">Converting Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml-programs/ml-programs.html">ML Programs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="convert-tensorflow.html">Converting from TensorFlow</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tensorflow-1-workflow.html">TensorFlow 1 Workflow</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Converting a TensorFlow 1 Image Classifier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-the-model">Download the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-the-graph-definition">Load the Graph Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convert-to-core-ml">Convert to Core ML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-a-test-image">Load a Test Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#input-the-image-and-make-a-prediction">Input the Image and Make a Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preprocess-the-image-before-converting">Preprocess the Image Before Converting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="convert-a-tensorflow-1-deepspeech-model.html">Converting a TensorFlow 1 DeepSpeech Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow-2.html">TensorFlow 2 Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert-tensorflow-2-bert-transformer-models.html">Converting TensorFlow 2 BERT Transformer Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../convert-pytorch/convert-pytorch.html">Converting from PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../conversion-options/conversion-options.html">Conversion Options</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model-intermediate-language.html">Model Intermediate Language</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/optimizing-models/optimizing-models.html">Optimizing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/api-overview/api-overview.html">Optimize API Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/pruning/pruning.html">Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/palettization/palettization.html">Palettization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/quantization-aware-training/quantization-aware-training.html">Linear 8-Bit Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/quantization-neural-network.html">Compressing Neural Network Weights</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Converters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../other-converters/libsvm-conversion.html">LibSVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other-converters/sci-kit-learn-conversion.html">Scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other-converters/xgboost-conversion.html">XGBoost</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MLModel</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../mlmodel/mlmodel.html">MLModel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mlmodel/xcode-model-preview-types.html">Xcode Model Preview Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mlmodel/mlmodel-utilities.html">MLModel Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mlmodel/model-prediction.html">Model Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mlmodel/updatable-model-examples/updatable-model-examples.html">Updatable Models</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Core ML Tools Guide</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="convert-tensorflow.html">Converting from TensorFlow</a> &raquo;</li>
      <li>Converting a TensorFlow 1 Image Classifier</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/unified/convert-tensorflow/convert-a-tensorflow-1-image-classifier.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="converting-a-tensorflow-1-image-classifier">
<h1>Converting a TensorFlow 1 Image Classifier<a class="headerlink" href="#converting-a-tensorflow-1-image-classifier" title="Permalink to this heading"></a></h1>
<p>The following example converts the TensorFlow Inception V1 image classifier to a Core ML neural network classifier model that directly predicts the class label of the input image. It demonstrates the importance of setting the image preprocessing parameters correctly to get the right results.</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading"></a></h2>
<p>To use TensorFlow 1 (version 1.15) for this example, you may need to change your version of Python to one that works with TensorFlow 1. For details, see the following:</p>
<ul class="simple">
<li><p>For virtual environments, see <a class="reference external" href="https://www.freecodecamp.org/news/manage-multiple-python-versions-and-virtual-environments-venv-pyenv-pyvenv-a29fb00c296f/">How to manage multiple Python versions</a>.</p></li>
<li><p>For Miniconda and Anaconda environments, see <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-python.html">Managing Python</a>.</p></li>
</ul>
<p>You may also need to install <a class="reference external" href="https://pillow.readthedocs.io/en/stable/">Pillow</a>, <a class="reference external" href="https://pypi.org/project/requests/">Requests</a>, and <a class="reference external" href="https://pypi.org/project/matplotlib/">matplotlib</a>. The following commands work for a Miniconda environment:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.7.9
conda<span class="w"> </span>install<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">1</span>.15
pip<span class="w"> </span>install<span class="w"> </span>pillow
conda<span class="w"> </span>install<span class="w"> </span>requests<span class="w"> </span>
conda<span class="w"> </span>install<span class="w"> </span>matplotlib
</pre></div>
</div>
</section>
<section id="download-the-model">
<h2>Download the Model<a class="headerlink" href="#download-the-model" title="Permalink to this heading"></a></h2>
<p>The following code downloads the Inception V1 frozen TF graph (the <code class="docutils literal notranslate"><span class="pre">.pb</span></code> file):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download the model and class label package</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span>  <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="k">def</span> <span class="nf">download_file_and_unzip</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">dir_path</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Download the frozen TensorFlow model and unzip it.</span>
<span class="sd">    url - The URL address of the frozen file</span>
<span class="sd">    dir_path - local directory</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dir_path</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">url</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">fpath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">fpath</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">urllib</span>
            <span class="n">urllib</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">fpath</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">urllib.request</span>
            <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">fpath</span><span class="p">)</span>

    <span class="n">tar</span> <span class="o">=</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fpath</span><span class="p">)</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">dir_path</span><span class="p">)</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">inception_v1_url</span> <span class="o">=</span> <span class="s1">&#39;https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz&#39;</span>
<span class="n">download_file_and_unzip</span><span class="p">(</span><span class="n">inception_v1_url</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="load-the-graph-definition">
<h2>Load the Graph Definition<a class="headerlink" href="#load-the-graph-definition" title="Permalink to this heading"></a></h2>
<p>The following code loads the TensorFlow graph to find the input and output tensor names. You use them in the conversion process and for running the graph for a numerical accuracy check:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the TF graph definition</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span> <span class="c1"># 1.x</span>


<span class="n">tf_model_path</span> <span class="o">=</span> <span class="s1">&#39;./inception_v1_2016_08_28_frozen.pb&#39;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">serialized</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">original_gdef</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GraphDef</span><span class="p">()</span>
<span class="n">original_gdef</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">serialized</span><span class="p">)</span>

<span class="c1"># Lets get some details about a few ops in the beginning and the end of the graph</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">original_gdef</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ops</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_operations</span><span class="p">()</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ops</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">N</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">op id </span><span class="si">{}</span><span class="s1"> : op type: &quot;</span><span class="si">{}</span><span class="s1">&quot;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">ops</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">));</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input(s):&#39;</span><span class="p">),</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name = </span><span class="si">{}</span><span class="s2">, shape: </span><span class="si">{}</span><span class="s2">, &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())),</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">output(s):&#39;</span><span class="p">),</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ops</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name = </span><span class="si">{}</span><span class="s2">, shape: </span><span class="si">{}</span><span class="s2">,&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())),</span>
</pre></div>
</div>
<p>As shown in the following results, the output of the <code class="docutils literal notranslate"><span class="pre">Placeholder</span></code> op is the input (<code class="docutils literal notranslate"><span class="pre">input:0</span></code>), and the output of the <code class="docutils literal notranslate"><span class="pre">Softmax</span></code> op (near the end of the graph) is the output (<code class="docutils literal notranslate"><span class="pre">InceptionV1/Logits/Predictions/Softmax:0</span></code>).</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>op id 0 : op type: &quot;Placeholder&quot;
input(s):

output(s):
name = input:0, shape: (1, 224, 224, 3),


op id 1 : op type: &quot;Const&quot;
input(s):

output(s):
name = InceptionV1/Conv2d_1a_7x7/weights:0, shape: (7, 7, 3, 64),


op id 2 : op type: &quot;Identity&quot;
input(s):
name = InceptionV1/Conv2d_1a_7x7/weights:0, shape: (7, 7, 3, 64), 

output(s):
name = InceptionV1/Conv2d_1a_7x7/weights/read:0, shape: (7, 7, 3, 64),


op id 1012 : op type: &quot;Softmax&quot;
input(s):
name = InceptionV1/Logits/Predictions/Reshape:0, shape: (1, 1001), 

output(s):
name = InceptionV1/Logits/Predictions/Softmax:0, shape: (1, 1001),


op id 1013 : op type: &quot;Const&quot;
input(s):

output(s):
name = InceptionV1/Logits/Predictions/Shape:0, shape: (2,),


op id 1014 : op type: &quot;Reshape&quot;
input(s):
name = InceptionV1/Logits/Predictions/Softmax:0, shape: (1, 1001), 
name = InceptionV1/Logits/Predictions/Shape:0, shape: (2,), 

output(s):
name = InceptionV1/Logits/Predictions/Reshape_1:0, shape: (1, 1001),
</pre></div>
</div>
</section>
<section id="convert-to-core-ml">
<h2>Convert to Core ML<a class="headerlink" href="#convert-to-core-ml" title="Permalink to this heading"></a></h2>
<p>The following code sets the <code class="docutils literal notranslate"><span class="pre">image_inputs</span></code> for <code class="docutils literal notranslate"><span class="pre">inputs</span></code> and the output name (<code class="docutils literal notranslate"><span class="pre">'InceptionV1/Logits/Predictions/Softmax'</span></code>) for <code class="docutils literal notranslate"><span class="pre">outputs</span></code> in order to use them with the <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.convert.html#module-coremltools.converters._converters_entry"><code class="docutils literal notranslate"><span class="pre">convert()</span></code></a> method. The <code class="docutils literal notranslate"><span class="pre">convert()</span></code> method produces a neural network by default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">coremltools</span> <span class="k">as</span> <span class="nn">ct</span>

<span class="n">image_inputs</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">ImageType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">classifier_config</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">ClassifierConfig</span><span class="p">(</span><span class="s1">&#39;imagenet_slim_labels.txt&#39;</span><span class="p">)</span>
<span class="n">coreml_model_file</span> <span class="o">=</span> <span class="s1">&#39;./inception_v1.mlmodel&#39;</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;InceptionV1/Logits/Predictions/Softmax&#39;</span><span class="p">]</span>


<span class="n">coreml_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">,</span> 
                          <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">image_inputs</span><span class="p">],</span> 
                          <span class="n">classifier_config</span><span class="o">=</span><span class="n">classifier_config</span><span class="p">,</span>
                          <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>

<span class="n">coreml_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">coreml_model_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The result shows the progress of the conversion:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Running TensorFlow Graph Passes: 100%|██████████| 7/7 [00:02&lt;00:00,  3.24 passes/s]
Converting Frontend ==&gt; MIL Ops: 100%|██████████| 441/441 [00:00&lt;00:00, 926.87 ops/s] 
Running MIL optimization passes: 100%|██████████| 17/17 [00:00&lt;00:00, 20.06 passes/s]
Translating MIL ==&gt; MLModel Ops: 100%|██████████| 839/839 [00:00&lt;00:00, 1085.04 ops/s]
</pre></div>
</div>
</section>
<section id="load-a-test-image">
<h2>Load a Test Image<a class="headerlink" href="#load-a-test-image" title="Permalink to this heading"></a></h2>
<p>To make predictions on the same image using both the original model and the converted model, the following sample code snippet loads a test image. It uses <a class="reference external" href="https://numpy.org">NumPy</a>, <a class="reference external" href="https://pillow.readthedocs.io/en/stable/">Pillow</a>, <a class="reference external" href="https://pypi.org/project/requests/">Requests</a>, and <a class="reference external" href="https://pypi.org/project/matplotlib/">matplotlib</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load an image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">PIL</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">imshow</span>
<span class="c1"># This is an image of a golden retriever from Wikipedia</span>
<span class="n">img_url</span> <span class="o">=</span> <span class="s1">&#39;https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_</span><span class="si">%2810581910556%</span><span class="s1">29.jpg&#39;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">img_url</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
</pre></div>
</div>
<p>The code shows the following image:</p>
<img alt="Core ML Tools overview" class="imgnoborder align-center" src="../../_images/Golden_Retriever_Carlos.png" />
<p><em>This image of a golden retriever is from Wikipedia.</em></p>
</section>
<section id="input-the-image-and-make-a-prediction">
<h2>Input the Image and Make a Prediction<a class="headerlink" href="#input-the-image-and-make-a-prediction" title="Permalink to this heading"></a></h2>
<p>The following code passes the PIL image into the Core ML model after resizing it, and uses a NumPy array of the image to make a prediction:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># To get CoreML predictions directly pass in the PIL image after resizing</span>
<span class="kn">import</span> <span class="nn">coremltools</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">([</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">],</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
<span class="n">coreml_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">img</span><span class="p">}</span>
<span class="n">coreml_output</span> <span class="o">=</span> <span class="n">coreml_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">coreml_inputs</span><span class="p">)</span>
<span class="n">coreml_pred_dict</span> <span class="o">=</span> <span class="n">coreml_output</span><span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">coreml_predicted_class_label</span> <span class="o">=</span> <span class="n">coreml_output</span><span class="p">[</span><span class="s1">&#39;classLabel&#39;</span><span class="p">]</span>

<span class="c1">#for getting TF prediction we get the numpy array of the image</span>
<span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s1">&#39;image shape:&#39;</span><span class="p">,</span> <span class="n">img_np</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s1">&#39;first few values: &#39;</span><span class="p">,</span> <span class="n">img_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;max value: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">img_np</span><span class="p">))</span>
<span class="n">img_tf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1">#now shape is [1,224,224,3] as required by TF</span>

<span class="c1"># Evaluate TF and get the highest label </span>
<span class="n">tf_input_name</span> <span class="o">=</span> <span class="s1">&#39;input:0&#39;</span>
<span class="n">tf_output_name</span> <span class="o">=</span> <span class="s1">&#39;InceptionV1/Logits/Predictions/Softmax:0&#39;</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span> <span class="o">=</span> <span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">tf_out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf_output_name</span><span class="p">,</span> 
                      <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">tf_input_name</span><span class="p">:</span> <span class="n">img_tf</span><span class="p">})</span>
<span class="n">tf_out</span> <span class="o">=</span> <span class="n">tf_out</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>    
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tf_out</span><span class="p">)</span>
<span class="n">label_file</span> <span class="o">=</span> <span class="s1">&#39;imagenet_slim_labels.txt&#39;</span> 
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">label_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    
<span class="c1">#print predictions   </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CoreML prediction class = </span><span class="si">{}</span><span class="s2">, probability = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">coreml_predicted_class_label</span><span class="p">,</span>
                                            <span class="nb">str</span><span class="p">(</span><span class="n">coreml_pred_dict</span><span class="p">[</span><span class="n">coreml_predicted_class_label</span><span class="p">])))</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TF prediction class = </span><span class="si">{}</span><span class="s2">, probability = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                            <span class="nb">str</span><span class="p">(</span><span class="n">tf_out</span><span class="p">[</span><span class="n">idx</span><span class="p">])))</span>
</pre></div>
</div>
<p>The result shows that both predictions match, which ensures that the conversion is correct. However, the class labels are incorrect:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>image shape: (224, 224, 3)
first few values:  [39. 33. 18. 42.] max value:  255.0


CoreML prediction class = thatch, probability = 0.5372982025146484
TF prediction class = thatch
, probability = 0.5372873
</pre></div>
</div>
<p>The class labels are incorrect because the image was not preprocessed correctly before it was passed to the neural network.</p>
</section>
<section id="preprocess-the-image-before-converting">
<h2>Preprocess the Image Before Converting<a class="headerlink" href="#preprocess-the-image-before-converting" title="Permalink to this heading"></a></h2>
<p>Preprocessing is always a crucial step when using neural networks on images. The best approach is to find the source of the pre-trained model and check for the preprocessing that the model’s author used during training and evaluation.</p>
<p>In this case, the TensorFlow model comes from the
<a class="reference external" href="https://github.com/tensorflow/models/tree/edb6ed22a801665946c63d650ab9a0b23d98e1b1/research/slim">SLIM library</a>,
and the preprocessing steps are defined in the <code class="docutils literal notranslate"><span class="pre">preprocess_for_eval</span></code> definition in <a class="reference external" href="https://github.com/tensorflow/models/blob/edb6ed22a801665946c63d650ab9a0b23d98e1b1/research/slim/preprocessing/inception_preprocessing.py#L243">inception_preprocessing.py</a>. The image pixels have to be scaled to lie within the interval <code class="docutils literal notranslate"><span class="pre">[-1,1]</span></code>.
(“models/research/slim/preprocessing/inception_preprocessing.py”).
The following code preprocesses the image and makes a new prediction:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img_tf</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="mf">255.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">img_tf</span> <span class="o">-</span> <span class="mi">1</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span> <span class="o">=</span> <span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">tf_out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf_output_name</span><span class="p">,</span> 
                      <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">tf_input_name</span><span class="p">:</span> <span class="n">img_tf</span><span class="p">})</span>
<span class="n">tf_out</span> <span class="o">=</span> <span class="n">tf_out</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>    
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tf_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TF prediction class = </span><span class="si">{}</span><span class="s2">, probability = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                            <span class="nb">str</span><span class="p">(</span><span class="n">tf_out</span><span class="p">[</span><span class="n">idx</span><span class="p">])))</span>
</pre></div>
</div>
<p>The TensorFlow model now predicts a dog as the highest class:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TF prediction class = English setter
, probability = 0.301507
</pre></div>
</div>
<p>Core ML automatically handles the image preprocessing when the input is of type image. However, the image biases and scale are not correct. The channel scale should be multiplied first before adding the bias. The following code converts the model again with this correction, and saves the newly converted model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">image_inputs</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">ImageType</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">classifier_config</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">ClassifierConfig</span><span class="p">(</span><span class="s1">&#39;imagenet_slim_labels.txt&#39;</span><span class="p">)</span>
<span class="n">coreml_model_file</span> <span class="o">=</span> <span class="s1">&#39;./inception_v1.mlmodel&#39;</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;InceptionV1/Logits/Predictions/Softmax&#39;</span><span class="p">]</span>


<span class="n">coreml_model</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">,</span> 
                          <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">image_inputs</span><span class="p">],</span> 
                          <span class="n">classifier_config</span><span class="o">=</span><span class="n">classifier_config</span><span class="p">,</span>
                          <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>

<span class="n">coreml_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">coreml_model_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The result shows the progress of the conversion:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Running TensorFlow Graph Passes: 100%|██████████| 7/7 [00:02&lt;00:00,  3.10 passes/s]
Converting Frontend ==&gt; MIL Ops: 100%|██████████| 441/441 [00:00&lt;00:00, 998.08 ops/s] 
Running MIL optimization passes: 100%|██████████| 17/17 [00:00&lt;00:00, 20.62 passes/s]
Translating MIL ==&gt; MLModel Ops: 100%|██████████| 839/839 [00:00&lt;00:00, 1125.96 ops/s]
</pre></div>
</div>
<p>The following code makes the prediction again with the newly converted Core ML model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Call CoreML predict again</span>
<span class="n">coreml_output</span> <span class="o">=</span> <span class="n">coreml_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">coreml_inputs</span><span class="p">)</span>
<span class="n">coreml_pred_dict</span> <span class="o">=</span> <span class="n">coreml_output</span><span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">coreml_predicted_class_label</span> <span class="o">=</span> <span class="n">coreml_output</span><span class="p">[</span><span class="s1">&#39;classLabel&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CoreML prediction class = </span><span class="si">{}</span><span class="s2">, probability = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">coreml_predicted_class_label</span><span class="p">,</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">coreml_pred_dict</span><span class="p">[</span><span class="n">coreml_predicted_class_label</span><span class="p">])))</span>

</pre></div>
</div>
<p>The output now correctly matches the TensorFlow output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CoreML prediction class = English setter, probability = 0.3015042543411255
</pre></div>
</div>
<div class="admonition-predictions-can-vary-slightly admonition">
<p class="admonition-title">Predictions Can Vary Slightly</p>
<p>Predictions with the default Core ML <code class="docutils literal notranslate"><span class="pre">predict</span></code> call may vary slightly, since by default it uses a lower-precision optimized path for faster execution. In previous versions of Core ML Tools, you would restrict execution to the CPU by specifying the <code class="docutils literal notranslate"><span class="pre">useCPUOnly=True</span></code> flag. This flag is now deprecated. Instead, use the <code class="docutils literal notranslate"><span class="pre">compute_units</span></code> parameter at load time or conversion time (that is, in <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.models.html#module-coremltools.models.model"><code class="docutils literal notranslate"><span class="pre">coremltools.models.MLModel</span></code></a> or <a class="reference external" href="https://apple.github.io/coremltools/source/coremltools.converters.mil.html#module-coremltools.converters.converters_entry"><code class="docutils literal notranslate"><span class="pre">coremltools.convert()</span></code></a>. For more information, see <span class="xref myst">Set the compute units</span>.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tensorflow-1-workflow.html" class="btn btn-neutral float-left" title="TensorFlow 1 Workflow" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="convert-a-tensorflow-1-deepspeech-model.html" class="btn btn-neutral float-right" title="Converting a TensorFlow 1 DeepSpeech Model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Apple Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>